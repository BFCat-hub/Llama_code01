#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void kmeans_set_zero(int *means) {     means[blockIdx.x * blockDim.x + threadIdx.x] = 0; }  int main() {         const int data_size = 100;          int *means_host = (int *)malloc(data_size * sizeof(int));     for (int i = 0; i < data_size; ++i) {         means_host[i] = i;     }          int *means_device;     cudaMalloc((void**)&means_device, data_size * sizeof(int));     cudaMemcpy(means_device, means_host, data_size * sizeof(int), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          kmeans_set_zero<<<gridDim, blockDim>>>(means_device);          cudaMemcpy(means_host, means_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%d ", means_host[i]);     }     printf("\n");          free(means_host);     cudaFree(means_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void Mul_half(float *src, float *dst) {     int index = threadIdx.x;     if (index < 3) {         dst[index] = src[index] * 0.5;     } }  int main() {         const int data_size = 3;          float *src_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         src_host[i] = i + 1.0;     }          float *src_device, *dst_device;     cudaMalloc((void**)&src_device, data_size * sizeof(float));     cudaMalloc((void**)&dst_device, data_size * sizeof(float));     cudaMemcpy(src_device, src_host, data_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim(1);             Mul_half<<<gridDim, blockDim>>>(src_device, dst_device);          float *dst_host = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(dst_host, dst_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.2f ", dst_host[i]);     }     printf("\n");          free(src_host);     free(dst_host);     cudaFree(src_device);     cudaFree(dst_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void resetIndices(long *vec_out, const long N) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;     if (idx < N) {         vec_out[idx] = idx;     } }  int main() {         const long data_size = 100;          long *vec_out_device;     cudaMalloc((void**)&vec_out_device, data_size * sizeof(long));          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          resetIndices<<<gridDim, blockDim>>>(vec_out_device, data_size);          long *vec_out_host = (long *)malloc(data_size * sizeof(long));     cudaMemcpy(vec_out_host, vec_out_device, data_size * sizeof(long), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (long i = 0; i < data_size; ++i) {         printf("%ld ", vec_out_host[i]);     }     printf("\n");          free(vec_out_host);     cudaFree(vec_out_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void set_offset_kernel(int stride, int size, int *output) {     for (int i = threadIdx.x; i < size; i += blockDim.x) {         output[i] = i * stride;     } }  int main() {         const int data_size = 100;     const int stride = 2;          int *output_device;     cudaMalloc((void**)&output_device, data_size * sizeof(int));          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          set_offset_kernel<<<gridDim, blockDim>>>(stride, data_size, output_device);          int *output_host = (int *)malloc(data_size * sizeof(int));     cudaMemcpy(output_host, output_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%d ", output_host[i]);     }     printf("\n");          free(output_host);     cudaFree(output_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void setSuppressed(int *suppressed, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }     suppressed[tid] = 0; }  int main() {         const int data_size = 100;          int *suppressed_device;     cudaMalloc((void**)&suppressed_device, data_size * sizeof(int));          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          setSuppressed<<<gridDim, blockDim>>>(suppressed_device, data_size);          int *suppressed_host = (int *)malloc(data_size * sizeof(int));     cudaMemcpy(suppressed_host, suppressed_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%d ", suppressed_host[i]);     }     printf("\n");          free(suppressed_host);     cudaFree(suppressed_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void allDivInplaceKernel(double *arr, double alpha, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         arr[i] /= alpha;     } }  int main() {         const int data_size = 100;     const double alpha = 2.0;          double *arr_device;     cudaMalloc((void**)&arr_device, data_size * sizeof(double));          double *arr_host = (double *)malloc(data_size * sizeof(double));     for (int i = 0; i < data_size; ++i) {         arr_host[i] = i + 1.0;     }          cudaMemcpy(arr_device, arr_host, data_size * sizeof(double), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          allDivInplaceKernel<<<gridDim, blockDim>>>(arr_device, alpha, data_size);          cudaMemcpy(arr_host, arr_device, data_size * sizeof(double), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.2f ", arr_host[i]);     }     printf("\n");          free(arr_host);     cudaFree(arr_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void incrementArrayOnDevice(float *a, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         a[idx] = a[idx] + 1.0f;     } }  int main() {         const int data_size = 100;          float *a_device;     cudaMalloc((void**)&a_device, data_size * sizeof(float));          float *a_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         a_host[i] = i + 1.0;     }          cudaMemcpy(a_device, a_host, data_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          incrementArrayOnDevice<<<gridDim, blockDim>>>(a_device, data_size);          cudaMemcpy(a_host, a_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.2f ", a_host[i]);     }     printf("\n");          free(a_host);     cudaFree(a_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void allMulInplaceKernel(double *arr, double alpha, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         arr[i] *= alpha;     } }  int main() {         const int data_size = 100;     const double alpha = 2.0;          double *arr_device;     cudaMalloc((void**)&arr_device, data_size * sizeof(double));          double *arr_host = (double *)malloc(data_size * sizeof(double));     for (int i = 0; i < data_size; ++i) {         arr_host[i] = i + 1.0;     }          cudaMemcpy(arr_device, arr_host, data_size * sizeof(double), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          allMulInplaceKernel<<<gridDim, blockDim>>>(arr_device, alpha, data_size);          cudaMemcpy(arr_host, arr_device, data_size * sizeof(double), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.2f ", arr_host[i]);     }     printf("\n");          free(arr_host);     cudaFree(arr_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void Init(const long long size, const double *in, double *out) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < size) {         out[i] = in[i];     } }  int main() {         const long long data_size = 100;          double *in_device, *out_device;     cudaMalloc((void**)&in_device, data_size * sizeof(double));     cudaMalloc((void**)&out_device, data_size * sizeof(double));          double *in_host = (double *)malloc(data_size * sizeof(double));     for (long long i = 0; i < data_size; ++i) {         in_host[i] = i + 1.0;     }          cudaMemcpy(in_device, in_host, data_size * sizeof(double), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          Init<<<gridDim, blockDim>>>(data_size, in_device, out_device);          double *out_host = (double *)malloc(data_size * sizeof(double));     cudaMemcpy(out_host, out_device, data_size * sizeof(double), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (long long i = 0; i < data_size; ++i) {         printf("%.2f ", out_host[i]);     }     printf("\n");          free(in_host);     free(out_host);     cudaFree(in_device);     cudaFree(out_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void subAvg(int *input, int count, int avg) {     int index = blockDim.x * blockIdx.x + threadIdx.x;     if (index < count) {         input[index] = input[index] - avg;     } }  int main() {         const int data_size = 100;          int *input_device;     cudaMalloc((void**)&input_device, data_size * sizeof(int));          int *input_host = (int *)malloc(data_size * sizeof(int));     for (int i = 0; i < data_size; ++i) {         input_host[i] = i + 1;     }          cudaMemcpy(input_device, input_host, data_size * sizeof(int), cudaMemcpyHostToDevice);          int sum = 0;     for (int i = 0; i < data_size; ++i) {         sum += input_host[i];     }     int avg = sum / data_size;          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          subAvg<<<gridDim, blockDim>>>(input_device, data_size, avg);          cudaMemcpy(input_host, input_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%d ", input_host[i]);     }     printf("\n");          free(input_host);     cudaFree(input_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h> #include <math.h>  __global__ void allExp2InplaceKernel(double *arr, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         arr[i] = exp2(arr[i]) * 9.0;     } }  int main() {         const int data_size = 100;          double *arr_device;     cudaMalloc((void**)&arr_device, data_size * sizeof(double));          double *arr_host = (double *)malloc(data_size * sizeof(double));     for (int i = 0; i < data_size; ++i) {         arr_host[i] = i + 1.0;     }          cudaMemcpy(arr_device, arr_host, data_size * sizeof(double), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          allExp2InplaceKernel<<<gridDim, blockDim>>>(arr_device, data_size);          cudaMemcpy(arr_host, arr_device, data_size * sizeof(double), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.2f ", arr_host[i]);     }     printf("\n");          free(arr_host);     cudaFree(arr_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void vector_add(float *a, float *b, float *c) {     int index = threadIdx.x + blockDim.x * blockIdx.x;     c[index] = a[index] + b[index]; }  int main() {         const int data_size = 100;          float *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, data_size * sizeof(float));     cudaMalloc((void**)&b_device, data_size * sizeof(float));     cudaMalloc((void**)&c_device, data_size * sizeof(float));          float *a_host = (float *)malloc(data_size * sizeof(float));     float *b_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         a_host[i] = i + 1.0;         b_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(a_device, a_host, data_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, data_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          vector_add<<<gridDim, blockDim>>>(a_device, b_device, c_device);          float *c_host = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(c_host, c_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.2f ", c_host[i]);     }     printf("\n");          free(a_host);     free(b_host);     free(c_host);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void setLabels(int *output, int dims, int clsNum) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }     output[tid] = tid % clsNum; }  int main() {         const int data_size = 100;     const int clsNum = 5;          int *output_device;     cudaMalloc((void**)&output_device, data_size * sizeof(int));          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          setLabels<<<gridDim, blockDim>>>(output_device, data_size, clsNum);          int *output_host = (int *)malloc(data_size * sizeof(int));     cudaMemcpy(output_host, output_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%d ", output_host[i]);     }     printf("\n");          free(output_host);     cudaFree(output_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void histogram(int n, int *color, int *bucket) {     int i = threadIdx.x + blockDim.x * blockIdx.x;     if (i < n) {         int c = color[i];         atomicAdd(&bucket[c], 1);     } }  int main() {         const int data_size = 100;     const int num_bins = 256;          int *color_device, *bucket_device;     cudaMalloc((void**)&color_device, data_size * sizeof(int));     cudaMalloc((void**)&bucket_device, num_bins * sizeof(int));          int *color_host = (int *)malloc(data_size * sizeof(int));     for (int i = 0; i < data_size; ++i) {         color_host[i] = i % num_bins;     }          cudaMemcpy(color_device, color_host, data_size * sizeof(int), cudaMemcpyHostToDevice);          int *bucket_host = (int *)malloc(num_bins * sizeof(int));     memset(bucket_host, 0, num_bins * sizeof(int));          cudaMemcpy(bucket_device, bucket_host, num_bins * sizeof(int), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          histogram<<<gridDim, blockDim>>>(data_size, color_device, bucket_device);          cudaMemcpy(bucket_host, bucket_device, num_bins * sizeof(int), cudaMemcpyDeviceToHost);          printf("Histogram Result after CUDA kernel execution:\n");     for (int i = 0; i < num_bins; ++i) {         printf("Bucket %d: %d\n", i, bucket_host[i]);     }          free(color_host);     free(bucket_host);     cudaFree(color_device);     cudaFree(bucket_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h> #include <math.h>  __global__ void sigmoid_kernel(float *input, float *output) {     int tid = threadIdx.x + blockIdx.x * blockDim.x;     output[tid] = 1.0 / (1.0 + expf(-input[tid])); }  int main() {         const int data_size = 100;          float *input_device, *output_device;     cudaMalloc((void**)&input_device, data_size * sizeof(float));     cudaMalloc((void**)&output_device, data_size * sizeof(float));          float *input_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         input_host[i] = i + 1.0;     }          cudaMemcpy(input_device, input_host, data_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          sigmoid_kernel<<<gridDim, blockDim>>>(input_device, output_device);          float *output_host = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(output_host, output_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.6f ", output_host[i]);     }     printf("\n");          free(input_host);     free(output_host);     cudaFree(input_device);     cudaFree(output_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void kernelUpdateHead(int *head, int *d_idxs_out, int n) {     int i = threadIdx.x + blockDim.x * blockIdx.x;     if (i < n) {         head[d_idxs_out[i]] = 1;     } }  int main() {         const int data_size = 100;          int *head_device, *d_idxs_out_device;     cudaMalloc((void**)&head_device, data_size * sizeof(int));     cudaMalloc((void**)&d_idxs_out_device, data_size * sizeof(int));          int *d_idxs_out_host = (int *)malloc(data_size * sizeof(int));     for (int i = 0; i < data_size; ++i) {         d_idxs_out_host[i] = i % data_size;     }          cudaMemcpy(d_idxs_out_device, d_idxs_out_host, data_size * sizeof(int), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          kernelUpdateHead<<<gridDim, blockDim>>>(head_device, d_idxs_out_device, data_size);          int *head_host = (int *)malloc(data_size * sizeof(int));     cudaMemcpy(head_host, head_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%d ", head_host[i]);     }     printf("\n");          free(d_idxs_out_host);     free(head_host);     cudaFree(d_idxs_out_device);     cudaFree(head_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void const_kernel(int N, float ALPHA, float *X, int INCX) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N) {         X[i * INCX] = ALPHA;     } }  int main() {         const int data_size = 100;     const float ALPHA = 2.0;          float *X_device;     cudaMalloc((void**)&X_device, data_size * sizeof(float));          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          const_kernel<<<gridDim, blockDim>>>(data_size, ALPHA, X_device, 1);          float *X_host = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(X_host, X_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.2f ", X_host[i]);     }     printf("\n");          free(X_host);     cudaFree(X_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void allLog2Kernel(const double *arr, double *buf, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         buf[i] = arr[i] / 2.0;     } }  int main() {         const int data_size = 100;          double *arr_device, *buf_device;     cudaMalloc((void**)&arr_device, data_size * sizeof(double));     cudaMalloc((void**)&buf_device, data_size * sizeof(double));          double *arr_host = (double *)malloc(data_size * sizeof(double));     for (int i = 0; i < data_size; ++i) {         arr_host[i] = i + 1.0;     }          cudaMemcpy(arr_device, arr_host, data_size * sizeof(double), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          allLog2Kernel<<<gridDim, blockDim>>>(arr_device, buf_device, data_size);          double *buf_host = (double *)malloc(data_size * sizeof(double));     cudaMemcpy(buf_host, buf_device, data_size * sizeof(double), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.2f ", buf_host[i]);     }     printf("\n");          free(arr_host);     free(buf_host);     cudaFree(arr_device);     cudaFree(buf_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void clearArray(unsigned char *arr, const unsigned int length) {     unsigned int offset = blockDim.x * blockIdx.x + threadIdx.x;     unsigned int skip = gridDim.x * blockDim.x;          while (offset < length) {         arr[offset] = 0;         offset += skip;     } }  int main() {         const unsigned int data_size = 100;          unsigned char *arr_device;     cudaMalloc((void**)&arr_device, data_size * sizeof(unsigned char));          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          clearArray<<<gridDim, blockDim>>>(arr_device, data_size);          unsigned char *arr_host = (unsigned char *)malloc(data_size * sizeof(unsigned char));     cudaMemcpy(arr_host, arr_device, data_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (unsigned int i = 0; i < data_size; ++i) {         printf("%d ", arr_host[i]);     }     printf("\n");          free(arr_host);     cudaFree(arr_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void Copy_List(const int element_numbers, const float *origin_list, float *list) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < element_numbers) {         list[i] = origin_list[i];     } }  int main() {         const int data_size = 100;          float *origin_list_device, *list_device;     cudaMalloc((void**)&origin_list_device, data_size * sizeof(float));     cudaMalloc((void**)&list_device, data_size * sizeof(float));          float *origin_list_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         origin_list_host[i] = i + 1.0;     }          cudaMemcpy(origin_list_device, origin_list_host, data_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          Copy_List<<<gridDim, blockDim>>>(data_size, origin_list_device, list_device);          float *list_host = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(list_host, list_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.2f ", list_host[i]);     }     printf("\n");          free(origin_list_host);     free(list_host);     cudaFree(origin_list_device);     cudaFree(list_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void add(int n, float *x, float *y) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     for (int i = index; i < n; i++) {         y[i] = x[i] + y[i];     } }  int main() {         const int data_size = 100;          float *x_device, *y_device;     cudaMalloc((void**)&x_device, data_size * sizeof(float));     cudaMalloc((void**)&y_device, data_size * sizeof(float));          float *x_host = (float *)malloc(data_size * sizeof(float));     float *y_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         x_host[i] = i + 1.0;         y_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(x_device, x_host, data_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(y_device, y_host, data_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);          add<<<gridDim, blockDim>>>(data_size, x_device, y_device);          float *y_result = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(y_result, y_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.2f ", y_result[i]);     }     printf("\n");          free(x_host);     free(y_host);     free(y_result);     cudaFree(x_device);     cudaFree(y_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void gpu_add(float *c, float *a, float *b, int n) {     for (int k = threadIdx.x; k < n; k += blockDim.x) {         c[k] = a[k] + b[k];     } }  int main() {         const int data_size = 100;          float *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, data_size * sizeof(float));     cudaMalloc((void**)&b_device, data_size * sizeof(float));     cudaMalloc((void**)&c_device, data_size * sizeof(float));          float *a_host = (float *)malloc(data_size * sizeof(float));     float *b_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         a_host[i] = i + 1.0;         b_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(a_device, a_host, data_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, data_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim(1);          gpu_add<<<gridDim, blockDim>>>(c_device, a_device, b_device, data_size);          float *c_result = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(c_result, c_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < data_size; ++i) {         printf("%.2f ", c_result[i]);     }     printf("\n");          free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void subtract_matrix(float *a, float *b, float *c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] - b[idx];     } }  int main() {         const int matrix_size = 100;          float *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, matrix_size * sizeof(float));     cudaMalloc((void**)&b_device, matrix_size * sizeof(float));     cudaMalloc((void**)&c_device, matrix_size * sizeof(float));          float *a_host = (float *)malloc(matrix_size * sizeof(float));     float *b_host = (float *)malloc(matrix_size * sizeof(float));     for (int i = 0; i < matrix_size; ++i) {         a_host[i] = i + 1.0;         b_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(a_device, a_host, matrix_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, matrix_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((matrix_size + blockDim.x - 1) / blockDim.x);          subtract_matrix<<<gridDim, blockDim>>>(a_device, b_device, c_device, matrix_size);          float *c_result = (float *)malloc(matrix_size * sizeof(float));     cudaMemcpy(c_result, c_device, matrix_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < matrix_size; ++i) {         printf("%.2f ", c_result[i]);     }     printf("\n");          free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void add_matrix(float *a, float *b, float *c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] + b[idx];     } }  int main() {         const int matrix_size = 100;          float *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, matrix_size * sizeof(float));     cudaMalloc((void**)&b_device, matrix_size * sizeof(float));     cudaMalloc((void**)&c_device, matrix_size * sizeof(float));          float *a_host = (float *)malloc(matrix_size * sizeof(float));     float *b_host = (float *)malloc(matrix_size * sizeof(float));     for (int i = 0; i < matrix_size; ++i) {         a_host[i] = i + 1.0;         b_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(a_device, a_host, matrix_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, matrix_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((matrix_size + blockDim.x - 1) / blockDim.x);          add_matrix<<<gridDim, blockDim>>>(a_device, b_device, c_device, matrix_size);          float *c_result = (float *)malloc(matrix_size * sizeof(float));     cudaMemcpy(c_result, c_device, matrix_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < matrix_size; ++i) {         printf("%.2f ", c_result[i]);     }     printf("\n");          free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void vecAdd(float *in1, float *in2, float *out, int len) {     int i = threadIdx.x + blockDim.x * blockIdx.x;     if (i < len) {         out[i] = in1[i] + in2[i];     } }  int main() {         const int vector_size = 100;          float *in1_device, *in2_device, *out_device;     cudaMalloc((void**)&in1_device, vector_size * sizeof(float));     cudaMalloc((void**)&in2_device, vector_size * sizeof(float));     cudaMalloc((void**)&out_device, vector_size * sizeof(float));          float *in1_host = (float *)malloc(vector_size * sizeof(float));     float *in2_host = (float *)malloc(vector_size * sizeof(float));     for (int i = 0; i < vector_size; ++i) {         in1_host[i] = i + 1.0;         in2_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(in1_device, in1_host, vector_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(in2_device, in2_host, vector_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((vector_size + blockDim.x - 1) / blockDim.x);          vecAdd<<<gridDim, blockDim>>>(in1_device, in2_device, out_device, vector_size);          float *out_result = (float *)malloc(vector_size * sizeof(float));     cudaMemcpy(out_result, out_device, vector_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < vector_size; ++i) {         printf("%.2f ", out_result[i]);     }     printf("\n");          free(in1_host);     free(in2_host);     free(out_result);     cudaFree(in1_device);     cudaFree(in2_device);     cudaFree(out_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void doubleArrayScalarAddKernel(double *d_in, double *d_out, int length, double scalar) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = d_in[tid] + scalar;     } }  int main() {         const int array_size = 100;          double *d_in_device, *d_out_device;     cudaMalloc((void**)&d_in_device, array_size * sizeof(double));     cudaMalloc((void**)&d_out_device, array_size * sizeof(double));          double *d_in_host = (double *)malloc(array_size * sizeof(double));     for (int i = 0; i < array_size; ++i) {         d_in_host[i] = i + 1.0;     }          cudaMemcpy(d_in_device, d_in_host, array_size * sizeof(double), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          double scalar = 5.0;          doubleArrayScalarAddKernel<<<gridDim, blockDim>>>(d_in_device, d_out_device, array_size, scalar);          double *d_out_result = (double *)malloc(array_size * sizeof(double));     cudaMemcpy(d_out_result, d_out_device, array_size * sizeof(double), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", d_out_result[i]);     }     printf("\n");          free(d_in_host);     free(d_out_result);     cudaFree(d_in_device);     cudaFree(d_out_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void dadd_matrix(double *a, double *b, double *c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] + b[idx];     } }  int main() {         const int matrix_size = 100;          double *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, matrix_size * sizeof(double));     cudaMalloc((void**)&b_device, matrix_size * sizeof(double));     cudaMalloc((void**)&c_device, matrix_size * sizeof(double));          double *a_host = (double *)malloc(matrix_size * sizeof(double));     double *b_host = (double *)malloc(matrix_size * sizeof(double));     for (int i = 0; i < matrix_size; ++i) {         a_host[i] = i + 1.0;         b_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(a_device, a_host, matrix_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, matrix_size * sizeof(double), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((matrix_size + blockDim.x - 1) / blockDim.x);          dadd_matrix<<<gridDim, blockDim>>>(a_device, b_device, c_device, matrix_size);          double *c_result = (double *)malloc(matrix_size * sizeof(double));     cudaMemcpy(c_result, c_device, matrix_size * sizeof(double), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < matrix_size; ++i) {         printf("%.2f ", c_result[i]);     }     printf("\n");          free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void test1(float *input, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }     if (input[tid * 4] != 0) {         input[tid * 4] = 0;     } }  int main() {         const int array_size = 100;          float *input_device;     cudaMalloc((void**)&input_device, array_size * 4 * sizeof(float));          float *input_host = (float *)malloc(array_size * 4 * sizeof(float));     for (int i = 0; i < array_size * 4; ++i) {         input_host[i] = i + 1.0;     }          cudaMemcpy(input_device, input_host, array_size * 4 * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          test1<<<gridDim, blockDim>>>(input_device, array_size);          float *output_result = (float *)malloc(array_size * 4 * sizeof(float));     cudaMemcpy(output_result, input_device, array_size * 4 * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size * 4; ++i) {         printf("%.2f ", output_result[i]);     }     printf("\n");          free(input_host);     free(output_result);     cudaFree(input_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void vecAddGPU(double *pdbA, double *pdbB, double *pdbC) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     pdbC[i] = pdbA[i] + pdbB[i]; }  int main() {         const int vector_size = 100;          double *pdbA_device, *pdbB_device, *pdbC_device;     cudaMalloc((void**)&pdbA_device, vector_size * sizeof(double));     cudaMalloc((void**)&pdbB_device, vector_size * sizeof(double));     cudaMalloc((void**)&pdbC_device, vector_size * sizeof(double));          double *pdbA_host = (double *)malloc(vector_size * sizeof(double));     double *pdbB_host = (double *)malloc(vector_size * sizeof(double));     for (int i = 0; i < vector_size; ++i) {         pdbA_host[i] = i + 1.0;         pdbB_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(pdbA_device, pdbA_host, vector_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(pdbB_device, pdbB_host, vector_size * sizeof(double), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((vector_size + blockDim.x - 1) / blockDim.x);          vecAddGPU<<<gridDim, blockDim>>>(pdbA_device, pdbB_device, pdbC_device);          double *pdbC_result = (double *)malloc(vector_size * sizeof(double));     cudaMemcpy(pdbC_result, pdbC_device, vector_size * sizeof(double), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < vector_size; ++i) {         printf("%.2f ", pdbC_result[i]);     }     printf("\n");          free(pdbA_host);     free(pdbB_host);     free(pdbC_result);     cudaFree(pdbA_device);     cudaFree(pdbB_device);     cudaFree(pdbC_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void doubleArrayScalarMultiplyKernel(double *d_in, double *d_out, int length, double scalar) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = d_in[tid] * scalar;     } }  int main() {         const int array_size = 100;          double *d_in_device, *d_out_device;     cudaMalloc((void**)&d_in_device, array_size * sizeof(double));     cudaMalloc((void**)&d_out_device, array_size * sizeof(double));          double *d_in_host = (double *)malloc(array_size * sizeof(double));     for (int i = 0; i < array_size; ++i) {         d_in_host[i] = i + 1.0;     }          cudaMemcpy(d_in_device, d_in_host, array_size * sizeof(double), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          double scalar = 2.0;          doubleArrayScalarMultiplyKernel<<<gridDim, blockDim>>>(d_in_device, d_out_device, array_size, scalar);          double *d_out_result = (double *)malloc(array_size * sizeof(double));     cudaMemcpy(d_out_result, d_out_device, array_size * sizeof(double), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", d_out_result[i]);     }     printf("\n");          free(d_in_host);     free(d_out_result);     cudaFree(d_in_device);     cudaFree(d_out_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void addV(int *a, int *b, int *c, int N) {     int index = threadIdx.x + blockIdx.x * blockDim.x;     if (index < N) {         c[index] = a[index] + b[index];     } }  int main() {         const int array_size = 100;          int *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, array_size * sizeof(int));     cudaMalloc((void**)&b_device, array_size * sizeof(int));     cudaMalloc((void**)&c_device, array_size * sizeof(int));          int *a_host = (int *)malloc(array_size * sizeof(int));     int *b_host = (int *)malloc(array_size * sizeof(int));     for (int i = 0; i < array_size; ++i) {         a_host[i] = i + 1;         b_host[i] = (i + 1) * 2;     }          cudaMemcpy(a_device, a_host, array_size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, array_size * sizeof(int), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          addV<<<gridDim, blockDim>>>(a_device, b_device, c_device, array_size);          int *c_result = (int *)malloc(array_size * sizeof(int));     cudaMemcpy(c_result, c_device, array_size * sizeof(int), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%d ", c_result[i]);     }     printf("\n");          free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void VecAdd(float *A, float *B, float *C, int N) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < N) {         C[i] = A[i] + B[i];     } }  int main() {         const int array_size = 100;          float *A_device, *B_device, *C_device;     cudaMalloc((void**)&A_device, array_size * sizeof(float));     cudaMalloc((void**)&B_device, array_size * sizeof(float));     cudaMalloc((void**)&C_device, array_size * sizeof(float));          float *A_host = (float *)malloc(array_size * sizeof(float));     float *B_host = (float *)malloc(array_size * sizeof(float));     for (int i = 0; i < array_size; ++i) {         A_host[i] = i + 1.0;         B_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(A_device, A_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(B_device, B_host, array_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          VecAdd<<<gridDim, blockDim>>>(A_device, B_device, C_device, array_size);          float *C_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(C_result, C_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", C_result[i]);     }     printf("\n");          free(A_host);     free(B_host);     free(C_result);     cudaFree(A_device);     cudaFree(B_device);     cudaFree(C_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void saxpy_gpu_kernel(float *x, float *y, float alpha, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         y[i] = alpha * x[i] + y[i];     } }  int main() {         const int array_size = 100;          float *x_device, *y_device;     cudaMalloc((void**)&x_device, array_size * sizeof(float));     cudaMalloc((void**)&y_device, array_size * sizeof(float));          float *x_host = (float *)malloc(array_size * sizeof(float));     float *y_host = (float *)malloc(array_size * sizeof(float));     for (int i = 0; i < array_size; ++i) {         x_host[i] = i + 1.0;         y_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(x_device, x_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(y_device, y_host, array_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          float alpha = 0.5;          saxpy_gpu_kernel<<<gridDim, blockDim>>>(x_device, y_device, alpha, array_size);          float *y_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(y_result, y_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", y_result[i]);     }     printf("\n");          free(x_host);     free(y_host);     free(y_result);     cudaFree(x_device);     cudaFree(y_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void sumArrays(float *A, float *B, float *C, const int N) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < N) {         C[i] = A[i] + B[i];     } }  int main() {         const int array_size = 100;          float *A_device, *B_device, *C_device;     cudaMalloc((void**)&A_device, array_size * sizeof(float));     cudaMalloc((void**)&B_device, array_size * sizeof(float));     cudaMalloc((void**)&C_device, array_size * sizeof(float));          float *A_host = (float *)malloc(array_size * sizeof(float));     float *B_host = (float *)malloc(array_size * sizeof(float));     for (int i = 0; i < array_size; ++i) {         A_host[i] = i + 1.0;         B_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(A_device, A_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(B_device, B_host, array_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          sumArrays<<<gridDim, blockDim>>>(A_device, B_device, C_device, array_size);          float *C_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(C_result, C_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", C_result[i]);     }     printf("\n");          free(A_host);     free(B_host);     free(C_result);     cudaFree(A_device);     cudaFree(B_device);     cudaFree(C_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void doubleArrayScalarSubtractKernel(double *d_in, double *d_out, int length, double scalar) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = d_in[tid] - scalar;     } }  int main() {         const int array_size = 100;          double *d_in_device, *d_out_device;     cudaMalloc((void**)&d_in_device, array_size * sizeof(double));     cudaMalloc((void**)&d_out_device, array_size * sizeof(double));          double *d_in_host = (double *)malloc(array_size * sizeof(double));     for (int i = 0; i < array_size; ++i) {         d_in_host[i] = i + 1.0;     }          cudaMemcpy(d_in_device, d_in_host, array_size * sizeof(double), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          double scalar = 2.0;          doubleArrayScalarSubtractKernel<<<gridDim, blockDim>>>(d_in_device, d_out_device, array_size, scalar);          double *d_out_result = (double *)malloc(array_size * sizeof(double));     cudaMemcpy(d_out_result, d_out_device, array_size * sizeof(double), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", d_out_result[i]);     }     printf("\n");          free(d_in_host);     free(d_out_result);     cudaFree(d_in_device);     cudaFree(d_out_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h> #include <math.h>  __global__ void doubleArrayElementwiseSquareKernel(double *d_in, double *d_out, int length) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = pow(d_in[tid], 2);     } }  int main() {         const int array_size = 100;          double *d_in_device, *d_out_device;     cudaMalloc((void**)&d_in_device, array_size * sizeof(double));     cudaMalloc((void**)&d_out_device, array_size * sizeof(double));          double *d_in_host = (double *)malloc(array_size * sizeof(double));     for (int i = 0; i < array_size; ++i) {         d_in_host[i] = i + 1.0;     }          cudaMemcpy(d_in_device, d_in_host, array_size * sizeof(double), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          doubleArrayElementwiseSquareKernel<<<gridDim, blockDim>>>(d_in_device, d_out_device, array_size);          double *d_out_result = (double *)malloc(array_size * sizeof(double));     cudaMemcpy(d_out_result, d_out_device, array_size * sizeof(double), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", d_out_result[i]);     }     printf("\n");          free(d_in_host);     free(d_out_result);     cudaFree(d_in_device);     cudaFree(d_out_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void sum_array_overlap(int *a, int *b, int *c, int N) {     int gid = blockIdx.x * blockDim.x + threadIdx.x;     if (gid < N) {         c[gid] = a[gid] + b[gid];     } }  int main() {         const int array_size = 100;          int *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, array_size * sizeof(int));     cudaMalloc((void**)&b_device, array_size * sizeof(int));     cudaMalloc((void**)&c_device, array_size * sizeof(int));          int *a_host = (int *)malloc(array_size * sizeof(int));     int *b_host = (int *)malloc(array_size * sizeof(int));     for (int i = 0; i < array_size; ++i) {         a_host[i] = i + 1;         b_host[i] = (i + 1) * 2;     }          cudaMemcpy(a_device, a_host, array_size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, array_size * sizeof(int), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          sum_array_overlap<<<gridDim, blockDim>>>(a_device, b_device, c_device, array_size);          int *c_result = (int *)malloc(array_size * sizeof(int));     cudaMemcpy(c_result, c_device, array_size * sizeof(int), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%d ", c_result[i]);     }     printf("\n");          free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void k_vec_divide(float *vec1, float *vec2, size_t max_size) {     for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < max_size; i += blockDim.x * gridDim.x) {         vec1[i] = vec1[i] / vec2[i];     } }  int main() {         const size_t array_size = 100;          float *vec1_device, *vec2_device;     cudaMalloc((void**)&vec1_device, array_size * sizeof(float));     cudaMalloc((void**)&vec2_device, array_size * sizeof(float));          float *vec1_host = (float *)malloc(array_size * sizeof(float));     float *vec2_host = (float *)malloc(array_size * sizeof(float));     for (size_t i = 0; i < array_size; ++i) {         vec1_host[i] = i + 1.0;         vec2_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(vec1_device, vec1_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(vec2_device, vec2_host, array_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          k_vec_divide<<<gridDim, blockDim>>>(vec1_device, vec2_device, array_size);          float *vec1_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(vec1_result, vec1_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (size_t i = 0; i < array_size; ++i) {         printf("%.2f ", vec1_result[i]);     }     printf("\n");          free(vec1_host);     free(vec2_host);     free(vec1_result);     cudaFree(vec1_device);     cudaFree(vec2_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void saxpi_nBlock(int n, float a, float *x, float *y) {     int idx = threadIdx.x + (blockIdx.x * blockDim.x);     if (idx < n) {         y[idx] = a * x[idx] + y[idx];     } }  int main() {         const int array_size = 100;          float *x_device, *y_device;     cudaMalloc((void**)&x_device, array_size * sizeof(float));     cudaMalloc((void**)&y_device, array_size * sizeof(float));          float *x_host = (float *)malloc(array_size * sizeof(float));     float *y_host = (float *)malloc(array_size * sizeof(float));     for (int i = 0; i < array_size; ++i) {         x_host[i] = i + 1.0;         y_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(x_device, x_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(y_device, y_host, array_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          float a = 0.5;          saxpi_nBlock<<<gridDim, blockDim>>>(array_size, a, x_device, y_device);          float *y_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(y_result, y_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", y_result[i]);     }     printf("\n");          free(x_host);     free(y_host);     free(y_result);     cudaFree(x_device);     cudaFree(y_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void cuda_record(float *p, float *seis_kt, int *Gxz, int ng) {     int id = threadIdx.x + blockDim.x * blockIdx.x;     if (id < ng) {         seis_kt[id] = p[Gxz[id]];     } }  int main() {         const int array_size = 100;          float *p_device, *seis_kt_device;     int *Gxz_device;      cudaMalloc((void**)&p_device, array_size * sizeof(float));     cudaMalloc((void**)&seis_kt_device, array_size * sizeof(float));     cudaMalloc((void**)&Gxz_device, array_size * sizeof(int));          float *p_host = (float *)malloc(array_size * sizeof(float));     float *seis_kt_host = (float *)malloc(array_size * sizeof(float));     int *Gxz_host = (int *)malloc(array_size * sizeof(int));      for (int i = 0; i < array_size; ++i) {         p_host[i] = i + 1.0;         seis_kt_host[i] = 0.0;         Gxz_host[i] = i % array_size;     }          cudaMemcpy(p_device, p_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(seis_kt_device, seis_kt_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(Gxz_device, Gxz_host, array_size * sizeof(int), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          cuda_record<<<gridDim, blockDim>>>(p_device, seis_kt_device, Gxz_device, array_size);          float *seis_kt_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(seis_kt_result, seis_kt_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", seis_kt_result[i]);     }     printf("\n");          free(p_host);     free(seis_kt_host);     free(Gxz_host);     free(seis_kt_result);     cudaFree(p_device);     cudaFree(seis_kt_device);     cudaFree(Gxz_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void vectorDiv(const float *A, const float *B, float *C, int numElements) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < numElements) {         C[i] = A[i] / B[i];     } }  int main() {         const int array_size = 100;          float *A_device, *B_device, *C_device;      cudaMalloc((void**)&A_device, array_size * sizeof(float));     cudaMalloc((void**)&B_device, array_size * sizeof(float));     cudaMalloc((void**)&C_device, array_size * sizeof(float));          float *A_host = (float *)malloc(array_size * sizeof(float));     float *B_host = (float *)malloc(array_size * sizeof(float));     float *C_host = (float *)malloc(array_size * sizeof(float));      for (int i = 0; i < array_size; ++i) {         A_host[i] = i + 1.0;         B_host[i] = (i + 1.0) * 2.0;         C_host[i] = 0.0;     }          cudaMemcpy(A_device, A_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(B_device, B_host, array_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          vectorDiv<<<gridDim, blockDim>>>(A_device, B_device, C_device, array_size);          cudaMemcpy(C_host, C_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", C_host[i]);     }     printf("\n");          free(A_host);     free(B_host);     free(C_host);     cudaFree(A_device);     cudaFree(B_device);     cudaFree(C_device);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void kernelSAXPY(int len, float a, float *d_x, float *d_y) {     const int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < len) {         d_y[i] = d_x[i] * a + d_y[i];     } }  int main() {         const int array_size = 100;          float *d_x, *d_y;      cudaMalloc((void**)&d_x, array_size * sizeof(float));     cudaMalloc((void**)&d_y, array_size * sizeof(float));          float *h_x = (float *)malloc(array_size * sizeof(float));     float *h_y = (float *)malloc(array_size * sizeof(float));      for (int i = 0; i < array_size; ++i) {         h_x[i] = i + 1.0;         h_y[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(d_x, h_x, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_y, h_y, array_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          float a = 0.5;          kernelSAXPY<<<gridDim, blockDim>>>(array_size, a, d_x, d_y);          float *h_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(h_result, d_y, array_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", h_result[i]);     }     printf("\n");          free(h_x);     free(h_y);     free(h_result);     cudaFree(d_x);     cudaFree(d_y);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void vectorAdd(const float *A, const float *B, float *C, int numElements) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < numElements) {         C[i] = A[i] + B[i];     } }  int main() {         const int array_size = 100;          float *A_device, *B_device, *C_device;      cudaMalloc((void**)&A_device, array_size * sizeof(float));     cudaMalloc((void**)&B_device, array_size * sizeof(float));     cudaMalloc((void**)&C_device, array_size * sizeof(float));          float *A_host = (float *)malloc(array_size * sizeof(float));     float *B_host = (float *)malloc(array_size * sizeof(float));      for (int i = 0; i < array_size; ++i) {         A_host[i] = i + 1.0;         B_host[i] = (i + 1.0) * 2.0;     }          cudaMemcpy(A_device, A_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(B_device, B_host, array_size * sizeof(float), cudaMemcpyHostToDevice);          dim3 blockDim(256);     dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);          vectorAdd<<<gridDim, blockDim>>>(A_device, B_device, C_device, array_size);          float *C_host = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(C_host, C_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);          printf("Result after CUDA kernel execution:\n");     for (int i = 0; i < array_size; ++i) {         printf("%.2f ", C_host[i]);     }     printf("\n");          free(A_host);     free(B_host);     free(C_host);     cudaFree(A_device);     cudaFree(B_device);     cudaFree(C_device);      return 0; }   
#include <stdio.h>#include <device_launch_parameters.h> #include <stdio.h>#include <cuda_runtime.h> #include <iostream>  __global__ void vectorAdd(double* a, double* b, double* c, int vector_size) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < vector_size) {         c[tid] = a[tid] + b[tid];     } }  int main() {         int vector_size = 100;          double *h_a, *h_b, *h_c;     h_a = new double[vector_size];     h_b = new double[vector_size];     h_c = new double[vector_size];          for (int i = 0; i < vector_size; ++i) {         h_a[i] = i;         h_b[i] = i * 2;     }          double *d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, vector_size * sizeof(double));     cudaMalloc((void**)&d_b, vector_size * sizeof(double));     cudaMalloc((void**)&d_c, vector_size * sizeof(double));          cudaMemcpy(d_a, h_a, vector_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, vector_size * sizeof(double), cudaMemcpyHostToDevice);          int block_size = 256;     int grid_size = (vector_size + block_size - 1) / block_size;          vectorAdd<<<grid_size, block_size>>>(d_a, d_b, d_c, vector_size);          cudaMemcpy(h_c, d_c, vector_size * sizeof(double), cudaMemcpyDeviceToHost);          for (int i = 0; i < vector_size; ++i) {         std::cout << h_c[i] << " ";     }     std::cout << std::endl;          delete[] h_a;     delete[] h_b;     delete[] h_c;     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void intAdd(int* c, const int* a, const int* b, const unsigned int d) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     if (i < d) {         c[i] = a[i] + b[i];     } }  int main() {         unsigned int vector_size = 100;          int *h_a, *h_b, *h_c;     h_a = (int*)malloc(vector_size * sizeof(int));     h_b = (int*)malloc(vector_size * sizeof(int));     h_c = (int*)malloc(vector_size * sizeof(int));          for (unsigned int i = 0; i < vector_size; ++i) {         h_a[i] = i;         h_b[i] = i * 2;     }          int *d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, vector_size * sizeof(int));     cudaMalloc((void**)&d_b, vector_size * sizeof(int));     cudaMalloc((void**)&d_c, vector_size * sizeof(int));          cudaMemcpy(d_a, h_a, vector_size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, vector_size * sizeof(int), cudaMemcpyHostToDevice);          int block_size = 256;     int grid_size = (vector_size + block_size - 1) / block_size;          intAdd<<<grid_size, block_size>>>(d_c, d_a, d_b, vector_size);          cudaMemcpy(h_c, d_c, vector_size * sizeof(int), cudaMemcpyDeviceToHost);          for (unsigned int i = 0; i < vector_size; ++i) {         printf("%d ", h_c[i]);     }     printf("\n");          free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void histo_atomic(const unsigned int* const vals, unsigned int* const histo, int numVals) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     if (i >= numVals)         return;     atomicAdd(&histo[vals[i]], 1); }  int main() {         int numVals = 100;          unsigned int* h_vals;     unsigned int* h_histo;     h_vals = (unsigned int*)malloc(numVals * sizeof(unsigned int));     h_histo = (unsigned int*)malloc(numVals * sizeof(unsigned int));          for (int i = 0; i < numVals; ++i) {         h_vals[i] = i % numVals;     }          unsigned int* d_vals;     unsigned int* d_histo;     cudaMalloc((void**)&d_vals, numVals * sizeof(unsigned int));     cudaMalloc((void**)&d_histo, numVals * sizeof(unsigned int));          cudaMemcpy(d_vals, h_vals, numVals * sizeof(unsigned int), cudaMemcpyHostToDevice);          cudaMemset(d_histo, 0, numVals * sizeof(unsigned int));          int block_size = 256;     dim3 grid_size((numVals + block_size - 1) / block_size, 1);          histo_atomic<<<grid_size, block_size>>>(d_vals, d_histo, numVals);          cudaMemcpy(h_histo, d_histo, numVals * sizeof(unsigned int), cudaMemcpyDeviceToHost);          for (int i = 0; i < numVals; ++i) {         printf("%u ", h_histo[i]);     }     printf("\n");          free(h_vals);     free(h_histo);     cudaFree(d_vals);     cudaFree(d_histo);      return 0; } 
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void vadd(const float* a, const float* b, float* c, const unsigned int count) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < count) {         c[i] = a[i] + b[i];     } }  int main() {         unsigned int vector_size = 100;          float *h_a, *h_b, *h_c;     h_a = (float*)malloc(vector_size * sizeof(float));     h_b = (float*)malloc(vector_size * sizeof(float));     h_c = (float*)malloc(vector_size * sizeof(float));          for (unsigned int i = 0; i < vector_size; ++i) {         h_a[i] = i * 1.5f;         h_b[i] = i * 2.0f;     }          float *d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, vector_size * sizeof(float));     cudaMalloc((void**)&d_b, vector_size * sizeof(float));     cudaMalloc((void**)&d_c, vector_size * sizeof(float));          cudaMemcpy(d_a, h_a, vector_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, vector_size * sizeof(float), cudaMemcpyHostToDevice);          int block_size = 256;     int grid_size = (vector_size + block_size - 1) / block_size;          vadd<<<grid_size, block_size>>>(d_a, d_b, d_c, vector_size);          cudaMemcpy(h_c, d_c, vector_size * sizeof(float), cudaMemcpyDeviceToHost);          for (unsigned int i = 0; i < vector_size; ++i) {         printf("%f ", h_c[i]);     }     printf("\n");          free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void intSubtract(int* c, const int* a, const int* b, const unsigned int d) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     if (i < d) {         c[i] = a[i] - b[i];     } }  int main() {         unsigned int vector_size = 100;          int *h_a, *h_b, *h_c;     h_a = (int*)malloc(vector_size * sizeof(int));     h_b = (int*)malloc(vector_size * sizeof(int));     h_c = (int*)malloc(vector_size * sizeof(int));          for (unsigned int i = 0; i < vector_size; ++i) {         h_a[i] = i * 2;         h_b[i] = i;         }          int *d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, vector_size * sizeof(int));     cudaMalloc((void**)&d_b, vector_size * sizeof(int));     cudaMalloc((void**)&d_c, vector_size * sizeof(int));          cudaMemcpy(d_a, h_a, vector_size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, vector_size * sizeof(int), cudaMemcpyHostToDevice);          int block_size = 256;     int grid_size = (vector_size + block_size - 1) / block_size;          intSubtract<<<grid_size, block_size>>>(d_c, d_a, d_b, vector_size);          cudaMemcpy(h_c, d_c, vector_size * sizeof(int), cudaMemcpyDeviceToHost);          for (unsigned int i = 0; i < vector_size; ++i) {         printf("%d ", h_c[i]);     }     printf("\n");          free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void transferMBR3(double* xy_copy, long long* a_copy, int tasks) {     for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < tasks; i += blockDim.x * gridDim.x) {         a_copy[i] = static_cast<long long>(xy_copy[i] * 10000000);     } }  int main() {         int tasks = 100;          double* h_xy_copy;     long long* h_a_copy;     h_xy_copy = (double*)malloc(tasks * sizeof(double));     h_a_copy = (long long*)malloc(tasks * sizeof(long long));          for (int i = 0; i < tasks; ++i) {         h_xy_copy[i] = i * 1.5;     }          double* d_xy_copy;     long long* d_a_copy;     cudaMalloc((void**)&d_xy_copy, tasks * sizeof(double));     cudaMalloc((void**)&d_a_copy, tasks * sizeof(long long));          cudaMemcpy(d_xy_copy, h_xy_copy, tasks * sizeof(double), cudaMemcpyHostToDevice);          int block_size = 256;     int grid_size = (tasks + block_size - 1) / block_size;          transferMBR3<<<grid_size, block_size>>>(d_xy_copy, d_a_copy, tasks);          cudaMemcpy(h_a_copy, d_a_copy, tasks * sizeof(long long), cudaMemcpyDeviceToHost);          for (int i = 0; i < tasks; ++i) {         printf("%lld ", h_a_copy[i]);     }     printf("\n");          free(h_xy_copy);     free(h_a_copy);     cudaFree(d_xy_copy);     cudaFree(d_a_copy);      return 0; }   
#include <device_launch_parameters.h> #include <cuda_runtime.h> #include <stdio.h>  __global__ void binarize_kernel(float* x, int n, float* binary) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i >= n)         return;     binary[i] = (x[i] >= 0) ? 1 : -1; }  int main() {         int n = 100;          float* h_x;     float* h_binary;     h_x = (float*)malloc(n * sizeof(float));     h_binary = (float*)malloc(n * sizeof(float));          for (int i = 0; i < n; ++i) {         h_x[i] = i - 50;     }          float* d_x;     float* d_binary;     cudaMalloc((void**)&d_x, n * sizeof(float));     cudaMalloc((void**)&d_binary, n * sizeof(float));          cudaMemcpy(d_x, h_x, n * sizeof(float), cudaMemcpyHostToDevice);          int block_size = 256;     dim3 grid_size((n + block_size - 1) / block_size, 1);          binarize_kernel<<<grid_size, block_size>>>(d_x, n, d_binary);          cudaMemcpy(h_binary, d_binary, n * sizeof(float), cudaMemcpyDeviceToHost);          for (int i = 0; i < n; ++i) {         printf("%f ", h_binary[i]);     }     printf("\n");          free(h_x);     free(h_binary);     cudaFree(d_x);     cudaFree(d_binary);      return 0; }   
