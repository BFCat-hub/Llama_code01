[
    {
        "id": "1",
        "c_code": "#include <stdio.h>  void add_100(int numElements, int *data) {     for (int idx = 0; idx < numElements; idx++) {         data[idx] += 100;     } }  int main() {          int array[] = {1, 2, 3, 4, 5};     int numElements = sizeof(array) / sizeof(array[0]);      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }           add_100(numElements, array);      printf(\"\\n\u4fee\u6539\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void add_100(int numElements, int* data) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid < numElements) {         data[tid] += 100;     } }  int main() {          int numElements = 1000;           int* h_data = (int*)malloc(numElements * sizeof(int));           for (int i = 0; i < numElements; ++i) {         h_data[i] = i;     }           int* d_data;     cudaMalloc((void**)&d_data, numElements * sizeof(int));           cudaMemcpy(d_data, h_data, numElements * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (numElements + blockSize - 1) / blockSize;           add_100<<<gridSize, blockSize>>>(numElements, d_data);           cudaMemcpy(h_data, d_data, numElements * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < numElements; ++i) {         printf(\"%d \", h_data[i]);     }           free(h_data);     cudaFree(d_data);      return 0; } "
    },
    {
        "id": "10",
        "c_code": "#include <stdio.h>  void test_cpu(float *input, const int dims) {     for (int tid = 0; tid < dims; tid++) {         if (tid == 0) {             input[tid] = 0;         }     } }  int main() {          int arraySize = 5;     float array[arraySize];      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", array[i]);     }           test_cpu(array, arraySize);      printf(\"\\n\u6d4b\u8bd5\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void test(float* input, const int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }      if (tid == 0) {         input[tid] = 0;     } }  int main() {          int arraySize = 1000;           float* h_input = (float*)malloc(arraySize * sizeof(float));           float* d_input;     cudaMalloc((void**)&d_input, arraySize * sizeof(float));           cudaMemcpy(d_input, h_input, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           test<<<gridSize, blockSize>>>(d_input, arraySize);           cudaMemcpy(h_input, d_input, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_input[i]);     }           free(h_input);     cudaFree(d_input);      return 0; } "
    },
    {
        "id": "100",
        "c_code": "#include <stdio.h>  void cpu_matrix_mul(int *a, int *b, int *c, int N) {     for (int row = 0; row < N; row++) {         for (int col = 0; col < N; col++) {             int sum = 0;             for (int i = 0; i < N; i++) {                 sum += a[row * N + i] * b[i * N + col];             }             c[row * N + col] = sum;         }     } }  int main() {          const int N = 3;     int a[N * N] = {1, 2, 3, 4, 5, 6, 7, 8, 9};     int b[N * N] = {9, 8, 7, 6, 5, 4, 3, 2, 1};     int c[N * N];           cpu_matrix_mul(a, b, c, N);           printf(\"Resultant matrix c:\\n\");     for (int i = 0; i < N; i++) {         for (int j = 0; j < N; j++) {             printf(\"%d \", c[i * N + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gpu_matrix_mul(int* a, int* b, int* c, int N) {     int row = blockIdx.y * blockDim.y + threadIdx.y;     int col = blockIdx.x * blockDim.x + threadIdx.x;     int sum = 0;      if (col < N && row < N) {         for (int i = 0; i < N; i++) {             sum += a[row * N + i] * b[i * N + col];         }         c[row * N + col] = sum;     } }  int main() {          int N = 512;            int* h_a = (int*)malloc(N * N * sizeof(int));     int* h_b = (int*)malloc(N * N * sizeof(int));     int* h_c = (int*)malloc(N * N * sizeof(int));                 int* d_a, * d_b, * d_c;     cudaMalloc((void**)&d_a, N * N * sizeof(int));     cudaMalloc((void**)&d_b, N * N * sizeof(int));     cudaMalloc((void**)&d_c, N * N * sizeof(int));                 dim3 gridSize((N + 15) / 16, (N + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           gpu_matrix_mul<<<gridSize, blockSize>>>(d_a, d_b, d_c, N);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);           free(h_a);     free(h_b);     free(h_c);      return 0; } "
    },
    {
        "id": "101",
        "c_code": "#include <stdio.h>  void grayscale(unsigned char *input, unsigned char *output, int size) {     unsigned char r, g, b;          for (int i = 0; i < size; i++) {         r = input[3 * i];         g = input[3 * i + 1];         b = input[3 * i + 2];         output[i] = (unsigned char)(0.21 * (float)r + 0.71 * (float)g + 0.07 * (float)b);     } }  int main() {          const int size = 3;     unsigned char input[size * 3] = {255, 0, 0, 0, 255, 0, 0, 0, 255};     unsigned char output[size];           grayscale(input, output, size);           printf(\"Resultant grayscale values:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", output[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void grayscale(unsigned char* input, unsigned char* output, int size) {     int i = threadIdx.x + blockDim.x * blockIdx.x;      if (i < size) {         unsigned char r, g, b;         r = input[3 * i];         g = input[3 * i + 1];         b = input[3 * i + 2];          output[i] = (unsigned char)(0.21 * (float)r + 0.71 * (float)g + 0.07 * (float)b);     } }  int main() {          int size = 512;            unsigned char* h_input = (unsigned char*)malloc(3 * size * sizeof(unsigned char));     unsigned char* h_output = (unsigned char*)malloc(size * sizeof(unsigned char));                 unsigned char* d_input, * d_output;     cudaMalloc((void**)&d_input, 3 * size * sizeof(unsigned char));     cudaMalloc((void**)&d_output, size * sizeof(unsigned char));                 dim3 gridSize((size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           grayscale<<<gridSize, blockSize>>>(d_input, d_output, size);                 cudaFree(d_input);     cudaFree(d_output);           free(h_input);     free(h_output);      return 0; } "
    },
    {
        "id": "102",
        "c_code": "#include <stdio.h>  void subtractMean_cpu(double *images, const double *meanImage, int imageNum, int pixelNum) {     for (int col = 0; col < pixelNum; col++) {         for (int row = 0; row < imageNum; ++row) {             images[row * pixelNum + col] -= meanImage[col];             if (images[row * pixelNum + col] < 0.0) {                 images[row * pixelNum + col] = 0.0;             }         }     } }  int main() {          const int imageNum = 2;     const int pixelNum = 3;     double images[imageNum * pixelNum] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     double meanImage[pixelNum] = {2.0, 3.0, 4.0};           subtractMean_cpu(images, meanImage, imageNum, pixelNum);           printf(\"Resultant images after subtracting mean:\\n\");     for (int i = 0; i < imageNum; i++) {         for (int j = 0; j < pixelNum; j++) {             printf(\"%f \", images[i * pixelNum + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void subtractMean(double* images, const double* meanImage, size_t imageNum, size_t pixelNum) {     size_t col = blockIdx.x * blockDim.x + threadIdx.x;      if (col >= pixelNum) {         return;     }      for (size_t row = 0; row < imageNum; ++row) {         images[row * pixelNum + col] -= meanImage[col];          if (images[row * pixelNum + col] < 0.0) {             images[row * pixelNum + col] = 0.0;         }     } }  int main() {          size_t imageNum = 512;        size_t pixelNum = 1024;             double* h_images = (double*)malloc(imageNum * pixelNum * sizeof(double));     double* h_meanImage = (double*)malloc(pixelNum * sizeof(double));                 double* d_images, * d_meanImage;     cudaMalloc((void**)&d_images, imageNum * pixelNum * sizeof(double));     cudaMalloc((void**)&d_meanImage, pixelNum * sizeof(double));                 dim3 gridSize((pixelNum + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           subtractMean<<<gridSize, blockSize>>>(d_images, d_meanImage, imageNum, pixelNum);                 cudaFree(d_images);     cudaFree(d_meanImage);           free(h_images);     free(h_meanImage);      return 0; } "
    },
    {
        "id": "103",
        "c_code": "#include <stdio.h>  void kernelMaximum(float *maxhd, float *maxvd, int start, int size) {     int tx = start;     float max_hd = 1.175494351e-38F;     float max_vd = 1.175494351e-38F;      for (; tx < size; tx++) {         if (maxhd[tx] > max_hd)             max_hd = maxhd[tx];         if (maxvd[tx] > max_vd)             max_vd = maxvd[tx];     } }  int main() {          const int size = 5;     float maxhd[size] = {1.0, 2.0, 3.0, 4.0, 5.0};     float maxvd[size] = {5.0, 4.0, 3.0, 2.0, 1.0};           kernelMaximum(maxhd, maxvd, 0, size);           printf(\"Max_hd: %f\\n\", maxhd[0]);     printf(\"Max_vd: %f\\n\", maxvd[0]);      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void kernelMaximum(float* maxhd, float* maxvd, int start, int size) {     int tx = start + threadIdx.x;      for (int i = size >> 1; i > 0; i >>= 1) {         __syncthreads();          if (tx < i) {             if (maxhd[tx] < maxhd[tx + i]) maxhd[tx] = maxhd[tx + i];             if (maxvd[tx] < maxvd[tx + i]) maxvd[tx] = maxvd[tx + i];         }     } }  int main() {          int start = 0;         int size = 1024;             float* h_maxhd = (float*)malloc(size * sizeof(float));     float* h_maxvd = (float*)malloc(size * sizeof(float));                 float* d_maxhd, * d_maxvd;     cudaMalloc((void**)&d_maxhd, size * sizeof(float));     cudaMalloc((void**)&d_maxvd, size * sizeof(float));                 dim3 gridSize(1, 1, 1);     dim3 blockSize(size, 1, 1);           kernelMaximum<<<gridSize, blockSize>>>(d_maxhd, d_maxvd, start, size);                 cudaFree(d_maxhd);     cudaFree(d_maxvd);           free(h_maxhd);     free(h_maxvd);      return 0; } "
    },
    {
        "id": "104",
        "c_code": "#include <stdio.h>  void SparseMatmul_forward(float *a, float *b, float *c, int *indptr, int *indices, int p, int size) {     for (int i = 0; i < size - 1; i++) {         for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {             int j = indices[jj];             for (int k = 0; k < p; k++) {                 c[i * p + k] += a[jj] * b[j * p + k];             }         }     } }  int main() {          const int size = 3;     const int p = 2;     float a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float b[] = {2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0};     float c[size * p] = {0.0};      int indptr[] = {0, 2, 4};        int indices[] = {1, 2, 0, 1};              SparseMatmul_forward(a, b, c, indptr, indices, p, size);           printf(\"Resultant matrix c:\\n\");     for (int i = 0; i < size; i++) {         for (int j = 0; j < p; j++) {             printf(\"%f \", c[i * p + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void cuda_SparseMatmul_forward_kernel(float* a_in, float* b_in, float* c_in, int* indptr, int* indices, int p) {     int i = blockIdx.x;     int k = threadIdx.x;      for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {         int j = indices[jj];         c_in[i * p + k] += a_in[jj] * b_in[j * p + k];     } }  int main() {          int numRows = 512;       int numCols = 256;       int numNonZeros = 1024;             float* h_a_in = (float*)malloc(numNonZeros * sizeof(float));     float* h_b_in = (float*)malloc(numCols * p * sizeof(float));     float* h_c_in = (float*)malloc(numRows * p * sizeof(float));     int* h_indptr = (int*)malloc((numRows + 1) * sizeof(int));     int* h_indices = (int*)malloc(numNonZeros * sizeof(int));                 float* d_a_in, * d_b_in, * d_c_in;     int* d_indptr, * d_indices;     cudaMalloc((void**)&d_a_in, numNonZeros * sizeof(float));     cudaMalloc((void**)&d_b_in, numCols * p * sizeof(float));     cudaMalloc((void**)&d_c_in, numRows * p * sizeof(float));     cudaMalloc((void**)&d_indptr, (numRows + 1) * sizeof(int));     cudaMalloc((void**)&d_indices, numNonZeros * sizeof(int));                 dim3 gridSize(numRows, 1, 1);     dim3 blockSize(p, 1, 1);           cuda_SparseMatmul_forward_kernel<<<gridSize, blockSize>>>(d_a_in, d_b_in, d_c_in, d_indptr, d_indices, p);                 cudaFree(d_a_in);     cudaFree(d_b_in);     cudaFree(d_c_in);     cudaFree(d_indptr);     cudaFree(d_indices);           free(h_a_in);     free(h_b_in);     free(h_c_in);     free(h_indptr);     free(h_indices);      return 0; } "
    },
    {
        "id": "105",
        "c_code": "#include <stdio.h>  void vectorMatrixMult(long int totalPixels, int availablePixels, int outPixelOffset, float *matrix, float *vector, float *out) {     for (long int i = 0; i < availablePixels; i++) {         float sum = 0.0;         for (long int j = 0; j < totalPixels; j++) {             sum += matrix[i * totalPixels + j] * vector[j];         }         out[i + outPixelOffset] = sum;     } }  int main() {          const long int totalPixels = 4;     const int availablePixels = 2;     const int outPixelOffset = 1;     float matrix[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0};     float vector[] = {2.0, 1.0, 3.0, 4.0};     float out[availablePixels + outPixelOffset];           vectorMatrixMult(totalPixels, availablePixels, outPixelOffset, matrix, vector, out);           printf(\"Resultant vector out:\\n\");     for (int i = 0; i < availablePixels + outPixelOffset; i++) {         printf(\"%f \", out[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void vectorMatrixMult(long int totalPixels, int availablePixels, int outPixelOffset, float* matrix, float* vector, float* out) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = blockDim.x * gridDim.x;      for (long int i = index; i < availablePixels; i += stride) {         float sum = 0.0;          for (long int j = 0; j < totalPixels; j++) {             sum += matrix[i * totalPixels + j] * vector[j];         }          out[i + outPixelOffset] = sum;     } }  int main() {          long int totalPixels = 1024;           int availablePixels = 512;             int outPixelOffset = 256;                    float* h_matrix = (float*)malloc(availablePixels * totalPixels * sizeof(float));     float* h_vector = (float*)malloc(totalPixels * sizeof(float));     float* h_out = (float*)malloc(availablePixels * sizeof(float));                 float* d_matrix, * d_vector, * d_out;     cudaMalloc((void**)&d_matrix, availablePixels * totalPixels * sizeof(float));     cudaMalloc((void**)&d_vector, totalPixels * sizeof(float));     cudaMalloc((void**)&d_out, availablePixels * sizeof(float));                 dim3 gridSize((availablePixels + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           vectorMatrixMult<<<gridSize, blockSize>>>(totalPixels, availablePixels, outPixelOffset, d_matrix, d_vector, d_out);                 cudaFree(d_matrix);     cudaFree(d_vector);     cudaFree(d_out);           free(h_matrix);     free(h_vector);     free(h_out);      return 0; } "
    },
    {
        "id": "106",
        "c_code": "#include <stdio.h>  void convertKinectDisparityInPlace_cpu(float *d_disparity, int pitch, int width, int height, float depth_scale) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < height; y++) {             float *d_in = (float *)((char *)d_disparity + y * pitch) + x;             *d_in = (*d_in == 0.0f) ? 1 : (-depth_scale / *d_in);         }     } }  int main() {          const int width = 3;     const int height = 2;     const int pitch = width * sizeof(float);     float d_disparity[width * height] = {0.0, 2.0, 0.0, 4.0, 0.0, 6.0};     float depth_scale = 2.0;           convertKinectDisparityInPlace_cpu(d_disparity, pitch, width, height, depth_scale);           printf(\"Resultant disparity values:\\n\");     for (int i = 0; i < width * height; i++) {         printf(\"%f \", d_disparity[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void convertKinectDisparityInPlace_kernel(float* d_disparity, int pitch, int width, int height, float depth_scale) {     const int x = blockIdx.x * blockDim.x + threadIdx.x;     const int y = blockIdx.y * blockDim.y + threadIdx.y;      if ((x < width) && (y < height)) {         float* d_in = (float*)((char*)d_disparity + y * pitch) + x;         *d_in = (*d_in == 0.0f) ? 1 : (-depth_scale / *d_in);     } }  int main() {          int width = 640;        int height = 480;       float depth_scale = 0.001f;             float* h_disparity = (float*)malloc(width * height * sizeof(float));                 float* d_disparity;     cudaMalloc((void**)&d_disparity, width * height * sizeof(float));                 dim3 gridSize((width + 15) / 16, (height + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           convertKinectDisparityInPlace_kernel<<<gridSize, blockSize>>>(d_disparity, width * sizeof(float), width, height, depth_scale);                 cudaFree(d_disparity);           free(h_disparity);      return 0; } "
    },
    {
        "id": "107",
        "c_code": "#include <stdio.h>  void SparseMatmul_backward(float *a, float *b_grad, float *c_grad, int *indptr, int *indices, int p, int size, float *grad) {     for (int i = 0; i < size - 1; i++) {         for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {             int j = indices[jj];             for (int k = 0; k < p; k++) {                 b_grad[j * p + k] += c_grad[i * p + k] * a[jj];             }         }     } }  int main() {          const int size = 3;     const int p = 2;     float a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float b_grad[] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0};     float c_grad[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float grad[size * p] = {0.0};      int indptr[] = {0, 2, 4};        int indices[] = {1, 2, 0, 1};              SparseMatmul_backward(a, b_grad, c_grad, indptr, indices, p, size, grad);           printf(\"Resultant gradient b_grad:\\n\");     for (int i = 0; i < size * p; i++) {         printf(\"%f \", b_grad[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void cuda_SparseMatmul_backward_kernel(float* a_in, float* b_in, float* c_in, int* indptr, int* indices, int p) {     int i = blockIdx.x;     int k = threadIdx.x;      for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {         int j = indices[jj];         b_in[j * p + k] += c_in[i * p + k] * a_in[jj];     } }  int main() {          int p = 256;             float* h_a = nullptr;       float* h_b = nullptr;       float* h_c = nullptr;       int* h_indptr = nullptr;       int* h_indices = nullptr;             float* d_a, *d_b, *d_c;     int* d_indptr, *d_indices;     cudaMalloc((void**)&d_a, sizeof(float));       cudaMalloc((void**)&d_b, sizeof(float));       cudaMalloc((void**)&d_c, sizeof(float));       cudaMalloc((void**)&d_indptr, sizeof(int));       cudaMalloc((void**)&d_indices, sizeof(int));                   dim3 gridSize(1, 1, 1);       dim3 blockSize(1, 1, 1);             cuda_SparseMatmul_backward_kernel<<<gridSize, blockSize>>>(d_a, d_b, d_c, d_indptr, d_indices, p);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);     cudaFree(d_indptr);     cudaFree(d_indices);                 return 0; } "
    },
    {
        "id": "108",
        "c_code": "#include <stdio.h> #include <math.h>  void subsample_ind_and_labels_cpu(int *d_ind_sub, const int *d_ind, unsigned int *d_label_sub, const unsigned int *d_label, int n_out, float inv_sub_factor) {     for (int ind_out = 0; ind_out < n_out; ind_out++) {         int ind_in = (int)floorf((float)(ind_out) * inv_sub_factor);         d_ind_sub[ind_out] = d_ind[ind_in];         d_label_sub[ind_out] = d_label[ind_in];     } }  int main() {          const int n_out = 3;     float inv_sub_factor = 0.5;     int d_ind[] = {1, 2, 3, 4, 5, 6};     unsigned int d_label[] = {10, 20, 30, 40, 50, 60};     int d_ind_sub[n_out];     unsigned int d_label_sub[n_out];           subsample_ind_and_labels_cpu(d_ind_sub, d_ind, d_label_sub, d_label, n_out, inv_sub_factor);           printf(\"Resultant subsampled indices and labels:\\n\");     for (int i = 0; i < n_out; i++) {         printf(\"Index: %d, Label: %u\\n\", d_ind_sub[i], d_label_sub[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <math.h>  __global__ void subsample_ind_and_labels_GPU(int* d_ind_sub, const int* d_ind, unsigned int* d_label_sub, const unsigned int* d_label, int n_out, float inv_sub_factor) {     unsigned int ind_out = blockIdx.x * blockDim.x + threadIdx.x;      if (ind_out < n_out) {         int ind_in = (int)floorf((float)(ind_out) * inv_sub_factor);         d_ind_sub[ind_out] = d_ind[ind_in];         d_label_sub[ind_out] = d_label[ind_in];     } }  int main() {          int n_out = 512;       float inv_sub_factor = 0.5f;             int* h_ind = nullptr;       unsigned int* h_label = nullptr;             int* d_ind, *d_ind_sub;     unsigned int* d_label, *d_label_sub;     cudaMalloc((void**)&d_ind, sizeof(int));       cudaMalloc((void**)&d_ind_sub, sizeof(int));       cudaMalloc((void**)&d_label, sizeof(unsigned int));       cudaMalloc((void**)&d_label_sub, sizeof(unsigned int));                   dim3 gridSize((n_out + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           subsample_ind_and_labels_GPU<<<gridSize, blockSize>>>(d_ind_sub, d_ind, d_label_sub, d_label, n_out, inv_sub_factor);                 cudaFree(d_ind);     cudaFree(d_ind_sub);     cudaFree(d_label);     cudaFree(d_label_sub);                 return 0; } "
    },
    {
        "id": "109",
        "c_code": "#include <stdio.h>  void mxm_1d_cpu(double *a, const int m, double *b, const int n, double *c, const int p) {     for (int i = 0; i < m; i++) {         for (int k = 0; k < p; k++) {             double s = 0.0;             for (int j = 0; j < n; j++) {                 s += a[j * m + i] * b[k * n + j];             }             c[k * m + i] = s;         }     } }  int main() {          const int m = 2;     const int n = 3;     const int p = 4;     double a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     double b[] = {2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0};     double c[p * m];           mxm_1d_cpu(a, m, b, n, c, p);           printf(\"Resultant matrix c:\\n\");     for (int i = 0; i < p; i++) {         for (int j = 0; j < m; j++) {             printf(\"%f \", c[i * m + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void mxm_1d(double* a, const int m, double* b, const int n, double* c, const int p) {     const int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i < m) {         for (int k = 0; k < p; k++) {             double s = 0.0;              for (int j = 0; j < n; j++) {                 s += a[j * m + i] * b[k * n + j];             }              c[k * m + i] = s;         }     } }  int main() {          int m = 256;       int n = 128;       int p = 64;              double* h_a = nullptr;       double* h_b = nullptr;             double* d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, sizeof(double));       cudaMalloc((void**)&d_b, sizeof(double));       cudaMalloc((void**)&d_c, sizeof(double));                   dim3 gridSize((m + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           mxm_1d<<<gridSize, blockSize>>>(d_a, m, d_b, n, d_c, p);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);                 return 0; } "
    },
    {
        "id": "11",
        "c_code": "#include <stdio.h>  void set_sorting_offset(const int nrows, const int ncols, int *offsets) {     int tid;     for (tid = 0; tid <= ncols; tid++) {         offsets[tid] = tid * nrows;     } }  int main() {          int numRows = 3;     int numCols = 4;     int offsetArray[numCols + 1];      printf(\"\u539f\u59cb\u504f\u79fb\u6570\u7ec4\uff1a\");     for (int i = 0; i <= numCols; i++) {         printf(\"%d \", offsetArray[i]);     }           set_sorting_offset(numRows, numCols, offsetArray);      printf(\"\\n\u8bbe\u7f6e\u540e\u7684\u504f\u79fb\u6570\u7ec4\uff1a\");     for (int i = 0; i <= numCols; i++) {         printf(\"%d \", offsetArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void set_sorting_offset(const int nrows, const int ncols, int* offsets) {     int tid = threadIdx.x + blockIdx.x * blockDim.x;     if (tid <= ncols) {         offsets[tid] = tid * nrows;     } }  int main() {          int nrows = 100;     int ncols = 10;           int* h_offsets = (int*)malloc((ncols + 1) * sizeof(int));           int* d_offsets;     cudaMalloc((void**)&d_offsets, (ncols + 1) * sizeof(int));           int blockSize = 256;     int gridSize = (ncols + blockSize - 1) / blockSize;           set_sorting_offset<<<gridSize, blockSize>>>(nrows, ncols, d_offsets);           cudaMemcpy(h_offsets, d_offsets, (ncols + 1) * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < ncols + 1; ++i) {         printf(\"%d \", h_offsets[i]);     }           free(h_offsets);     cudaFree(d_offsets);      return 0; } "
    },
    {
        "id": "110",
        "c_code": "#include <stdio.h> #include <math.h>  void fabsf_clamp_cpu(int N, float *X, int INCX, float clamp_min, float clamp_max) {     for (int i = 0; i < N; ++i) {         if (X[i * INCX] >= 0) {             X[i * INCX] = fmin(clamp_max, fmax(clamp_min, X[i * INCX]));         } else {             X[i * INCX] = fmin(-clamp_min, fmax(-clamp_max, X[i * INCX]));         }     } }  int main() {          const int N = 5;     const float clamp_min = -1.0;     const float clamp_max = 1.0;     float X[] = {-2.0, -1.0, 0.0, 1.0, 2.0};           fabsf_clamp_cpu(N, X, 1, clamp_min, clamp_max);           printf(\"Resultant array X:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", X[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <math.h>  __global__ void fabsf_clamp_kernel(int N, float* X, int INCX, float clamp_min, float clamp_max) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i < N) {         if (X[i * INCX] >= 0)             X[i * INCX] = fminf(clamp_max, fmaxf(clamp_min, X[i * INCX]));         else             X[i * INCX] = fminf(-clamp_min, fmaxf(-clamp_max, X[i * INCX]));     } }  int main() {          int N = 1024;       float clamp_min = -1.0f;       float clamp_max = 1.0f;              float* h_X = nullptr;             float* d_X;     cudaMalloc((void**)&d_X, sizeof(float));                   dim3 gridSize((N + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           fabsf_clamp_kernel<<<gridSize, blockSize>>>(N, d_X, 1, clamp_min, clamp_max);                 cudaFree(d_X);                 return 0; } "
    },
    {
        "id": "111",
        "c_code": "#include <stdio.h>  void cpu_matrix_mult(int *h_a, int *h_b, int *h_result, int m, int n, int k) {     for (int i = 0; i < m; ++i) {         for (int j = 0; j < k; ++j) {             int tmp = 0.0;             for (int h = 0; h < n; ++h) {                 tmp += h_a[i * n + h] * h_b[h * k + j];             }             h_result[i * k + j] = tmp;         }     } }  int main() {          const int m = 2;     const int n = 3;     const int k = 2;     int h_a[] = {1, 2, 3, 4, 5, 6};     int h_b[] = {2, 3, 4, 5, 6, 7};     int h_result[m * k];           cpu_matrix_mult(h_a, h_b, h_result, m, n, k);           printf(\"Resultant matrix h_result:\\n\");     for (int i = 0; i < m; i++) {         for (int j = 0; j < k; j++) {             printf(\"%d \", h_result[i * k + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void gpu_matrix_mult(int* a, int* b, int* c, int m, int n, int k) {     int row = blockIdx.y * blockDim.y + threadIdx.y;     int col = blockIdx.x * blockDim.x + threadIdx.x;     int sum = 0;      if (col < k && row < m) {         for (int i = 0; i < n; i++) {             sum += a[row * n + i] * b[i * k + col];         }          c[row * k + col] = sum;     } }  int main() {          int m = 256;       int n = 128;       int k = 64;              int* h_a = nullptr;       int* h_b = nullptr;             int* d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, sizeof(int));       cudaMalloc((void**)&d_b, sizeof(int));       cudaMalloc((void**)&d_c, sizeof(int));                   dim3 gridSize((k + 15) / 16, (m + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           gpu_matrix_mult<<<gridSize, blockSize>>>(d_a, d_b, d_c, m, n, k);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);                 return 0; } "
    },
    {
        "id": "112",
        "c_code": "#include <stdio.h>  inline void MulMatrixOnCPU(float *A, float *B, float *C, int nx, int ny) {     int i, j, k;     float sum = 0.0;     for (i = 0; i < nx; i++) {         for (j = 0; j < ny; j++) {             sum = 0.0;             for (k = 0; k < nx; k++) {                 sum = sum + A[i * nx + k] * B[k * nx + j];             }             C[i * nx + j] = sum;         }     } }  int main() {          const int nx = 2;     const int ny = 2;     float A[] = {1.0, 2.0, 3.0, 4.0};     float B[] = {5.0, 6.0, 7.0, 8.0};     float C[nx * nx];           MulMatrixOnCPU(A, B, C, nx, ny);           printf(\"Resultant matrix C:\\n\");     for (int i = 0; i < nx; i++) {         for (int j = 0; j < nx; j++) {             printf(\"%f \", C[i * nx + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void MulMatrixOnGPU(float* A, float* B, float* C, int nx, int ny) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     int j = threadIdx.y + blockIdx.y * blockDim.y;      if (i < nx && j < ny) {         float sum = 0.0;          for (int k = 0; k < nx; k++) {             sum += A[i * nx + k] * B[k * nx + j];         }          C[i * nx + j] = sum;     } }  int main() {          int nx = 256;       int ny = 128;             float* h_A = nullptr;       float* h_B = nullptr;       float* h_C = new float[nx * ny];             float* d_A, *d_B, *d_C;     cudaMalloc((void**)&d_A, sizeof(float) * nx * nx);       cudaMalloc((void**)&d_B, sizeof(float) * nx * nx);       cudaMalloc((void**)&d_C, sizeof(float) * nx * nx);                   dim3 gridSize((nx + 15) / 16, (ny + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           MulMatrixOnGPU<<<gridSize, blockSize>>>(d_A, d_B, d_C, nx, ny);                 cudaFree(d_A);     cudaFree(d_B);     cudaFree(d_C);           delete[] h_C;      return 0; } "
    },
    {
        "id": "113",
        "c_code": "#include <stdio.h>  int matrixMulHost(float *h_M, float *h_N, float *h_P, int width) {     int Pvalue;     for (int row = 0; row < width; ++row) {         for (int col = 0; col < width; ++col) {             Pvalue = 0;             for (int k = 0; k < width; ++k) {                 Pvalue += h_M[row * width + k] * h_N[k * width + col];             }             h_P[row * width + col] = Pvalue;         }     }     return 0; }  int main() {          const int width = 2;     float h_M[] = {1.0, 2.0, 3.0, 4.0};     float h_N[] = {5.0, 6.0, 7.0, 8.0};     float h_P[width * width];           matrixMulHost(h_M, h_N, h_P, width);           printf(\"Resultant matrix h_P:\\n\");     for (int i = 0; i < width; i++) {         for (int j = 0; j < width; j++) {             printf(\"%f \", h_P[i * width + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void MatrixMulKernel(float* d_M, float* d_N, float* d_P, int width) {     int Row = blockIdx.y * blockDim.y + threadIdx.y;     int Col = blockIdx.x * blockDim.x + threadIdx.x;      if ((Row < width) && (Col < width)) {         float Pvalue = 0;         for (int i = 0; i < width; ++i) {             Pvalue += d_M[Row * width + i] * d_N[i * width + Col];         }         d_P[Row * width + Col] = Pvalue;     } }  int main() {                int width = 100;       float* h_M = (float*)malloc(width * width * sizeof(float));     float* h_N = (float*)malloc(width * width * sizeof(float));     float* h_P = (float*)malloc(width * width * sizeof(float));      float* d_M, * d_N, * d_P;     cudaMalloc((void**)&d_M, width * width * sizeof(float));     cudaMalloc((void**)&d_N, width * width * sizeof(float));     cudaMalloc((void**)&d_P, width * width * sizeof(float));           cudaMemcpy(d_M, h_M, width * width * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_N, h_N, width * width * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (width + blockSize.y - 1) / blockSize.y);     MatrixMulKernel<<<gridSize, blockSize>>>(d_M, d_N, d_P, width);           cudaMemcpy(h_P, d_P, width * width * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_M);     free(h_N);     free(h_P);     cudaFree(d_M);     cudaFree(d_N);     cudaFree(d_P);      return 0; } "
    },
    {
        "id": "114",
        "c_code": "#include <stdio.h>  void mmul_cpu(const float *A, const float *B, float *C, int r1, int c1, int r2, int c2) {     for (int idx = 0; idx < c2; idx++) {         for (int idy = 0; idy < r1; idy++) {             float temp = 0;             for (int i = 0; i < c1; i++) {                 temp += A[idy * c1 + i] * B[i * c2 + idx];             }             C[idy * c2 + idx] = temp;         }     } }  int main() {          const int r1 = 2;     const int c1 = 3;     const int r2 = 3;     const int c2 = 2;     float A[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float B[] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0};     float C[r1 * c2];           mmul_cpu(A, B, C, r1, c1, r2, c2);           printf(\"Resultant matrix C:\\n\");     for (int i = 0; i < r1; i++) {         for (int j = 0; j < c2; j++) {             printf(\"%f \", C[i * c2 + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void mmul(const float* A, const float* B, float* C, int r1, int c1, int r2, int c2) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;     int idy = threadIdx.y + blockDim.y * blockIdx.y;      if ((idx < c2) && (idy < c1)) {         float temp = 0;          for (int i = 0; i < c1; i++)             temp += A[idy * c1 + i] * B[i * c2 + idx];          C[idy * c2 + idx] = temp;     } }  int main() {          int r1 = 256;       int c1 = 128;       int r2 = 128;       int c2 = 64;              float* h_A = nullptr;       float* h_B = nullptr;       float* h_C = new float[r1 * c2];             float* d_A, *d_B, *d_C;     cudaMalloc((void**)&d_A, sizeof(float) * r1 * c1);       cudaMalloc((void**)&d_B, sizeof(float) * c1 * c2);       cudaMalloc((void**)&d_C, sizeof(float) * r1 * c2);                   dim3 gridSize((c2 + 15) / 16, (r1 + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           mmul<<<gridSize, blockSize>>>(d_A, d_B, d_C, r1, c1, r2, c2);                 cudaFree(d_A);     cudaFree(d_B);     cudaFree(d_C);           delete[] h_C;      return 0; } "
    },
    {
        "id": "115",
        "c_code": "#include <stdio.h>  void Dot(float *C, float *A, float *B, const int r, const int c, const int n) {     float temp;     for (int i = 0; i < r; i++) {         for (int j = 0; j < c; j++) {             temp = 0.0;             for (int k = 0; k < n; k++) {                 temp += A[i * n + k] * B[k * c + j];             }             C[i * c + j] = temp;         }     } }  int main() {          const int r = 2;     const int c = 2;     const int n = 3;     float A[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float B[] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0};     float C[r * c];           Dot(C, A, B, r, c, n);           printf(\"Resultant matrix C:\\n\");     for (int i = 0; i < r; i++) {         for (int j = 0; j < c; j++) {             printf(\"%f \", C[i * c + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void Kernel_Dot_reduction2(float* dev_c, float* reduction, int r, const int c, const int n, int size_block) {     unsigned int i = blockDim.x * blockIdx.x + threadIdx.x;     unsigned int j = blockDim.y * blockIdx.y + threadIdx.y;      if (i >= r || j >= c) return;      float temp = 0;     for (int k = 0; k < size_block; k++) {         temp += reduction[i * (c * size_block) + j * size_block + k];     }      dev_c[i * c + j] = temp; }  int main() {                int r = 100;      int c = 100;     int n = 100;     int size_block = 16;      float* h_reduction = (float*)malloc(r * c * n * sizeof(float));     float* h_dev_c = (float*)malloc(r * c * sizeof(float));      float* d_reduction, * d_dev_c;     cudaMalloc((void**)&d_reduction, r * c * n * sizeof(float));     cudaMalloc((void**)&d_dev_c, r * c * sizeof(float));           cudaMemcpy(d_reduction, h_reduction, r * c * n * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);     dim3 gridSize((r + blockSize.x - 1) / blockSize.x, (c + blockSize.y - 1) / blockSize.y);     Kernel_Dot_reduction2<<<gridSize, blockSize>>>(d_dev_c, d_reduction, r, c, n, size_block);           cudaMemcpy(h_dev_c, d_dev_c, r * c * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_reduction);     free(h_dev_c);     cudaFree(d_reduction);     cudaFree(d_dev_c);      return 0; } "
    },
    {
        "id": "116",
        "c_code": "#include <stdio.h>  void Forwardsub_cpu(double *RES, double *LS, double *LW, double *LPR, int NI, int NJ, int Start, int J, int n) {     for (int i = 0; i < n; i++) {         int IJ = ((Start + i) * NI) + (J - (Start + i));         RES[IJ] = (RES[IJ] - LS[IJ] * RES[IJ - 1] - LW[IJ] * RES[IJ - NJ]) * LPR[IJ];     } }  int main() {          const int NI = 4;     const int NJ = 4;     const int Start = 1;     const int J = 2;     const int n = 2;     double RES[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};     double LS[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6};     double LW[] = {2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5};     double LPR[] = {0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16};           Forwardsub_cpu(RES, LS, LW, LPR, NI, NJ, Start, J, n);           printf(\"Resultant array RES:\\n\");     for (int i = 0; i < NI * NJ; i++) {         printf(\"%f \", RES[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void Forwardsub(double* RES, double* LS, double* LW, double* LPR, int NI, int NJ, int Start, int J, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;          if (i < n) {         int IJ = ((Start + i) * NI) + (J - (Start + i));         RES[IJ] = (RES[IJ] - LS[IJ] * RES[IJ - 1] - LW[IJ] * RES[IJ - NJ]) * LPR[IJ];     } }  int main() {                int NI = 100;      int NJ = 100;     int Start = 0;     int J = 10;     int n = 50;      double* h_RES = (double*)malloc(NI * NJ * sizeof(double));     double* h_LS = (double*)malloc(NI * NJ * sizeof(double));     double* h_LW = (double*)malloc(NI * NJ * sizeof(double));     double* h_LPR = (double*)malloc(NI * NJ * sizeof(double));      double* d_RES, * d_LS, * d_LW, * d_LPR;     cudaMalloc((void**)&d_RES, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_LS, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_LW, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_LPR, NI * NJ * sizeof(double));           cudaMemcpy(d_RES, h_RES, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_LS, h_LS, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_LW, h_LW, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_LPR, h_LPR, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);     dim3 gridSize((n + blockSize.x - 1) / blockSize.x, 1);     Forwardsub<<<gridSize, blockSize>>>(d_RES, d_LS, d_LW, d_LPR, NI, NJ, Start, J, n);           cudaMemcpy(h_RES, d_RES, NI * NJ * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_RES);     free(h_LS);     free(h_LW);     free(h_LPR);     cudaFree(d_RES);     cudaFree(d_LS);     cudaFree(d_LW);     cudaFree(d_LPR);      return 0; } "
    },
    {
        "id": "117",
        "c_code": "#include <stdio.h>  void cpu_rows_dc_offset_remove_layer_kernel(float *output, float *input, unsigned int width, unsigned int height, unsigned int depth) {     for (unsigned int channel = 0; channel < depth; channel++)         for (unsigned int row = 0; row < height; row++)             for (unsigned int column = 0; column < (width - 1); column++) {                 unsigned int idx = (channel * height + row) * width + column;                 output[idx] = input[idx] - input[idx + 1];             } }  int main() {          const unsigned int width = 3;     const unsigned int height = 2;     const unsigned int depth = 2;     float input[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0};     float output[width * height * depth];           cpu_rows_dc_offset_remove_layer_kernel(output, input, width, height, depth);           printf(\"Resultant array output:\\n\");     for (unsigned int channel = 0; channel < depth; channel++) {         for (unsigned int row = 0; row < height; row++) {             for (unsigned int column = 0; column < width; column++) {                 unsigned int idx = (channel * height + row) * width + column;                 printf(\"%f \", output[idx]);             }             printf(\"\\n\");         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void cuda_rows_dc_offset_remove_layer_kernel(float* output, float* input, unsigned int width, unsigned int height, unsigned int depth) {     unsigned int column = threadIdx.x + blockIdx.x * blockDim.x;     unsigned int row = threadIdx.y + blockIdx.y * blockDim.y;     unsigned int channel = threadIdx.z + blockIdx.z * blockDim.z;      if (channel < depth && row < height && column < (width - 1)) {         unsigned int idx = (channel * height + row) * width + column;         output[idx] = input[idx] - input[idx + 1];     } }  int main() {                unsigned int width = 100;      unsigned int height = 100;     unsigned int depth = 3;      float* h_output = (float*)malloc(width * height * depth * sizeof(float));     float* h_input = (float*)malloc(width * height * depth * sizeof(float));      float* d_output, * d_input;     cudaMalloc((void**)&d_output, width * height * depth * sizeof(float));     cudaMalloc((void**)&d_input, width * height * depth * sizeof(float));           cudaMemcpy(d_output, h_output, width * height * depth * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_input, h_input, width * height * depth * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16, 1);      dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y, (depth + blockSize.z - 1) / blockSize.z);     cuda_rows_dc_offset_remove_layer_kernel<<<gridSize, blockSize>>>(d_output, d_input, width, height, depth);           cudaMemcpy(h_output, d_output, width * height * depth * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_output);     free(h_input);     cudaFree(d_output);     cudaFree(d_input);      return 0; } "
    },
    {
        "id": "118",
        "c_code": "#include <stdio.h>  void cpu_cross_correlate(float *Isg, float *Iss, float *sp, float *gp, int npml, int nnz, int nnx) {     for (int i1 = npml; i1 < nnz - npml; i1++) {         for (int i2 = npml; i2 < nnx - npml; i2++) {             int id = i1 + i2 * nnz;             float ps = sp[id];             float pg = gp[id];             Isg[id] += ps * pg;             Iss[id] += ps * ps;         }     } }  int main() {          const int npml = 1;     const int nnz = 4;     const int nnx = 3;     float sp[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0};     float gp[] = {12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0};     float Isg[nnz * nnx] = {0};     float Iss[nnz * nnx] = {0};           cpu_cross_correlate(Isg, Iss, sp, gp, npml, nnz, nnx);           printf(\"Resultant arrays Isg and Iss:\\n\");     for (int i2 = 0; i2 < nnx; i2++) {         for (int i1 = 0; i1 < nnz; i1++) {             int id = i1 + i2 * nnz;             printf(\"Isg[%d]: %f, Iss[%d]: %f\\n\", id, Isg[id], id, Iss[id]);         }     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void cuda_cross_correlate(float* Isg, float* Iss, float* sp, float* gp, int npml, int nnz, int nnx) {     int i1 = threadIdx.x + blockDim.x * blockIdx.x;     int i2 = threadIdx.y + blockDim.y * blockIdx.y;     int id = i1 + i2 * nnz;      if (i1 >= npml && i1 < nnz - npml && i2 >= npml && i2 < nnx - npml) {         float ps = sp[id];         float pg = gp[id];         Isg[id] += ps * pg;         Iss[id] += ps * ps;     } }  int main() {                int npml = 5;      int nnz = 100;     int nnx = 100;      float* h_Isg = (float*)malloc(nnz * nnx * sizeof(float));     float* h_Iss = (float*)malloc(nnz * nnx * sizeof(float));     float* h_sp = (float*)malloc(nnz * nnx * sizeof(float));     float* h_gp = (float*)malloc(nnz * nnx * sizeof(float));      float* d_Isg, * d_Iss, * d_sp, * d_gp;     cudaMalloc((void**)&d_Isg, nnz * nnx * sizeof(float));     cudaMalloc((void**)&d_Iss, nnz * nnx * sizeof(float));     cudaMalloc((void**)&d_sp, nnz * nnx * sizeof(float));     cudaMalloc((void**)&d_gp, nnz * nnx * sizeof(float));           cudaMemcpy(d_Isg, h_Isg, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Iss, h_Iss, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_sp, h_sp, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_gp, h_gp, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((nnz + blockSize.x - 1) / blockSize.x, (nnx + blockSize.y - 1) / blockSize.y);     cuda_cross_correlate<<<gridSize, blockSize>>>(d_Isg, d_Iss, d_sp, d_gp, npml, nnz, nnx);           cudaMemcpy(h_Isg, d_Isg, nnz * nnx * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_Iss, d_Iss, nnz * nnx * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_Isg);     free(h_Iss);     free(h_sp);     free(h_gp);     cudaFree(d_Isg);     cudaFree(d_Iss);     cudaFree(d_sp);     cudaFree(d_gp);      return 0; } "
    },
    {
        "id": "119",
        "c_code": "#include <stdio.h>  void colorConvert(unsigned char *grayImage, unsigned char *colorImage, int rows, int columns) {     for (int column = 0; column < columns; column++) {         for (int row = 0; row < rows; row++) {             int offset = column + (columns * row);             unsigned char grayValue = 0.07 * colorImage[offset * 3] + 0.71 * colorImage[offset * 3 + 1] + 0.21 * colorImage[offset * 3 + 2];             grayImage[offset] = grayValue;         }     } }  int main() {          const int rows = 2;     const int columns = 2;     unsigned char colorImage[] = {255, 0, 0, 0, 255, 0, 0, 0, 255, 128, 128, 128};     unsigned char grayImage[rows * columns];           colorConvert(grayImage, colorImage, rows, columns);           printf(\"Resultant array grayImage:\\n\");     for (int row = 0; row < rows; row++) {         for (int column = 0; column < columns; column++) {             int offset = column + (columns * row);             printf(\"%u \", grayImage[offset]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void colorConvert(unsigned char* grayImage, unsigned char* colorImage, int rows, int columns) {     int column = blockIdx.x * blockDim.x + threadIdx.x;     int row = blockIdx.y * blockDim.y + threadIdx.y;      if ((column < columns) && (row < rows)) {         int offset = column + (columns * row);         unsigned char grayValue = 0.07 * colorImage[offset * 3] + 0.71 * colorImage[offset * 3 + 1] + 0.21 * colorImage[offset * 3 + 2];         grayImage[offset] = grayValue;     } }  int main() {                int rows = 100;      int columns = 100;      unsigned char* h_grayImage = (unsigned char*)malloc(rows * columns * sizeof(unsigned char));     unsigned char* h_colorImage = (unsigned char*)malloc(rows * columns * 3 * sizeof(unsigned char));      unsigned char* d_grayImage, * d_colorImage;     cudaMalloc((void**)&d_grayImage, rows * columns * sizeof(unsigned char));     cudaMalloc((void**)&d_colorImage, rows * columns * 3 * sizeof(unsigned char));           cudaMemcpy(d_grayImage, h_grayImage, rows * columns * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_colorImage, h_colorImage, rows * columns * 3 * sizeof(unsigned char), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((columns + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y);     colorConvert<<<gridSize, blockSize>>>(d_grayImage, d_colorImage, rows, columns);           cudaMemcpy(h_grayImage, d_grayImage, rows * columns * sizeof(unsigned char), cudaMemcpyDeviceToHost);                 free(h_grayImage);     free(h_colorImage);     cudaFree(d_grayImage);     cudaFree(d_colorImage);      return 0; } "
    },
    {
        "id": "12",
        "c_code": "#include <stdio.h>  void dot_cpu(float *c, float *a, float *b, int size) {     int t_id;     for (t_id = 0; t_id < size; t_id++) {         c[t_id] = a[t_id] * b[t_id];     } }  int main() {          int vectorSize = 5;     float vectorA[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float vectorB[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultVector[vectorSize];      printf(\"\u5411\u91cf A\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorA[i]);     }      printf(\"\\n\u5411\u91cf B\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorB[i]);     }           dot_cpu(resultVector, vectorA, vectorB, vectorSize);      printf(\"\\n\u70b9\u4e58\u540e\u7684\u5411\u91cf C\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", resultVector[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void dotKernel(float* c, float* a, float* b) {     int t_id = blockIdx.x * blockDim.x + threadIdx.x;     c[t_id] = a[t_id] * b[t_id]; }  int main() {          int arraySize = 1000;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_b = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);         h_b[i] = static_cast<float>(2 * i);     }           float* d_a;     float* d_b;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_b, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           dotKernel<<<gridSize, blockSize>>>(d_c, d_a, d_b);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "120",
        "c_code": "#include <stdio.h>  void init_image_array_CPU(unsigned long long int *image, int pixels_per_image) {     for (int my_pixel = 0; my_pixel < pixels_per_image; my_pixel++) {         image[my_pixel] = (unsigned long long int)(0);         my_pixel += pixels_per_image;         image[my_pixel] = (unsigned long long int)(0);         my_pixel += pixels_per_image;         image[my_pixel] = (unsigned long long int)(0);         my_pixel += pixels_per_image;         image[my_pixel] = (unsigned long long int)(0);     } }  int main() {          const int pixels_per_image = 4;     unsigned long long int image[pixels_per_image * 4];            init_image_array_CPU(image, pixels_per_image);           printf(\"Resultant array image:\\n\");     for (int i = 0; i < pixels_per_image * 4; i++) {         printf(\"%llu \", image[i]);     }      return 0; } ",
        "cuda_code": "  #include <stdio.h>   __global__ void init_image_array_GPU(unsigned long long int* image, int pixels_per_image) {     int my_pixel = threadIdx.x + blockIdx.x * blockDim.x;      while (my_pixel < pixels_per_image * 4) {         image[my_pixel] = static_cast<unsigned long long int>(0);         my_pixel += blockDim.x * gridDim.x;     } }  int main() {                int pixels_per_image = 1000;      int num_blocks = 100;     int threads_per_block = 256;      unsigned long long int* h_image = (unsigned long long int*)malloc(pixels_per_image * 4 * sizeof(unsigned long long int));     unsigned long long int* d_image;     cudaMalloc((void**)&d_image, pixels_per_image * 4 * sizeof(unsigned long long int));           cudaMemcpy(d_image, h_image, pixels_per_image * 4 * sizeof(unsigned long long int), cudaMemcpyHostToDevice);           init_image_array_GPU<<<num_blocks, threads_per_block>>>(d_image, pixels_per_image);           cudaMemcpy(h_image, d_image, pixels_per_image * 4 * sizeof(unsigned long long int), cudaMemcpyDeviceToHost);                 free(h_image);     cudaFree(d_image);      return 0; } "
    },
    {
        "id": "121",
        "c_code": "#include <stdio.h>  void diffusion(const double *x0, double *x1, int nx, int ny, double dt) {     int i, j;     auto width = nx + 2;     for (j = 1; j < ny + 1; ++j) {         for (i = 1; i < nx + 1; ++i) {             auto pos = i + j * width;             x1[pos] = x0[pos] + dt * (-4. * x0[pos] + x0[pos - width] + x0[pos + width] + x0[pos - 1] + x0[pos + 1]);         }     } }  int main() {          const int nx = 2;     const int ny = 2;     const double dt = 0.1;     double x0[(nx + 2) * (ny + 2)] = {0.0};      double x1[(nx + 2) * (ny + 2)] = {0.0};           diffusion(x0, x1, nx, ny, dt);           printf(\"Resultant array x1:\\n\");     for (int j = 0; j < ny + 2; j++) {         for (int i = 0; i < nx + 2; i++) {             auto pos = i + j * (nx + 2);             printf(\"%f \", x1[pos]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void diffusion(double* x0, double* x1, int nx, int ny, double dt) {     int i = threadIdx.x + blockDim.x * blockIdx.x + 1;     int j = threadIdx.y + blockDim.y * blockIdx.y + 1;      if (i < nx - 1 && j < ny - 1) {         int pos = nx * j + i;         x1[pos] = x0[pos] + dt * (-4. * x0[pos] + x0[pos - 1] + x0[pos + 1] + x0[pos - nx] + x0[pos + nx]);     } }  int main() {                int nx = 100;      int ny = 100;     double dt = 0.01;      double* h_x0 = (double*)malloc(nx * ny * sizeof(double));     double* h_x1 = (double*)malloc(nx * ny * sizeof(double));      double* d_x0, * d_x1;     cudaMalloc((void**)&d_x0, nx * ny * sizeof(double));     cudaMalloc((void**)&d_x1, nx * ny * sizeof(double));           cudaMemcpy(d_x0, h_x0, nx * ny * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((nx + blockSize.x - 2) / blockSize.x, (ny + blockSize.y - 2) / blockSize.y);     diffusion<<<gridSize, blockSize>>>(d_x0, d_x1, nx, ny, dt);           cudaMemcpy(h_x1, d_x1, nx * ny * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_x0);     free(h_x1);     cudaFree(d_x0);     cudaFree(d_x1);      return 0; } "
    },
    {
        "id": "122",
        "c_code": "#include <stdio.h>  void compute_b_minus_Rx(double *out, double *x, double *b, double *cotans, int *neighbors, int meshStride, int n) {     for (int i = 0; i < n; i++) {         out[i] = b[i];         for (int iN = 0; iN < meshStride; ++iN) {             int neighbor = neighbors[i * meshStride + iN];             double weight = cotans[i * meshStride + iN];             out[i] += weight * x[neighbor];         }     } }  int main() {          const int n = 3;     const int meshStride = 2;     double x[] = {1.0, 2.0, 3.0};     double b[] = {4.0, 5.0, 6.0};     double cotans[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6};     int neighbors[] = {1, 2, 0, 2, 0, 1};     double out[n];           compute_b_minus_Rx(out, x, b, cotans, neighbors, meshStride, n);           printf(\"Resultant array out:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%f \", out[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void compute_b_minus_Rx(double* out, double* x, double* b, double* cotans, int* neighbors, int meshStride, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = gridDim.x * blockDim.x;      for (int i = index; i < n; i += stride) {         out[i] = b[i];          for (int iN = 0; iN < meshStride; ++iN) {             int neighbor = neighbors[i * meshStride + iN];             double weight = cotans[i * meshStride + iN];             out[i] += weight * x[neighbor];         }     } }  int main() {                int n = 100;      int meshStride = 5;       double* h_out = (double*)malloc(n * sizeof(double));     double* h_x = (double*)malloc(n * sizeof(double));     double* h_b = (double*)malloc(n * sizeof(double));     double* h_cotans = (double*)malloc(n * meshStride * sizeof(double));     int* h_neighbors = (int*)malloc(n * meshStride * sizeof(int));      double* d_out, * d_x, * d_b, * d_cotans;     int* d_neighbors;      cudaMalloc((void**)&d_out, n * sizeof(double));     cudaMalloc((void**)&d_x, n * sizeof(double));     cudaMalloc((void**)&d_b, n * sizeof(double));     cudaMalloc((void**)&d_cotans, n * meshStride * sizeof(double));     cudaMalloc((void**)&d_neighbors, n * meshStride * sizeof(int));           cudaMemcpy(d_x, h_x, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_cotans, h_cotans, n * meshStride * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_neighbors, h_neighbors, n * meshStride * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x);     compute_b_minus_Rx<<<gridSize, blockSize>>>(d_out, d_x, d_b, d_cotans, d_neighbors, meshStride, n);           cudaMemcpy(h_out, d_out, n * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_out);     free(h_x);     free(h_b);     free(h_cotans);     free(h_neighbors);     cudaFree(d_out);     cudaFree(d_x);     cudaFree(d_b);     cudaFree(d_cotans);     cudaFree(d_neighbors);      return 0; } "
    },
    {
        "id": "123",
        "c_code": "#include <stdio.h> #include <math.h>  void binarize_weights(float *weights, int n, int size, float *binary) {     int i, f;     for (f = 0; f < n; ++f) {         float mean = 0;         for (i = 0; i < size; ++i) {             mean += fabs(weights[f * size + i]);         }         mean = mean / size;         for (i = 0; i < size; ++i) {             binary[f * size + i] = (weights[f * size + i] > 0) ? mean : -mean;         }     } }  int main() {          const int n = 2;     const int size = 3;     float weights[] = {1.0, -2.0, 3.0, -4.0, 5.0, -6.0};     float binary[n * size];           binarize_weights(weights, n, size, binary);           printf(\"Resultant array binary:\\n\");     for (int f = 0; f < n; f++) {         for (int i = 0; i < size; i++) {             printf(\"%f \", binary[f * size + i]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void binarize_weights_kernel(float* weights, int n, int size, float* binary) {     int f = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (f >= n)         return;      int i = 0;     float mean = 0;      for (i = 0; i < size; ++i) {         mean += abs(weights[f * size + i]);     }      mean = mean / size;      for (i = 0; i < size; ++i) {         binary[f * size + i] = (weights[f * size + i] > 0) ? mean : -mean;     } }  int main() {                int n = 100;      int size = 50;       float* h_weights = (float*)malloc(n * size * sizeof(float));     float* h_binary = (float*)malloc(n * size * sizeof(float));      float* d_weights, * d_binary;     cudaMalloc((void**)&d_weights, n * size * sizeof(float));     cudaMalloc((void**)&d_binary, n * size * sizeof(float));           cudaMemcpy(d_weights, h_weights, n * size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n * size + blockSize.x - 1) / blockSize.x);     binarize_weights_kernel<<<gridSize, blockSize>>>(d_weights, n, size, d_binary);           cudaMemcpy(h_binary, d_binary, n * size * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_weights);     free(h_binary);     cudaFree(d_weights);     cudaFree(d_binary);      return 0; } "
    },
    {
        "id": "124",
        "c_code": "#include <stdio.h>  void gather_points_kernel(int b, int c, int n, int m, const float *points, const int *idx, float *out) {     for (int i = 0; i < b; i++) {         for (int l = 0; l < c; l++) {             for (int j = 0; j < m; j++) {                 int a = idx[i * m + j];                 out[(i * c + l) * m + j] = points[(i * c + l) * n + a];             }         }     } }  int main() {          const int b = 2;     const int c = 3;     const int n = 4;     const int m = 5;     float points[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};     int idx[] = {1, 3, 0, 2, 1, 3, 0, 2, 1, 3};     float out[b * c * m];           gather_points_kernel(b, c, n, m, points, idx, out);           printf(\"Resultant array out:\\n\");     for (int i = 0; i < b; i++) {         for (int l = 0; l < c; l++) {             for (int j = 0; j < m; j++) {                 printf(\"%f \", out[(i * c + l) * m + j]);             }             printf(\"\\n\");         }     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gather_points_kernel(int b, int c, int n, int m, const float* __restrict__ points, const int* __restrict__ idx, float* __restrict__ out) {     for (int i = blockIdx.x; i < b; i += gridDim.x) {         for (int l = blockIdx.y; l < c; l += gridDim.y) {             for (int j = threadIdx.x; j < m; j += blockDim.x) {                 int a = idx[i * m + j];                 out[(i * c + l) * m + j] = points[(i * c + l) * n + a];             }         }     } }  int main() {                int b = 100;      int c = 3;     int n = 500;     int m = 10;      float* h_points = (float*)malloc(b * c * n * sizeof(float));     int* h_idx = (int*)malloc(b * m * sizeof(int));     float* h_out = (float*)malloc(b * c * m * sizeof(float));      float* d_points, * d_out;     int* d_idx;      cudaMalloc((void**)&d_points, b * c * n * sizeof(float));     cudaMalloc((void**)&d_idx, b * m * sizeof(int));     cudaMalloc((void**)&d_out, b * c * m * sizeof(float));           cudaMemcpy(d_points, h_points, b * c * n * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_idx, h_idx, b * m * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize(b, c);       gather_points_kernel<<<gridSize, blockSize>>>(b, c, n, m, d_points, d_idx, d_out);           cudaMemcpy(h_out, d_out, b * c * m * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_points);     free(h_idx);     free(h_out);     cudaFree(d_points);     cudaFree(d_idx);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "125",
        "c_code": "#include <stdio.h>  void matrix_mult(int left_rows, int shared_dimensions, int right_columns, float *left, float *right, float *result) {     int row, column, cell;     for (row = 0; row < left_rows; row++) {         for (column = 0; column < right_columns; column++) {             result[row * right_columns + column] = 0;             for (cell = 0; cell < shared_dimensions; cell++) {                 result[row * right_columns + column] += left[row * shared_dimensions + cell] * right[cell * right_columns + column];             }         }     } }  int main() {          const int left_rows = 2;     const int shared_dimensions = 3;     const int right_columns = 4;     float left[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float right[] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0};     float result[left_rows * right_columns];           matrix_mult(left_rows, shared_dimensions, right_columns, left, right, result);           printf(\"Resultant array result:\\n\");     for (int i = 0; i < left_rows; i++) {         for (int j = 0; j < right_columns; j++) {             printf(\"%f \", result[i * right_columns + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gpu_matrix_mult(int left_rows, int shared_dimensions, int right_columns, float* left, float* right, float* result) {     int row = blockIdx.y * blockDim.y + threadIdx.y;     int column = blockIdx.x * blockDim.x + threadIdx.x;      if (row < left_rows && column < right_columns) {         int index = row * right_columns + column;         result[index] = 0;          for (int cell = 0; cell < shared_dimensions; cell++) {             result[index] += left[row * shared_dimensions + cell] * right[cell * right_columns + column];         }     } }  int main() {                int left_rows = 100;      int shared_dimensions = 50;     int right_columns = 200;      float* h_left = (float*)malloc(left_rows * shared_dimensions * sizeof(float));     float* h_right = (float*)malloc(shared_dimensions * right_columns * sizeof(float));     float* h_result = (float*)malloc(left_rows * right_columns * sizeof(float));      float* d_left, * d_right, * d_result;     cudaMalloc((void**)&d_left, left_rows * shared_dimensions * sizeof(float));     cudaMalloc((void**)&d_right, shared_dimensions * right_columns * sizeof(float));     cudaMalloc((void**)&d_result, left_rows * right_columns * sizeof(float));           cudaMemcpy(d_left, h_left, left_rows * shared_dimensions * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_right, h_right, shared_dimensions * right_columns * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((right_columns + blockSize.x - 1) / blockSize.x, (left_rows + blockSize.y - 1) / blockSize.y);     gpu_matrix_mult<<<gridSize, blockSize>>>(left_rows, shared_dimensions, right_columns, d_left, d_right, d_result);           cudaMemcpy(h_result, d_result, left_rows * right_columns * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_left);     free(h_right);     free(h_result);     cudaFree(d_left);     cudaFree(d_right);     cudaFree(d_result);      return 0; } "
    },
    {
        "id": "126",
        "c_code": "#include <stdio.h>  void matrixMultiplication_cpu(int *host_a, int *host_b, int *host_c, int row_a, int col_a, int col_b) {     for (int i = 0; i < row_a; ++i) {         for (int j = 0; j < col_b; ++j) {             int tmp = 0;             for (int k = 0; k < col_a; ++k) {                 tmp += host_a[i * col_a + k] * host_b[k * col_b + j];             }             host_c[i * col_b + j] = tmp;         }     } }  int main() {          const int row_a = 2;     const int col_a = 3;     const int col_b = 4;     int host_a[] = {1, 2, 3, 4, 5, 6};     int host_b[] = {7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18};     int host_c[row_a * col_b];           matrixMultiplication_cpu(host_a, host_b, host_c, row_a, col_a, col_b);           printf(\"Resultant array host_c:\\n\");     for (int i = 0; i < row_a; i++) {         for (int j = 0; j < col_b; j++) {             printf(\"%d \", host_c[i * col_b + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void matrixMultiplication(int* dev_a, int* dev_b, int* dev_c, int row_a, int col_a, int col_b) {     int row = threadIdx.y + blockIdx.y * blockDim.y;     int col = threadIdx.x + blockIdx.x * blockDim.x;     int ret = 0;      if (row < row_a && col < col_b) {         for (int i = 0; i < col_a; ++i) {             ret += dev_a[row * col_a + i] * dev_b[i * col_b + col];         }          dev_c[row * col_b + col] = ret;     } }  int main() {                int row_a = 100;      int col_a = 50;     int col_b = 200;      int* h_a = (int*)malloc(row_a * col_a * sizeof(int));     int* h_b = (int*)malloc(col_a * col_b * sizeof(int));     int* h_c = (int*)malloc(row_a * col_b * sizeof(int));      int* d_a, * d_b, * d_c;     cudaMalloc((void**)&d_a, row_a * col_a * sizeof(int));     cudaMalloc((void**)&d_b, col_a * col_b * sizeof(int));     cudaMalloc((void**)&d_c, row_a * col_b * sizeof(int));           cudaMemcpy(d_a, h_a, row_a * col_a * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, col_a * col_b * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((col_b + blockSize.x - 1) / blockSize.x, (row_a + blockSize.y - 1) / blockSize.y);     matrixMultiplication<<<gridSize, blockSize>>>(d_a, d_b, d_c, row_a, col_a, col_b);           cudaMemcpy(h_c, d_c, row_a * col_b * sizeof(int), cudaMemcpyDeviceToHost);                 free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "127",
        "c_code": "#include <stdio.h>  void Backwardsub(double *U, double *RES, double *UN, double *UE, double *LPR, int NI, int NJ, int End, int J, int n) {     for (int i = 0; i < n; i++) {         int IJ = ((End - i) * NI) + (J - (End - i));         RES[IJ] = RES[IJ] - UN[IJ] * RES[IJ + 1] - UE[IJ] * RES[IJ + NJ];         U[IJ] = U[IJ] + RES[IJ];     } }  int main() {          const int NI = 3;     const int NJ = 3;     const int End = 1;     const int J = 1;     const int n = 1;     double U[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};     double RES[] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};     double UN[] = {1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0};     double UE[] = {2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0};     double LPR[] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};           Backwardsub(U, RES, UN, UE, LPR, NI, NJ, End, J, n);           printf(\"Resultant array U:\\n\");     for (int i = 0; i < NI; i++) {         for (int j = 0; j < NJ; j++) {             printf(\"%f \", U[i * NJ + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void Backwardsub(double* U, double* RES, double* UN, double* UE, double* LPR, int NI, int NJ, int End, int J, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i < n) {         int IJ = ((End - i) * NI) + (J - (End - i));         RES[IJ] = RES[IJ] - UN[IJ] * RES[IJ + 1] - UE[IJ] * RES[IJ + NJ];         U[IJ] = U[IJ] + RES[IJ];     } }  int main() {                int NI = 100;      int NJ = 100;     int End = 50;     int J = 25;     int n = 10;      double* h_U = (double*)malloc(NI * NJ * sizeof(double));     double* h_RES = (double*)malloc(NI * NJ * sizeof(double));     double* h_UN = (double*)malloc(NI * NJ * sizeof(double));     double* h_UE = (double*)malloc(NI * NJ * sizeof(double));     double* h_LPR = (double*)malloc(NI * NJ * sizeof(double));      double* d_U, * d_RES, * d_UN, * d_UE, * d_LPR;     cudaMalloc((void**)&d_U, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_RES, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_UN, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_UE, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_LPR, NI * NJ * sizeof(double));           cudaMemcpy(d_U, h_U, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_RES, h_RES, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_UN, h_UN, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_UE, h_UE, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_LPR, h_LPR, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x);     Backwardsub<<<gridSize, blockSize>>>(d_U, d_RES, d_UN, d_UE, d_LPR, NI, NJ, End, J, n);           cudaMemcpy(h_U, d_U, NI * NJ * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_U);     free(h_RES);     free(h_UN);     free(h_UE);     free(h_LPR);     cudaFree(d_U);     cudaFree(d_RES);     cudaFree(d_UN);     cudaFree(d_UE);     cudaFree(d_LPR);      return 0; } "
    },
    {
        "id": "128",
        "c_code": "#include <stdio.h>  void convolution_cpu_1d(float *input, const float *mask, float *output, int array_size, int mask_size) {     int MASK_RADIUS = mask_size / 2;     float temp = 0.0f;     int ELEMENT_INDEX = 0;      for (int i = 0; i < array_size; i++) {         temp = 0;          for (int j = 0; j < mask_size; j++) {             ELEMENT_INDEX = i - MASK_RADIUS + j;              if (!(ELEMENT_INDEX < 0 || ELEMENT_INDEX > (array_size - 1))) {                 temp += input[ELEMENT_INDEX] * mask[j];             }         }          output[i] = temp;     } }  int main() {          const int array_size = 10;     const int mask_size = 3;     float input[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0};     float mask[] = {0.1, 0.2, 0.1};     float output[array_size];           convolution_cpu_1d(input, mask, output, array_size, mask_size);           printf(\"Resultant array output:\\n\");     for (int i = 0; i < array_size; i++) {         printf(\"%f \", output[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void convolution_gpu_1d_naive(float* input, float* mask, float* output, int array_size, int mask_size) {     int gid = blockIdx.x * blockDim.x + threadIdx.x;     int MASK_RADIUS = mask_size / 2;     int ELEMENT_INDEX = 0;     float temp = 0.0f;      if (gid < array_size) {         for (int j = 0; j < mask_size; j++) {             ELEMENT_INDEX = gid - MASK_RADIUS + j;             if (!(ELEMENT_INDEX < 0 || ELEMENT_INDEX > (array_size - 1))) {                 temp += input[ELEMENT_INDEX] * mask[j];             }         }          output[gid] = temp;     } }  int main() {                int array_size = 100;      int mask_size = 5;          float* h_input = (float*)malloc(array_size * sizeof(float));     float* h_mask = (float*)malloc(mask_size * sizeof(float));     float* h_output = (float*)malloc(array_size * sizeof(float));      float* d_input, * d_mask, * d_output;     cudaMalloc((void**)&d_input, array_size * sizeof(float));     cudaMalloc((void**)&d_mask, mask_size * sizeof(float));     cudaMalloc((void**)&d_output, array_size * sizeof(float));           cudaMemcpy(d_input, h_input, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_mask, h_mask, mask_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((array_size + blockSize.x - 1) / blockSize.x);     convolution_gpu_1d_naive<<<gridSize, blockSize>>>(d_input, d_mask, d_output, array_size, mask_size);           cudaMemcpy(h_output, d_output, array_size * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_input);     free(h_mask);     free(h_output);     cudaFree(d_input);     cudaFree(d_mask);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "129",
        "c_code": "#include <stdio.h>  void getRho(const int numOfNucl, const double *psi, const double *occNo, double *rho, const char debug) {     *rho = 0;      for (int i = 0; i < numOfNucl; ++i)         *rho += occNo[i] * psi[i] * psi[i];      if (debug == 1)         printf(\"DEBUG: Print of RHO:\\nRHO = %f\\nThis is the last line (RHO).\\n\\n\", *rho); }  int main() {          const int numOfNucl = 3;     const char debug = 1;     double psi[] = {0.1, 0.2, 0.3};     double occNo[] = {1.0, 2.0, 3.0};     double rho;           getRho(numOfNucl, psi, occNo, &rho, debug);           printf(\"Resultant RHO: %f\\n\", rho);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void getRho_cuda(const double* psi, const double* occNo, double* rho) {     extern __shared__ double dcopy[];      dcopy[threadIdx.x] = occNo[threadIdx.x] * psi[threadIdx.x] * psi[threadIdx.x];      __syncthreads();      for (int tc = blockDim.x, stepSize = 1; tc > 0; tc >>= 1, stepSize <<= 1) {         int pa = threadIdx.x * stepSize;         int pb = pa + stepSize;          if (pb < blockDim.x) {             dcopy[pa] += dcopy[pb];         }     }      if (threadIdx.x == 0) {         *rho = dcopy[0];     } }  int main() {                int array_size = 100;       double* h_psi = (double*)malloc(array_size * sizeof(double));     double* h_occNo = (double*)malloc(array_size * sizeof(double));     double* h_rho = (double*)malloc(sizeof(double));      double* d_psi, * d_occNo, * d_rho;     cudaMalloc((void**)&d_psi, array_size * sizeof(double));     cudaMalloc((void**)&d_occNo, array_size * sizeof(double));     cudaMalloc((void**)&d_rho, sizeof(double));           cudaMemcpy(d_psi, h_psi, array_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_occNo, h_occNo, array_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize(1);         int sharedMemorySize = blockSize.x * sizeof(double);      getRho_cuda<<<gridSize, blockSize, sharedMemorySize>>>(d_psi, d_occNo, d_rho);           cudaMemcpy(h_rho, d_rho, sizeof(double), cudaMemcpyDeviceToHost);                 free(h_psi);     free(h_occNo);     free(h_rho);     cudaFree(d_psi);     cudaFree(d_occNo);     cudaFree(d_rho);      return 0; } "
    },
    {
        "id": "13",
        "c_code": "#include <stdio.h>  void matDiagAddInplace_cpu(double *mat, double alpha, int dim) {     for (int i = 0; i < dim; i++) {         mat[i * dim + i] += alpha;     } }  int main() {          int matrixDim = 3;     double matrix[3][3] = {{1.1, 2.2, 3.3},                            {4.4, 5.5, 6.6},                            {7.7, 8.8, 9.9}};     double alpha = 10.0;      printf(\"\u539f\u59cb\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < matrixDim; i++) {         for (int j = 0; j < matrixDim; j++) {             printf(\"%.2f \", matrix[i][j]);         }         printf(\"\\n\");     }           matDiagAddInplace_cpu((double *)matrix, alpha, matrixDim);      printf(\"\\n\u5bf9\u89d2\u7ebf\u5143\u7d20\u52a0\u4e0a\u5e38\u6570\u540e\u7684\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < matrixDim; i++) {         for (int j = 0; j < matrixDim; j++) {             printf(\"%.2f \", matrix[i][j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void matDiagAddInplaceKernel(double* mat, double alpha, int dim) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < dim) {         mat[i * dim + i] += alpha;     } }  int main() {          int matrixDim = 5;           double* h_mat = (double*)malloc(matrixDim * matrixDim * sizeof(double));           for (int i = 0; i < matrixDim * matrixDim; ++i) {         h_mat[i] = static_cast<double>(i);     }           double* d_mat;     cudaMalloc((void**)&d_mat, matrixDim * matrixDim * sizeof(double));           cudaMemcpy(d_mat, h_mat, matrixDim * matrixDim * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (matrixDim * matrixDim + blockSize - 1) / blockSize;           matDiagAddInplaceKernel<<<gridSize, blockSize>>>(d_mat, 2.0, matrixDim);           cudaMemcpy(h_mat, d_mat, matrixDim * matrixDim * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < matrixDim; ++i) {         for (int j = 0; j < matrixDim; ++j) {             printf(\"%f \", h_mat[i * matrixDim + j]);         }         printf(\"\\n\");     }           free(h_mat);     cudaFree(d_mat);      return 0; } "
    },
    {
        "id": "130",
        "c_code": "#include <stdio.h> #include <math.h>  void colLog2SumExp2_cpu(const double *mat, double *buf, int m, int n) {     for (int j = 0; j < n; j++) {         double maximum = mat[j];          for (int i = 1; i < m; i++) {             if (mat[i * n + j] > maximum) {                 maximum = mat[i * n + j];             }         }          double res = 0.0;          for (int i = 0; i < m; i++) {             res += exp(mat[i * n + j] - maximum);         }          buf[j] = log2(res) + maximum;     } }  int main() {          const int m = 3;     const int n = 2;     double mat[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     double buf[n];           colLog2SumExp2_cpu(mat, buf, m, n);           for (int j = 0; j < n; j++) {         printf(\"Resultant buf[%d]: %f\\n\", j, buf[j]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void colLog2SumExp2Kernel(const double* mat, double* buf, int m, int n) {     int j = blockIdx.x * blockDim.x + threadIdx.x;      if (j < n) {         double maximum = mat[j];          for (int i = 1; i < m; i++) {             if (mat[i * n + j] > maximum) {                 maximum = mat[i * n + j];             }         }          double res = 0.0;          for (int i = 0; i < m; i++) {             res += mat[i * n + j] - maximum;         }          buf[j] = res + maximum;     } }  int main() {                int m = 100;      int n = 50;        double* h_mat = (double*)malloc(m * n * sizeof(double));     double* h_buf = (double*)malloc(n * sizeof(double));      double* d_mat, * d_buf;     cudaMalloc((void**)&d_mat, m * n * sizeof(double));     cudaMalloc((void**)&d_buf, n * sizeof(double));           cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x);      colLog2SumExp2Kernel<<<gridSize, blockSize>>>(d_mat, d_buf, m, n);           cudaMemcpy(h_buf, d_buf, n * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_mat);     free(h_buf);     cudaFree(d_mat);     cudaFree(d_buf);      return 0; } "
    },
    {
        "id": "131",
        "c_code": "#include <stdio.h>  void bitPrune_cpu(unsigned char *out, float *in, int frontPrune, int outputlength, int inputLength, int n) {     for (int i = 0; i < n; i++) {         int batch = i / outputlength;         int indexInBatch = i % outputlength;         int batchInJump = batch * inputLength;         int indexOutBatch = i % outputlength;         int batchOutJump = batch * outputlength;         int frontJump = frontPrune;         out[batchOutJump + indexOutBatch] = (char)(in[batchInJump + frontJump + indexInBatch] > 0);     } }  int main() {          const int outputlength = 4;     const int inputLength = 6;     const int n = 8;     float in[] = {1.0, -2.0, 3.0, -4.0, 5.0, -6.0, 7.0, -8.0};     unsigned char out[n];           bitPrune_cpu(out, in, 1, outputlength, inputLength, n);           for (int i = 0; i < n; i++) {         printf(\"Resultant out[%d]: %d\\n\", i, out[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void bitPrune(unsigned char *out, float *in, int frontPrune, int outputLength, int inputLength, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i >= n) {         return;     }      int batch = i / outputLength;     int indexInBatch = i % outputLength;      int batchInJump = batch * inputLength;     int indexOutBatch = i % outputLength;     int batchOutJump = batch * outputLength;      int frontJump = frontPrune;     out[batchOutJump + indexOutBatch] = (char)(in[batchInJump + frontJump + indexInBatch] > 0); }  int main() {          int frontPrune = 10;      int outputLength = 100;      int inputLength = 120;      int n = 1000;       unsigned char *out;      float *in;            cudaSetDevice(0);           unsigned char *d_out;     float *d_in;      cudaMalloc((void **)&d_out, n * outputLength * sizeof(unsigned char));     cudaMalloc((void **)&d_in, n * inputLength * sizeof(float));           cudaMemcpy(d_in, in, n * inputLength * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           bitPrune<<<blocksPerGrid, threadsPerBlock>>>(d_out, d_in, frontPrune, outputLength, inputLength, n);           cudaDeviceSynchronize();           cudaMemcpy(out, d_out, n * outputLength * sizeof(unsigned char), cudaMemcpyDeviceToHost);           cudaFree(d_out);     cudaFree(d_in);      return 0; } "
    },
    {
        "id": "132",
        "c_code": "#include <stdio.h>  void residual(double *out, double *x, double *b, double *cotans, int *neighbors, double *diag, int meshStride, int n) {     for (int i = 0; i < n; i++) {         out[i] = diag[i] * x[i] - b[i];         for (int iN = 0; iN < meshStride; ++iN) {             int neighbor = neighbors[i * meshStride + iN];             double weight = cotans[i * meshStride + iN];             out[i] -= weight * x[neighbor];         }     } }  int main() {          const int n = 5;     double x[] = {1.0, 2.0, 3.0, 4.0, 5.0};     double b[] = {10.0, 20.0, 30.0, 40.0, 50.0};     double cotans[] = {0.1, 0.2, 0.3, 0.4, 0.5};     int neighbors[] = {1, 0, 2, 1, 3, 2, 4, 3, 0, 4, 3, 2};     double diag[] = {2.0, 3.0, 4.0, 5.0, 6.0};     double out[n];           residual(out, x, b, cotans, neighbors, diag, 3, n);           for (int i = 0; i < n; i++) {         printf(\"Resultant out[%d]: %f\\n\", i, out[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void residual(double* out, double* x, double* b, double* cotans, int* neighbors, double* diag, int meshStride, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = gridDim.x * blockDim.x;      for (int i = index; i < n; i += stride) {         out[i] = diag[i] * x[i] - b[i];          for (int iN = 0; iN < meshStride; ++iN) {             int neighbor = neighbors[i * meshStride + iN];             double weight = cotans[i * meshStride + iN];             out[i] -= weight * x[neighbor];         }     } }  int main() {                int n = 100;      int meshStride = 6;       double* h_out = (double*)malloc(n * sizeof(double));     double* h_x = (double*)malloc(n * sizeof(double));     double* h_b = (double*)malloc(n * sizeof(double));     double* h_cotans = (double*)malloc(n * meshStride * sizeof(double));     int* h_neighbors = (int*)malloc(n * meshStride * sizeof(int));     double* h_diag = (double*)malloc(n * sizeof(double));      double* d_out, * d_x, * d_b, * d_cotans, * d_diag;     int* d_neighbors;      cudaMalloc((void**)&d_out, n * sizeof(double));     cudaMalloc((void**)&d_x, n * sizeof(double));     cudaMalloc((void**)&d_b, n * sizeof(double));     cudaMalloc((void**)&d_cotans, n * meshStride * sizeof(double));     cudaMalloc((void**)&d_neighbors, n * meshStride * sizeof(int));     cudaMalloc((void**)&d_diag, n * sizeof(double));           cudaMemcpy(d_out, h_out, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_x, h_x, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_cotans, h_cotans, n * meshStride * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_neighbors, h_neighbors, n * meshStride * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_diag, h_diag, n * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x);      residual<<<gridSize, blockSize>>>(d_out, d_x, d_b, d_cotans, d_neighbors, d_diag, meshStride, n);           cudaMemcpy(h_out, d_out, n * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_out);     free(h_x);     free(h_b);     free(h_cotans);     free(h_neighbors);     free(h_diag);      cudaFree(d_out);     cudaFree(d_x);     cudaFree(d_b);     cudaFree(d_cotans);     cudaFree(d_neighbors);     cudaFree(d_diag);      return 0; } "
    },
    {
        "id": "133",
        "c_code": "#include <stdio.h>  void forward_avgpool_layer(int batch, int c, int h, int w, float *input, float *output) {     int b, i, k;     for (b = 0; b < batch; ++b) {         for (k = 0; k < c; ++k) {             int out_index = k + b * c;             output[out_index] = 0;             for (i = 0; i < h * w; ++i) {                 int in_index = i + h * w * (k + b * c);                 output[out_index] += input[in_index];             }             output[out_index] /= h * w;         }     } }  int main() {          const int batch = 2;     const int channels = 3;     const int height = 4;     const int width = 4;      float input[batch * channels * height * width];     float output[batch * channels];                 forward_avgpool_layer(batch, channels, height, width, input, output);           for (int b = 0; b < batch; ++b) {         for (int c = 0; c < channels; ++c) {             printf(\"Resultant output[%d][%d]: %f\\n\", b, c, output[c + b * channels]);         }     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void forward_avgpool_layer_kernel(int n, int w, int h, int c, float* input, float* output) {     int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (id >= n)         return;      int k = id % c;     id /= c;     int b = id;      int i;     int out_index = (k + c * b);     output[out_index] = 0;      for (i = 0; i < w * h; ++i) {         int in_index = i + h * w * (k + b * c);         output[out_index] += input[in_index];     }      output[out_index] /= w * h; }  int main() {                int n = 100;      int w = 32;       int h = 32;       int c = 3;         float* h_input = (float*)malloc(n * w * h * c * sizeof(float));     float* h_output = (float*)malloc(n * c * sizeof(float));      float* d_input, * d_output;     cudaMalloc((void**)&d_input, n * w * h * c * sizeof(float));     cudaMalloc((void**)&d_output, n * c * sizeof(float));           cudaMemcpy(d_input, h_input, n * w * h * c * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x, 1);       forward_avgpool_layer_kernel<<<gridSize, blockSize>>>(n, w, h, c, d_input, d_output);           cudaMemcpy(h_output, d_output, n * c * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_input);     free(h_output);     cudaFree(d_input);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "134",
        "c_code": "#include <stdio.h>  void convolutionColumnCPU(float *h_Dst, float *h_Src, float *h_Filter, int imageW, int imageH, int filterR) {     int x, y, k;     for (y = 0; y < imageH; y++) {         for (x = 0; x < imageW; x++) {             float sum = 0;             for (k = -filterR; k <= filterR; k++) {                 int d = y + k;                 if (d >= 0 && d < imageH) {                     sum += h_Src[d * imageW + x] * h_Filter[filterR - k];                 }             }             h_Dst[y * imageW + x] = sum;         }     } }  int main() {          const int imageW = 4;     const int imageH = 4;     const int filterR = 1;      float h_Src[imageH * imageW];     float h_Filter[2 * filterR + 1];     float h_Dst[imageH * imageW];                 convolutionColumnCPU(h_Dst, h_Src, h_Filter, imageW, imageH, filterR);           for (int y = 0; y < imageH; ++y) {         for (int x = 0; x < imageW; ++x) {             printf(\"Resultant h_Dst[%d][%d]: %f\\n\", y, x, h_Dst[y * imageW + x]);         }     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void kernel_columns(const float* filter, const float* buffer, float* output, int imageW, int imageH, int filterR) {     int idx_x = threadIdx.x + blockDim.x * blockIdx.x;     int idx_y = threadIdx.y + blockDim.y * blockIdx.y;     int grid_width = gridDim.x * blockDim.x;     int idx = grid_width * idx_y + idx_x;      float sum = 0;      for (int k = -filterR; k <= filterR; k++) {         int d = idx_y + k;          if (d >= 0 && d < imageH) {             sum += buffer[d * imageW + idx_x] * filter[filterR - k];         }     }      output[idx] = sum; }  int main() {                int imageW = 512;         int imageH = 512;         int filterR = 3;           float* h_filter = (float*)malloc((2 * filterR + 1) * sizeof(float));     float* h_buffer = (float*)malloc(imageW * imageH * sizeof(float));     float* h_output = (float*)malloc(imageW * imageH * sizeof(float));      float* d_filter, * d_buffer, * d_output;     cudaMalloc((void**)&d_filter, (2 * filterR + 1) * sizeof(float));     cudaMalloc((void**)&d_buffer, imageW * imageH * sizeof(float));     cudaMalloc((void**)&d_output, imageW * imageH * sizeof(float));           cudaMemcpy(d_filter, h_filter, (2 * filterR + 1) * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_buffer, h_buffer, imageW * imageH * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((imageW + blockSize.x - 1) / blockSize.x, (imageH + blockSize.y - 1) / blockSize.y);      kernel_columns<<<gridSize, blockSize>>>(d_filter, d_buffer, d_output, imageW, imageH, filterR);           cudaMemcpy(h_output, d_output, imageW * imageH * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_filter);     free(h_buffer);     free(h_output);     cudaFree(d_filter);     cudaFree(d_buffer);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "135",
        "c_code": "#include <stdio.h>  void matrMult(float *A, float *B, float *C, int rowsA, int colsA, int colsB) {     for (int i = 0; i < rowsA; ++i) {         for (int j = 0; j < colsB; ++j) {             for (int k = 0; k < colsA; ++k) {                 C[i * colsB + j] += A[i * colsA + k] * B[k * colsB + j];             }         }     } }  int main() {          const int rowsA = 2;     const int colsA = 3;     const int colsB = 2;      float A[rowsA * colsA] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float B[colsA * colsB] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0};     float C[rowsA * colsB] = {0.0};           matrMult(A, B, C, rowsA, colsA, colsB);           for (int i = 0; i < rowsA; ++i) {         for (int j = 0; j < colsB; ++j) {             printf(\"Resultant C[%d][%d]: %f\\n\", i, j, C[i * colsB + j]);         }     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gpuMatrMultD(float* Ad, float* Bd, float* Cd, int rowsA, int colsA, int colsB) {     int bIndx = blockIdx.x;     int bIndy = blockIdx.y;     int tIndx = threadIdx.x;     int tIndy = threadIdx.y;      Cd[(blockDim.x * bIndx + tIndx) * colsB + blockDim.y * bIndy + tIndy] = 0;      for (int k = 0; k < colsA; ++k) {         Cd[(blockDim.x * bIndx + tIndx) * colsB + blockDim.y * bIndy + tIndy] +=             Ad[(blockDim.x * bIndx + tIndx) * colsA + k] * Bd[k * colsB + blockDim.y * bIndy + tIndy];     } }  int main() {                int rowsA = 512;         int colsA = 256;         int colsB = 128;          float* h_Ad = (float*)malloc(rowsA * colsA * sizeof(float));     float* h_Bd = (float*)malloc(colsA * colsB * sizeof(float));     float* h_Cd = (float*)malloc(rowsA * colsB * sizeof(float));      float* d_Ad, * d_Bd, * d_Cd;     cudaMalloc((void**)&d_Ad, rowsA * colsA * sizeof(float));     cudaMalloc((void**)&d_Bd, colsA * colsB * sizeof(float));     cudaMalloc((void**)&d_Cd, rowsA * colsB * sizeof(float));           cudaMemcpy(d_Ad, h_Ad, rowsA * colsA * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Bd, h_Bd, colsA * colsB * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((colsB + blockSize.x - 1) / blockSize.x, (rowsA + blockSize.y - 1) / blockSize.y);      gpuMatrMultD<<<gridSize, blockSize>>>(d_Ad, d_Bd, d_Cd, rowsA, colsA, colsB);           cudaMemcpy(h_Cd, d_Cd, rowsA * colsB * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_Ad);     free(h_Bd);     free(h_Cd);     cudaFree(d_Ad);     cudaFree(d_Bd);     cudaFree(d_Cd);      return 0; } "
    },
    {
        "id": "136",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void add_sources_d(const float *const model, float *wfp, const float *const source_amplitude,                    const int *const sources_z, const int *const sources_x,                    const int nz, const int nx, const int nt, const int ns, const int it) {     int x, b;      for (x = 0; x < nx; x++) {         for (b = 0; b < ns; b++) {             int i = sources_z[b * ns + x] * nx + sources_x[b * ns + x];             int ib = b * nz * nx + i;             wfp[ib] += source_amplitude[b * ns * nt + x * nt + it] * model[i];         }     } }  int main() {          const int nz = 3;     const int nx = 4;     const int nt = 5;     const int ns = 2;     const int it = 3;      float *model = (float *)malloc(nz * nx * sizeof(float));     float *wfp = (float *)malloc(ns * nz * nx * sizeof(float));     float *source_amplitude = (float *)malloc(ns * nt * nx * sizeof(float));     int *sources_z = (int *)malloc(ns * nx * sizeof(int));     int *sources_x = (int *)malloc(ns * nx * sizeof(int));           for (int i = 0; i < nz * nx; ++i) {         model[i] = i + 1.0;     }      for (int i = 0; i < ns * nz * nx; ++i) {         wfp[i] = 0.0;     }      for (int i = 0; i < ns * nt * nx; ++i) {         source_amplitude[i] = i + 0.5;     }      for (int i = 0; i < ns * nx; ++i) {         sources_z[i] = i % nz;         sources_x[i] = i % nx;     }           add_sources_d(model, wfp, source_amplitude, sources_z, sources_x, nz, nx, nt, ns, it);           for (int i = 0; i < ns * nz * nx; ++i) {         printf(\"Resultant wfp[%d]: %f\\n\", i, wfp[i]);     }           free(model);     free(wfp);     free(source_amplitude);     free(sources_z);     free(sources_x);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void add_sources_d(const float* const model, float* wfp, const float* const source_amplitude,                                const int* const sources_z, const int* const sources_x, const int nz, const int nx,                                const int nt, const int ns, const int it) {     int x = threadIdx.x;     int b = blockIdx.x;     int i = sources_z[b * ns + x] * nx + sources_x[b * ns + x];     int ib = b * nz * nx + i;     wfp[ib] += source_amplitude[b * ns * nt + x * nt + it] * model[i]; }  int main() {                int nz = 100;         int nx = 100;         int nt = 100;         int ns = 10;           float* h_model = (float*)malloc(nz * nx * sizeof(float));     float* h_wfp = (float*)malloc(nz * nx * ns * sizeof(float));     float* h_source_amplitude = (float*)malloc(ns * nt * sizeof(float));     int* h_sources_z = (int*)malloc(ns * sizeof(int));     int* h_sources_x = (int*)malloc(ns * sizeof(int));      float* d_model, * d_wfp, * d_source_amplitude;     int* d_sources_z, * d_sources_x;      cudaMalloc((void**)&d_model, nz * nx * sizeof(float));     cudaMalloc((void**)&d_wfp, nz * nx * ns * sizeof(float));     cudaMalloc((void**)&d_source_amplitude, ns * nt * sizeof(float));     cudaMalloc((void**)&d_sources_z, ns * sizeof(int));     cudaMalloc((void**)&d_sources_x, ns * sizeof(int));           cudaMemcpy(d_model, h_model, nz * nx * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_wfp, h_wfp, nz * nx * ns * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_source_amplitude, h_source_amplitude, ns * nt * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_sources_z, h_sources_z, ns * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_sources_x, h_sources_x, ns * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(16);      dim3 gridSize(ns);      int it = 0;       add_sources_d<<<gridSize, blockSize>>>(d_model, d_wfp, d_source_amplitude, d_sources_z, d_sources_x, nz, nx, nt, ns, it);           cudaMemcpy(h_wfp, d_wfp, nz * nx * ns * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_model);     free(h_wfp);     free(h_source_amplitude);     free(h_sources_z);     free(h_sources_x);      cudaFree(d_model);     cudaFree(d_wfp);     cudaFree(d_source_amplitude);     cudaFree(d_sources_z);     cudaFree(d_sources_x);      return 0; } "
    },
    {
        "id": "137",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>  void variance_cpu(float *x, float *mean, int batch, int filters, int spatial, float *variance) {     float scale = 1. / (batch * spatial - 1);     int i, j, k;      for (i = 0; i < filters; ++i) {         variance[i] = 0;          for (j = 0; j < batch; ++j) {             for (k = 0; k < spatial; ++k) {                 int index = j * filters * spatial + i * spatial + k;                 variance[i] += pow((x[index] - mean[i]), 2);             }         }          variance[i] *= scale;     } }  int main() {          const int batch = 2;     const int filters = 3;     const int spatial = 4;      float *x = (float *)malloc(batch * filters * spatial * sizeof(float));     float *mean = (float *)malloc(filters * sizeof(float));     float *variance = (float *)malloc(filters * sizeof(float));           for (int i = 0; i < batch * filters * spatial; ++i) {         x[i] = i + 1.0;     }      for (int i = 0; i < filters; ++i) {         mean[i] = i + 0.5;     }           variance_cpu(x, mean, batch, filters, spatial, variance);           for (int i = 0; i < filters; ++i) {         printf(\"Resultant variance[%d]: %f\\n\", i, variance[i]);     }           free(x);     free(mean);     free(variance);      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void variance_kernel(float* x, float* mean, int batch, int filters, int spatial, float* variance) {     float scale = 1.f / (batch * spatial - 1);     int j, k;     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i >= filters)         return;      variance[i] = 0;      for (j = 0; j < batch; ++j) {         for (k = 0; k < spatial; ++k) {             int index = j * filters * spatial + i * spatial + k;             variance[i] += powf((x[index] - mean[i]), 2);         }     }      variance[i] *= scale; }  int main() {                int batch = 32;          int filters = 64;        int spatial = 128;        float* h_x = (float*)malloc(batch * filters * spatial * sizeof(float));     float* h_mean = (float*)malloc(filters * sizeof(float));     float* h_variance = (float*)malloc(filters * sizeof(float));      float* d_x, * d_mean, * d_variance;     cudaMalloc((void**)&d_x, batch * filters * spatial * sizeof(float));     cudaMalloc((void**)&d_mean, filters * sizeof(float));     cudaMalloc((void**)&d_variance, filters * sizeof(float));           cudaMemcpy(d_x, h_x, batch * filters * spatial * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_mean, h_mean, filters * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((filters + blockSize.x - 1) / blockSize.x, 1);      variance_kernel<<<gridSize, blockSize>>>(d_x, d_mean, batch, filters, spatial, d_variance);           cudaMemcpy(h_variance, d_variance, filters * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_x);     free(h_mean);     free(h_variance);     cudaFree(d_x);     cudaFree(d_mean);     cudaFree(d_variance);      return 0; } "
    },
    {
        "id": "138",
        "c_code": "#include <stdio.h>  void grad_y_cpu(const float *u, float *grad, long depth, long rows, long cols) {     for (int x = 0; x < cols; x++) {         for (int y = 0; y < rows; y++) {             for (int z = 0; z < depth; z++) {                 unsigned long size2d = rows * cols;                 unsigned long long idx = z * size2d + y * cols + x;                 float uidx = u[idx];                  if (y > 0) {                     grad[idx] = (uidx - u[z * size2d + (y - 1) * cols + x]);                 }             }         }     } }  int main() {          long depth = 3;     long rows = 4;     long cols = 5;           float u[depth * rows * cols];           for (int i = 0; i < depth * rows * cols; i++) {         u[i] = 1.0f;     }           float grad[depth * rows * cols];           grad_y_cpu(u, grad, depth, rows, cols);           for (int i = 0; i < depth * rows * cols; i++) {         printf(\"%f \", grad[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void grad_y(const float* u, float* grad, long depth, long rows, long cols) {     unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;     unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;     unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;      if (x >= cols || y >= rows || z >= depth)         return;      unsigned long size2d = rows * cols;     unsigned long long idx = z * size2d + y * cols + x;     float uidx = u[idx];      if (y - 1 >= 0 && y < rows) {         grad[idx] = (uidx - u[z * size2d + (y - 1) * cols + x]);     } }  int main() {                long depth = 16;       long rows = 128;       long cols = 128;        float* h_u = (float*)malloc(depth * rows * cols * sizeof(float));     float* h_grad = (float*)malloc(depth * rows * cols * sizeof(float));      float* d_u, *d_grad;     cudaMalloc((void**)&d_u, depth * rows * cols * sizeof(float));     cudaMalloc((void**)&d_grad, depth * rows * cols * sizeof(float));           cudaMemcpy(d_u, h_u, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16, 1);      dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y, (depth + blockSize.z - 1) / blockSize.z);      grad_y<<<gridSize, blockSize>>>(d_u, d_grad, depth, rows, cols);           cudaMemcpy(h_grad, d_grad, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_u);     free(h_grad);     cudaFree(d_u);     cudaFree(d_grad);      return 0; } "
    },
    {
        "id": "139",
        "c_code": "#include <stdio.h>  void grad_x_cpu(const float *u, float *grad, long depth, long rows, long cols) {     for (int x = 0; x < cols; x++) {         for (int y = 0; y < rows; y++) {             for (int z = 0; z < depth; z++) {                 unsigned long size2d = rows * cols;                 unsigned long long idx = z * size2d + y * cols + x;                 float uidx = u[idx];                  if (x > 0) {                     grad[idx] = (uidx - u[z * size2d + y * cols + (x - 1)]);                 }             }         }     } }  int main() {          long depth = 3;     long rows = 4;     long cols = 5;           float u[depth * rows * cols];           for (int i = 0; i < depth * rows * cols; i++) {         u[i] = 1.0f;     }           float grad[depth * rows * cols];           grad_x_cpu(u, grad, depth, rows, cols);           for (int i = 0; i < depth * rows * cols; i++) {         printf(\"%f \", grad[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void grad_x(const float* u, float* grad, long depth, long rows, long cols) {     unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;     unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;     unsigned long z = threadIdx.z + blockIdx.z *blockDim.z;      if (x >= cols || y >= rows || z >= depth)         return;      unsigned long size2d = rows * cols;     unsigned long long idx = z * size2d + y * cols + x;     float uidx = u[idx];      if (x - 1 >= 0 && x < cols) {         grad[idx] = (uidx - u[z * size2d + y * cols + (x - 1)]);     } }  int main() {                long depth = 16;       long rows = 128;       long cols = 128;        float* h_u = (float*)malloc(depth * rows * cols * sizeof(float));     float* h_grad = (float*)malloc(depth * rows * cols * sizeof(float));      float* d_u, *d_grad;     cudaMalloc((void**)&d_u, depth * rows * cols * sizeof(float));     cudaMalloc((void**)&d_grad, depth * rows * cols * sizeof(float));           cudaMemcpy(d_u, h_u, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16, 1);      dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y, (depth + blockSize.z - 1) / blockSize.z);      grad_x<<<gridSize, blockSize>>>(d_u, d_grad, depth, rows, cols);           cudaMemcpy(h_grad, d_grad, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_u);     free(h_grad);     cudaFree(d_u);     cudaFree(d_grad);      return 0; } "
    },
    {
        "id": "14",
        "c_code": "#include <stdio.h>  void cpuAddCorrAndCorrection(float *L, float *r, int N) {     for (int u = 0; u < N; u++) {         L[u] -= r[u];     } }  int main() {          int arraySize = 5;     float arrayL[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayR[] = {0.5, 1.5, 2.5, 3.5, 4.5};      printf(\"\u6570\u7ec4 L\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayL[i]);     }      printf(\"\\n\u6570\u7ec4 R\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayR[i]);     }           cpuAddCorrAndCorrection(arrayL, arrayR, arraySize);      printf(\"\\n\u76f8\u52a0\u540e\u7684\u6570\u7ec4 L\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayL[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void cudaAddCorrAndCorrection(float* L, float* r, int N) {     int u = (blockIdx.x * blockDim.x) + threadIdx.x;     if (u >= N)         return;          L[u] -= r[u]; }  int main() {          int arraySize = 1000;           float* h_L = (float*)malloc(arraySize * sizeof(float));     float* h_r = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_L[i] = static_cast<float>(i);         h_r[i] = static_cast<float>(2 * i);     }           float* d_L;     float* d_r;     cudaMalloc((void**)&d_L, arraySize * sizeof(float));     cudaMalloc((void**)&d_r, arraySize * sizeof(float));           cudaMemcpy(d_L, h_L, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_r, h_r, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           cudaAddCorrAndCorrection<<<gridSize, blockSize>>>(d_L, d_r, arraySize);           cudaMemcpy(h_L, d_L, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_L[i]);     }           free(h_L);     free(h_r);     cudaFree(d_L);     cudaFree(d_r);      return 0; } "
    },
    {
        "id": "140",
        "c_code": "#include <stdio.h> #include <math.h>  void GraphSum_forward(float *in, float *out, int *indptr, int *indices, int dim, int size) {     for (int src = 0; src < size - 1; src++) {         for (int i = indptr[src]; i < indptr[src + 1]; i++) {             int dst = indices[i];             float coef = 1.0 / sqrtf((indptr[src + 1] - indptr[src]) * (indptr[dst + 1] - indptr[dst]));              for (int j = 0; j < dim; j++) {                 out[src * dim + j] += coef * in[dst * dim + j];             }         }     } }  int main() {          int dim = 3;      int size = 4;            int indptr[5] = {0, 2, 3, 5, 7};     int indices[7] = {1, 2, 0, 3, 0, 2, 3};           float in[size * dim];     float out[size * dim];           for (int i = 0; i < size * dim; i++) {         in[i] = 1.0f;         out[i] = 0.0f;      }           GraphSum_forward(in, out, indptr, indices, dim, size);           for (int i = 0; i < size * dim; i++) {         printf(\"%f \", out[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void cuda_GraphSum_forward_kernel(float* d_in_data, float* d_out_data, int* d_indptr, int* d_indices, int dim, int numNodes) {     int src = blockIdx.x;     int j = threadIdx.x;     int ptr_src_0 = d_indptr[src];     int ptr_stc_1 = d_indptr[src + 1];      for (int i = ptr_src_0; i < ptr_stc_1; i++) {         int dst = d_indices[i];         float coef = 1.0 / sqrtf((ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst]));         d_out_data[src * dim + j] += coef * d_in_data[dst * dim + j];     } }  int main() {                int dim = 256;       int numNodes = 128;        float* h_d_in_data = (float*)malloc(numNodes * dim * sizeof(float));     float* h_d_out_data = (float*)malloc(numNodes * dim * sizeof(float));     int* h_d_indptr = ;     int* h_d_indices = ;      float* d_d_in_data, *d_d_out_data;     int* d_d_indptr, *d_d_indices;     cudaMalloc((void**)&d_d_in_data, numNodes * dim * sizeof(float));     cudaMalloc((void**)&d_d_out_data, numNodes * dim * sizeof(float));     cudaMalloc((void**)&d_d_indptr, );     cudaMalloc((void**)&d_d_indices, );           cudaMemcpy(d_d_in_data, h_d_in_data, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_out_data, h_d_out_data, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_indptr, h_d_indptr, , cudaMemcpyHostToDevice);     cudaMemcpy(d_d_indices, h_d_indices, , cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize(numNodes);      cuda_GraphSum_forward_kernel<<<gridSize, blockSize>>>(d_d_in_data, d_d_out_data, d_d_indptr, d_d_indices, dim, numNodes);           cudaMemcpy(h_d_out_data, d_d_out_data, numNodes * dim * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_d_in_data);     free(h_d_out_data);     cudaFree(d_d_in_data);     cudaFree(d_d_out_data);     cudaFree(d_d_indptr);     cudaFree(d_d_indices);      return 0; } "
    },
    {
        "id": "141",
        "c_code": "#include <stdio.h>  void apply_grayscale(const unsigned char *image, unsigned char *grayimg, int width, int height);  int main() {               int width = 100;       int height = 100;            unsigned char image[width * height * 3];           unsigned char grayimg[width * height];           apply_grayscale(image, grayimg, width, height);                for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             printf(\"%u \", grayimg[y * width + x]);         }         printf(\"\\n\");     }      return 0; }  void apply_grayscale(const unsigned char *image, unsigned char *grayimg, int width, int height) {     for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             const unsigned char R = image[(y * width + x) * 3 + 0];             const unsigned char G = image[(y * width + x) * 3 + 1];             const unsigned char B = image[(y * width + x) * 3 + 2];             unsigned char gray = (307 * R + 604 * G + 113 * B) >> 10;             grayimg[y * width + x] = gray;         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void apply_grayscale(unsigned char* grayimg, const unsigned char* image, int width, int height) {     unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;     unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;      if (x < width && y < height) {         const unsigned char R = image[(y * width + x) * 3 + 0];         const unsigned char G = image[(y * width + x) * 3 + 1];         const unsigned char B = image[(y * width + x) * 3 + 2];         unsigned char gray = (307 * R + 604 * G + 113 * B) >> 10;         grayimg[y * width + x] = gray;     } }  int main() {                int width = 512;       int height = 512;        unsigned char* h_image = ;     unsigned char* h_grayimg = (unsigned char*)malloc(width * height * sizeof(unsigned char));      unsigned char* d_image, *d_grayimg;     cudaMalloc((void**)&d_image, width * height * 3 * sizeof(unsigned char));     cudaMalloc((void**)&d_grayimg, width * height * sizeof(unsigned char));           cudaMemcpy(d_image, h_image, width * height * 3 * sizeof(unsigned char), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y);      apply_grayscale<<<gridSize, blockSize>>>(d_grayimg, d_image, width, height);           cudaMemcpy(h_grayimg, d_grayimg, width * height * sizeof(unsigned char), cudaMemcpyDeviceToHost);                 free(h_grayimg);     cudaFree(d_image);     cudaFree(d_grayimg);      return 0; } "
    },
    {
        "id": "142",
        "c_code": "#include <stdio.h>  void getOffsetBox_cpu(const int *clsIndex, const float *max_coordinate, float *offset, int dims, int batchSize, const float *before_nms_boxes);  int main() {               int dims = 10;              int batchSize = 5;                int clsIndex[batchSize * dims];     float max_coordinate[batchSize * dims * 4];     float offset[batchSize * dims];     float before_nms_boxes[batchSize * dims * 4];           getOffsetBox_cpu(clsIndex, max_coordinate, offset, dims, batchSize, before_nms_boxes);                for (int i = 0; i < batchSize; i++) {         for (int j = 0; j < dims; j++) {             printf(\"%f \", offset[i * dims + j]);         }         printf(\"\\n\");     }      return 0; }  void getOffsetBox_cpu(const int *clsIndex, const float *max_coordinate, float *offset, int dims, int batchSize, const float *before_nms_boxes) {     for (int tid = 0; tid < dims; tid++) {         int numPerbatch = dims;         for (int i = 0; i < batchSize; i++) {             if (before_nms_boxes[i * dims * 4 + tid * 4] == -1) {                 offset[i * numPerbatch + tid] = 0;             } else {                 offset[i * numPerbatch + tid] = clsIndex[i * numPerbatch + tid] * (max_coordinate[i * dims * 4] + 1);             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void getOffsetBox(const int* clsIndex, const float* max_coordinate, float* offset, int dims, int batchSize, const float* before_nms_boxes) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      int numPerbatch = dims;      for (int i = 0; i < batchSize; i++) {         if (before_nms_boxes[i * dims * 4 + tid * 4] == (-1)) {             offset[i * numPerbatch + tid] = 0;         } else {             offset[i * numPerbatch + tid] = clsIndex[i * numPerbatch + tid] * (max_coordinate[i * dims * 4] + 1);         }     } }  int main() {                int dims = 256;       int batchSize = 128;        int* h_clsIndex = ;     float* h_max_coordinate = ;     float* h_offset = (float*)malloc(batchSize * dims * sizeof(float));     float* h_before_nms_boxes = ;      int* d_clsIndex;     float* d_max_coordinate, *d_offset, *d_before_nms_boxes;     cudaMalloc((void**)&d_clsIndex, batchSize * dims * sizeof(int));     cudaMalloc((void**)&d_max_coordinate, batchSize * dims * 4 * sizeof(float));     cudaMalloc((void**)&d_offset, batchSize * dims * sizeof(float));     cudaMalloc((void**)&d_before_nms_boxes, batchSize * dims * 4 * sizeof(float));           cudaMemcpy(d_clsIndex, h_clsIndex, batchSize * dims * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_max_coordinate, h_max_coordinate, batchSize * dims * 4 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_before_nms_boxes, h_before_nms_boxes, batchSize * dims * 4 * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((dims + blockSize.x - 1) / blockSize.x, 1);      getOffsetBox<<<gridSize, blockSize>>>(d_clsIndex, d_max_coordinate, d_offset, dims, batchSize, d_before_nms_boxes);           cudaMemcpy(h_offset, d_offset, batchSize * dims * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_offset);     cudaFree(d_clsIndex);     cudaFree(d_max_coordinate);     cudaFree(d_offset);     cudaFree(d_before_nms_boxes);      return 0; } "
    },
    {
        "id": "143",
        "c_code": "#include <stdio.h>  void sgemm_kernelCPU(const float *host_inputArray1, const float *host_inputArray2, float *host_inputArray3, int M, int N, int K, float alpha, float beta);  int main() {               int M = 3;       int N = 4;     int K = 5;           float host_inputArray1[M * K];     float host_inputArray2[K * N];     float host_inputArray3[M * N];           for (int i = 0; i < M * K; i++) {         host_inputArray1[i] = i + 1;     }      for (int i = 0; i < K * N; i++) {         host_inputArray2[i] = i + 1;     }      for (int i = 0; i < M * N; i++) {         host_inputArray3[i] = 0;     }           sgemm_kernelCPU(host_inputArray1, host_inputArray2, host_inputArray3, M, N, K, 1.0, 0.0);                for (int i = 0; i < M; i++) {         for (int j = 0; j < N; j++) {             printf(\"%f \", host_inputArray3[i * N + j]);         }         printf(\"\\n\");     }      return 0; }  void sgemm_kernelCPU(const float *host_inputArray1, const float *host_inputArray2, float *host_inputArray3, int M, int N, int K, float alpha, float beta) {     for (int row = 0; row < M; row++) {         for (int column = 0; column < N; column++) {             float element_c = 0.f;             for (int e = 0; e < K; e++) {                 element_c += host_inputArray1[row * K + e] * host_inputArray2[e * N + column];             }             host_inputArray3[row * N + column] = alpha * element_c + beta * host_inputArray3[row * N + column];         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void sgemm_kernelGPU(const float* host_inputArray1, const float* host_inputArray2, float* host_inputArray3, int M, int N, int K, float alpha, float beta) {     int column = blockIdx.x * blockDim.x + threadIdx.x;     int row = blockIdx.y * blockDim.y + threadIdx.y;      if (row < M && column < N) {         float element_c = 0.f;          for (int eachElement = 0; eachElement < K; eachElement++) {             element_c += host_inputArray1[row * K + eachElement] * host_inputArray2[eachElement * N + column];         }          host_inputArray3[row * N + column] = alpha * element_c + beta * host_inputArray3[row * N + column];     } }  int main() {                int M = 512;       int N = 512;       int K = 256;        float* h_inputArray1 = ;     float* h_inputArray2 = ;     float* h_inputArray3 = ;      float* d_inputArray1, *d_inputArray2, *d_inputArray3;     cudaMalloc((void**)&d_inputArray1, M * K * sizeof(float));     cudaMalloc((void**)&d_inputArray2, K * N * sizeof(float));     cudaMalloc((void**)&d_inputArray3, M * N * sizeof(float));           cudaMemcpy(d_inputArray1, h_inputArray1, M * K * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_inputArray2, h_inputArray2, K * N * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_inputArray3, h_inputArray3, M * N * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);       dim3 gridSize((N + blockSize.x - 1) / blockSize.x, (M + blockSize.y - 1) / blockSize.y);      sgemm_kernelGPU<<<gridSize, blockSize>>>(d_inputArray1, d_inputArray2, d_inputArray3, M, N, K, 1.0f, 0.0f);           cudaMemcpy(h_inputArray3, d_inputArray3, M * N * sizeof(float), cudaMemcpyDeviceToHost);                 cudaFree(d_inputArray1);     cudaFree(d_inputArray2);     cudaFree(d_inputArray3);      return 0; } "
    },
    {
        "id": "144",
        "c_code": "#include <stdio.h> #include <math.h>  void GraphSum_backward(float *in_grad, float *out_grad, int *indptr, int *indices, int size, int dim);  int main() {               int size = 5;       int dim = 3;              float in_grad[size * dim];     float out_grad[size * dim];     int indptr[size + 1];     int indices[10] = {0, 1, 1, 2, 0, 2, 3, 4, 4, 3};             for (int i = 0; i < size * dim; i++) {         in_grad[i] = 0;         out_grad[i] = i + 1;     }      for (int i = 0; i < size + 1; i++) {         indptr[i] = i * 2;       }           GraphSum_backward(in_grad, out_grad, indptr, indices, size, dim);                for (int i = 0; i < size; i++) {         for (int j = 0; j < dim; j++) {             printf(\"%f \", in_grad[i * dim + j]);         }         printf(\"\\n\");     }      return 0; }  void GraphSum_backward(float *in_grad, float *out_grad, int *indptr, int *indices, int size, int dim) {     for (int src = 0; src < size - 1; src++) {         for (int i = indptr[src]; i < indptr[src + 1]; i++) {             int dst = indices[i];             float coef = 1.0 / sqrtf((indptr[src + 1] - indptr[src]) * (indptr[dst + 1] - indptr[dst]));             for (int j = 0; j < dim; j++) {                 in_grad[src * dim + j] += coef * out_grad[dst * dim + j];             }         }     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void cuda_GraphSum_backward_kernel(float* d_in_grad, float* d_out_grad, int* d_indptr, int* d_indices, int dim, int numNodes) {     int src = blockIdx.x;     int j = threadIdx.x;     int ptr_src_0 = d_indptr[src];     int ptr_stc_1 = d_indptr[src + 1];      #pragma unroll     for (int i = ptr_src_0; i < ptr_stc_1; i++) {         int dst = d_indices[i];         float coef = 1.0 / sqrtf((ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst]));          d_in_grad[src * dim + j] += coef * d_out_grad[dst * dim + j];     } }  int main() {                int dim = 256;       int numNodes = 128;        float* h_d_in_grad = ;     float* h_d_out_grad = ;     int* h_d_indptr = ;     int* h_d_indices = ;      float* d_d_in_grad, *d_d_out_grad;     int* d_d_indptr, *d_d_indices;      cudaMalloc((void**)&d_d_in_grad, numNodes * dim * sizeof(float));     cudaMalloc((void**)&d_d_out_grad, numNodes * dim * sizeof(float));     cudaMalloc((void**)&d_d_indptr, (numNodes + 1) * sizeof(int));     cudaMalloc((void**)&d_d_indices, );           cudaMemcpy(d_d_in_grad, h_d_in_grad, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_out_grad, h_d_out_grad, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_indptr, h_d_indptr, (numNodes + 1) * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_indices, h_d_indices, , cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize(numNodes);      cuda_GraphSum_backward_kernel<<<gridSize, blockSize>>>(d_d_in_grad, d_d_out_grad, d_d_indptr, d_d_indices, dim, numNodes);           cudaMemcpy(h_d_in_grad, d_d_in_grad, numNodes * dim * sizeof(float), cudaMemcpyDeviceToHost);                 cudaFree(d_d_in_grad);     cudaFree(d_d_out_grad);     cudaFree(d_d_indptr);     cudaFree(d_d_indices);      return 0; } "
    },
    {
        "id": "145",
        "c_code": "#include <stdio.h> #include <math.h>  void CDFfunction(float *median, float *stdvLogNormalFrame, float *MeanLogNormalFrame, unsigned char *currentFrame, int pixelsPerFrame);  int main() {               int pixelsPerFrame = 100;             float median[pixelsPerFrame];     float stdvLogNormalFrame[pixelsPerFrame];     float MeanLogNormalFrame[pixelsPerFrame];     unsigned char currentFrame[pixelsPerFrame];           for (int i = 0; i < pixelsPerFrame; i++) {         median[i] = 10.0;         stdvLogNormalFrame[i] = 2.0;         MeanLogNormalFrame[i] = 5.0;         currentFrame[i] = i % 256;       }           CDFfunction(median, stdvLogNormalFrame, MeanLogNormalFrame, currentFrame, pixelsPerFrame);                for (int i = 0; i < pixelsPerFrame; i++) {         printf(\"%u \", currentFrame[i]);     }      return 0; }  void CDFfunction(float *median, float *stdvLogNormalFrame, float *MeanLogNormalFrame, unsigned char *currentFrame, int pixelsPerFrame) {     int pixel;     for (pixel = 0; pixel < pixelsPerFrame; pixel++) {         float newvalue;         float x = currentFrame[pixel];         newvalue = -((log(x) - median[pixel]) - MeanLogNormalFrame[pixel]) / (sqrt(2.0) * stdvLogNormalFrame[pixel]);         float summ = 0.5f + 0.5f * erf(newvalue);         if (summ >= 0.3) {             currentFrame[pixel] = (unsigned char)255;         } else {             currentFrame[pixel] = (unsigned char)0;         }     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void CDFfunction(float* median, float* stdvLogNormalFrame, float* MeanLogNormalFrame, unsigned char* currentFrame, int pixelsPerFrame) {     int pixel = threadIdx.x + blockIdx.x * blockDim.x;      if (pixel < pixelsPerFrame) {         float newvalue;         float x = currentFrame[pixel];          newvalue = -((logf(x) - median[pixel]) - MeanLogNormalFrame[pixel]) / (sqrtf(2) * stdvLogNormalFrame[pixel]);          float summ = 0.5f + 0.5f * erff(newvalue);          if (summ >= 0.3) {             currentFrame[pixel] = (unsigned char)255;         } else {             currentFrame[pixel] = (unsigned char)0;         }     } }  int main() {                int pixelsPerFrame = 1024;        float* h_median = ;     float* h_stdvLogNormalFrame = ;     float* h_MeanLogNormalFrame = ;     unsigned char* h_currentFrame = ;      float* d_median, *d_stdvLogNormalFrame, *d_MeanLogNormalFrame;     unsigned char* d_currentFrame;      cudaMalloc((void**)&d_median, pixelsPerFrame * sizeof(float));     cudaMalloc((void**)&d_stdvLogNormalFrame, pixelsPerFrame * sizeof(float));     cudaMalloc((void**)&d_MeanLogNormalFrame, pixelsPerFrame * sizeof(float));     cudaMalloc((void**)&d_currentFrame, pixelsPerFrame * sizeof(unsigned char));           cudaMemcpy(d_median, h_median, pixelsPerFrame * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_stdvLogNormalFrame, h_stdvLogNormalFrame, pixelsPerFrame * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_MeanLogNormalFrame, h_MeanLogNormalFrame, pixelsPerFrame * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_currentFrame, h_currentFrame, pixelsPerFrame * sizeof(unsigned char), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((pixelsPerFrame + blockSize.x - 1) / blockSize.x);      CDFfunction<<<gridSize, blockSize>>>(d_median, d_stdvLogNormalFrame, d_MeanLogNormalFrame, d_currentFrame, pixelsPerFrame);           cudaMemcpy(h_currentFrame, d_currentFrame, pixelsPerFrame * sizeof(unsigned char), cudaMemcpyDeviceToHost);                 cudaFree(d_median);     cudaFree(d_stdvLogNormalFrame);     cudaFree(d_MeanLogNormalFrame);     cudaFree(d_currentFrame);      return 0; } "
    },
    {
        "id": "146",
        "c_code": "#include <stdio.h>  void mul(float *M, float *N, float *K, float height_M, float width_N, float width_M);  int main() {               float height_M = 3;     float width_N = 4;     float width_M = 2;           float M[height_M * width_M];     float N[width_M * width_N];     float K[height_M * width_N];           for (int i = 0; i < height_M * width_M; i++) {         M[i] = i + 1;     }      for (int i = 0; i < width_M * width_N; i++) {         N[i] = i + 2;     }           mul(M, N, K, height_M, width_N, width_M);                for (int i = 0; i < height_M; i++) {         for (int j = 0; j < width_N; j++) {             printf(\"%f \", K[i * (int)width_N + j]);         }         printf(\"\\n\");     }      return 0; }  void mul(float *M, float *N, float *K, float height_M, float width_N, float width_M) {     for (int i = 0; i < height_M; i++) {         for (int j = 0; j < width_N; j++) {             float sum = 0;             for (int k = 0; k < width_M; k++) {                 float a = M[i * (int)width_M + k];                 float b = N[k * (int)width_N + j];                 sum += a * b;             }             K[i * (int)width_N + j] = sum;         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void matrixmul(float* Md, float* Nd, float* Pd, float width, float width_blk, float height_blk, float width_M, float width_N, float height_M, int m, int n) {     int bx = blockIdx.x;     int by = blockIdx.y;     int tx = threadIdx.x;     int ty = threadIdx.y;     int Row = by * width_blk + ty;     int Col = bx * height_blk + tx;     float pValue = 0;      if (Col < (int)width_N && Row < (int)height_M) {         for (int i = 0; i < width; i++) {             float Melement = Md[Row * (int)width_M + i];             float Nelement = Nd[i * (int)width_N + Col];             pValue += Melement * Nelement;         }         Pd[Row * (int)width_N + Col] = pValue;     } }  int main() {                float* h_Md = ;     float* h_Nd = ;     float* h_Pd = ;      float* d_Md, *d_Nd, *d_Pd;      cudaMalloc((void**)&d_Md, );     cudaMalloc((void**)&d_Nd, );     cudaMalloc((void**)&d_Pd, );           cudaMemcpy(d_Md, h_Md, , cudaMemcpyHostToDevice);     cudaMemcpy(d_Nd, h_Nd, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      matrixmul<<<gridSize, blockSize>>>(d_Md, d_Nd, d_Pd, );           cudaMemcpy(h_Pd, d_Pd, , cudaMemcpyDeviceToHost);                 cudaFree(d_Md);     cudaFree(d_Nd);     cudaFree(d_Pd);      return 0; } "
    },
    {
        "id": "147",
        "c_code": "#include <stdio.h> #include <math.h>  void softmax_x_ent_cpu(int n, float *pred, float *truth, float *delta, float *error);  int main() {               int n = 5;             float pred[n];     float truth[n];     float delta[n];     float error[n];           for (int i = 0; i < n; i++) {         pred[i] = 0.2;         truth[i] = (i == 2) ? 1.0 : 0.0;       }           softmax_x_ent_cpu(n, pred, truth, delta, error);                printf(\"Error: \");     for (int i = 0; i < n; i++) {         printf(\"%f \", error[i]);     }     printf(\"\\n\");      printf(\"Delta: \");     for (int i = 0; i < n; i++) {         printf(\"%f \", delta[i]);     }     printf(\"\\n\");      return 0; }  void softmax_x_ent_cpu(int n, float *pred, float *truth, float *delta, float *error) {     int i;     for (i = 0; i < n; ++i) {         float t = truth[i];         float p = pred[i];         error[i] = (t) ? -log(p) : 0;         delta[i] = t - p;     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void softmax_kernel(float* input, int n, int batch, int batch_offset, int groups, int group_offset, int stride, float temp, float* output) {     int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (id >= batch * groups)         return;      int b = id / groups;     int g = id % groups;     int i;     float sum = 0;     float largest = -INFINITY;      for (i = 0; i < n; ++i) {         int val = (input + b * batch_offset + g * group_offset)[i * stride];         largest = (val > largest) ? val : largest;     }      for (i = 0; i < n; ++i) {         float e = expf((input + b * batch_offset + g * group_offset)[i * stride] / temp - largest / temp);         sum += e;         (output + b * batch_offset + g * group_offset)[i * stride] = e;     }      for (i = 0; i < n; ++i) {         (output + b * batch_offset + g * group_offset)[i * stride] /= sum;     } }  int main() {                float* h_input = ;     float* h_output = ;      float* d_input, *d_output;      cudaMalloc((void**)&d_input, );     cudaMalloc((void**)&d_output, );           cudaMemcpy(d_input, h_input, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      softmax_kernel<<<gridSize, blockSize>>>(d_input, , d_output);           cudaMemcpy(h_output, d_output, , cudaMemcpyDeviceToHost);                 cudaFree(d_input);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "148",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>  void normalize_img(double *image, long int image_size, int bands);  int main() {               long int image_size = 10;       int bands = 3;                        double *image = (double *)malloc(image_size * bands * sizeof(double));           for (long int i = 0; i < image_size * bands; i++) {         image[i] = i + 1;     }           normalize_img(image, image_size, bands);                for (int i = 0; i < bands; i++) {         for (long int j = 0; j < image_size; j++) {             printf(\"%f \", image[i * image_size + j]);         }         printf(\"\\n\");     }      free(image);      return 0; }  void normalize_img(double *image, long int image_size, int bands) {     long int i, j;     long int row;     double *D = (double *)calloc(image_size, sizeof(double));      for (i = 0; i < image_size * bands; i++) {         D[i % image_size] += image[i];     }      for (i = 0; i < image_size; i++) {         D[i] = pow(D[i] + 1.0e-16, -1);     }      for (i = 0; i < bands; i++) {         row = i * image_size;         for (j = 0; j < image_size; j++) {             image[row + j] = image[row + j] * D[j];         }     }      free(D); } ",
        "cuda_code": "#include <stdio.h>   __global__ void normalizacion(float* image_c, int bands, long int image_size, float* normM_c, float* normM1_c) {     long int j, i;     float norm_val = 0, aux = 0, pixel = 0;      i = blockIdx.x * blockDim.x + threadIdx.x;      if (i < image_size) {         for (j = 0; j < bands; j++) {             norm_val += image_c[j * image_size + i];         }          norm_val = 1.0 / (norm_val + 1.0e-16);          for (j = 0; j < bands; j++) {             pixel = image_c[j * image_size + i] * norm_val;             image_c[j * image_size + i] = pixel;             aux += pixel * pixel;         }          normM_c[i] = aux;         normM1_c[i] = aux;     } }  int main() {                float* h_image = ;     float* h_normM = ;     float* h_normM1 = ;      float* d_image, *d_normM, *d_normM1;      cudaMalloc((void**)&d_image, );     cudaMalloc((void**)&d_normM, );     cudaMalloc((void**)&d_normM1, );           cudaMemcpy(d_image, h_image, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      normalizacion<<<gridSize, blockSize>>>(d_image, , d_normM, d_normM1);           cudaMemcpy(h_normM, d_normM, , cudaMemcpyDeviceToHost);     cudaMemcpy(h_normM1, d_normM1, , cudaMemcpyDeviceToHost);                 cudaFree(d_image);     cudaFree(d_normM);     cudaFree(d_normM1);      return 0; } "
    },
    {
        "id": "149",
        "c_code": "#include <stdio.h>  void permuteData_cpu(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize);  int main() {               int num = 2;                int devideNum = 3;          int featureSize = 4;        int priorNum = 2;           int batchSize = 2;                float *input = (float *)malloc(batchSize * num * devideNum * priorNum * featureSize * sizeof(float));     float *output = (float *)malloc(batchSize * num * devideNum * priorNum * sizeof(float));           for (int i = 0; i < batchSize * num * devideNum * priorNum * featureSize; i++) {         input[i] = i + 1;     }           permuteData_cpu(input, output, num, devideNum, featureSize, priorNum, batchSize);                for (int i = 0; i < batchSize; i++) {         for (int j = 0; j < num * devideNum * priorNum; j++) {             printf(\"%f \", output[i * num * devideNum * priorNum + j]);         }         printf(\"\\n\");     }      free(input);     free(output);      return 0; }  void permuteData_cpu(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize) {     for (int tid = 0; tid < num; tid++) {         int numPerbatch = num * devideNum * priorNum;         for (int s = 0; s < batchSize; s++) {             for (int i = 0; i < priorNum; i++) {                 for (int j = 0; j < devideNum; j++) {                     output[s * numPerbatch + tid * priorNum * devideNum + i * devideNum + j] =                         input[s * numPerbatch + (i * devideNum * featureSize) + (j * featureSize) + tid];                 }             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void permuteData(const float* input, float* output, int num, int devideNum, int featureSize, int priorNum, int batchSize) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= num) {         return;     }      int numPerbatch = num * devideNum * priorNum;      for (int s = 0; s < batchSize; s++) {         for (int i = 0; i < priorNum; i++) {             for (int j = 0; j < devideNum; j++) {                 output[s * numPerbatch + tid * priorNum * devideNum + i * devideNum + j] = input[s * numPerbatch + (i * devideNum * featureSize) + (j * featureSize) + tid];             }         }     } }  int main() {                float* h_input = ;     float* h_output = ;      float* d_input, *d_output;      cudaMalloc((void**)&d_input, );     cudaMalloc((void**)&d_output, );           cudaMemcpy(d_input, h_input, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      permuteData<<<gridSize, blockSize>>>(d_input, d_output, );           cudaMemcpy(h_output, d_output, , cudaMemcpyDeviceToHost);                 cudaFree(d_input);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "15",
        "c_code": "#include <stdio.h>  void fill_cpu(int N, float ALPHA, float *X, int INCX) {     int i;     for (i = 0; i < N; ++i) {         X[i * INCX] = ALPHA;     } }  int main() {          int arraySize = 5;     float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float alpha = 2.0;     int incX = 2;      printf(\"\u539f\u59cb\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }           fill_cpu(arraySize, alpha, arrayX, incX);      printf(\"\\n\u586b\u5145\u540e\u7684\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void fill_kernel(int N, float ALPHA, float* X, int INCX) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N)         X[i * INCX] = ALPHA; }  int main() {          int arraySize = 1000;           float ALPHA = 2.0;     int INCX = 2;           float* h_X = (float*)malloc(arraySize * sizeof(float));           float* d_X;     cudaMalloc((void**)&d_X, arraySize * sizeof(float));           dim3 blockSize(256, 1, 1);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1, 1);           fill_kernel<<<gridSize, blockSize>>>(arraySize, ALPHA, d_X, INCX);           cudaMemcpy(h_X, d_X, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_X[i]);     }           free(h_X);     cudaFree(d_X);      return 0; } "
    },
    {
        "id": "150",
        "c_code": "#include <stdio.h> #include <math.h>  void cpuSimpleCorrelator(float *xi, float *xq, float *sr, float *si, int sLength, float *L, int uLength);  int main() {               int sLength = 5;        int uLength = 8;              float xi[uLength + sLength];     float xq[uLength + sLength];     float sr[uLength];     float si[uLength];     float L[uLength];           for (int i = 0; i < uLength + sLength; i++) {         xi[i] = i + 1;         xq[i] = i + 2;     }      for (int i = 0; i < uLength; i++) {         sr[i] = i + 3;         si[i] = i + 4;     }           cpuSimpleCorrelator(xi, xq, sr, si, sLength, L, uLength);                for (int i = 0; i < uLength; i++) {         printf(\"%f \", L[i]);     }      return 0; }  void cpuSimpleCorrelator(float *xi, float *xq, float *sr, float *si, int sLength, float *L, int uLength) {     for (int u = 0; u < uLength; u++) {         float real = 0;         float imag = 0;         float a, b, c, d;          for (int n = u; n < u + sLength; n++) {             a = xi[n];             b = xq[n];             c = sr[n - u];             d = si[n - u] * (-1);             real += (a * c) - (b * d);             imag += (a * d) + (b * c);         }          L[u] = sqrt(real * real + imag * imag);     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void cudaSimpleCorrelator(float* xi, float* xq, float* sr, float* si, int sLength, float* L, int uLength) {     int u = (blockIdx.x * blockDim.x) + threadIdx.x;      if (u >= uLength)         return;      float real = 0;     float imag = 0;     float a, b, c, d;      for (int n = u; n < u + sLength; n++) {         a = xi[n];         b = xq[n];         c = sr[n - u];         d = si[n - u] * (-1);          real += (a * c) - (b * d);         imag += (a * d) + (b * c);     }      L[u] = sqrt(real * real + imag * imag); }  int main() {                float* h_xi = ;     float* h_xq = ;     float* h_sr = ;     float* h_si = ;     float* h_L = ;      float* d_xi, *d_xq, *d_sr, *d_si, *d_L;      cudaMalloc((void**)&d_xi, );     cudaMalloc((void**)&d_xq, );     cudaMalloc((void**)&d_sr, );     cudaMalloc((void**)&d_si, );     cudaMalloc((void**)&d_L, );           cudaMemcpy(d_xi, h_xi, , cudaMemcpyHostToDevice);     cudaMemcpy(d_xq, h_xq, , cudaMemcpyHostToDevice);     cudaMemcpy(d_sr, h_sr, , cudaMemcpyHostToDevice);     cudaMemcpy(d_si, h_si, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      cudaSimpleCorrelator<<<gridSize, blockSize>>>(d_xi, d_xq, d_sr, d_si, );           cudaMemcpy(h_L, d_L, , cudaMemcpyDeviceToHost);                 cudaFree(d_xi);     cudaFree(d_xq);     cudaFree(d_sr);     cudaFree(d_si);     cudaFree(d_L);      return 0; } "
    },
    {
        "id": "151",
        "c_code": "#include <stdio.h>  void convertKinectDisparityToRegularDisparity_cpu(float *d_regularDisparity, int d_regularDisparityPitch, const float *d_KinectDisparity, int d_KinectDisparityPitch, int width, int height);  int main() {               int width = 5;     int height = 3;           float d_KinectDisparity[height][width];     float d_regularDisparity[height][width];           for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             d_KinectDisparity[y][x] = x + y + 1;         }     }           convertKinectDisparityToRegularDisparity_cpu((float *)d_regularDisparity, width * sizeof(float), (float *)d_KinectDisparity, width * sizeof(float), width, height);                for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             printf(\"%f \", d_regularDisparity[y][x]);         }         printf(\"\\n\");     }      return 0; }  void convertKinectDisparityToRegularDisparity_cpu(float *d_regularDisparity, int d_regularDisparityPitch, const float *d_KinectDisparity, int d_KinectDisparityPitch, int width, int height) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < height; y++) {             float d_in = *((float *)((char *)d_KinectDisparity + y * d_KinectDisparityPitch) + x);             float d_out = (d_in == 0.0f) ? 1 : -d_in;             *((float *)((char *)d_regularDisparity + y * d_regularDisparityPitch) + x) = d_out;         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void convertKinectDisparityToRegularDisparity_kernel(float* d_regularDisparity, int d_regularDisparityPitch,                                                                const float* d_KinectDisparity, int d_KinectDisparityPitch,                                                                int width, int height) {     const int x = blockIdx.x * blockDim.x + threadIdx.x;     const int y = blockIdx.y * blockDim.y + threadIdx.y;      if ((x < width) && (y < height)) {         float d_in = *((float*)((char*)d_KinectDisparity + y * d_KinectDisparityPitch) + x);         float d_out = (d_in == 0.0f) ? 1 : -d_in;         *((float*)((char*)d_regularDisparity + y * d_regularDisparityPitch) + x) = d_out;     } }  int main() {                float* h_KinectDisparity = ;     float* h_regularDisparity = ;      float* d_KinectDisparity, *d_regularDisparity;      cudaMalloc((void**)&d_KinectDisparity, );     cudaMalloc((void**)&d_regularDisparity, );           cudaMemcpy(d_KinectDisparity, h_KinectDisparity, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      convertKinectDisparityToRegularDisparity_kernel<<<gridSize, blockSize>>>(d_regularDisparity, );           cudaMemcpy(h_regularDisparity, d_regularDisparity, , cudaMemcpyDeviceToHost);                 cudaFree(d_KinectDisparity);     cudaFree(d_regularDisparity);      return 0; } "
    },
    {
        "id": "152",
        "c_code": "#include <stdio.h>  void runFilterCpu(float *I, float *Q, int samplesLength, float *filter, int filterLength, float *filtered_I, float *filtered_Q, int convLength);  int main() {               int samplesLength = 10;     int filterLength = 3;     int convLength = samplesLength - filterLength + 1;           float I[samplesLength];     float Q[samplesLength];     float filter[filterLength];     float filtered_I[convLength];     float filtered_Q[convLength];           for (int i = 0; i < samplesLength; i++) {         I[i] = i + 1;         Q[i] = i + 2;     }      for (int i = 0; i < filterLength; i++) {         filter[i] = i + 1;     }           runFilterCpu(I, Q, samplesLength, filter, filterLength, filtered_I, filtered_Q, convLength);                printf(\"Filtered I: \");     for (int i = 0; i < convLength; i++) {         printf(\"%f \", filtered_I[i]);     }     printf(\"\\n\");      printf(\"Filtered Q: \");     for (int i = 0; i < convLength; i++) {         printf(\"%f \", filtered_Q[i]);     }     printf(\"\\n\");      return 0; }  void runFilterCpu(float *I, float *Q, int samplesLength, float *filter, int filterLength, float *filtered_I, float *filtered_Q, int convLength) {     for (int sampleIndex = 0; sampleIndex < convLength; sampleIndex++) {         int index;         float sumI, sumQ;         sumI = 0;         sumQ = 0;          for (int j = sampleIndex - filterLength + 1; j <= sampleIndex; j++) {             index = sampleIndex - j;              if ((j < samplesLength) && (j >= 0)) {                 sumI += filter[index] * I[j];                 sumQ += filter[index] * Q[j];             }         }          filtered_I[sampleIndex] = sumI;         filtered_Q[sampleIndex] = sumQ;     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void runFilterCuda(float* I, float* Q, int samplesLength, float* filter, int filterLength,                                float* filtered_I, float* filtered_Q, int convLength) {     int sampleIndex = (blockIdx.x * blockDim.x) + threadIdx.x;      if (sampleIndex >= convLength)         return;      int index;     float sumI, sumQ;      sumI = 0;     sumQ = 0;      for (int j = sampleIndex - filterLength + 1; j <= sampleIndex; j++) {         index = sampleIndex - j;          if ((j < samplesLength) && (j >= 0)) {             sumI += filter[index] * I[j];             sumQ += filter[index] * Q[j];         }     }      filtered_I[sampleIndex] = sumI;     filtered_Q[sampleIndex] = sumQ; }  int main() {                float* h_I = ;     float* h_Q = ;     float* h_filter = ;     float* h_filtered_I = ;     float* h_filtered_Q = ;      float* d_I, *d_Q, *d_filter, *d_filtered_I, *d_filtered_Q;      cudaMalloc((void**)&d_I, );     cudaMalloc((void**)&d_Q, );     cudaMalloc((void**)&d_filter, );     cudaMalloc((void**)&d_filtered_I, );     cudaMalloc((void**)&d_filtered_Q, );           cudaMemcpy(d_I, h_I, , cudaMemcpyHostToDevice);     cudaMemcpy(d_Q, h_Q, , cudaMemcpyHostToDevice);     cudaMemcpy(d_filter, h_filter, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      runFilterCuda<<<gridSize, blockSize>>>(d_I, d_Q, );           cudaMemcpy(h_filtered_I, d_filtered_I, , cudaMemcpyDeviceToHost);     cudaMemcpy(h_filtered_Q, d_filtered_Q, , cudaMemcpyDeviceToHost);                 cudaFree(d_I);     cudaFree(d_Q);     cudaFree(d_filter);     cudaFree(d_filtered_I);     cudaFree(d_filtered_Q);      return 0; } "
    },
    {
        "id": "153",
        "c_code": "#include <stdio.h> #include <math.h>  void l2normalize_cpu(float *x, float *dx, int batch, int filters, int spatial);  int main() {               int batch = 2;     int filters = 3;     int spatial = 4;           float x[batch * filters * spatial];     float dx[batch * filters * spatial];           for (int i = 0; i < batch * filters * spatial; i++) {         x[i] = i + 1;     }           l2normalize_cpu(x, dx, batch, filters, spatial);                printf(\"Normalized x: \");     for (int i = 0; i < batch * filters * spatial; i++) {         printf(\"%f \", x[i]);     }     printf(\"\\n\");      printf(\"dx: \");     for (int i = 0; i < batch * filters * spatial; i++) {         printf(\"%f \", dx[i]);     }     printf(\"\\n\");      return 0; }  void l2normalize_cpu(float *x, float *dx, int batch, int filters, int spatial) {     int b, f, i;      for (b = 0; b < batch; ++b) {         for (i = 0; i < spatial; ++i) {             float sum = 0;              for (f = 0; f < filters; ++f) {                 int index = b * filters * spatial + f * spatial + i;                 sum += powf(x[index], 2);             }              sum = sqrtf(sum);              for (f = 0; f < filters; ++f) {                 int index = b * filters * spatial + f * spatial + i;                 x[index] /= sum;                 dx[index] = (1 - x[index]) / sum;             }         }     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void l2normalize_kernel(int N, float* x, float* dx, int batch, int filters, int spatial) {     int index = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (index >= N)         return;      int b = index / spatial;     int i = index % spatial;     int f;     float sum = 0;      for (f = 0; f < filters; ++f) {         int index = b * filters * spatial + f * spatial + i;         sum += powf(x[index], 2);     }      sum = sqrtf(sum);      if (sum == 0)         sum = 1;      for (f = 0; f < filters; ++f) {         int index = b * filters * spatial + f * spatial + i;         x[index] /= sum;         dx[index] = (1 - x[index]) / sum;     } }  int main() {                float* h_x = ;     float* h_dx = ;      float* d_x, *d_dx;      cudaMalloc((void**)&d_x, );     cudaMalloc((void**)&d_dx, );           cudaMemcpy(d_x, h_x, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      int N = ;     int batch = ;     int filters = ;     int spatial = ;      l2normalize_kernel<<<gridSize, blockSize>>>(N, d_x, d_dx, batch, filters, spatial);           cudaMemcpy(h_dx, d_dx, , cudaMemcpyDeviceToHost);                 cudaFree(d_x);     cudaFree(d_dx);      return 0; } "
    },
    {
        "id": "154",
        "c_code": "#include <stdio.h> #include <math.h>  void distanceMatCalc(long int totalPixels, int availablePixels, int outPixelOffset, int patchSize, float *distMat, float *data, float filtSig);  int main() {               long int totalPixels = 3;     int availablePixels = 2;     int outPixelOffset = 1;     int patchSize = 2;           float distMat[availablePixels * totalPixels];     float data[totalPixels * patchSize * patchSize];           for (long int i = 0; i < totalPixels * patchSize * patchSize; i++) {         data[i] = i + 1;     }           distanceMatCalc(totalPixels, availablePixels, outPixelOffset, patchSize, distMat, data, 1.0);                for (long int i = 0; i < availablePixels * totalPixels; i++) {         printf(\"%f \", distMat[i]);     }     printf(\"\\n\");      return 0; }  void distanceMatCalc(long int totalPixels, int availablePixels, int outPixelOffset, int patchSize, float *distMat, float *data, float filtSig) {     for (long int i = 0; i < availablePixels * totalPixels; i++) {         int data_i = i / totalPixels + outPixelOffset;         int data_j = i % totalPixels;         float tmp = 0.0;          if (data_i != data_j) {             for (int elem = 0; elem < patchSize * patchSize; elem++) {                 float diff = data[data_i * patchSize * patchSize + elem] - data[data_j * patchSize * patchSize + elem];                 tmp += diff * diff;             }             tmp = exp(-tmp / filtSig);         }          distMat[i] = tmp;     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void distanceMatCalc(long int totalPixels, int availablePixels, int outPixelOffset, int patchSize, float* distMat, float* data, float filtSig) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = blockDim.x * gridDim.x;      for (long int i = index; i < availablePixels * totalPixels; i += stride) {         int data_i = i / totalPixels + outPixelOffset;         int data_j = i % totalPixels;         float tmp = 0.0;          if (data_i != data_j) {             for (int elem = 0; elem < patchSize * patchSize; elem++) {                 float diff = (data[data_i * patchSize * patchSize + elem] - data[data_j * patchSize * patchSize + elem]);                 tmp += diff * diff;             }              tmp = exp(-tmp / filtSig);         }          distMat[i] = tmp;     } }  int main() {                float* h_distMat = ;     float* h_data = ;      float* d_distMat, *d_data;      cudaMalloc((void**)&d_distMat, );     cudaMalloc((void**)&d_data, );           cudaMemcpy(d_data, h_data, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      long int totalPixels = ;     int availablePixels = ;     int outPixelOffset = ;     int patchSize = ;     float filtSig = ;      distanceMatCalc<<<gridSize, blockSize>>>(totalPixels, availablePixels, outPixelOffset, patchSize, d_distMat, d_data, filtSig);           cudaMemcpy(h_distMat, d_distMat, , cudaMemcpyDeviceToHost);                 cudaFree(d_distMat);     cudaFree(d_data);      return 0; } "
    },
    {
        "id": "155",
        "c_code": "#include <stdio.h>  void shortcut_kernel_cpu(int size, int minw, int minh, int minc, int stride, int sample, int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out);  int main() {               int size = 3;     int minw = 2;     int minh = 2;     int minc = 2;     int stride = 2;     int sample = 3;     int batch = 4;     int w1 = 1;     int h1 = 1;     int c1 = 1;     int w2 = 2;     int h2 = 2;     int c2 = 2;           float add[size * stride * w1 * h1 * c1 * batch];     float out[sample * w2 * h2 * c2 * batch];           for (int i = 0; i < size * stride * w1 * h1 * c1 * batch; i++) {         add[i] = i + 1;     }      for (int i = 0; i < sample * w2 * h2 * c2 * batch; i++) {         out[i] = i + 2;     }           shortcut_kernel_cpu(size, minw, minh, minc, stride, sample, batch, w1, h1, c1, add, w2, h2, c2, out);                for (int i = 0; i < sample * w2 * h2 * c2 * batch; i++) {         printf(\"%f \", out[i]);     }     printf(\"\\n\");      return 0; }  void shortcut_kernel_cpu(int size, int minw, int minh, int minc, int stride, int sample, int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out) {     for (int id = 0; id < size; id++) {         int i = id % minw;         id /= minw;         int j = id % minh;         id /= minh;         int k = id % minc;         id /= minc;         int b = id % batch;          int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));         int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));          out[out_index] += add[add_index];     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void shortcut_kernel(int size, int minw, int minh, int minc, int stride, int sample, int batch,                                  int w1, int h1, int c1, float* add, int w2, int h2, int c2, float* out) {     int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (id >= size)         return;      int i = id % minw;     id /= minw;     int j = id % minh;     id /= minh;     int k = id % minc;     id /= minc;     int b = id % batch;      int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));     int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));      atomicAdd(&out[out_index], add[add_index]); }  int main() {                float* h_add = ;     float* h_out = ;      float* d_add, *d_out;      cudaMalloc((void**)&d_add, );     cudaMalloc((void**)&d_out, );           cudaMemcpy(d_add, h_add, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      int size = ;     int minw = ;     int minh = ;     int minc = ;     int stride = ;     int sample = ;     int batch = ;     int w1 = ;     int h1 = ;     int c1 = ;     int w2 = ;     int h2 = ;     int c2 = ;      shortcut_kernel<<<gridSize, blockSize>>>(size, minw, minh, minc, stride, sample, batch, w1, h1, c1, d_add, w2, h2, c2, d_out);           cudaMemcpy(h_out, d_out, , cudaMemcpyDeviceToHost);                 cudaFree(d_add);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "156",
        "c_code": "#include <stdio.h>  float dot_cpu(int N, float *X, int INCX, float *Y, int INCY);  int main() {               int N = 5;     int INCX = 1;     int INCY = 1;           float X[N * INCX];     float Y[N * INCY];           for (int i = 0; i < N; i++) {         X[i * INCX] = i + 1;         Y[i * INCY] = i + 2;     }           float result = dot_cpu(N, X, INCX, Y, INCY);                printf(\"Dot Product: %f\\n\", result);      return 0; }  float dot_cpu(int N, float *X, int INCX, float *Y, int INCY) {     int i;     float dot = 0;      for (i = 0; i < N; ++i) {         dot += X[i * INCX] * Y[i * INCY];     }      return dot; } ",
        "cuda_code": "#include <stdio.h>   __global__ void dot_kernel(float* output, float scale, int batch, int n, int size, float* delta) {     int index = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     int f1 = index / n;     int f2 = index % n;      if (f2 <= f1)         return;      float sum = 0;     float norm1 = 0;     float norm2 = 0;     int b, i;      for (b = 0; b < batch; ++b) {         for (i = 0; i < size; ++i) {             int i1 = b * size * n + f1 * size + i;             int i2 = b * size * n + f2 * size + i;             sum += output[i1] * output[i2];             norm1 += output[i1] * output[i1];             norm2 += output[i2] * output[i2];         }     }      norm1 = sqrt(norm1);     norm2 = sqrt(norm2);     float norm = norm1 * norm2;     sum = sum / norm;      for (b = 0; b < batch; ++b) {         for (i = 0; i < size; ++i) {             int i1 = b * size * n + f1 * size + i;             int i2 = b * size * n + f2 * size + i;             delta[i1] += -scale * sum * output[i2] / norm;             delta[i2] += -scale * sum * output[i1] / norm;         }     } }  int main() {                float* h_output = ;     float* h_delta = ;      float* d_output, *d_delta;      cudaMalloc((void**)&d_output, );     cudaMalloc((void**)&d_delta, );           cudaMemcpy(d_output, h_output, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      int batch = ;     int n = ;     int size = ;     float scale = ;      dot_kernel<<<gridSize, blockSize>>>(d_output, scale, batch, n, size, d_delta);           cudaMemcpy(h_delta, d_delta, , cudaMemcpyDeviceToHost);                 cudaFree(d_output);     cudaFree(d_delta);      return 0; } "
    },
    {
        "id": "157",
        "c_code": "#include <stdio.h> #include <math.h>  void k_adam_kernel(float *m, float *v, float *w, const float *d, int max_size, float beta1, float beta2, float beta1_tpower, float beta2_tpower, float learning_rate);  int main() {               int max_size = 5;     float beta1 = 0.9;     float beta2 = 0.999;     float beta1_tpower = 1.0;     float beta2_tpower = 1.0;     float learning_rate = 0.001;           float m[max_size];     float v[max_size];     float w[max_size];     float d[max_size];           for (int i = 0; i < max_size; i++) {         m[i] = i + 1;         v[i] = i + 2;         w[i] = i + 3;         d[i] = i + 4;     }           k_adam_kernel(m, v, w, d, max_size, beta1, beta2, beta1_tpower, beta2_tpower, learning_rate);                printf(\"Updated w: \");     for (int i = 0; i < max_size; i++) {         printf(\"%f \", w[i]);     }     printf(\"\\n\");      return 0; }  void k_adam_kernel(float *m, float *v, float *w, const float *d, int max_size, float beta1, float beta2, float beta1_tpower, float beta2_tpower, float learning_rate) {     const float eps = 1e-8;      for (int i = 0; i < max_size; i++) {         float d_temp = d[i];         m[i] = m[i] * beta1 + d_temp * (1 - beta1);         v[i] = v[i] * beta2 + d_temp * d_temp * (1 - beta2);          float m_hat = m[i] / (1 - beta1_tpower);         float v_hat = sqrt(v[i] / (1 - beta2_tpower)) + eps;          w[i] += (m_hat / v_hat) * (-learning_rate);     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void k_adam_kernel(float *m, float *v, float *w, const float *d, int max_size, float beta1, float beta2, float beta1_tpower, float beta2_tpower, float learning_rate) {     const float eps = 1e-8;          for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < max_size; i += blockDim.x * gridDim.x) {         float d_temp = d[i];         m[i] = m[i] * beta1 + d_temp * (1 - beta1);         v[i] = v[i] * beta2 + d_temp * d_temp * (1 - beta2);         float m_hat = m[i] / (1 - beta1_tpower);         float v_hat = __fsqrt_rn(v[i] / (1 - beta2_tpower)) + eps;         w[i] += (m_hat / v_hat) * (-learning_rate);     } }  int main() {          int max_size = 1000;     float *m, *v, *w, *d;             cudaSetDevice(0);           float *d_m, *d_v, *d_w, *d_d;     cudaMalloc((void **)&d_m, max_size * sizeof(float));     cudaMalloc((void **)&d_v, max_size * sizeof(float));     cudaMalloc((void **)&d_w, max_size * sizeof(float));     cudaMalloc((void **)&d_d, max_size * sizeof(float));           cudaMemcpy(d_m, m, max_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_v, v, max_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_w, w, max_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_d, d, max_size * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (max_size + threadsPerBlock - 1) / threadsPerBlock;           k_adam_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_m, d_v, d_w, d_d, max_size, 0.9, 0.999, 0.9, 0.999, 0.001);           cudaDeviceSynchronize();           cudaMemcpy(w, d_w, max_size * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_m);     cudaFree(d_v);     cudaFree(d_w);     cudaFree(d_d);      return 0; } "
    },
    {
        "id": "158",
        "c_code": "#include <stdio.h>  void convLayer_forward(int N, int M, int C, int H, int W, int K, float *X, float *Wk, float *Y);  int main() {               int N = 1;     int M = 1;     int C = 1;     int H = 5;     int W = 5;     int K = 3;           float X[N * C * H * W];     float Wk[M * C * K * K];     float Y[N * M * (H - K + 1) * (W - K + 1)];           for (int i = 0; i < N * C * H * W; i++) {         X[i] = i + 1;     }      for (int i = 0; i < M * C * K * K; i++) {         Wk[i] = i + 2;     }           convLayer_forward(N, M, C, H, W, K, X, Wk, Y);                for (int i = 0; i < N * M * (H - K + 1) * (W - K + 1); i++) {         printf(\"%f \", Y[i]);     }     printf(\"\\n\");      return 0; }  void convLayer_forward(int N, int M, int C, int H, int W, int K, float *X, float *Wk, float *Y) {     int n, m, c, h, w, p, q;     int H_out = H - K + 1;     int W_out = W - K + 1;      for (n = 0; n < N; n++)         for (m = 0; m < M; m++)             for (h = 0; h < H_out; h++)                 for (w = 0; w < W_out; w++) {                     Y[n * M * H_out * W_out + m * H_out * W_out + h * W_out + w] = 0;                      for (c = 0; c < C; c++)                         for (p = 0; p < K; p++)                             for (q = 0; q < K; q++)                                 Y[n * M * H_out * W_out + m * H_out * W_out + h * W_out + w] +=                                     X[n * C * H * W + c * H * W + (h + p) * W + (w + q)] * Wk[m * C * K * K + c * K * K + p * K + q];                 } } ",
        "cuda_code": "#include <stdio.h>   __global__ void ConvLayerForward_Kernel(int C, int W_grid, int K, float *X, float *W, float *Y) {     int n, m, h, w, c, p, q;          n = blockIdx.x;     m = blockIdx.y;     h = blockIdx.z / W_grid + threadIdx.y;     w = blockIdx.z % W_grid + threadIdx.x;      float acc = 0;      for (c = 0; c < C; c++) {         for (p = 0; p < K; p++) {             for (q = 0; q < K; q++) {                 acc += X[n * C * W_grid * W_grid + c * W_grid * W_grid + (h + p) * W_grid + (w + q)] * W[m * C * K * K + c * K * K + p * K + q];             }         }     }      Y[n * W_grid * W_grid * W_grid + m * W_grid * W_grid + h * W_grid + w] = acc; }  int main() {          int C = 3, W_grid = 4, K = 3;       float *X, *W, *Y;             cudaSetDevice(0);           float *d_X, *d_W, *d_Y;     cudaMalloc((void **)&d_X, C * W_grid * W_grid * sizeof(float));     cudaMalloc((void **)&d_W, C * K * K * sizeof(float));     cudaMalloc((void **)&d_Y, W_grid * W_grid * W_grid * sizeof(float));           cudaMemcpy(d_X, X, C * W_grid * W_grid * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_W, W, C * K * K * sizeof(float), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(K, K);     dim3 blocksPerGrid(W_grid, W_grid, W_grid);           ConvLayerForward_Kernel<<<blocksPerGrid, threadsPerBlock>>>(C, W_grid, K, d_X, d_W, d_Y);           cudaDeviceSynchronize();           cudaMemcpy(Y, d_Y, W_grid * W_grid * W_grid * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_X);     cudaFree(d_W);     cudaFree(d_Y);      return 0; } "
    },
    {
        "id": "159",
        "c_code": "#include <stdio.h>  void opL23_cpu(float *vec, float *vec1, long depth, long rows, long cols);  int main() {               long depth = 2;     long rows = 3;     long cols = 4;           float vec[depth * rows * cols];     float vec1[depth * rows * cols];           for (long i = 0; i < depth * rows * cols; i++) {         vec[i] = i + 1;         vec1[i] = i + 2;     }           opL23_cpu(vec, vec1, depth, rows, cols);                for (long i = 0; i < depth * rows * cols; i++) {         printf(\"%f \", vec[i]);     }     printf(\"\\n\");      return 0; }  void opL23_cpu(float *vec, float *vec1, long depth, long rows, long cols) {     for (int x = 0; x < cols; x++) {         for (int y = 0; y < rows; y++) {             for (int z = 0; z < depth; z++) {                 unsigned long long i = z * rows * cols + y * cols + x;                 unsigned long long j = z * rows * cols + y * cols;                 unsigned long size2d = cols;                 unsigned long size3d = depth * rows * cols + rows * cols + cols;                  if (i + cols + 1 >= size3d)                     return;                  vec[i + cols] = 0.5 * (vec1[i + cols] + vec1[i]);                  if (j + 1 >= size2d)                     return;                  vec[j] = 0.5 * (vec1[j]);             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void opL23(float *vec, float *vec1, long depth, long rows, long cols) {     unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;     unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;     unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;     unsigned long long i = z * rows * cols + y * cols + x;     unsigned long long j = z * rows * cols + y * cols;     unsigned long size2d = cols;     unsigned long size3d = depth * rows * cols + rows * cols + cols;      if (x >= cols || y >= rows || z >= depth)         return;      if (i + cols + 1 >= size3d)         return;      vec[i + cols] = 0.5 * (vec1[i + cols] + vec1[i]);      if (j + 1 >= size2d)         return;      vec[j] = 0.5 * (vec1[j]); }  int main() {          long depth = 3, rows = 4, cols = 5;       float *vec, *vec1;             cudaSetDevice(0);           float *d_vec, *d_vec1;     cudaMalloc((void **)&d_vec, depth * rows * cols * sizeof(float));     cudaMalloc((void **)&d_vec1, depth * rows * cols * sizeof(float));           cudaMemcpy(d_vec, vec, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec1, vec1, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(16, 16, 1);     dim3 blocksPerGrid((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,                        (rows + threadsPerBlock.y - 1) / threadsPerBlock.y,                        (depth + threadsPerBlock.z - 1) / threadsPerBlock.z);           opL23<<<blocksPerGrid, threadsPerBlock>>>(d_vec, d_vec1, depth, rows, cols);           cudaDeviceSynchronize();           cudaMemcpy(vec, d_vec, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_vec);     cudaFree(d_vec1);      return 0; } "
    },
    {
        "id": "16",
        "c_code": "#include <stdio.h>  void scal_cpu(int N, float ALPHA, float *X, int INCX) {     int i;     for (i = 0; i < N; ++i) {         X[i * INCX] *= ALPHA;     } }  int main() {          int arraySize = 5;     float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float alpha = 2.0;     int incX = 2;      printf(\"\u539f\u59cb\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }           scal_cpu(arraySize, alpha, arrayX, incX);      printf(\"\\n\u7f29\u653e\u540e\u7684\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void scal_kernel(int N, float ALPHA, float* X, int INCX) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N)         X[i * INCX] *= ALPHA; }  int main() {          int arraySize = 1000;           float ALPHA = 2.0;     int INCX = 2;           float* h_X = (float*)malloc(arraySize * sizeof(float));           float* d_X;     cudaMalloc((void**)&d_X, arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_X[i] = static_cast<float>(i);     }           cudaMemcpy(d_X, h_X, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256, 1, 1);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1, 1);           scal_kernel<<<gridSize, blockSize>>>(arraySize, ALPHA, d_X, INCX);           cudaMemcpy(h_X, d_X, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_X[i]);     }           free(h_X);     cudaFree(d_X);      return 0; } "
    },
    {
        "id": "160",
        "c_code": "#include <stdio.h>  void upsample_cpu(float *in, int w, int h, int c, int batch, int stride, int forward, float scale, float *out);  int main() {               int w = 2;     int h = 2;     int c = 3;     int batch = 1;     int stride = 2;     int forward = 1;      float scale = 2.0;           float in[batch * w * h * c];     float out[batch * w * h * c * stride * stride];           for (int i = 0; i < batch * w * h * c; i++) {         in[i] = i + 1;     }           upsample_cpu(in, w, h, c, batch, stride, forward, scale, out);                for (int i = 0; i < batch * w * h * c * stride * stride; i++) {         printf(\"%f \", out[i]);     }     printf(\"\\n\");      return 0; }  void upsample_cpu(float *in, int w, int h, int c, int batch, int stride, int forward, float scale, float *out) {     int i, j, k, b;      for (b = 0; b < batch; ++b) {         for (k = 0; k < c; ++k) {             for (j = 0; j < h * stride; ++j) {                 for (i = 0; i < w * stride; ++i) {                     int in_index = b * w * h * c + k * w * h + (j / stride) * w + i / stride;                     int out_index = b * w * h * c * stride * stride + k * w * h * stride * stride + j * w * stride + i;                      if (forward)                         out[out_index] = scale * in[in_index];                     else                         in[in_index] += scale * out[out_index];                 }             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void upsample_kernel(size_t N, float *x, int w, int h, int c, int batch, int stride, int forward, float scale, float *out) {     size_t i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i >= N)         return;      int out_index = i;     int out_w = i % (w * stride);     i = i / (w * stride);     int out_h = i % (h * stride);     i = i / (h * stride);     int out_c = i % c;     i = i / c;     int b = i % batch;     int in_w = out_w / stride;     int in_h = out_h / stride;     int in_c = out_c;     int in_index = b * w * h * c + in_c * w * h + in_h * w + in_w;      if (forward)         atomicAdd(out + out_index, scale * x[in_index]);     else         atomicAdd(x + in_index, scale * out[out_index]); }  int main() {          size_t N = 1000;     int w = 16, h = 16, c = 3, batch = 4, stride = 2, forward = 1;     float scale = 0.5;       float *x, *out;             cudaSetDevice(0);           float *d_x, *d_out;     cudaMalloc((void **)&d_x, N * sizeof(float));     cudaMalloc((void **)&d_out, N * sizeof(float));           cudaMemcpy(d_x, x, N * sizeof(float), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(256);     dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x, 1);           upsample_kernel<<<blocksPerGrid, threadsPerBlock>>>(N, d_x, w, h, c, batch, stride, forward, scale, d_out);           cudaDeviceSynchronize();           cudaMemcpy(out, d_out, N * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_x);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "161",
        "c_code": "#include <stdio.h>  void rgb2yuv_kernel(int img_size, unsigned char *gpu_img_in_r, unsigned char *gpu_img_in_g, unsigned char *gpu_img_in_b,                     unsigned char *gpu_img_out_y, unsigned char *gpu_img_out_u, unsigned char *gpu_img_out_v);  int main() {               int img_size = 5;           unsigned char gpu_img_in_r[img_size];     unsigned char gpu_img_in_g[img_size];     unsigned char gpu_img_in_b[img_size];     unsigned char gpu_img_out_y[img_size];     unsigned char gpu_img_out_u[img_size];     unsigned char gpu_img_out_v[img_size];           for (int i = 0; i < img_size; i++) {         gpu_img_in_r[i] = i + 1;         gpu_img_in_g[i] = i + 2;         gpu_img_in_b[i] = i + 3;     }           rgb2yuv_kernel(img_size, gpu_img_in_r, gpu_img_in_g, gpu_img_in_b, gpu_img_out_y, gpu_img_out_u, gpu_img_out_v);                printf(\"Y: \");     for (int i = 0; i < img_size; i++) {         printf(\"%u \", gpu_img_out_y[i]);     }     printf(\"\\n\");      printf(\"U: \");     for (int i = 0; i < img_size; i++) {         printf(\"%u \", gpu_img_out_u[i]);     }     printf(\"\\n\");      printf(\"V: \");     for (int i = 0; i < img_size; i++) {         printf(\"%u \", gpu_img_out_v[i]);     }     printf(\"\\n\");      return 0; }  void rgb2yuv_kernel(int img_size, unsigned char *gpu_img_in_r, unsigned char *gpu_img_in_g, unsigned char *gpu_img_in_b,                     unsigned char *gpu_img_out_y, unsigned char *gpu_img_out_u, unsigned char *gpu_img_out_v) {     unsigned char r, g, b;      for (int index = 0; index < img_size; index++) {         r = gpu_img_in_r[index];         g = gpu_img_in_g[index];         b = gpu_img_in_b[index];          gpu_img_out_y[index] = (unsigned char)(0.299 * r + 0.587 * g + 0.114 * b);         gpu_img_out_u[index] = (unsigned char)(-0.169 * r - 0.331 * g + 0.499 * b + 128);         gpu_img_out_v[index] = (unsigned char)(0.499 * r - 0.418 * g - 0.0813 * b + 128);     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void rgb2yuv_kernel(int img_size, unsigned char *gpu_img_in_r, unsigned char *gpu_img_in_g, unsigned char *gpu_img_in_b,                                 unsigned char *gpu_img_out_y, unsigned char *gpu_img_out_u, unsigned char *gpu_img_out_v) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < img_size) {         unsigned char r = gpu_img_in_r[index];         unsigned char g = gpu_img_in_g[index];         unsigned char b = gpu_img_in_b[index];          gpu_img_out_y[index] = (unsigned char)(0.299 * r + 0.587 * g + 0.114 * b);         gpu_img_out_u[index] = (unsigned char)(-0.169 * r - 0.331 * g + 0.499 * b + 128);         gpu_img_out_v[index] = (unsigned char)(0.499 * r - 0.418 * g - 0.0813 * b + 128);     } }  int main() {          int img_size = 1000;       unsigned char *gpu_img_in_r, *gpu_img_in_g, *gpu_img_in_b, *gpu_img_out_y, *gpu_img_out_u, *gpu_img_out_v;                cudaSetDevice(0);           unsigned char *d_gpu_img_in_r, *d_gpu_img_in_g, *d_gpu_img_in_b, *d_gpu_img_out_y, *d_gpu_img_out_u, *d_gpu_img_out_v;     cudaMalloc((void **)&d_gpu_img_in_r, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_in_g, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_in_b, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_y, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_u, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_v, img_size * sizeof(unsigned char));           cudaMemcpy(d_gpu_img_in_r, gpu_img_in_r, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_gpu_img_in_g, gpu_img_in_g, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_gpu_img_in_b, gpu_img_in_b, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (img_size + threadsPerBlock - 1) / threadsPerBlock;           rgb2yuv_kernel<<<blocksPerGrid, threadsPerBlock>>>(img_size, d_gpu_img_in_r, d_gpu_img_in_g, d_gpu_img_in_b,                                                        d_gpu_img_out_y, d_gpu_img_out_u, d_gpu_img_out_v);           cudaDeviceSynchronize();           cudaMemcpy(gpu_img_out_y, d_gpu_img_out_y, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);     cudaMemcpy(gpu_img_out_u, d_gpu_img_out_u, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);     cudaMemcpy(gpu_img_out_v, d_gpu_img_out_v, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);           cudaFree(d_gpu_img_in_r);     cudaFree(d_gpu_img_in_g);     cudaFree(d_gpu_img_in_b);     cudaFree(d_gpu_img_out_y);     cudaFree(d_gpu_img_out_u);     cudaFree(d_gpu_img_out_v);      return 0; } "
    },
    {
        "id": "162",
        "c_code": "#include <stdio.h>  void getDRho(const int numOfNucl, const double *psi, const double **dpsi, const double *occNo, double *drho, const char debug);  int main() {               int numOfNucl = 3;     double psi[] = {1.0, 2.0, 3.0};     double *dpsi[numOfNucl];     for (int i = 0; i < numOfNucl; ++i) {         dpsi[i] = new double[3];          for (int j = 0; j < 3; ++j) {             dpsi[i][j] = i + j + 1.0;         }     }     double occNo[] = {0.5, 0.7, 0.9};     double drho[3];     char debug = 1;            getDRho(numOfNucl, psi, (const double **)dpsi, occNo, drho, debug);                printf(\"DRHO: %f %f %f\\n\", drho[0], drho[1], drho[2]);           for (int i = 0; i < numOfNucl; ++i) {         delete[] dpsi[i];     }      return 0; }  void getDRho(const int numOfNucl, const double *psi, const double **dpsi, const double *occNo, double *drho, const char debug) {     drho[0] = 0;     drho[1] = 0;     drho[2] = 0;      for (int i = 0; i < numOfNucl; ++i) {         drho[0] = drho[0] + 2 * occNo[i] * psi[i] * dpsi[i][0];         drho[1] = drho[1] + 2 * occNo[i] * psi[i] * dpsi[i][1];         drho[2] = drho[2] + 2 * occNo[i] * psi[i] * dpsi[i][2];     }      if (debug == 1) {         printf(\"DEBUG \u2581 print \u2581 of \u2581 DRHO:\\n\");         printf(\"\\t%f\\t%f\\t%f\\n\", drho[0], drho[1], drho[2]);         printf(\"This \u2581 is \u2581 the \u2581 last \u2581 line ( DRHO ).\\n\\n\");     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void getDRho_cuda(const double *psi, const double *dpsi, const double *occNo, double *drho) {     extern __shared__ double dcopy[];      unsigned int idx = blockIdx.x + gridDim.x * threadIdx.x;      dcopy[threadIdx.x] = 2 * occNo[threadIdx.x] * psi[threadIdx.x] * dpsi[idx];      __syncthreads();      for (int tc = blockDim.x, stepSize = 1; tc > 0; tc >>= 1, stepSize <<= 1) {         int pa = threadIdx.x * stepSize;         int pb = pa + stepSize;          if (pb < blockDim.x)             dcopy[pa] += dcopy[pb];     }      if (threadIdx.x == 0) {         drho[blockIdx.x] = dcopy[0];     } }  int main() {          int block_size = 256;      int grid_size = 1000;      int shared_memory_size = block_size * sizeof(double);      double *psi, *dpsi, *occNo, *drho;            cudaSetDevice(0);           double *d_psi, *d_dpsi, *d_occNo, *d_drho;     cudaMalloc((void **)&d_psi, grid_size * block_size * sizeof(double));     cudaMalloc((void **)&d_dpsi, grid_size * block_size * sizeof(double));     cudaMalloc((void **)&d_occNo, block_size * sizeof(double));     cudaMalloc((void **)&d_drho, grid_size * sizeof(double));           cudaMemcpy(d_psi, psi, grid_size * block_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_dpsi, dpsi, grid_size * block_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_occNo, occNo, block_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(block_size);     dim3 blocksPerGrid(grid_size);           getDRho_cuda<<<blocksPerGrid, threadsPerBlock, shared_memory_size>>>(d_psi, d_dpsi, d_occNo, d_drho);           cudaDeviceSynchronize();           cudaMemcpy(drho, d_drho, grid_size * sizeof(double), cudaMemcpyDeviceToHost);           cudaFree(d_psi);     cudaFree(d_dpsi);     cudaFree(d_occNo);     cudaFree(d_drho);      return 0; } "
    },
    {
        "id": "163",
        "c_code": "#include <stdio.h>  void opL12_cpu(float *vec, float *vec1, long depth, long rows, long cols);  int main() {               long depth = 3;     long rows = 4;     long cols = 5;           float vec[depth * rows * cols];     float vec1[depth * rows * cols];           for (long i = 0; i < depth * rows * cols; i++) {         vec[i] = i + 1;         vec1[i] = i + 2;     }           opL12_cpu(vec, vec1, depth, rows, cols);                for (long i = 0; i < depth * rows * cols; i++) {         printf(\"%f \", vec[i]);     }     printf(\"\\n\");      return 0; }  void opL12_cpu(float *vec, float *vec1, long depth, long rows, long cols) {     for (int x = 0; x < cols; x++) {         for (int y = 0; y < rows; y++) {             for (int z = 0; z < depth; x++) {                 unsigned long long i = z * rows * cols + y * cols + x;                 unsigned long long j = z * rows * cols + y * cols;                 unsigned long size2d = cols;                 unsigned long size3d = depth * rows * cols + rows * cols + cols;                  if (i + cols + 1 >= size3d)                     return;                  vec[i + 1] = 0.25 * (vec1[i + 1] + vec1[i] + vec1[i + cols + 1] + vec1[i + cols]);                  if (j + 1 >= size2d)                     return;                  vec[j] = 0.25 * (vec1[j] + vec1[j + cols]);             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void opL12(float *vec, float *vec1, long depth, long rows, long cols) {     unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;     unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;     unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;     unsigned long long i = z * rows * cols + y * cols + x;     unsigned long long j = z * rows * cols + y * cols;     unsigned long size2d = cols;     unsigned long size3d = depth * rows * cols + rows * cols + cols;      if (x >= cols || y >= rows || z >= depth)         return;      if (i + cols + 1 >= size3d)         return;      vec[i + 1] = 0.25 * (vec1[i + 1] + vec1[i] + vec1[i + cols + 1] + vec1[i + cols]);      if (j + 1 >= size2d)         return;      vec[j] = 0.25 * (vec1[j] + vec1[j + cols]); }  int main() {          long depth = 3, rows = 4, cols = 5;       float *vec, *vec1;             cudaSetDevice(0);           float *d_vec, *d_vec1;     cudaMalloc((void **)&d_vec, depth * rows * cols * sizeof(float));     cudaMalloc((void **)&d_vec1, depth * rows * cols * sizeof(float));           cudaMemcpy(d_vec, vec, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec1, vec1, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(16, 16, 1);     dim3 blocksPerGrid((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,                        (rows + threadsPerBlock.y - 1) / threadsPerBlock.y,                        (depth + threadsPerBlock.z - 1) / threadsPerBlock.z);           opL12<<<blocksPerGrid, threadsPerBlock>>>(d_vec, d_vec1, depth, rows, cols);           cudaDeviceSynchronize();           cudaMemcpy(vec, d_vec, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_vec);     cudaFree(d_vec1);      return 0; } "
    },
    {
        "id": "164",
        "c_code": "#include <stdio.h>  void cpuBYUSimplified(float *xi, float *xq, float *sr, float *si, int N, int Lq, float *L);  int main() {               int N = 10;     int Lq = 5;           float xi[N * 8 * Lq];     float xq[N * 8 * Lq];     float sr[Lq];     float si[Lq];     float L[N];           for (int i = 0; i < N * 8 * Lq; i++) {         xi[i] = i + 1;         xq[i] = i + 2;     }      for (int i = 0; i < Lq; i++) {         sr[i] = i + 3;         si[i] = i + 4;     }           cpuBYUSimplified(xi, xq, sr, si, N, Lq, L);                for (int i = 0; i < N; i++) {         printf(\"%f \", L[i]);     }     printf(\"\\n\");      return 0; }  void cpuBYUSimplified(float *xi, float *xq, float *sr, float *si, int N, int Lq, float *L) {     for (int u = 0; u < N; u++) {         float uSum = 0;         float r_i, r_q, q_i, q_q;         float realPart, imagPart;          for (int k = 0; k <= 7; k++) {             realPart = 0;             imagPart = 0;              for (int l = 0; l < Lq; l++) {                 r_i = xi[u + k * Lq + l];                 r_q = xq[u + k * Lq + l];                 q_i = sr[l];                 q_q = si[l] * (-1);                  realPart += (r_i * q_i) - (r_q * q_q);                 imagPart += (r_i * q_q) + (r_q * q_i);             }              uSum += (realPart * realPart) + (imagPart * imagPart);         }          L[u] = uSum;     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void cudaBYUSimplified(float *xi, float *xq, float *sr, float *si, int N, int Lq, float *L) {     int u = (blockIdx.x * blockDim.x) + threadIdx.x;      if (u >= N)         return;      float uSum = 0;     float r_i, r_q, q_i, q_q;     float realPart, imagPart;      for (int k = 0; k <= 7; k++) {         realPart = 0;         imagPart = 0;          for (int l = 0; l < Lq; l++) {             r_i = xi[u + k * Lq + l];             r_q = xq[u + k * Lq + l];             q_i = sr[l];             q_q = si[l] * (-1);              realPart += (r_i * q_i) - (r_q * q_q);             imagPart += (r_i * q_q) + (r_q * q_i);         }          uSum += (realPart * realPart) + (imagPart * imagPart);     }      L[u] = uSum; }  int main() {          int N = 1000;       int Lq = 10;        float *xi, *xq, *sr, *si, *L;             cudaSetDevice(0);           float *d_xi, *d_xq, *d_sr, *d_si, *d_L;     cudaMalloc((void **)&d_xi, N * 8 * Lq * sizeof(float));     cudaMalloc((void **)&d_xq, N * 8 * Lq * sizeof(float));     cudaMalloc((void **)&d_sr, Lq * sizeof(float));     cudaMalloc((void **)&d_si, Lq * sizeof(float));     cudaMalloc((void **)&d_L, N * sizeof(float));           cudaMemcpy(d_xi, xi, N * 8 * Lq * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_xq, xq, N * 8 * Lq * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_sr, sr, Lq * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_si, si, Lq * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;           cudaBYUSimplified<<<blocksPerGrid, threadsPerBlock>>>(d_xi, d_xq, d_sr, d_si, N, Lq, d_L);           cudaDeviceSynchronize();           cudaMemcpy(L, d_L, N * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_xi);     cudaFree(d_xq);     cudaFree(d_sr);     cudaFree(d_si);     cudaFree(d_L);      return 0; } "
    },
    {
        "id": "165",
        "c_code": "#include <stdio.h> #include <assert.h>  void shortcut_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float s1, float s2, float *out);  int main() {               int batch = 2;     int w1 = 4, h1 = 4, c1 = 3;     int w2 = 2, h2 = 2, c2 = 2;     float s1 = 0.5, s2 = 0.7;           float add[w1 * h1 * c1 * batch];     float out[w2 * h2 * c2 * batch];           for (int i = 0; i < w1 * h1 * c1 * batch; i++) {         add[i] = i + 1;     }           shortcut_cpu(batch, w1, h1, c1, add, w2, h2, c2, s1, s2, out);                for (int i = 0; i < w2 * h2 * c2 * batch; i++) {         printf(\"%f \", out[i]);     }     printf(\"\\n\");      return 0; }  void shortcut_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float s1, float s2, float *out) {     int stride = w1 / w2;     int sample = w2 / w1;      assert(stride == h1 / h2);     assert(sample == h2 / h1);      if (stride < 1)         stride = 1;     if (sample < 1)         sample = 1;      int minw = (w1 < w2) ? w1 : w2;     int minh = (h1 < h2) ? h1 : h2;     int minc = (c1 < c2) ? c1 : c2;      int i, j, k, b;      for (b = 0; b < batch; ++b) {         for (k = 0; k < minc; ++k) {             for (j = 0; j < minh; ++j) {                 for (i = 0; i < minw; ++i) {                     int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));                     int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));                     out[out_index] = s1 * out[out_index] + s2 * add[add_index];                 }             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void shortcut_kernel(int size, int minw, int minh, int minc, int stride, int sample, int batch, int w1, int h1, int c1,                                 float *add, int w2, int h2, int c2, float s1, float s2, float *out) {     int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (id >= size)         return;      int i = id % minw;     id /= minw;     int j = id % minh;     id /= minh;     int k = id % minc;     id /= minc;     int b = id % batch;      int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));     int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));      out[out_index] = s1 * out[out_index] + s2 * add[add_index]; }  int main() {          int size = 1000;       int minw = 16, minh = 16, minc = 3, stride = 2, sample = 2, batch = 4;     int w1 = 8, h1 = 8, c1 = 3, w2 = 8, h2 = 8, c2 = 3;     float s1 = 0.5, s2 = 0.5;       float *add, *out;                     cudaSetDevice(0);           float *d_add, *d_out;     cudaMalloc((void **)&d_add, minw * stride * sizeof(float));     cudaMalloc((void **)&d_out, size * sizeof(float));           cudaMemcpy(d_add, add, minw * stride * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;           shortcut_kernel<<<blocksPerGrid, threadsPerBlock>>>(size, minw, minh, minc, stride, sample, batch, w1, h1, c1, d_add,                                                         w2, h2, c2, s1, s2, d_out);           cudaDeviceSynchronize();           cudaMemcpy(out, d_out, size * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_add);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "166",
        "c_code": "#include <stdio.h>  void get_before_nms_data_cpu(const float *boxes, const float *scores, const int *labels, const int *index, float *boxes_out, float *scores_out, int *labels_out, int dims);  int main() {               int dims = 5;           float boxes[dims * 4];     float scores[dims];     int labels[dims];     int index[dims];     float boxes_out[dims * 4];     float scores_out[dims];     int labels_out[dims];           for (int i = 0; i < dims * 4; i++) {         boxes[i] = i + 1;     }      for (int i = 0; i < dims; i++) {         scores[i] = i + 0.1;         labels[i] = i;         index[i] = i % 2;      }           get_before_nms_data_cpu(boxes, scores, labels, index, boxes_out, scores_out, labels_out, dims);                for (int i = 0; i < dims; i++) {         printf(\"Box %d: (%f, %f, %f, %f) - Score: %f - Label: %d\\n\", i,                boxes_out[i * 4], boxes_out[i * 4 + 1], boxes_out[i * 4 + 2], boxes_out[i * 4 + 3],                scores_out[i], labels_out[i]);     }      return 0; }  void get_before_nms_data_cpu(const float *boxes, const float *scores, const int *labels, const int *index, float *boxes_out, float *scores_out, int *labels_out, int dims) {     for (int tid = 0; tid < dims; tid++) {         if (index[tid] == 0) {             boxes_out[tid * 4 + 0] = -1;             boxes_out[tid * 4 + 1] = -1;             boxes_out[tid * 4 + 2] = -1;             boxes_out[tid * 4 + 3] = -1;             scores_out[tid] = -1;             labels_out[tid] = -1;         } else {             boxes_out[tid * 4 + 0] = boxes[tid * 4 + 0];             boxes_out[tid * 4 + 1] = boxes[tid * 4 + 1];             boxes_out[tid * 4 + 2] = boxes[tid * 4 + 2];             boxes_out[tid * 4 + 3] = boxes[tid * 4 + 3];             scores_out[tid] = scores[tid];             labels_out[tid] = labels[tid];         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void get_before_nms_data(const float *boxes, const float *scores, const int *labels, const int *index,                                      float *boxes_out, float *scores_out, int *labels_out, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      if (index[tid] == 0) {         boxes_out[tid * 4 + 0] = -1;         boxes_out[tid * 4 + 1] = -1;         boxes_out[tid * 4 + 2] = -1;         boxes_out[tid * 4 + 3] = -1;         scores_out[tid] = -1;         labels_out[tid] = -1;     } else {         boxes_out[tid * 4 + 0] = boxes[tid * 4 + 0];         boxes_out[tid * 4 + 1] = boxes[tid * 4 + 1];         boxes_out[tid * 4 + 2] = boxes[tid * 4 + 2];         boxes_out[tid * 4 + 3] = boxes[tid * 4 + 3];         scores_out[tid] = scores[tid];         labels_out[tid] = labels[tid];     } }  int main() {          int dims = 1000;       float *boxes, *scores, *boxes_out, *scores_out;       int *labels, *index, *labels_out;                           cudaSetDevice(0);           float *d_boxes, *d_scores, *d_boxes_out, *d_scores_out;     int *d_labels, *d_index, *d_labels_out;      cudaMalloc((void **)&d_boxes, dims * 4 * sizeof(float));     cudaMalloc((void **)&d_scores, dims * sizeof(float));     cudaMalloc((void **)&d_labels, dims * sizeof(int));     cudaMalloc((void **)&d_index, dims * sizeof(int));     cudaMalloc((void **)&d_boxes_out, dims * 4 * sizeof(float));     cudaMalloc((void **)&d_scores_out, dims * sizeof(float));     cudaMalloc((void **)&d_labels_out, dims * sizeof(int));           cudaMemcpy(d_boxes, boxes, dims * 4 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_scores, scores, dims * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_labels, labels, dims * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_index, index, dims * sizeof(int), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;           get_before_nms_data<<<blocksPerGrid, threadsPerBlock>>>(d_boxes, d_scores, d_labels, d_index,                                                             d_boxes_out, d_scores_out, d_labels_out, dims);           cudaDeviceSynchronize();           cudaMemcpy(boxes_out, d_boxes_out, dims * 4 * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(scores_out, d_scores_out, dims * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(labels_out, d_labels_out, dims * sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_boxes);     cudaFree(d_scores);     cudaFree(d_labels);     cudaFree(d_index);     cudaFree(d_boxes_out);     cudaFree(d_scores_out);     cudaFree(d_labels_out);      return 0; } "
    },
    {
        "id": "167",
        "c_code": "#include <stdio.h>   float im2col_get_pixel(const float *data_im, int height, int width, int channels, int row, int col, int channel, int pad) {               return 1.0; }  void im2col_cpu(float *data_im, int channels, int height, int width, int ksize, int stride, int pad, float *data_col);  int main() {               int channels = 3;     int height = 4;     int width = 4;     int ksize = 2;     int stride = 2;     int pad = 0;           float data_im[channels * height * width];     float data_col[channels * ksize * ksize * ((height - ksize + 2 * pad) / stride + 1) * ((width - ksize + 2 * pad) / stride + 1)];           for (int i = 0; i < channels * height * width; i++) {         data_im[i] = i + 1;     }           im2col_cpu(data_im, channels, height, width, ksize, stride, pad, data_col);                for (int i = 0; i < channels * ksize * ksize * ((height - ksize + 2 * pad) / stride + 1) * ((width - ksize + 2 * pad) / stride + 1); i++) {         printf(\"data_col[%d] = %f\\n\", i, data_col[i]);     }      return 0; }  void im2col_cpu(float *data_im, int channels, int height, int width, int ksize, int stride, int pad, float *data_col) {     int c, h, w;     int height_col = (height + 2 * pad - ksize) / stride + 1;     int width_col = (width + 2 * pad - ksize) / stride + 1;     int channels_col = channels * ksize * ksize;      for (c = 0; c < channels_col; ++c) {         int w_offset = c % ksize;         int h_offset = (c / ksize) % ksize;         int c_im = c / ksize / ksize;          for (h = 0; h < height_col; ++h) {             for (w = 0; w < width_col; ++w) {                 int im_row = h_offset + h * stride;                 int im_col = w_offset + w * stride;                 int col_index = (c * height_col + h) * width_col + w;                 data_col[col_index] = im2col_get_pixel(data_im, height, width, channels, im_row, im_col, c_im, pad);             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void im2col_gpu_kernel(const int n, const float *data_im, const int height, const int width, const int ksize,                                   const int pad, const int stride, const int height_col, const int width_col,                                   float *data_col) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      for (; index < n; index += blockDim.x * gridDim.x) {         int w_out = index % width_col;         int h_index = index / width_col;         int h_out = h_index % height_col;         int channel_in = h_index / height_col;         int channel_out = channel_in * ksize * ksize;         int h_in = h_out * stride - pad;         int w_in = w_out * stride - pad;          float *data_col_ptr = data_col;         data_col_ptr += (channel_out * height_col + h_out) * width_col + w_out;          const float *data_im_ptr = data_im;         data_im_ptr += (channel_in * height + h_in) * width + w_in;          for (int i = 0; i < ksize; ++i) {             for (int j = 0; j < ksize; ++j) {                 int h = h_in + i;                 int w = w_in + j;                  *data_col_ptr = (h >= 0 && w >= 0 && h < height && w < width) ? data_im_ptr[i * width + j] : 0;                 data_col_ptr += height_col * width_col;             }         }     } }  int main() {          int n = 1000;            int height = 32;         int width = 32;          int ksize = 3;           int pad = 1;             int stride = 1;          int height_col = 30;      int width_col = 30;       float *data_im, *data_col;            cudaSetDevice(0);           float *d_data_im, *d_data_col;     cudaMalloc((void **)&d_data_im, height * width * sizeof(float));     cudaMalloc((void **)&d_data_col, height_col * width_col * ksize * ksize * n * sizeof(float));           cudaMemcpy(d_data_im, data_im, height * width * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           im2col_gpu_kernel<<<blocksPerGrid, threadsPerBlock>>>(n, d_data_im, height, width, ksize, pad, stride,                                                           height_col, width_col, d_data_col);           cudaDeviceSynchronize();           cudaMemcpy(data_col, d_data_col, height_col * width_col * ksize * ksize * n * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_data_im);     cudaFree(d_data_col);      return 0; } "
    },
    {
        "id": "168",
        "c_code": "#include <stdio.h>  void getTopkNum(const float *inputScore, const int *inputIndex, float *outputScore, int *outputIndex, float threshold, const int dims, int *anchorIndex, int *classIndex, const int classNum, int batchSize, int totalScoreNum);  int main() {               int dims = 10;     int batchSize = 3;     int totalScoreNum = 5;     int classNum = 2;     float threshold = 0.5;           float inputScore[batchSize * totalScoreNum];     int inputIndex[batchSize * totalScoreNum];     float outputScore[batchSize * dims];     int outputIndex[batchSize * dims];     int anchorIndex[batchSize * dims];     int classIndex[batchSize * dims];           for (int i = 0; i < batchSize * totalScoreNum; i++) {         inputScore[i] = 0.1 * i;         inputIndex[i] = i;     }           getTopkNum(inputScore, inputIndex, outputScore, outputIndex, threshold, dims, anchorIndex, classIndex, classNum, batchSize, totalScoreNum);                for (int i = 0; i < batchSize * dims; i++) {         printf(\"outputScore[%d] = %f, outputIndex[%d] = %d, anchorIndex[%d] = %d, classIndex[%d] = %d\\n\", i, outputScore[i], i, outputIndex[i], i, anchorIndex[i], i, classIndex[i]);     }      return 0; }  void getTopkNum(const float *inputScore, const int *inputIndex, float *outputScore, int *outputIndex, float threshold, const int dims, int *anchorIndex, int *classIndex, const int classNum, int batchSize, int totalScoreNum) {     for (int tid = 0; tid < dims; tid++) {         for (int i = 0; i < batchSize; i++) {             if (inputScore[i * totalScoreNum + tid] >= threshold) {                 outputScore[i * dims + tid] = inputScore[i * totalScoreNum + tid];                 outputIndex[i * dims + tid] = inputIndex[i * totalScoreNum + tid];                 anchorIndex[i * dims + tid] = outputIndex[i * dims + tid] / classNum;                 classIndex[i * dims + tid] = outputIndex[i * dims + tid] % classNum;             } else {                 outputScore[i * dims + tid] = 0.0f;                 outputIndex[i * dims + tid] = -1;                 anchorIndex[i * dims + tid] = -1;                 classIndex[i * dims + tid] = -1;             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void getTopkNum(const float *inputScore, const int *inputIndex, float *outputScore, int *outputIndex,                             float threshold, const int dims, int *anchorIndex, int *classIndex, const int classNum,                             int batchSize, int totalScoreNum) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      for (int i = 0; i < batchSize; i++) {         if (inputScore[i * totalScoreNum + tid] >= threshold) {             outputScore[i * dims + tid] = inputScore[i * totalScoreNum + tid];             outputIndex[i * dims + tid] = inputIndex[i * totalScoreNum + tid];             anchorIndex[i * dims + tid] = outputIndex[i * dims + tid] / classNum;             classIndex[i * dims + tid] = outputIndex[i * dims + tid] % classNum;         } else {             outputScore[i * dims + tid] = 0.0f;             outputIndex[i * dims + tid] = -1;             anchorIndex[i * dims + tid] = -1;             classIndex[i * dims + tid] = -1;         }     } }  int main() {          int dims = 1000;             float threshold = 0.5;       int classNum = 10;           int batchSize = 4;           int totalScoreNum = 100;      float *inputScore, *outputScore;      int *inputIndex, *outputIndex, *anchorIndex, *classIndex;            cudaSetDevice(0);           float *d_inputScore, *d_outputScore;     int *d_inputIndex, *d_outputIndex, *d_anchorIndex, *d_classIndex;      cudaMalloc((void **)&d_inputScore, batchSize * totalScoreNum * sizeof(float));     cudaMalloc((void **)&d_inputIndex, batchSize * totalScoreNum * sizeof(int));     cudaMalloc((void **)&d_outputScore, batchSize * dims * sizeof(float));     cudaMalloc((void **)&d_outputIndex, batchSize * dims * sizeof(int));     cudaMalloc((void **)&d_anchorIndex, batchSize * dims * sizeof(int));     cudaMalloc((void **)&d_classIndex, batchSize * dims * sizeof(int));           cudaMemcpy(d_inputScore, inputScore, batchSize * totalScoreNum * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_inputIndex, inputIndex, batchSize * totalScoreNum * sizeof(int), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;           getTopkNum<<<blocksPerGrid, threadsPerBlock>>>(d_inputScore, d_inputIndex, d_outputScore, d_outputIndex, threshold,                                                    dims, d_anchorIndex, d_classIndex, classNum, batchSize,                                                    totalScoreNum);           cudaDeviceSynchronize();           cudaMemcpy(outputScore, d_outputScore, batchSize * dims * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(outputIndex, d_outputIndex, batchSize * dims * sizeof(int), cudaMemcpyDeviceToHost);     cudaMemcpy(anchorIndex, d_anchorIndex, batchSize * dims * sizeof(int), cudaMemcpyDeviceToHost);     cudaMemcpy(classIndex, d_classIndex, batchSize * dims * sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_inputScore);     cudaFree(d_inputIndex);     cudaFree(d_outputScore);     cudaFree(d_outputIndex);     cudaFree(d_anchorIndex);     cudaFree(d_classIndex);      return 0; } "
    },
    {
        "id": "169",
        "c_code": "#include <stdio.h> #include <math.h>  void fractal_cpu(const int width, const int frames, unsigned char *const pic);  int main() {          const int width = 800;     const int frames = 30;     unsigned char pic[width * width * frames];           fractal_cpu(width, frames, pic);           for (int frame = 0; frame < frames; frame++) {         printf(\"Frame %d:\\n\", frame);         for (int row = 0; row < width; row++) {             for (int col = 0; col < width; col++) {                 printf(\"%4d \", pic[frame * width * width + row * width + col]);             }             printf(\"\\n\");         }         printf(\"\\n\");     }      return 0; }  void fractal_cpu(const int width, const int frames, unsigned char *const pic) {     for (int i = 0; i < width * width * frames; i++) {         const float Delta = 0.00304f;         const float xMid = -0.055846456f;         const float yMid = -0.668311119f;         const int frame = i / (width * width);         float delta = Delta * powf(0.975f, frame);         const int col = i % width;         const float xMin = xMid - delta;         const float yMin = yMid - delta;         const float dw = 2.0f * delta / width;         const int row = (i / width) % width;         const float cy = yMin + row * dw;         const float cx = xMin + col * dw;         float x = cx;         float y = cy;         float x2, y2;         int count = 256;          do {             x2 = x * x;             y2 = y * y;             y = 2.0 * x * y + cy;             x = x2 - y2 + cx;             count--;         } while ((count > 0) && ((x2 + y2) <= 5.0));          pic[frame * width * width + row * width + col] = (unsigned char)count;     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void fractal(const int width, const int frames, unsigned char *const pic) {     const long i = threadIdx.x + blockIdx.x * (long)blockDim.x;      if (i > width * width * frames) {         return;     }      const float Delta = 0.00304f;     const float xMid = -0.055846456f;     const float yMid = -0.668311119f;      const int frame = i / (width * width);     float delta = Delta * powf(0.975f, frame);      const int col = i % width;     const float xMin = xMid - delta;     const float yMin = yMid - delta;      const float dw = 2.0f * delta / width;     const int row = (i / width) % width;      const float cy = yMin + row * dw;     const float cx = xMin + col * dw;      float x = cx;     float y = cy;     float x2, y2;     int count = 256;      do {         x2 = x * x;         y2 = y * y;         y = 2.0 * x * y + cy;         x = x2 - y2 + cx;         count--;     } while ((count > 0) && ((x2 + y2) <= 5.0));      pic[frame * width * width + row * width + col] = (unsigned char)count; }  int main() {          int width = 800;       int frames = 100;      unsigned char *pic;            cudaSetDevice(0);           unsigned char *d_pic;     cudaMalloc((void **)&d_pic, frames * width * width * sizeof(unsigned char));           int threadsPerBlock = 256;     int blocksPerGrid = (width * width * frames + threadsPerBlock - 1) / threadsPerBlock;           fractal<<<blocksPerGrid, threadsPerBlock>>>(width, frames, d_pic);           cudaDeviceSynchronize();           cudaMemcpy(pic, d_pic, frames * width * width * sizeof(unsigned char), cudaMemcpyDeviceToHost);           cudaFree(d_pic);      return 0; } "
    },
    {
        "id": "17",
        "c_code": "#include <stdio.h>  void PSIfill_cpu(float *array, int conv_length, int n) {     for (int i = 0; i < n; i++) {         array[i] = array[i % conv_length];     } }  int main() {          int arraySize = 8;     float inputArray[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8};     int convLength = 3;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           PSIfill_cpu(inputArray, convLength, arraySize);      printf(\"\\nPSI \u586b\u5145\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void PSIfill(float* array, int conv_length, int maxThreads) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i >= maxThreads)         return;          array[i] = array[i % conv_length]; }  int main() {          int arraySize = 1000;     int convLength = 10;           float* h_array = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_array[i] = static_cast<float>(i);     }           float* d_array;     cudaMalloc((void**)&d_array, arraySize * sizeof(float));           cudaMemcpy(d_array, h_array, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           PSIfill<<<gridSize, blockSize>>>(d_array, convLength, arraySize);           cudaMemcpy(h_array, d_array, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_array[i]);     }           free(h_array);     cudaFree(d_array);      return 0; } "
    },
    {
        "id": "170",
        "c_code": "#include <stdio.h>  void bit8Channels_cpu(unsigned char *out, unsigned char *in, int channel, int n);  int main() {          const int n = 5;     const int channels = 3;     unsigned char in[n * 8] = {0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,                                0xFE, 0xDC, 0xBA, 0x98, 0x76, 0x54, 0x32, 0x10,                                0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88,                                0x99, 0xAA, 0xBB, 0xCC, 0xDD, 0xEE, 0xFF, 0x00,                                0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77};           unsigned char out[n * channels];           for (int ch = 1; ch <= channels; ++ch) {         bit8Channels_cpu(out, in, ch, n);         printf(\"Output for Channel %d:\\n\", ch);         for (int i = 0; i < n; ++i) {             printf(\"%02X \", out[i * channels + ch - 1]);         }         printf(\"\\n\\n\");     }      return 0; }  void bit8Channels_cpu(unsigned char *out, unsigned char *in, int channel, int n) {     for (int i = 0; i < n; ++i) {         int firstIndexToGrab = i * 8;         unsigned char bit0 = (in[firstIndexToGrab + 0] & 0x01) << 0;         unsigned char bit1 = (in[firstIndexToGrab + 1] & 0x01) << 1;         unsigned char bit2 = (in[firstIndexToGrab + 2] & 0x01) << 2;         unsigned char bit3 = (in[firstIndexToGrab + 3] & 0x01) << 3;         unsigned char bit4 = (in[firstIndexToGrab + 4] & 0x01) << 4;         unsigned char bit5 = (in[firstIndexToGrab + 5] & 0x01) << 5;         unsigned char bit6 = (in[firstIndexToGrab + 6] & 0x01) << 6;         unsigned char bit7 = (in[firstIndexToGrab + 7] & 0x01) << 7;         unsigned char output = bit7 | bit6 | bit5 | bit4 | bit3 | bit2 | bit1 | bit0;         int outputIndex = i * 8 + channel - 1;         out[outputIndex] = output;     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void bit8Channels(unsigned char *out, unsigned char *in, int channel, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i >= n) {         return;     }      int firstIndexToGrab = i * 8;     unsigned char bit0 = (in[firstIndexToGrab + 0] & 0x01) << 0;     unsigned char bit1 = (in[firstIndexToGrab + 1] & 0x01) << 1;     unsigned char bit2 = (in[firstIndexToGrab + 2] & 0x01) << 2;     unsigned char bit3 = (in[firstIndexToGrab + 3] & 0x01) << 3;     unsigned char bit4 = (in[firstIndexToGrab + 4] & 0x01) << 4;     unsigned char bit5 = (in[firstIndexToGrab + 5] & 0x01) << 5;     unsigned char bit6 = (in[firstIndexToGrab + 6] & 0x01) << 6;     unsigned char bit7 = (in[firstIndexToGrab + 7] & 0x01) << 7;      unsigned char output = bit7 | bit6 | bit5 | bit4 | bit3 | bit2 | bit1 | bit0;      int outputIndex = i * 8 + channel - 1;     out[outputIndex] = output; }  int main() {          int n = 1000;      int channel = 3;      unsigned char *out, *in;            cudaSetDevice(0);           unsigned char *d_out, *d_in;     cudaMalloc((void **)&d_out, n * 8 * sizeof(unsigned char));     cudaMalloc((void **)&d_in, n * 8 * sizeof(unsigned char));           cudaMemcpy(d_in, in, n * 8 * sizeof(unsigned char), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           bit8Channels<<<blocksPerGrid, threadsPerBlock>>>(d_out, d_in, channel, n);           cudaDeviceSynchronize();           cudaMemcpy(out, d_out, n * 8 * sizeof(unsigned char), cudaMemcpyDeviceToHost);           cudaFree(d_out);     cudaFree(d_in);      return 0; } "
    },
    {
        "id": "171",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void *Match(int num_points, float *P, float *Q, int q_points, int *idx, int start, int end);  int main() {          const int num_points = 3;     const int q_points = 3;     const int points_per_coordinate = 3;     const int array_size = num_points * points_per_coordinate;     const int start = 0;     const int end = num_points;           float P[array_size] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f, 9.0f};     float Q[array_size] = {10.0f, 11.0f, 12.0f, 13.0f, 14.0f, 15.0f, 16.0f, 17.0f, 18.0f};               int idx[num_points];           Match(num_points, P, Q, q_points, idx, start, end);           printf(\"Matching Indices:\\n\");     for (int i = 0; i < num_points; ++i) {         printf(\"P[%d] matches with Q[%d]\\n\", i, idx[i]);     }      return 0; }  void *Match(int num_points, float *P, float *Q, int q_points, int *idx, int start, int end) {     float dist;     float max_dist;      for (int i = start; i < end; i++) {         max_dist = 1000000000.0f;          for (int j = 0; j < num_points; j++) {             dist = (P[0 + i * 3] - Q[0 + j * 3]) * (P[0 + i * 3] - Q[0 + j * 3]) +                    (P[1 + i * 3] - Q[1 + j * 3]) * (P[1 + i * 3] - Q[1 + j * 3]) +                    (P[2 + i * 3] - Q[2 + j * 3]) * (P[2 + i * 3] - Q[2 + j * 3]);              if (dist < max_dist) {                 max_dist = dist;                 idx[i] = j;             }         }     }      return (void *)0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void Match(float *P, float *Q, int q_points, int *idx) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     float min = 100000;     float d;     float xp = P[0 + i * 3];     float yp = P[1 + i * 3];     float zp = P[2 + i * 3];     float xq, yq, zq;     int j;      for (j = 0; j < q_points / 2; j++) {         xq = Q[0 + j * 3];         yq = Q[1 + j * 3];         zq = Q[2 + j * 3];         d = (xp - xq) * (xp - xq) + (yp - yq) * (yp - yq) + (zp - zq) * (zp - zq);         if (d < min) {             min = d;             idx[i] = j;         }     }      for (j = j; j < q_points; j++) {         xq = Q[0 + j * 3];         yq = Q[1 + j * 3];         zq = Q[2 + j * 3];         d = (xp - xq) * (xp - xq) + (yp - yq) * (yp - yq) + (zp - zq) * (zp - zq);         if (d < min) {             min = d;             idx[i] = j;         }     } }  int main() {          int q_points = 100;      float *P, *Q;      int *idx;            cudaSetDevice(0);           float *d_P, *d_Q;     int *d_idx;      cudaMalloc((void **)&d_P, 3 * sizeof(float));     cudaMalloc((void **)&d_Q, 3 * q_points * sizeof(float));     cudaMalloc((void **)&d_idx, sizeof(int));           cudaMemcpy(d_P, P, 3 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Q, Q, 3 * q_points * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = 1;            Match<<<blocksPerGrid, threadsPerBlock>>>(d_P, d_Q, q_points, d_idx);           cudaDeviceSynchronize();           cudaMemcpy(idx, d_idx, sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_P);     cudaFree(d_Q);     cudaFree(d_idx);      return 0; } "
    },
    {
        "id": "172",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void col2im_add_pixel(float *data_im, int height, int width, int channels, int im_row, int im_col, int c_im, int pad, float val) {      }  void col2im_cpu(float *data_col, int channels, int height, int width, int ksize, int stride, int pad, float *data_im);  int main() {          const int channels = 3;     const int height = 4;     const int width = 4;     const int ksize = 2;     const int stride = 2;     const int pad = 0;           float data_col[channels * ksize * ksize * ((height + 2 * pad - ksize) / stride + 1) * ((width + 2 * pad - ksize) / stride + 1)];               float data_im[channels * height * width];           col2im_cpu(data_col, channels, height, width, ksize, stride, pad, data_im);            return 0; }  void col2im_cpu(float *data_col, int channels, int height, int width, int ksize, int stride, int pad, float *data_im) {     int c, h, w;     int height_col = (height + 2 * pad - ksize) / stride + 1;     int width_col = (width + 2 * pad - ksize) / stride + 1;     int channels_col = channels * ksize * ksize;      for (c = 0; c < channels_col; ++c) {         int w_offset = c % ksize;         int h_offset = (c / ksize) % ksize;         int c_im = c / ksize / ksize;          for (h = 0; h < height_col; ++h) {             for (w = 0; w < width_col; ++w) {                 int im_row = h_offset + h * stride;                 int im_col = w_offset + w * stride;                 int col_index = (c * height_col + h) * width_col + w;                 float val = data_col[col_index];                                   col2im_add_pixel(data_im, height, width, channels, im_row, im_col, c_im, pad, val);             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void col2im_gpu_kernel(const int n, const float *data_col, const int height, const int width, const int ksize,                                   const int pad, const int stride, const int height_col, const int width_col,                                   float *data_im) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      for (; index < n; index += blockDim.x * gridDim.x) {         float val = 0;         int w = index % width + pad;         int h = (index / width) % height + pad;         int c = index / (width * height);         int w_col_start = (w < ksize) ? 0 : (w - ksize) / stride + 1;         int w_col_end = min(w / stride + 1, width_col);         int h_col_start = (h < ksize) ? 0 : (h - ksize) / stride + 1;         int h_col_end = min(h / stride + 1, height_col);         int offset = (c * ksize * ksize + h * ksize + w) * height_col * width_col;         int coeff_h_col = (1 - stride * ksize * height_col) * width_col;         int coeff_w_col = (1 - stride * height_col * width_col);          for (int h_col = h_col_start; h_col < h_col_end; ++h_col) {             for (int w_col = w_col_start; w_col < w_col_end; ++w_col) {                 val += data_col[offset + h_col * coeff_h_col + w_col * coeff_w_col];             }         }          data_im[index] += val;     } }  int main() {          int n = 1000;      int height = 64;      int width = 64;      int ksize = 3;      int pad = 1;      int stride = 1;      int height_col = (height + 2 * pad - ksize) / stride + 1;     int width_col = (width + 2 * pad - ksize) / stride + 1;      float *data_col;      float *data_im;            cudaSetDevice(0);           float *d_data_col, *d_data_im;      cudaMalloc((void **)&d_data_col, n * sizeof(float));     cudaMalloc((void **)&d_data_im, n * sizeof(float));           cudaMemcpy(d_data_col, data_col, n * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           col2im_gpu_kernel<<<blocksPerGrid, threadsPerBlock>>>(n, d_data_col, height, width, ksize, pad, stride,                                                            height_col, width_col, d_data_im);           cudaDeviceSynchronize();           cudaMemcpy(data_im, d_data_im, n * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_data_col);     cudaFree(d_data_im);      return 0; } "
    },
    {
        "id": "173",
        "c_code": "#include <stdio.h>  void yuv2rgb_kernel(int img_size, unsigned char *gpu_img_in_y, unsigned char *gpu_img_in_u, unsigned char *gpu_img_in_v,                      unsigned char *gpu_img_out_r, unsigned char *gpu_img_out_g, unsigned char *gpu_img_out_b);  int main() {          const int img_size = 10;     unsigned char gpu_img_in_y[img_size];     unsigned char gpu_img_in_u[img_size];     unsigned char gpu_img_in_v[img_size];     unsigned char gpu_img_out_r[img_size];     unsigned char gpu_img_out_g[img_size];     unsigned char gpu_img_out_b[img_size];           for (int i = 0; i < img_size; ++i) {         gpu_img_in_y[i] = 100;         gpu_img_in_u[i] = 50;         gpu_img_in_v[i] = 150;     }           yuv2rgb_kernel(img_size, gpu_img_in_y, gpu_img_in_u, gpu_img_in_v, gpu_img_out_r, gpu_img_out_g, gpu_img_out_b);           for (int i = 0; i < img_size; ++i) {         printf(\"(%d, %d, %d) -> (%d, %d, %d)\\n\", gpu_img_in_y[i], gpu_img_in_u[i], gpu_img_in_v[i],                gpu_img_out_r[i], gpu_img_out_g[i], gpu_img_out_b[i]);     }      return 0; }  void yuv2rgb_kernel(int img_size, unsigned char *gpu_img_in_y, unsigned char *gpu_img_in_u, unsigned char *gpu_img_in_v,                      unsigned char *gpu_img_out_r, unsigned char *gpu_img_out_g, unsigned char *gpu_img_out_b) {     int rt, gt, bt;     int rt2, gt2, bt2;          for (int index = 0; index < img_size; index++) {         rt = (int)(gpu_img_in_y[index] + 1.402 * (gpu_img_in_v[index] - 128));         gt = (int)(gpu_img_in_y[index] - 0.344 * (gpu_img_in_u[index] - 128) - 0.714 * (gpu_img_in_v[index] - 128));         bt = (int)gpu_img_in_y[index] + 1.772 * (gpu_img_in_u[index] - 128);          rt2 = (rt > 255) ? 255 : rt;         gt2 = (gt > 255) ? 255 : gt;         bt2 = (bt > 255) ? 255 : bt;          gpu_img_out_r[index] = (rt2 < 0) ? 0 : rt2;         gpu_img_out_g[index] = (gt2 < 0) ? 0 : gt2;         gpu_img_out_b[index] = (bt2 < 0) ? 0 : bt2;     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void yuv2rgb_kernel(int img_size, unsigned char *gpu_img_in_y, unsigned char *gpu_img_in_u,                                unsigned char *gpu_img_in_v, unsigned char *gpu_img_out_r,                                unsigned char *gpu_img_out_g, unsigned char *gpu_img_out_b) {     int rt, gt, bt;     int rt2, gt2, bt2;     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < img_size) {         rt = (int)(gpu_img_in_y[index] + 1.402 * (gpu_img_in_v[index] - 128));         gt = (int)(gpu_img_in_y[index] - 0.344 * (gpu_img_in_u[index] - 128) - 0.714 * (gpu_img_in_v[index] - 128));         bt = (int)gpu_img_in_y[index] + 1.772 * (gpu_img_in_u[index] - 128);          rt2 = (rt > 255) ? 255 : rt;         gt2 = (gt > 255) ? 255 : gt;         bt2 = (bt > 255) ? 255 : bt;          gpu_img_out_r[index] = (rt2 < 0) ? 0 : rt2;         gpu_img_out_b[index] = (bt2 < 0) ? 0 : bt2;         gpu_img_out_g[index] = (gt2 < 0) ? 0 : gt2;     } }  int main() {          int img_size = 1000;       unsigned char *gpu_img_in_y, *gpu_img_in_u, *gpu_img_in_v;     unsigned char *gpu_img_out_r, *gpu_img_out_g, *gpu_img_out_b;                      cudaSetDevice(0);           unsigned char *d_gpu_img_in_y, *d_gpu_img_in_u, *d_gpu_img_in_v;     unsigned char *d_gpu_img_out_r, *d_gpu_img_out_g, *d_gpu_img_out_b;      cudaMalloc((void **)&d_gpu_img_in_y, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_in_u, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_in_v, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_r, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_g, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_b, img_size * sizeof(unsigned char));           cudaMemcpy(d_gpu_img_in_y, gpu_img_in_y, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_gpu_img_in_u, gpu_img_in_u, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_gpu_img_in_v, gpu_img_in_v, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (img_size + threadsPerBlock - 1) / threadsPerBlock;           yuv2rgb_kernel<<<blocksPerGrid, threadsPerBlock>>>(img_size, d_gpu_img_in_y, d_gpu_img_in_u, d_gpu_img_in_v,                                                       d_gpu_img_out_r, d_gpu_img_out_g, d_gpu_img_out_b);           cudaDeviceSynchronize();           cudaMemcpy(gpu_img_out_r, d_gpu_img_out_r, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);     cudaMemcpy(gpu_img_out_g, d_gpu_img_out_g, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);     cudaMemcpy(gpu_img_out_b, d_gpu_img_out_b, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);           cudaFree(d_gpu_img_in_y);     cudaFree(d_gpu_img_in_u);     cudaFree(d_gpu_img_in_v);     cudaFree(d_gpu_img_out_r);     cudaFree(d_gpu_img_out_g);     cudaFree(d_gpu_img_out_b);      return 0; } "
    },
    {
        "id": "174",
        "c_code": "#include <stdio.h>  void get_boxes_for_nms_cpu(const float *boxes_before_nms, const float *offset, float *boxes_for_nms, int dims);  int main() {          const int dims = 5;       float boxes_before_nms[dims * 4];       float offset[dims];       float boxes_for_nms[dims * 4];           for (int i = 0; i < dims * 4; ++i) {         boxes_before_nms[i] = i + 1;     }     for (int i = 0; i < dims; ++i) {         offset[i] = 0.5;     }           get_boxes_for_nms_cpu(boxes_before_nms, offset, boxes_for_nms, dims);           for (int i = 0; i < dims * 4; ++i) {         printf(\"%f \", boxes_for_nms[i]);     }      return 0; }  void get_boxes_for_nms_cpu(const float *boxes_before_nms, const float *offset, float *boxes_for_nms, int dims) {     for (int tid = 0; tid < dims; tid++) {         if (boxes_before_nms[tid * 4] == -1 && boxes_before_nms[tid * 4 + 1] == -1 &&             boxes_before_nms[tid * 4 + 2] == -1 && boxes_before_nms[tid * 4 + 3] == -1) {             boxes_for_nms[tid * 4] = -1;             boxes_for_nms[tid * 4 + 1] = -1;             boxes_for_nms[tid * 4 + 2] = -1;             boxes_for_nms[tid * 4 + 3] = -1;         } else {             boxes_for_nms[tid * 4] = boxes_before_nms[tid * 4] + offset[tid];             boxes_for_nms[tid * 4 + 1] = boxes_before_nms[tid * 4 + 1] + offset[tid];             boxes_for_nms[tid * 4 + 2] = boxes_before_nms[tid * 4 + 2] + offset[tid];             boxes_for_nms[tid * 4 + 3] = boxes_before_nms[tid * 4 + 3] + offset[tid];         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void get_boxes_for_nms(const float *boxes_before_nms, const float *offset, float *boxes_for_nms, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      if (boxes_before_nms[tid * 4 + 0] == (-1) && boxes_before_nms[tid * 4 + 1] == (-1) &&         boxes_before_nms[tid * 4 + 2] == (-1) && boxes_before_nms[tid * 4 + 3] == (-1)) {         boxes_for_nms[tid * 4 + 0] = (-1);         boxes_for_nms[tid * 4 + 1] = (-1);         boxes_for_nms[tid * 4 + 2] = (-1);         boxes_for_nms[tid * 4 + 3] = (-1);     } else {         boxes_for_nms[tid * 4 + 0] = boxes_before_nms[tid * 4 + 0] + offset[tid];         boxes_for_nms[tid * 4 + 1] = boxes_before_nms[tid * 4 + 1] + offset[tid];         boxes_for_nms[tid * 4 + 2] = boxes_before_nms[tid * 4 + 2] + offset[tid];         boxes_for_nms[tid * 4 + 3] = boxes_before_nms[tid * 4 + 3] + offset[tid];     } }  int main() {          int dims = 1000;       float *boxes_before_nms, *offset, *boxes_for_nms;                      cudaSetDevice(0);           float *d_boxes_before_nms, *d_offset, *d_boxes_for_nms;      cudaMalloc((void **)&d_boxes_before_nms, dims * 4 * sizeof(float));     cudaMalloc((void **)&d_offset, dims * sizeof(float));     cudaMalloc((void **)&d_boxes_for_nms, dims * 4 * sizeof(float));           cudaMemcpy(d_boxes_before_nms, boxes_before_nms, dims * 4 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_offset, offset, dims * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;           get_boxes_for_nms<<<blocksPerGrid, threadsPerBlock>>>(d_boxes_before_nms, d_offset, d_boxes_for_nms, dims);           cudaDeviceSynchronize();           cudaMemcpy(boxes_for_nms, d_boxes_for_nms, dims * 4 * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_boxes_before_nms);     cudaFree(d_offset);     cudaFree(d_boxes_for_nms);      return 0; } "
    },
    {
        "id": "175",
        "c_code": "#include <stdio.h> #include <assert.h>  void eltwise_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out, int sum, int mult);  int main() {          const int batch = 2;     const int w1 = 4, h1 = 3, c1 = 2;     const int w2 = 2, h2 = 3, c2 = 1;     const int sum = 1, mult = 0;           float add[batch * w1 * h1 * c1];     float out[w2 * h2 * c2 * batch];           for (int i = 0; i < batch * w1 * h1 * c1; ++i) {         add[i] = i + 1;     }           eltwise_cpu(batch, w1, h1, c1, add, w2, h2, c2, out, sum, mult);           for (int i = 0; i < w2 * h2 * c2 * batch; ++i) {         printf(\"%f \", out[i]);     }      return 0; }  void eltwise_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out, int sum, int mult) {     int stride = w1 / w2;     int sample = w2 / w1;     assert(stride == h1 / h2);     assert(sample == h2 / h1);      if (stride < 1) stride = 1;     if (sample < 1) sample = 1;      int minw = (w1 < w2) ? w1 : w2;     int minh = (h1 < h2) ? h1 : h2;     int minc = (c1 < c2) ? c1 : c2;      int i, j, k, b;      if (mult == 1) {         for (b = 0; b < batch; ++b) {             for (k = 0; k < minc; ++k) {                 for (j = 0; j < minh; ++j) {                     for (i = 0; i < minw; ++i) {                         int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));                         int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));                         out[out_index] = out[out_index] * add[add_index];                     }                 }             }         }     } else if (sum == 1) {         for (b = 0; b < batch; ++b) {             for (k = 0; k < minc; ++k) {                 for (j = 0; j < minh; ++j) {                     for (i = 0; i < minw; ++i) {                         int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));                         int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));                         out[out_index] = out[out_index] + add[add_index];                     }                 }             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void eltwise_kernel(int size, int minw, int minh, int minc, int stride, int sample, int batch,                                int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out,                                int sum, int mult) {     int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (id >= size) {         return;     }      int i = id % minw;     id /= minw;     int j = id % minh;     id /= minh;     int k = id % minc;     id /= minc;     int b = id % batch;      int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));     int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));      if (mult == 1)         out[out_index] = out[out_index] * add[add_index];     else if (sum == 1)         out[out_index] = out[out_index] + add[add_index]; }  int main() {          int size = 1000;       float *add, *out;                      cudaSetDevice(0);           float *d_add, *d_out;      cudaMalloc((void **)&d_add, size * sizeof(float));     cudaMalloc((void **)&d_out, size * sizeof(float));           cudaMemcpy(d_add, add, size * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;           eltwise_kernel<<<blocksPerGrid, threadsPerBlock>>>(size,  d_add, );           cudaDeviceSynchronize();           cudaMemcpy(out, d_out, size * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_add);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "176",
        "c_code": "#include <stdio.h>  void decode_cpu(const float *anchor, const float *locData, float *predictBox, int dims, float scaleClamp, int batchSize);  int main() {          const int dims = 4;     const int batchSize = 2;     const float scaleClamp = 5.0;           float anchor[batchSize * dims * 4];     float locData[batchSize * dims * 4];     float predictBox[batchSize * dims * 4];           for (int i = 0; i < batchSize * dims * 4; ++i) {         anchor[i] = i + 1;         locData[i] = (i + 1) * 0.1;     }           decode_cpu(anchor, locData, predictBox, dims, scaleClamp, batchSize);           for (int i = 0; i < batchSize * dims * 4; ++i) {         printf(\"%f \", predictBox[i]);     }      return 0; }  void decode_cpu(const float *anchor, const float *locData, float *predictBox, int dims, float scaleClamp, int batchSize) {     for (int tid = 0; tid < dims; tid++) {         for (int i = 0; i < batchSize; i++) {             float anchorW = anchor[i * dims * 4 + tid * 4 + 2] - anchor[i * dims * 4 + tid * 4];             float anchorH = anchor[i * dims * 4 + tid * 4 + 3] - anchor[i * dims * 4 + tid * 4 + 1];             float anchorCx = anchor[i * dims * 4 + tid * 4] + 0.5 * anchorW;             float anchorCy = anchor[i * dims * 4 + tid * 4 + 1] + 0.5 * anchorH;              float dx = locData[i * dims * 4 + tid * 4];             float dy = locData[i * dims * 4 + tid * 4 + 1];             float dw = locData[i * dims * 4 + tid * 4 + 2];             float dh = locData[i * dims * 4 + tid * 4 + 3];              if (dw > scaleClamp) {                 dw = scaleClamp;             }             if (dh > scaleClamp) {                 dh = scaleClamp;             }              float preCx = dx * anchorW + anchorCx;             float preCy = dy * anchorH + anchorCy;             float preW = anchorW * 0.5;             float preH = anchorH * 0.5;              predictBox[i * dims * 4 + tid * 4] = preCx - 0.5 * preW;             predictBox[i * dims * 4 + tid * 4 + 1] = preCy - 0.5 * preH;             predictBox[i * dims * 4 + tid * 4 + 2] = preCx + 0.5 * preW;             predictBox[i * dims * 4 + tid * 4 + 3] = preCy + 0.5 * preH;         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void decode(const float *anchor, const float *locData, float *predictBox,                        int dims, float scaleClamp, int batchSize) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      for (int i = 0; i < batchSize; i++) {         float anchorW = anchor[i * dims * 4 + tid * 4 + 2] - anchor[i * dims * 4 + tid * 4];         float anchorH = anchor[i * dims * 4 + tid * 4 + 3] - anchor[i * dims * 4 + tid * 4 + 1];         float anchorCx = anchor[i * dims * 4 + tid * 4] + 0.5 * anchorW;         float anchorCy = anchor[i * dims * 4 + tid * 4 + 1] + 0.5 * anchorH;          float dx = locData[i * dims * 4 + tid * 4];         float dy = locData[i * dims * 4 + tid * 4 + 1];         float dw = locData[i * dims * 4 + tid * 4 + 2];         float dh = locData[i * dims * 4 + tid * 4 + 3];          if (dw > scaleClamp) {             dw = scaleClamp;         }          if (dh > scaleClamp) {             dh = scaleClamp;         }          float preCx = dx * anchorW + anchorCx;         float preCy = dy * anchorH + anchorCy;         float preW = anchorW * 0.5;         float preH = anchorH * 0.5;          predictBox[i * dims * 4 + tid * 4] = preCx - 0.5 * preW;         predictBox[i * dims * 4 + tid * 4 + 1] = preCy - 0.5 * preH;         predictBox[i * dims * 4 + tid * 4 + 2] = preCx + 0.5 * preW;         predictBox[i * dims * 4 + tid * 4 + 3] = preCy + 0.5 * preH;     } }  int main() {          int dims = 1000;       float scaleClamp = 1.0;       int batchSize = 1;        float *anchor, *locData, *predictBox;                      cudaSetDevice(0);           float *d_anchor, *d_locData, *d_predictBox;      cudaMalloc((void **)&d_anchor, dims * 4 * batchSize * sizeof(float));     cudaMalloc((void **)&d_locData, dims * 4 * batchSize * sizeof(float));     cudaMalloc((void **)&d_predictBox, dims * 4 * batchSize * sizeof(float));           cudaMemcpy(d_anchor, anchor, dims * 4 * batchSize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_locData, locData, dims * 4 * batchSize * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;           decode<<<blocksPerGrid, threadsPerBlock>>>(d_anchor, d_locData, d_predictBox, dims, scaleClamp, batchSize);           cudaDeviceSynchronize();           cudaMemcpy(predictBox, d_predictBox, dims * 4 * batchSize * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_anchor);     cudaFree(d_locData);     cudaFree(d_predictBox);      return 0; } "
    },
    {
        "id": "177",
        "c_code": "#include <stdio.h>  void nlf_down_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data);  int main() {          const int n = 2;     const int channel = 3;     const int height = 4;     const int width = 4;     const int wsize = 5;           float filters[n / channel * wsize * height * width];     float top_data[n * height * width];           for (int i = 0; i < n / channel * wsize * height * width; ++i) {         filters[i] = i + 1;     }      for (int i = 0; i < n * height * width; ++i) {         top_data[i] = i + 1;     }           nlf_down_forward_cpu(n, filters, channel, height, width, wsize, top_data);           for (int i = 0; i < n * height * width; ++i) {         printf(\"%f \", top_data[i]);     }      return 0; }  void nlf_down_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index * step;         int fbase = index / channel * wsize * step;          for (int row = 0; row < height; row++) {             for (int col = 0; col < width; col++) {                 float temp = 0;                 int r, c, shift;                  r = row;                 c = col;                 shift = 0 * step + row * width + col;                 temp += top_data[base + r * width + c] * filters[fbase + shift];                  r = row - 1;                 c = col;                 shift = 1 * step + row * width + col;                 if (r >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];                 else temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row - 1;                 c = col - 1;                 shift = 2 * step + row * width + col;                 if (r >= 0 && c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];                 else temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row - 1;                 c = col + 1;                 shift = 3 * step + row * width + col;                 if (r >= 0 && c < width) temp += top_data[base + r * width + c] * filters[fbase + shift];                 else temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row;                 c = col - 1;                 shift = 4 * step + row * width + col;                 if (c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];                 else temp += top_data[base + row * width + col] * filters[fbase + shift];                  top_data[base + row * width + col] = temp;             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void nlf_down_forward(const int n, const float *filters, const int channel,                                  const int height, const int width, const int wsize, float *top_data) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index >= n) {         return;     }      int step = height * width;     int base = index * step;     int fbase = index / channel * wsize * step;      for (int row = 0; row < height; row++) {         for (int col = 0; col < width; col++) {             float temp = 0;             int r, c, shift;                           r = row;             c = col;             shift = 0 * step + row * width + col;             temp += top_data[base + r * width + c] * filters[fbase + shift];                           r = row - 1;             c = col;             shift = 1 * step + row * width + col;             if (r >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];             else temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row - 1;             c = col - 1;             shift = 2 * step + row * width + col;             if (r >= 0 && c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];             else temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row - 1;             c = col + 1;             shift = 3 * step + row * width + col;             if (r >= 0 && c < width) temp += top_data[base + r * width + c] * filters[fbase + shift];             else temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row;             c = col - 1;             shift = 4 * step + row * width + col;             if (c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];             else temp += top_data[base + row * width + col] * filters[fbase + shift];              top_data[base + row * width + col] = temp;         }     } }  int main() {          int n = 1000;       int channel = 3;       int height = 64;       int width = 64;       int wsize = 5;        float *filters, *top_data;                      cudaSetDevice(0);           float *d_filters, *d_top_data;      cudaMalloc((void **)&d_filters, n / channel * wsize * height * width * sizeof(float));     cudaMalloc((void **)&d_top_data, n * height * width * sizeof(float));           cudaMemcpy(d_filters, filters, n / channel * wsize * height * width * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_top_data, top_data, n * height * width * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           nlf_down_forward<<<blocksPerGrid, threadsPerBlock>>>(n, d_filters, channel, height, width, wsize, d_top_data);           cudaDeviceSynchronize();           cudaMemcpy(top_data, d_top_data, n * height * width * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_filters);     cudaFree(d_top_data);      return 0; } "
    },
    {
        "id": "178",
        "c_code": "#include <stdio.h>  void nlf_filter_left_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff);  int main() {          const int n = 2;     const int channel = 3;     const int height = 4;     const int width = 4;     const int wsize = 5;           float bottom_data[n * channel * height * width];     float top_data[n * channel * height * width];     float temp_diff[n * channel * height * width];     float filters_diff[n / height * height * wsize];           for (int i = 0; i < n * channel * height * width; ++i) {         bottom_data[i] = i + 1;         top_data[i] = i + 1;         temp_diff[i] = i + 1;     }      for (int i = 0; i < n / height * height * wsize; ++i) {         filters_diff[i] = i + 1;     }           nlf_filter_left_backward_cpu(n, bottom_data, top_data, temp_diff, channel, height, width, wsize, filters_diff);           for (int i = 0; i < n / height * height * wsize; ++i) {         printf(\"%f \", filters_diff[i]);     }      return 0; }  void nlf_filter_left_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index / step * step * channel + index % step;         int fbase = index / step * step * wsize + index % step;         int row = index % step / width;         int col = index % step % width;          for (int i = 0; i < channel; i++) {             filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col + 1 < width)                 filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base + 1 + i * step];             else                 filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col + 1 < width && row - 1 >= 0)                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * top_data[base - width + 1 + i * step];             else                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col + 1 < width && row + 1 < height)                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * top_data[base + width + 1 + i * step];             else                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row + 1 < height)                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base + width + i * step];             else                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void nlf_filter_left_backward(const int n, const float *bottom_data, const float *top_data,                                           const float *temp_diff, const int channel,                                           const int height, const int width, const int wsize,                                           float *filters_diff) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index >= n) {         return;     }      int step = height * width;     int base = index / step * step * channel + index % step;     int fbase = index / step * step * wsize + index % step;     int row = index % step / width;     int col = index % step % width;      for (int i = 0; i < channel; i++) {         filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col + 1 < width)             filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base + 1 + i * step];         else             filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col + 1 < width && row - 1 >= 0)             filters_diff[fbase + 2 * step] +=                 temp_diff[base + i * step] * top_data[base - width + 1 + i * step];         else             filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col + 1 < width && row + 1 < height)             filters_diff[fbase + 3 * step] +=                 temp_diff[base + i * step] * top_data[base + width + 1 + i * step];         else             filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row + 1 < height)             filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base + width + i * step];         else             filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];     } }  int main() {          int n = 1000;       int channel = 3;       int height = 64;       int width = 64;       int wsize = 5;        float *bottom_data, *top_data, *temp_diff, *filters_diff;                      cudaSetDevice(0);           float *d_bottom_data, *d_top_data, *d_temp_diff, *d_filters_diff;      cudaMalloc((void **)&d_bottom_data, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_top_data, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_temp_diff, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_filters_diff, n * height * width * wsize * sizeof(float));           cudaMemcpy(d_bottom_data, bottom_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_top_data, top_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_temp_diff, temp_diff, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           nlf_filter_left_backward<<<blocksPerGrid, threadsPerBlock>>>(n, d_bottom_data, d_top_data, d_temp_diff,                                                                  channel, height, width, wsize, d_filters_diff);           cudaDeviceSynchronize();           cudaMemcpy(filters_diff, d_filters_diff, n * height * width * wsize * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_bottom_data);     cudaFree(d_top_data);     cudaFree(d_temp_diff);     cudaFree(d_filters_diff);      return 0; } "
    },
    {
        "id": "179",
        "c_code": "#include <stdio.h>  void nlf_filter_down_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff);  int main() {          const int n = 2;     const int channel = 3;     const int height = 4;     const int width = 4;     const int wsize = 5;           float bottom_data[n * channel * height * width];     float top_data[n * channel * height * width];     float temp_diff[n * channel * height * width];     float filters_diff[n / height * height * wsize];           for (int i = 0; i < n * channel * height * width; ++i) {         bottom_data[i] = i + 1;         top_data[i] = i + 1;         temp_diff[i] = i + 1;     }      for (int i = 0; i < n / height * height * wsize; ++i) {         filters_diff[i] = i + 1;     }           nlf_filter_down_backward_cpu(n, bottom_data, top_data, temp_diff, channel, height, width, wsize, filters_diff);           for (int i = 0; i < n / height * height * wsize; ++i) {         printf(\"%f \", filters_diff[i]);     }      return 0; }  void nlf_filter_down_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index / step * step * channel + index % step;         int fbase = index / step * step * wsize + index % step;         int row = index % step / width;         int col = index % step % width;          for (int i = 0; i < channel; i++) {             filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row - 1 >= 0)                 filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base - width + i * step];             else                 filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row - 1 >= 0 && col - 1 >= 0)                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * top_data[base - width - 1 + i * step];             else                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row - 1 >= 0 && col + 1 < width)                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * top_data[base - width + 1 + i * step];             else                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col - 1 >= 0)                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base - 1 + i * step];             else                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void nlf_filter_down_backward(const int n, const float *bottom_data, const float *top_data,                                          const float *temp_diff, const int channel,                                          const int height, const int width, const int wsize,                                          float *filters_diff) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index >= n) {         return;     }      int step = height * width;     int base = index / step * step * channel + index % step;     int fbase = index / step * step * wsize + index % step;     int row = index % step / width;     int col = index % step % width;      for (int i = 0; i < channel; i++) {         filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row - 1 >= 0)             filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base - width + i * step];         else             filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row - 1 >= 0 && col - 1 >= 0)             filters_diff[fbase + 2 * step] +=                 temp_diff[base + i * step] * top_data[base - width - 1 + i * step];         else             filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row - 1 >= 0 && col + 1 < width)             filters_diff[fbase + 3 * step] +=                 temp_diff[base + i * step] * top_data[base - width + 1 + i * step];         else             filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col - 1 >= 0)             filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base - 1 + i * step];         else             filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];     } }  int main() {          int n = 1000;       int channel = 3;       int height = 64;       int width = 64;       int wsize = 5;        float *bottom_data, *top_data, *temp_diff, *filters_diff;                      cudaSetDevice(0);           float *d_bottom_data, *d_top_data, *d_temp_diff, *d_filters_diff;      cudaMalloc((void **)&d_bottom_data, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_top_data, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_temp_diff, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_filters_diff, n * height * width * wsize * sizeof(float));           cudaMemcpy(d_bottom_data, bottom_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_top_data, top_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_temp_diff, temp_diff, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           nlf_filter_down_backward<<<blocksPerGrid, threadsPerBlock>>>(n, d_bottom_data, d_top_data, d_temp_diff,                                                                 channel, height, width, wsize, d_filters_diff);           cudaDeviceSynchronize();           cudaMemcpy(filters_diff, d_filters_diff, n * height * width * wsize * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_bottom_data);     cudaFree(d_top_data);     cudaFree "
    },
    {
        "id": "18",
        "c_code": "#include <stdio.h>  void host_add(float *c, float *a, float *b, int n) {     for (int k = 0; k < n; k++) {         c[k] = a[k] + b[k];     } }  int main() {          int arraySize = 5;     float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           host_add(resultArray, arrayA, arrayB, arraySize);      printf(\"\\n\u76f8\u52a0\u540e\u7684\u6570\u7ec4 C\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void gpu_add(float* c, float* a, float* b, int n) {     int j = blockIdx.x * blockDim.x + threadIdx.x;     if (j < n) {         c[j] = a[j] + b[j];     } }  int main() {          int arraySize = 1000;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_b = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);         h_b[i] = static_cast<float>(2 * i);     }           float* d_a;     float* d_b;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_b, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           gpu_add<<<gridSize, blockSize>>>(d_c, d_a, d_b, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "180",
        "c_code": "#include <stdio.h>  void nlf_up_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index * step;         int fbase = index / channel * wsize * step;                  for (int row = height - 1; row >= 0; row--) {             for (int col = width - 1; col >= 0; col--) {                 float temp = 0;                 int r = row;                 int c = col;                  int shift = 0 * step + row * width + col;                 temp += top_data[base + r * width + c] * filters[fbase + shift];                  r = row + 1;                 c = col;                 shift = 1 * step + row * width + col;                 if (r < height)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row + 1;                 c = col - 1;                 shift = 2 * step + row * width + col;                 if (r < height && c >= 0)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row + 1;                 c = col + 1;                 shift = 3 * step + row * width + col;                 if (r < height && c < width)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row;                 c = col + 1;                 shift = 4 * step + row * width + col;                 if (c < width)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  top_data[base + row * width + col] = temp;             }         }     } }  int main() {          int n = 1;      int channel = 3;      int height = 4;      int width = 4;      int wsize = 3;            float filters[n * wsize * channel * height * width];     float top_data[n * channel * height * width];           nlf_up_forward_cpu(n, filters, channel, height, width, wsize, top_data);            return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void nlf_up_forward(const int n, const float *filters, const int channel,                                const int height, const int width, const int wsize,                                float *top_data) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index >= n) {         return;     }      int step = height * width;     int base = index * step;     int fbase = index / channel * wsize * step;      for (int row = height - 1; row >= 0; row--) {         for (int col = width - 1; col >= 0; col--) {             float temp = 0;             int r = row;             int c = col;             int shift = 0 * step + row * width + col;             temp += top_data[base + r * width + c] * filters[fbase + shift];              r = row + 1;             c = col;             shift = 1 * step + row * width + col;             if (r < height)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];              r = row + 1;             c = col - 1;             shift = 2 * step + row * width + col;             if (r < height && c >= 0)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];              r = row + 1;             c = col + 1;             shift = 3 * step + row * width + col;             if (r < height && c < width)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];              r = row;             c = col + 1;             shift = 4 * step + row * width + col;             if (c < width)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];              top_data[base + row * width + col] = temp;         }     } }  int main() {          int n = 1000;       int channel = 3;       int height = 64;       int width = 64;       int wsize = 5;        float *filters, *top_data;                      cudaSetDevice(0);           float *d_filters, *d_top_data;      cudaMalloc((void **)&d_filters, n * height * width * channel * wsize * sizeof(float));     cudaMalloc((void **)&d_top_data, n * height * width * channel * sizeof(float));           cudaMemcpy(d_filters, filters, n * height * width * channel * wsize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_top_data, top_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           nlf_up_forward<<<blocksPerGrid, threadsPerBlock>>>(n, d_filters, channel, height, width, wsize, d_top_data);           cudaDeviceSynchronize();           cudaMemcpy(top_data, d_top_data, n * height * width * channel * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_filters);     cudaFree(d_top_data);      return 0; } "
    },
    {
        "id": "19",
        "c_code": "#include <stdio.h>  void mul_Scalar_matrix(float *a, float value, float *c, int N) {     for (int idx = 0; idx < N; idx++) {         c[idx] = a[idx] * value;     } }  int main() {          int arraySize = 6;     float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};     float scalarValue = 2.0;     float resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }           mul_Scalar_matrix(arrayA, scalarValue, resultArray, arraySize);      printf(\"\\n\u6807\u91cf\u4e58\u6cd5\u540e\u7684\u6570\u7ec4 C\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void mul_Scalar_matrix(float* a, float value, float* c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] * value;     } }  int main() {          int arraySize = 1000;           float value = 2.0;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);     }           float* d_a;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           mul_Scalar_matrix<<<gridSize, blockSize>>>(d_a, value, d_c, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_c);     cudaFree(d_a);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "2",
        "c_code": "#include <stdio.h>  void get_ev(double *old_arr, double *new_arr, int size) {     int tid;     for (tid = 0; tid < size; tid++) {         new_arr[tid] = old_arr[tid];     } }  int main() {          double old_array[] = {1.5, 2.3, 3.7, 4.2, 5.8};     int numElements = sizeof(old_array) / sizeof(old_array[0]);      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", old_array[i]);     }           double new_array[numElements];           get_ev(old_array, new_array, numElements);      printf(\"\\n\u590d\u5236\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", new_array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void get_ev(double* old_arr, double* new_arr) {     int tid = threadIdx.x + blockIdx.x * blockDim.x;     new_arr[tid] = old_arr[tid]; }  int main() {          int numElements = 1000;           double* h_old_arr = (double*)malloc(numElements * sizeof(double));     double* h_new_arr = (double*)malloc(numElements * sizeof(double));           for (int i = 0; i < numElements; ++i) {         h_old_arr[i] = static_cast<double>(i);     }           double* d_old_arr;     double* d_new_arr;     cudaMalloc((void**)&d_old_arr, numElements * sizeof(double));     cudaMalloc((void**)&d_new_arr, numElements * sizeof(double));           cudaMemcpy(d_old_arr, h_old_arr, numElements * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (numElements + blockSize - 1) / blockSize;           get_ev<<<gridSize, blockSize>>>(d_old_arr, d_new_arr);           cudaMemcpy(h_new_arr, d_new_arr, numElements * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_new_arr[i]);     }           free(h_old_arr);     free(h_new_arr);     cudaFree(d_old_arr);     cudaFree(d_new_arr);      return 0; } "
    },
    {
        "id": "20",
        "c_code": "#include <stdio.h>  void initWith_cpu(float num, float *a, int N) {     for (int i = 0; i < N; i++) {         a[i] = num;     } }  int main() {          int arraySize = 5;     float arrayA[arraySize];     float initialValue = 3.14;           initWith_cpu(initialValue, arrayA, arraySize);      printf(\"\u521d\u59cb\u5316\u540e\u7684\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void initWith(float num, float* a, int N) {     int index = threadIdx.x + blockIdx.x * blockDim.x;     int stride = blockDim.x * gridDim.x;     for (int i = index; i < N; i += stride) {         a[i] = num;     } }  int main() {          int arraySize = 1000;           float initialValue = 3.0;           float* h_a = (float*)malloc(arraySize * sizeof(float));           float* d_a;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           initWith<<<gridSize, blockSize>>>(initialValue, d_a, arraySize);           cudaMemcpy(h_a, d_a, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_a[i]);     }           free(h_a);     cudaFree(d_a);      return 0; } "
    },
    {
        "id": "21",
        "c_code": "#include <stdio.h>  void zeroIndices_cpu(long *vec_out, const long N) {     for (int idx = 0; idx < N; idx++) {         vec_out[idx] = vec_out[idx] - vec_out[0];     } }  int main() {          int arraySize = 6;     long vector[arraySize] = {10, 20, 30, 40, 50, 60};      printf(\"\u539f\u59cb\u5411\u91cf\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%ld \", vector[i]);     }           zeroIndices_cpu(vector, arraySize);      printf(\"\\n\u96f6\u5316\u540e\u7684\u5411\u91cf\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%ld \", vector[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void zeroIndices(long* vec_out, const long N) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;     if (idx < N) {         vec_out[idx] = vec_out[idx] - vec_out[0];     } }  int main() {          long arraySize = 1000;           long* h_vec_out = (long*)malloc(arraySize * sizeof(long));           for (long i = 0; i < arraySize; ++i) {         h_vec_out[i] = static_cast<long>(i);     }           long* d_vec_out;     cudaMalloc((void**)&d_vec_out, arraySize * sizeof(long));           cudaMemcpy(d_vec_out, h_vec_out, arraySize * sizeof(long), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           zeroIndices<<<gridSize, blockSize>>>(d_vec_out, arraySize);           cudaMemcpy(h_vec_out, d_vec_out, arraySize * sizeof(long), cudaMemcpyDeviceToHost);           for (long i = 0; i < 10; ++i) {         printf(\"%ld \", h_vec_out[i]);     }           free(h_vec_out);     cudaFree(d_vec_out);      return 0; } "
    },
    {
        "id": "22",
        "c_code": "#include <stdio.h>  void saxpy_serial(const int dim, float a, float *x, float *y) {     for (int i = 0; i < dim; i++) {         y[i] += a * x[i];     } }  int main() {          int vectorSize = 5;     float vectorX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float vectorY[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float alpha = 2.0;      printf(\"\u5411\u91cf X\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorX[i]);     }      printf(\"\\n\u5411\u91cf Y\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorY[i]);     }           saxpy_serial(vectorSize, alpha, vectorX, vectorY);      printf(\"\\nSAXPY \u540e\u7684\u5411\u91cf Y\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorY[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void saxpy_gpu(const int dim, float a, float* x, float* y) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < dim) {         y[i] = a * x[i] + y[i];     } }  int main() {          int arraySize = 1000;           float a = 2.0;     float* h_x = (float*)malloc(arraySize * sizeof(float));     float* h_y = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_x[i] = static_cast<float>(i);         h_y[i] = static_cast<float>(2 * i);     }           float* d_x;     float* d_y;     cudaMalloc((void**)&d_x, arraySize * sizeof(float));     cudaMalloc((void**)&d_y, arraySize * sizeof(float));           cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_y, h_y, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           saxpy_gpu<<<gridSize, blockSize>>>(arraySize, a, d_x, d_y);           cudaMemcpy(h_y, d_y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_y[i]);     }           free(h_x);     free(h_y);     cudaFree(d_x);     cudaFree(d_y);      return 0; } "
    },
    {
        "id": "23",
        "c_code": "#include <stdio.h>  void getCanBusData(int *canData, int size) {     for (int idx = 0; idx < size; idx++) {         canData[idx] += 1;     } }  int main() {          int dataSize = 8;     int canData[dataSize] = {10, 20, 30, 40, 50, 60, 70, 80};      printf(\"\u539f\u59cb CAN \u6570\u636e\uff1a\");     for (int i = 0; i < dataSize; i++) {         printf(\"%d \", canData[i]);     }           getCanBusData(canData, dataSize);      printf(\"\\n\u5904\u7406\u540e\u7684 CAN \u6570\u636e\uff1a\");     for (int i = 0; i < dataSize; i++) {         printf(\"%d \", canData[i]);     }      return 0; } #include <stdio.h>  void getCanBusData(int *canData, int size) {     for (int idx = 0; idx < size; idx++) {         canData[idx] += 1;     } }  int main() {          int dataSize = 8;     int canData[dataSize] = {10, 20, 30, 40, 50, 60, 70, 80};      printf(\"\u539f\u59cb CAN \u6570\u636e\uff1a\");     for (int i = 0; i < dataSize; i++) {         printf(\"%d \", canData[i]);     }           getCanBusData(canData, dataSize);      printf(\"\\n\u5904\u7406\u540e\u7684 CAN \u6570\u636e\uff1a\");     for (int i = 0; i < dataSize; i++) {         printf(\"%d \", canData[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void getCanBusData(int* canData, int size, int nthreads, int nblocks) {     int i;     int idx = blockIdx.x * blockDim.x + threadIdx.x;     for (i = idx; i < size; i += nthreads * nblocks) {         atomicAdd(&canData[i], 1);     } }  int main() {          int arraySize = 1000;           int* h_canData = (int*)malloc(arraySize * sizeof(int));           int* d_canData;     cudaMalloc((void**)&d_canData, arraySize * sizeof(int));           cudaMemcpy(d_canData, h_canData, arraySize * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           getCanBusData<<<gridSize, blockSize>>>(d_canData, arraySize, blockSize, gridSize);           cudaMemcpy(h_canData, d_canData, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_canData[i]);     }           free(h_canData);     cudaFree(d_canData);      return 0; } "
    },
    {
        "id": "24",
        "c_code": "#include <stdio.h>  void sum_array_cpu(float *a, float *b, float *c, const int size) {     for (int i = 0; i < size; ++i) {         c[i] = a[i] + b[i];     } }  int main() {          int arraySize = 5;     float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           sum_array_cpu(arrayA, arrayB, resultArray, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff08\u548c\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void sum_array_1Dgrid_1Dblock(float* a, float* b, float* c, int nx) {     int gid = blockDim.x * blockIdx.x + threadIdx.x;     if (gid < nx) {         c[gid] = a[gid] + b[gid];     } }  int main() {          int arraySize = 1000;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_b = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);         h_b[i] = static_cast<float>(2 * i);     }           float* d_a;     float* d_b;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_b, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           sum_array_1Dgrid_1Dblock<<<gridSize, blockSize>>>(d_a, d_b, d_c, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "25",
        "c_code": "#include <stdio.h>  void matColMeanDiv_cpu(double *buf, int m, int n, double *tmp) {     for (int i = 0; i < n; i++) {         buf[i] = tmp[i] / m;     } }  int main() {          int numRows = 3;     int numCols = 4;     double matrix[numRows][numCols] = {{1.0, 2.0, 3.0, 4.0},                                        {5.0, 6.0, 7.0, 8.0},                                        {9.0, 10.0, 11.0, 12.0}};     double resultArray[numCols];           double colMeanArray[numCols] = {0.0};     for (int i = 0; i < numRows; i++) {         for (int j = 0; j < numCols; j++) {             colMeanArray[j] += matrix[i][j];         }     }     for (int j = 0; j < numCols; j++) {         colMeanArray[j] /= numRows;     }      printf(\"\u539f\u59cb\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < numRows; i++) {         for (int j = 0; j < numCols; j++) {             printf(\"%.2f \", matrix[i][j]);         }         printf(\"\\n\");     }           matColMeanDiv_cpu(resultArray, numRows, numCols, colMeanArray);      printf(\"\\n\u6bcf\u5217\u5747\u503c\u9664\u6cd5\u540e\u7684\u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < numCols; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void matColMeanDiv(double* buf, int m, int n, double* tmp) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         buf[i] = tmp[i] / static_cast<double>(m);     } }  int main() {          int rows = 1000;     int cols = 10;           double* h_buf = (double*)malloc(cols * sizeof(double));     double* h_tmp = (double*)malloc(cols * sizeof(double));           for (int i = 0; i < cols; ++i) {         h_tmp[i] = static_cast<double>(i);     }           double* d_buf;     double* d_tmp;     cudaMalloc((void**)&d_buf, cols * sizeof(double));     cudaMalloc((void**)&d_tmp, cols * sizeof(double));           cudaMemcpy(d_tmp, h_tmp, cols * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (cols + blockSize - 1) / blockSize;           matColMeanDiv<<<gridSize, blockSize>>>(d_buf, rows, cols, d_tmp);           cudaMemcpy(h_buf, d_buf, cols * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_buf[i]);     }           free(h_buf);     free(h_tmp);     cudaFree(d_buf);     cudaFree(d_tmp);      return 0; } "
    },
    {
        "id": "26",
        "c_code": "#include <stdio.h>  void dmul_Scalar_matrix(double *a, double value, double *c, int N) {     for (int idx = 0; idx < N; idx++) {         c[idx] = a[idx] * value;     } }  int main() {          int arraySize = 6;     double arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};     double scalarValue = 2.0;     double resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }           dmul_Scalar_matrix(arrayA, scalarValue, resultArray, arraySize);      printf(\"\\n\u6807\u91cf\u4e58\u6cd5\u540e\u7684\u6570\u7ec4 C\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void dmul_Scalar_matrix(double* a, double value, double* c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] * value;     } }  int main() {          int arraySize = 1000;           double value = 2.0;           double* h_a = (double*)malloc(arraySize * sizeof(double));     double* h_c = (double*)malloc(arraySize * sizeof(double));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<double>(i);     }           double* d_a;     double* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(double));     cudaMalloc((void**)&d_c, arraySize * sizeof(double));           cudaMemcpy(d_a, h_a, arraySize * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           dmul_Scalar_matrix<<<gridSize, blockSize>>>(d_a, value, d_c, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_c);     cudaFree(d_a);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "27",
        "c_code": "#include <stdio.h>  void countRangesGlobal(int size, int *A, int *B) {     for (int i = 0; i < size; i++) {         int x = A[i] / 100;         B[x] += 1;     } }  int main() {          int arraySize = 8;     int inputArray[] = {50, 120, 250, 350, 420, 550, 670, 800};     int resultArray[9] = {0};       printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", inputArray[i]);     }           countRangesGlobal(arraySize, inputArray, resultArray);      printf(\"\\n\u7edf\u8ba1\u540e\u7684\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < 9; i++) {         printf(\"%d \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void countRangesGlobal(int size, int* A, int* B) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i >= size)         return;      int x = A[i] / 100;     atomicAdd(&B[x], 1); }  int main() {          int arraySize = 1000;           int* h_A = (int*)malloc(arraySize * sizeof(int));     int* h_B = (int*)malloc(arraySize * sizeof(int));           for (int i = 0; i < arraySize; ++i) {         h_A[i] = i;         h_B[i] = 0;     }           int* d_A;     int* d_B;     cudaMalloc((void**)&d_A, arraySize * sizeof(int));     cudaMalloc((void**)&d_B, arraySize * sizeof(int));           cudaMemcpy(d_A, h_A, arraySize * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_B, h_B, arraySize * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           countRangesGlobal<<<gridSize, blockSize>>>(arraySize, d_A, d_B);           cudaMemcpy(h_B, d_B, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_B[i]);     }           free(h_A);     free(h_B);     cudaFree(d_A);     cudaFree(d_B);      return 0; } "
    },
    {
        "id": "28",
        "c_code": "#include <stdio.h>  void dsubtract_matrix(double *a, double *b, double *c, int N) {     for (int idx = 0; idx < N; idx++) {         c[idx] = a[idx] - b[idx];     } }  int main() {          int arraySize = 6;     double arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};     double arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5, 5.5};     double resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           dsubtract_matrix(arrayA, arrayB, resultArray, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff08\u5dee\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void dsubtract_matrix(double* a, double* b, double* c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] - b[idx];     } }  int main() {          int arraySize = 1000;           double* h_a = (double*)malloc(arraySize * sizeof(double));     double* h_b = (double*)malloc(arraySize * sizeof(double));     double* h_c = (double*)malloc(arraySize * sizeof(double));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<double>(i);         h_b[i] = static_cast<double>(2 * i);     }           double* d_a;     double* d_b;     double* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(double));     cudaMalloc((void**)&d_b, arraySize * sizeof(double));     cudaMalloc((void**)&d_c, arraySize * sizeof(double));           cudaMemcpy(d_a, h_a, arraySize * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           dsubtract_matrix<<<gridSize, blockSize>>>(d_a, d_b, d_c, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "29",
        "c_code": "#include <stdio.h>  void add_arrays(int n, float *x, float *y, float *z) {     for (int i = 0; i < n; i++) {         z[i] = x[i] + y[i];     } }  int main() {          int arraySize = 5;     float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayY[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }      printf(\"\\n\u6570\u7ec4 Y\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayY[i]);     }           add_arrays(arraySize, arrayX, arrayY, resultArray);      printf(\"\\n\u6570\u7ec4 Z\uff08\u548c\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void add_arrays(int n, float* x, float* y, float* z) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < n) {         z[i] = x[i] + y[i];     } }  int main() {          int arraySize = 1000;           float* h_x = (float*)malloc(arraySize * sizeof(float));     float* h_y = (float*)malloc(arraySize * sizeof(float));     float* h_z = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_x[i] = static_cast<float>(i);         h_y[i] = static_cast<float>(2 * i);     }           float* d_x;     float* d_y;     float* d_z;     cudaMalloc((void**)&d_x, arraySize * sizeof(float));     cudaMalloc((void**)&d_y, arraySize * sizeof(float));     cudaMalloc((void**)&d_z, arraySize * sizeof(float));           cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_y, h_y, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           add_arrays<<<gridSize, blockSize>>>(arraySize, d_x, d_y, d_z);           cudaMemcpy(h_z, d_z, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_z[i]);     }           free(h_x);     free(h_y);     free(h_z);     cudaFree(d_x);     cudaFree(d_y);     cudaFree(d_z);      return 0; } "
    },
    {
        "id": "3",
        "c_code": "#include <stdio.h>  void square(int *array, int arrayCount) {     for (int idx = 0; idx < arrayCount; idx++) {         array[idx] *= array[idx];     } }  int main() {          int array[] = {2, 4, 6, 8, 10};     int numElements = sizeof(array) / sizeof(array[0]);      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }           square(array, numElements);      printf(\"\\n\u5e73\u65b9\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void square(int* array, int arrayCount) {     int idx = threadIdx.x + blockIdx.x * blockDim.x;     if (idx < arrayCount) {         array[idx] *= array[idx];     } }  int main() {          int arrayCount = 1000;           int* h_array = (int*)malloc(arrayCount * sizeof(int));           for (int i = 0; i < arrayCount; ++i) {         h_array[i] = i;     }           int* d_array;     cudaMalloc((void**)&d_array, arrayCount * sizeof(int));           cudaMemcpy(d_array, h_array, arrayCount * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arrayCount + blockSize - 1) / blockSize;           square<<<gridSize, blockSize>>>(d_array, arrayCount);           cudaMemcpy(h_array, d_array, arrayCount * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_array[i]);     }           free(h_array);     cudaFree(d_array);      return 0; } "
    },
    {
        "id": "30",
        "c_code": "#include <stdio.h>  void sum_arrays_cpu(int *a, int *b, int *c, int size) {     for (int i = 0; i < size; i++) {         c[i] = a[i] + b[i];     } }  int main() {          int arraySize = 5;     int arrayA[] = {1, 2, 3, 4, 5};     int arrayB[] = {10, 20, 30, 40, 50};     int resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", arrayB[i]);     }           sum_arrays_cpu(arrayA, arrayB, resultArray, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff08\u548c\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void sum_arrays_gpu(int* a, int* b, int* c, int size) {     int index = blockDim.x * blockIdx.x + threadIdx.x;     if (index < size) {         c[index] = a[index] + b[index];     } }  int main() {          int arraySize = 1000;           int* h_a = (int*)malloc(arraySize * sizeof(int));     int* h_b = (int*)malloc(arraySize * sizeof(int));     int* h_c = (int*)malloc(arraySize * sizeof(int));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = i;         h_b[i] = 2 * i;     }           int* d_a;     int* d_b;     int* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(int));     cudaMalloc((void**)&d_b, arraySize * sizeof(int));     cudaMalloc((void**)&d_c, arraySize * sizeof(int));           cudaMemcpy(d_a, h_a, arraySize * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           sum_arrays_gpu<<<gridSize, blockSize>>>(d_a, d_b, d_c, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "31",
        "c_code": "#include <stdio.h>  void iKernel_cpu(float *A, float *B, float *C, const int N) {     for (int i = 0; i < N; i++) {         C[i] = A[i] + B[i];     } }  int main() {          int arraySize = 6;     float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};     float arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5, 5.5};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           iKernel_cpu(arrayA, arrayB, resultArray, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void iKernel(float* A, float* B, float* C, const int N) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < N) {         C[i] = A[i] + B[i];     } }  int main() {          const int arraySize = 1000;           float* h_A = (float*)malloc(arraySize * sizeof(float));     float* h_B = (float*)malloc(arraySize * sizeof(float));     float* h_C = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_A[i] = static_cast<float>(i);         h_B[i] = static_cast<float>(2 * i);     }           float* d_A;     float* d_B;     float* d_C;     cudaMalloc((void**)&d_A, arraySize * sizeof(float));     cudaMalloc((void**)&d_B, arraySize * sizeof(float));     cudaMalloc((void**)&d_C, arraySize * sizeof(float));           cudaMemcpy(d_A, h_A, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_B, h_B, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           iKernel<<<gridSize, blockSize>>>(d_A, d_B, d_C, arraySize);           cudaMemcpy(h_C, d_C, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_C[i]);     }           free(h_A);     free(h_B);     free(h_C);     cudaFree(d_A);     cudaFree(d_B);     cudaFree(d_C);      return 0; } "
    },
    {
        "id": "32",
        "c_code": "#include <stdio.h>  void multiplyIntValues(int *destination, int *vector, int value, unsigned int end) {     for (unsigned int i = 0; i < end; i++) {         destination[i] = vector[i] * value;     } }  int main() {          unsigned int arraySize = 5;     int vector[] = {1, 2, 3, 4, 5};     int resultArray[arraySize];     int multiplier = 3;      printf(\"\u539f\u59cb\u5411\u91cf\uff1a\");     for (unsigned int i = 0; i < arraySize; i++) {         printf(\"%d \", vector[i]);     }           multiplyIntValues(resultArray, vector, multiplier, arraySize);      printf(\"\\n\u4e58\u6cd5\u540e\u7684\u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < arraySize; i++) {         printf(\"%d \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void intMultiply(int* result, const int* val1, const int val2, const unsigned int size) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     if (i < size) {         result[i] = val1[i] * val2;     } }  int main() {          const int arraySize = 1000;           int* h_result = (int*)malloc(arraySize * sizeof(int));     int* h_val1 = (int*)malloc(arraySize * sizeof(int));     const int h_val2 = 2;             for (int i = 0; i < arraySize; ++i) {         h_val1[i] = i;     }           int* d_result;     int* d_val1;     cudaMalloc((void**)&d_result, arraySize * sizeof(int));     cudaMalloc((void**)&d_val1, arraySize * sizeof(int));           cudaMemcpy(d_val1, h_val1, arraySize * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           intMultiply<<<gridSize, blockSize>>>(d_result, d_val1, h_val2, arraySize);           cudaMemcpy(h_result, d_result, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_result[i]);     }           free(h_result);     free(h_val1);     cudaFree(d_result);     cudaFree(d_val1);      return 0; } "
    },
    {
        "id": "33",
        "c_code": "#include <stdio.h>  void doubleArrayScalarDivide_cpu(double *d_in, int *d_out, int length, double scalar) {     for (int idx = 0; idx < length; idx++) {         d_out[idx] = d_in[idx] / scalar;     } }  int main() {          int arraySize = 5;     double doubleArray[] = {10.0, 20.0, 30.0, 40.0, 50.0};     int resultArray[arraySize];     double scalar = 2.0;      printf(\"\u539f\u59cb\u53cc\u7cbe\u5ea6\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", doubleArray[i]);     }           doubleArrayScalarDivide_cpu(doubleArray, resultArray, arraySize, scalar);      printf(\"\\n\u9664\u6cd5\u540e\u7684\u6574\u6570\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void doubleArrayScalarDivideKernel(double* d_in, int* d_out, int length, double scalar) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = static_cast<int>(d_in[tid] / scalar);     } }  int main() {          const int arraySize = 1000;           double* h_d_in = (double*)malloc(arraySize * sizeof(double));     int* h_d_out = (int*)malloc(arraySize * sizeof(int));     const double scalar = 2.0;             for (int i = 0; i < arraySize; ++i) {         h_d_in[i] = static_cast<double>(i);     }           double* d_d_in;     int* d_d_out;     cudaMalloc((void**)&d_d_in, arraySize * sizeof(double));     cudaMalloc((void**)&d_d_out, arraySize * sizeof(int));           cudaMemcpy(d_d_in, h_d_in, arraySize * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           doubleArrayScalarDivideKernel<<<gridSize, blockSize>>>(d_d_in, d_d_out, arraySize, scalar);           cudaMemcpy(h_d_out, d_d_out, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_d_out[i]);     }           free(h_d_in);     free(h_d_out);     cudaFree(d_d_in);     cudaFree(d_d_out);      return 0; } "
    },
    {
        "id": "34",
        "c_code": "#include <stdio.h>  void add(const int x, const int y, const int WIDTH, int *c, const int *a, const int *b) {     int i = y * WIDTH + x;     c[i] = a[i] + b[i]; }  int main() {          const int WIDTH = 3;     const int HEIGHT = 2;     const int arraySize = WIDTH * HEIGHT;      int arrayA[arraySize] = {1, 2, 3, 4, 5, 6};     int arrayB[arraySize] = {7, 8, 9, 10, 11, 12};     int resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", arrayB[i]);     }           add(1, 1, WIDTH, resultArray, arrayA, arrayB);      printf(\"\\n\u6570\u7ec4 C\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>   #define N 16  __global__ void addKernel(int* c, const int* a, const int* b) {     int x = threadIdx.x;     int y = threadIdx.y;     int i = y * blockDim.x + x;     c[i] = a[i] + b[i]; }  int main() {          int a[N][N], b[N][N], c[N][N];           int* d_a;     int* d_b;     int* d_c;     cudaMalloc((void**)&d_a, N * N * sizeof(int));     cudaMalloc((void**)&d_b, N * N * sizeof(int));     cudaMalloc((void**)&d_c, N * N * sizeof(int));           for (int i = 0; i < N * N; ++i) {         a[i / N][i % N] = i;         b[i / N][i % N] = 2 * i;     }           cudaMemcpy(d_a, a, N * N * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, b, N * N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(N, N);     dim3 gridSize(1, 1);           addKernel<<<gridSize, blockSize>>>(d_c, d_a, d_b);           cudaMemcpy(c, d_c, N * N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < N; ++i) {         for (int j = 0; j < N; ++j) {             printf(\"%d \", c[i][j]);         }         printf(\"\\n\");     }           cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "35",
        "c_code": "#include <stdio.h>  void activate_array_leaky_cpu(float *x, int n) {     for (int index = 0; index < n; index++) {         float val = x[index];         x[index] = (val > 0) ? val : val / 10;     } }  int main() {          int arraySize = 5;     float inputArray[] = {2.0, -3.0, 4.0, -5.0, 6.0};      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           activate_array_leaky_cpu(inputArray, arraySize);      printf(\"\\n\u6fc0\u6d3b\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void activate_array_leaky_kernel(float* x, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     if (index < n) {         float val = x[index];         x[index] = (val > 0) ? val : val / 10;     } }  int main() {          const int arraySize = 1000;           float* h_x = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_x[i] = static_cast<float>(i - 500);       }           float* d_x;     cudaMalloc((void**)&d_x, arraySize * sizeof(float));           cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           activate_array_leaky_kernel<<<gridSize, blockSize>>>(d_x, arraySize);           cudaMemcpy(h_x, d_x, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_x[i]);     }           free(h_x);     cudaFree(d_x);      return 0; } "
    },
    {
        "id": "36",
        "c_code": "#include <stdio.h>  void logistic_cpu(unsigned int n, float a, float *x, float *z) {     for (unsigned int myId = 0; myId < n; myId++) {         z[myId] = a * x[myId] * (1 - x[myId]);     } }  int main() {          unsigned int arraySize = 5;     float inputArray[] = {0.2, 0.5, 0.7, 0.3, 0.8};     float resultArray[arraySize];     float a = 2.0;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           logistic_cpu(arraySize, a, inputArray, resultArray);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void logistic(unsigned int n, float a, float* x, float* z) {     unsigned int myId = blockDim.x * blockIdx.x + threadIdx.x;     if (myId < n) {         z[myId] = a * x[myId] * (1 - x[myId]);     } }  int main() {          const unsigned int arraySize = 1000;           float* h_x = (float*)malloc(arraySize * sizeof(float));     float* h_z = (float*)malloc(arraySize * sizeof(float));           for (unsigned int i = 0; i < arraySize; ++i) {         h_x[i] = static_cast<float>(i) / arraySize;       }           float* d_x;     float* d_z;     cudaMalloc((void**)&d_x, arraySize * sizeof(float));     cudaMalloc((void**)&d_z, arraySize * sizeof(float));           cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           logistic<<<gridSize, blockSize>>>(arraySize, 2.0f, d_x, d_z);           cudaMemcpy(h_z, d_z, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (unsigned int i = 0; i < 10; ++i) {         printf(\"%f \", h_z[i]);     }           free(h_x);     free(h_z);     cudaFree(d_x);     cudaFree(d_z);      return 0; } "
    },
    {
        "id": "37",
        "c_code": "#include <stdio.h>  void add_kernel(float *inputleft, float *inputright, float *output, int count) {     for (int idx = 0; idx < count; idx++) {         output[idx] = inputleft[idx] + inputright[idx];     } }  int main() {          int arraySize = 4;     float inputLeft[] = {1.1, 2.2, 3.3, 4.4};     float inputRight[] = {0.5, 1.5, 2.5, 3.5};     float resultArray[arraySize];      printf(\"\u5de6\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputLeft[i]);     }      printf(\"\\n\u53f3\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputRight[i]);     }           add_kernel(inputLeft, inputRight, resultArray, arraySize);      printf(\"\\n\u8f93\u51fa\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void add_kernel(float* inputleft, float* inputright, float* output, int count) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;     if (idx < count) {         output[idx] = inputleft[idx] + inputright[idx];     } }  int main() {          const int arraySize = 1000;           float* h_inputleft = (float*)malloc(arraySize * sizeof(float));     float* h_inputright = (float*)malloc(arraySize * sizeof(float));     float* h_output = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_inputleft[i] = static_cast<float>(i);         h_inputright[i] = static_cast<float>(2 * i);     }           float* d_inputleft;     float* d_inputright;     float* d_output;     cudaMalloc((void**)&d_inputleft, arraySize * sizeof(float));     cudaMalloc((void**)&d_inputright, arraySize * sizeof(float));     cudaMalloc((void**)&d_output, arraySize * sizeof(float));           cudaMemcpy(d_inputleft, h_inputleft, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_inputright, h_inputright, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           add_kernel<<<gridSize, blockSize>>>(d_inputleft, d_inputright, d_output, arraySize);           cudaMemcpy(h_output, d_output, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_output[i]);     }           free(h_inputleft);     free(h_inputright);     free(h_output);     cudaFree(d_inputleft);     cudaFree(d_inputright);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "38",
        "c_code": "#include <stdio.h>  void mul_cpu(int N, float *X, int INCX, float *Y, int INCY) {     for (int i = 0; i < N; ++i) {         Y[i * INCY] *= X[i * INCX];     } }  int main() {          int arraySize = 5;     float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayY[] = {0.5, 1.5, 2.5, 3.5, 4.5};      printf(\"\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }      printf(\"\\n\u6570\u7ec4 Y\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayY[i]);     }           mul_cpu(arraySize, arrayX, 1, arrayY, 1);      printf(\"\\n\u6570\u7ec4 Y\uff08\u4e58\u6cd5\u540e\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayY[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void mul_kernel(int N, float* X, int INCX, float* Y, int INCY) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N) {         Y[i * INCY] *= X[i * INCX];     } }  int main() {          const int arraySize = 1000;           float* h_X = (float*)malloc(arraySize * sizeof(float));     float* h_Y = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_X[i] = static_cast<float>(i);         h_Y[i] = static_cast<float>(2 * i);     }           float* d_X;     float* d_Y;     cudaMalloc((void**)&d_X, arraySize * sizeof(float));     cudaMalloc((void**)&d_Y, arraySize * sizeof(float));           cudaMemcpy(d_X, h_X, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Y, h_Y, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           mul_kernel<<<gridSize, blockSize>>>(arraySize, d_X, 1, d_Y, 1);           cudaMemcpy(h_Y, d_Y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_Y[i]);     }           free(h_X);     free(h_Y);     cudaFree(d_X);     cudaFree(d_Y);      return 0; } "
    },
    {
        "id": "39",
        "c_code": "#include <stdio.h>  void pathPlan(int *devSpeed, int *devSteer, int size) {     for (int tid = 0; tid < size; tid++) {         devSpeed[tid] += 1;         devSteer[tid] += 1;     } }  int main() {          int arraySize = 4;     int speedArray[] = {10, 20, 30, 40};     int steerArray[] = {1, 2, 3, 4};      printf(\"\u901f\u5ea6\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", speedArray[i]);     }      printf(\"\\n\u65b9\u5411\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", steerArray[i]);     }           pathPlan(speedArray, steerArray, arraySize);      printf(\"\\n\u8ba1\u5212\u540e\u7684\u901f\u5ea6\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", speedArray[i]);     }      printf(\"\\n\u8ba1\u5212\u540e\u7684\u65b9\u5411\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", steerArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void pathPlan(int* devSpeed, int* devSteer, int size) {     int tid = threadIdx.x + blockIdx.x * blockDim.x;     while (tid < size) {         devSpeed[tid] += 1;         devSteer[tid] += 1;         tid += blockDim.x * gridDim.x;     } }  int main() {          const int arraySize = 1000;           int* h_devSpeed = (int*)malloc(arraySize * sizeof(int));     int* h_devSteer = (int*)malloc(arraySize * sizeof(int));           for (int i = 0; i < arraySize; ++i) {         h_devSpeed[i] = i;         h_devSteer[i] = 2 * i;     }           int* d_devSpeed;     int* d_devSteer;     cudaMalloc((void**)&d_devSpeed, arraySize * sizeof(int));     cudaMalloc((void**)&d_devSteer, arraySize * sizeof(int));           cudaMemcpy(d_devSpeed, h_devSpeed, arraySize * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_devSteer, h_devSteer, arraySize * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           pathPlan<<<gridSize, blockSize>>>(d_devSpeed, d_devSteer, arraySize);           cudaMemcpy(h_devSpeed, d_devSpeed, arraySize * sizeof(int), cudaMemcpyDeviceToHost);     cudaMemcpy(h_devSteer, d_devSteer, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"Speed: %d, Steer: %d\\n\", h_devSpeed[i], h_devSteer[i]);     }           free(h_devSpeed);     free(h_devSteer);     cudaFree(d_devSpeed);     cudaFree(d_devSteer);      return 0; } "
    },
    {
        "id": "4",
        "c_code": "#include <stdio.h>  void add(int n, float *x, float *y) {     for (int i = 0; i < n; i++) {         y[i] = x[i] + y[i];     } }  int main() {          int numElements = 5;     float x[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float y[] = {2.0, 4.0, 6.0, 8.0, 10.0};      printf(\"\u539f\u59cb\u6570\u7ec4 x\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", x[i]);     }      printf(\"\\n\u539f\u59cb\u6570\u7ec4 y\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", y[i]);     }           add(numElements, x, y);      printf(\"\\n\u76f8\u52a0\u540e\u7684\u6570\u7ec4 y\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", y[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void add(int n, float* x, float* y) {     int i = threadIdx.x;     if (i < n) {         y[i] = x[i] + y[i];     } }  int main() {          int arraySize = 1000;           float* h_x = (float*)malloc(arraySize * sizeof(float));     float* h_y = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_x[i] = static_cast<float>(i);         h_y[i] = static_cast<float>(2 * i);     }           float* d_x;     float* d_y;     cudaMalloc((void**)&d_x, arraySize * sizeof(float));     cudaMalloc((void**)&d_y, arraySize * sizeof(float));           cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_y, h_y, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           add<<<gridSize, blockSize>>>(arraySize, d_x, d_y);           cudaMemcpy(h_y, d_y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_y[i]);     }           free(h_x);     free(h_y);     cudaFree(d_x);     cudaFree(d_y);      return 0; } "
    },
    {
        "id": "40",
        "c_code": "#include <stdio.h>  void mult_add_into_cpu(int N, float *X, float *Y, float *Z) {     for (int i = 0; i < N; ++i) {         Z[i] += X[i] * Y[i];     } }  int main() {          int arraySize = 5;     float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayY[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }      printf(\"\\n\u6570\u7ec4 Y\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayY[i]);     }           mult_add_into_cpu(arraySize, arrayX, arrayY, resultArray);      printf(\"\\n\u6570\u7ec4 Z\uff08\u4e58\u6cd5\u5e76\u52a0\u6cd5\u540e\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void mult_add_into_kernel(int n, float* a, float* b, float* c) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < n) {         c[i] += a[i] * b[i];     } }  int main() {          const int arraySize = 1000;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_b = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);         h_b[i] = static_cast<float>(2 * i);         h_c[i] = static_cast<float>(3 * i);     }           float* d_a;     float* d_b;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_b, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_c, h_c, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           mult_add_into_kernel<<<gridSize, blockSize>>>(arraySize, d_a, d_b, d_c);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "41",
        "c_code": "#include <stdio.h>  void InitReduction(int *flags, int voxelCount, int *reduction, int reductionSize) {     for (int tid = 0; tid < reductionSize; tid++) {         reduction[tid] = (tid < voxelCount) ? flags[tid] : 0;     } }  int main() {          int voxelCount = 4;     int reductionSize = 6;     int flagsArray[] = {1, 0, 1, 0};     int reductionArray[reductionSize];      printf(\"\u6807\u5fd7\u6570\u7ec4\uff1a\");     for (int i = 0; i < voxelCount; i++) {         printf(\"%d \", flagsArray[i]);     }           InitReduction(flagsArray, voxelCount, reductionArray, reductionSize);      printf(\"\\n\u521d\u59cb\u5316\u7684\u7f29\u51cf\u6570\u7ec4\uff1a\");     for (int i = 0; i < reductionSize; i++) {         printf(\"%d \", reductionArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void InitReduction(bool* flags, int voxelCount, int* reduction, int reductionSize) {     int tid = threadIdx.x + blockIdx.x * blockDim.x;     if (tid < reductionSize) {         reduction[tid] = (tid < voxelCount) ? flags[tid] : 0;     } }  int main() {          const int voxelCount = 1000;     const int reductionSize = 1024;            bool* h_flags = (bool*)malloc(voxelCount * sizeof(bool));     int* h_reduction = (int*)malloc(reductionSize * sizeof(int));           for (int i = 0; i < voxelCount; ++i) {         h_flags[i] = i % 2 == 0;      }           bool* d_flags;     int* d_reduction;     cudaMalloc((void**)&d_flags, voxelCount * sizeof(bool));     cudaMalloc((void**)&d_reduction, reductionSize * sizeof(int));           cudaMemcpy(d_flags, h_flags, voxelCount * sizeof(bool), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((reductionSize + blockSize.x - 1) / blockSize.x, 1);           InitReduction<<<gridSize, blockSize>>>(d_flags, voxelCount, d_reduction, reductionSize);           cudaMemcpy(h_reduction, d_reduction, reductionSize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_reduction[i]);     }           free(h_flags);     free(h_reduction);     cudaFree(d_flags);     cudaFree(d_reduction);      return 0; } "
    },
    {
        "id": "42",
        "c_code": "#include <stdio.h>  void Function_update_sgd_cpu(float lr, float *parameter, float *gradient, int size) {     for (int i = 0; i < size; i++) {         parameter[i] -= lr * gradient[i];     } }  int main() {          int arraySize = 3;     float learningRate = 0.1;     float parameterArray[] = {1.0, 2.0, 3.0};     float gradientArray[] = {0.5, 1.0, 1.5};      printf(\"\u53c2\u6570\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", parameterArray[i]);     }      printf(\"\\n\u68af\u5ea6\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", gradientArray[i]);     }           Function_update_sgd_cpu(learningRate, parameterArray, gradientArray, arraySize);      printf(\"\\n\u66f4\u65b0\u540e\u7684\u53c2\u6570\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", parameterArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void Kernel_Function_update_sgd(float lr, float* dev_parameter, float* dev_gradient, int size) {     int tid = blockDim.x * blockIdx.x + threadIdx.x;     int N = size;     while (tid < N) {         dev_parameter[tid] -= lr * dev_gradient[tid];         tid += gridDim.x * blockDim.x;     } }  int main() {          const int arraySize = 1000;           float* h_dev_parameter = (float*)malloc(arraySize * sizeof(float));     float* h_dev_gradient = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_dev_parameter[i] = static_cast<float>(i);         h_dev_gradient[i] = static_cast<float>(2 * i);     }           float* d_dev_parameter;     float* d_dev_gradient;     cudaMalloc((void**)&d_dev_parameter, arraySize * sizeof(float));     cudaMalloc((void**)&d_dev_gradient, arraySize * sizeof(float));           cudaMemcpy(d_dev_parameter, h_dev_parameter, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_dev_gradient, h_dev_gradient, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           Kernel_Function_update_sgd<<<gridSize, blockSize>>>(0.01f, d_dev_parameter, d_dev_gradient, arraySize);           cudaMemcpy(h_dev_parameter, d_dev_parameter, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_dev_parameter[i]);     }           free(h_dev_parameter);     free(h_dev_gradient);     cudaFree(d_dev_parameter);     cudaFree(d_dev_gradient);      return 0; } "
    },
    {
        "id": "43",
        "c_code": "#include <stdio.h>  void operacionCPU(float *u, float *lu, float u_m, float u_d, int n) {     int idx = 0;     while (idx < n) {         lu[idx] = (u[idx] - u_m) / u_d;         idx += 1;     } }  int main() {          int arraySize = 4;     float uArray[] = {2.0, 3.0, 4.0, 5.0};     float luArray[arraySize];     float u_m = 3.0;     float u_d = 2.0;      printf(\"\u6570\u7ec4 u\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", uArray[i]);     }           operacionCPU(uArray, luArray, u_m, u_d, arraySize);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4 lu\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", luArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void operacionKernelGPU(float* u, float* lu, float u_m, float u_d, int n) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;     if (idx < n) {         lu[idx] = (u[idx] - u_m) / u_d;     } }  int main() {          const int arraySize = 1000;           float* h_u = (float*)malloc(arraySize * sizeof(float));     float* h_lu = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_u[i] = static_cast<float>(i);     }           float* d_u;     float* d_lu;     cudaMalloc((void**)&d_u, arraySize * sizeof(float));     cudaMalloc((void**)&d_lu, arraySize * sizeof(float));           cudaMemcpy(d_u, h_u, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           operacionKernelGPU<<<gridSize, blockSize>>>(d_u, d_lu, 5.0f, 2.0f, arraySize);           cudaMemcpy(h_lu, d_lu, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_lu[i]);     }           free(h_u);     free(h_lu);     cudaFree(d_u);     cudaFree(d_lu);      return 0; } "
    },
    {
        "id": "44",
        "c_code": "#include <stdio.h>  void host_add(float *c, float *a, float *b, int n) {     for (int k = 0; k < n; k++) {         c[k] = a[k] + b[k];     } }  int main() {          int arraySize = 4;     float arrayA[] = {1.0, 2.0, 3.0, 4.0};     float arrayB[] = {5.0, 6.0, 7.0, 8.0};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           host_add(resultArray, arrayA, arrayB, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff08\u76f8\u52a0\u540e\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void gpu_add(float* c, float* a, float* b, int n) {     int j = blockIdx.x * blockDim.x + threadIdx.x;     int m = gridDim.x * blockDim.x;     for (int k = j; k < n; k += m) {         c[k] = a[k] + b[k];     } }  int main() {          const int arraySize = 1000;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_b = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);         h_b[i] = static_cast<float>(2 * i);     }           float* d_a;     float* d_b;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_b, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           gpu_add<<<gridSize, blockSize>>>(d_c, d_a, d_b, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "45",
        "c_code": "#include <stdio.h> #include <math.h>  void squareSerial(float *d_in, float *d_out, int N) {     for (unsigned int i = 0; i < N; ++i) {         d_out[i] = pow(d_in[i] / (d_in[i] - 2.3), 3);     } }  int main() {          int arraySize = 3;     float inputArray[] = {1.0, 3.0, 5.0};     float outputArray[arraySize];      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           squareSerial(inputArray, outputArray, arraySize);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h> #include <cmath>  __global__ void squareKernel(float* d_in, float* d_out, int N) {     const unsigned int lid = threadIdx.x;     const unsigned int gid = blockIdx.x * blockDim.x + lid;     if (gid < N) {         d_out[gid] = pow(d_in[gid] / (d_in[gid] - 2.3), 3);     } }  int main() {          const int arraySize = 1000;           float* h_d_in = (float*)malloc(arraySize * sizeof(float));     float* h_d_out = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_d_in[i] = static_cast<float>(i);     }           float* d_d_in;     float* d_d_out;     cudaMalloc((void**)&d_d_in, arraySize * sizeof(float));     cudaMalloc((void**)&d_d_out, arraySize * sizeof(float));           cudaMemcpy(d_d_in, h_d_in, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           squareKernel<<<gridSize, blockSize>>>(d_d_in, d_d_out, arraySize);           cudaMemcpy(h_d_out, d_d_out, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_d_out[i]);     }           free(h_d_in);     free(h_d_out);     cudaFree(d_d_in);     cudaFree(d_d_out);      return 0; } "
    },
    {
        "id": "46",
        "c_code": "#include <stdio.h>  void doubleArrayVectorAdd_cpu(double *d_in_a, double *d_in_b, double *d_out, int length) {     for (int idx = 0; idx < length; idx++) {         d_out[idx] = d_in_a[idx] + d_in_b[idx];     } }  int main() {          int arraySize = 3;     double arrayA[] = {1.5, 2.5, 3.5};     double arrayB[] = {0.5, 1.0, 1.5};     double resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           doubleArrayVectorAdd_cpu(arrayA, arrayB, resultArray, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff08\u76f8\u52a0\u540e\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void doubleArrayVectorAddKernel(double* d_in_a, double* d_in_b, double* d_out, int length) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = d_in_a[tid] + d_in_b[tid];     } }  int main() {          const int arraySize = 1000;           double* h_d_in_a = (double*)malloc(arraySize * sizeof(double));     double* h_d_in_b = (double*)malloc(arraySize * sizeof(double));     double* h_d_out = (double*)malloc(arraySize * sizeof(double));           for (int i = 0; i < arraySize; ++i) {         h_d_in_a[i] = static_cast<double>(i);         h_d_in_b[i] = static_cast<double>(2 * i);     }           double* d_d_in_a;     double* d_d_in_b;     double* d_d_out;     cudaMalloc((void**)&d_d_in_a, arraySize * sizeof(double));     cudaMalloc((void**)&d_d_in_b, arraySize * sizeof(double));     cudaMalloc((void**)&d_d_out, arraySize * sizeof(double));           cudaMemcpy(d_d_in_a, h_d_in_a, arraySize * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_in_b, h_d_in_b, arraySize * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           doubleArrayVectorAddKernel<<<gridSize, blockSize>>>(d_d_in_a, d_d_in_b, d_d_out, arraySize);           cudaMemcpy(h_d_out, d_d_out, arraySize * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_d_out[i]);     }           free(h_d_in_a);     free(h_d_in_b);     free(h_d_out);     cudaFree(d_d_in_a);     cudaFree(d_d_in_b);     cudaFree(d_d_out);      return 0; } "
    },
    {
        "id": "47",
        "c_code": "#include <stdio.h>  void fill_matrix(double *const A, const int rows, const int cols) {     for (int row = 0; row < rows; row++) {         for (int col = 0; col < cols; col++) {             A[row * cols + col] = row;         }     } }  int main() {          int numRows = 3;     int numCols = 4;     double matrix[numRows * numCols];           fill_matrix(matrix, numRows, numCols);           printf(\"\u586b\u5145\u540e\u7684\u77e9\u9635\uff1a\\n\");     for (int row = 0; row < numRows; row++) {         for (int col = 0; col < numCols; col++) {             printf(\"%.2f \", matrix[row * numCols + col]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void fill_matrix(double* const A, const int rows, const int cols) {     const int row = blockIdx.y * blockDim.y + threadIdx.y;     const int col = blockIdx.x * blockDim.x + threadIdx.x;     if (row < rows && col < cols) {         A[row * cols + col] = static_cast<double>(row);     } }  int main() {          const int rows = 10;     const int cols = 5;           double* h_A = (double*)malloc(rows * cols * sizeof(double));           double* d_A;     cudaMalloc((void**)&d_A, rows * cols * sizeof(double));           dim3 blockSize(16, 16);     dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y);           fill_matrix<<<gridSize, blockSize>>>(d_A, rows, cols);           cudaMemcpy(h_A, d_A, rows * cols * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < std::min(10, rows); ++i) {         for (int j = 0; j < std::min(5, cols); ++j) {             printf(\"%f \", h_A[i * cols + j]);         }         printf(\"\\n\");     }           free(h_A);     cudaFree(d_A);      return 0; } "
    },
    {
        "id": "48",
        "c_code": "#include <stdio.h>  void evenoddincrement_cpu(float *g_data, int even_inc, int odd_inc, int size) {     for (int tx = 0; tx < size; tx++) {         if ((tx % 2) == 0) {             g_data[tx] += even_inc;         } else {             g_data[tx] += odd_inc;         }     } }  int main() {          int arraySize = 6;     float dataArray[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     int evenIncrement = 2;     int oddIncrement = 1;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", dataArray[i]);     }           evenoddincrement_cpu(dataArray, evenIncrement, oddIncrement, arraySize);      printf(\"\\n\u589e\u91cf\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", dataArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void evenoddincrement(float* g_data, int even_inc, int odd_inc) {     int tx = threadIdx.x + blockIdx.x * blockDim.x;     if ((tx % 2) == 0) {         g_data[tx] += even_inc;     } else {         g_data[tx] += odd_inc;     } }  int main() {          const int arraySize = 1000;           float* h_data = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_data[i] = static_cast<float>(i);     }           float* d_data;     cudaMalloc((void**)&d_data, arraySize * sizeof(float));           cudaMemcpy(d_data, h_data, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           evenoddincrement<<<gridSize, blockSize>>>(d_data, 2, 3);           cudaMemcpy(h_data, d_data, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_data[i]);     }           free(h_data);     cudaFree(d_data);      return 0; } "
    },
    {
        "id": "49",
        "c_code": "#include <stdio.h>  void copy_cpu(int N, float *X, int INCX, float *Y, int INCY) {     for (int i = 0; i < N; ++i) {         Y[i * INCY] = X[i * INCX];     } }  int main() {          int arraySize = 4;     float sourceArray[] = {1.1, 2.2, 3.3, 4.4};     float destinationArray[arraySize];     int INCX = 1;     int INCY = 2;      printf(\"\u6e90\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", sourceArray[i]);     }           copy_cpu(arraySize, sourceArray, INCX, destinationArray, INCY);      printf(\"\\n\u590d\u5236\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", destinationArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void copy_kernel(int N, float* X, int OFFX, int INCX, float* Y, int OFFY, int INCY) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N) {         Y[i * INCY + OFFY] = X[i * INCX + OFFX];     } }  int main() {          const int arraySize = 1000;           float* h_X = (float*)malloc(arraySize * sizeof(float));     float* h_Y = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_X[i] = static_cast<float>(i);     }           float* d_X;     float* d_Y;     cudaMalloc((void**)&d_X, arraySize * sizeof(float));     cudaMalloc((void**)&d_Y, arraySize * sizeof(float));           cudaMemcpy(d_X, h_X, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           copy_kernel<<<gridSize, blockSize>>>(arraySize, d_X, 0, 1, d_Y, 0, 1);           cudaMemcpy(h_Y, d_Y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_Y[i]);     }           free(h_X);     free(h_Y);     cudaFree(d_X);     cudaFree(d_Y);      return 0; } "
    },
    {
        "id": "5",
        "c_code": "#include <stdio.h>  void scale_host(float *array, float scale, int N) {     for (int idx = 0; idx < N; idx++) {         array[idx] *= scale;     } }  int main() {          int numElements = 5;     float array[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float scale_factor = 2.0;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", array[i]);     }           scale_host(array, scale_factor, numElements);      printf(\"\\n\u7f29\u653e\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void scale_dev(float* array, float scale, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         array[idx] *= scale;     } }  int main() {          int arraySize = 1000;           float scale = 1.5f;           float* h_array = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_array[i] = static_cast<float>(i);     }           float* d_array;     cudaMalloc((void**)&d_array, arraySize * sizeof(float));           cudaMemcpy(d_array, h_array, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           scale_dev<<<gridSize, blockSize>>>(d_array, scale, arraySize);           cudaMemcpy(h_array, d_array, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_array[i]);     }           free(h_array);     cudaFree(d_array);      return 0; } "
    },
    {
        "id": "50",
        "c_code": "#include <stdio.h>  void clearLabel(float *prA, float *prB, unsigned int num_nodes, float base) {     for (unsigned int id = 0; id < num_nodes; id++) {         prA[id] = base + prA[id] * 0.85;         prB[id] = 0;     } }  int main() {          unsigned int numNodes = 5;     float prAArray[] = {0.1, 0.2, 0.3, 0.4, 0.5};     float prBArray[numNodes];     float baseValue = 0.05;      printf(\"prA \u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < numNodes; i++) {         printf(\"%.2f \", prAArray[i]);     }           clearLabel(prAArray, prBArray, numNodes, baseValue);      printf(\"\\n\u6e05\u96f6\u540e\u7684 prA \u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < numNodes; i++) {         printf(\"%.2f \", prAArray[i]);     }      printf(\"\\n\u6e05\u96f6\u540e\u7684 prB \u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < numNodes; i++) {         printf(\"%.2f \", prBArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void clearLabel(float* prA, float* prB, unsigned int num_nodes, float base) {     unsigned int id = blockDim.x * blockIdx.x + threadIdx.x;     if (id < num_nodes) {         prA[id] = base + prA[id] * 0.85;         prB[id] = 0;     } }  int main() {          const unsigned int num_nodes = 1000;           float* h_prA = (float*)malloc(num_nodes * sizeof(float));     float* h_prB = (float*)malloc(num_nodes * sizeof(float));           for (unsigned int i = 0; i < num_nodes; ++i) {         h_prA[i] = static_cast<float>(i);         h_prB[i] = static_cast<float>(2 * i);     }           float* d_prA;     float* d_prB;     cudaMalloc((void**)&d_prA, num_nodes * sizeof(float));     cudaMalloc((void**)&d_prB, num_nodes * sizeof(float));           cudaMemcpy(d_prA, h_prA, num_nodes * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_prB, h_prB, num_nodes * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((num_nodes + blockSize.x - 1) / blockSize.x, 1);           clearLabel<<<gridSize, blockSize>>>(d_prA, d_prB, num_nodes, 1.0);           cudaMemcpy(h_prA, d_prA, num_nodes * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_prB, d_prB, num_nodes * sizeof(float), cudaMemcpyDeviceToHost);           for (unsigned int i = 0; i < 10; ++i) {         printf(\"prA[%u]: %f, prB[%u]: %f\\n\", i, h_prA[i], i, h_prB[i]);     }           free(h_prA);     free(h_prB);     cudaFree(d_prA);     cudaFree(d_prB);      return 0; } "
    },
    {
        "id": "51",
        "c_code": "#include <stdio.h>  void delay_kernel_cpu(int *N_mobil, int *Tau, int dia) {     int N = N_mobil[0];     for (int id = 0; id < N; id++) {         if (Tau[id] > 0) {             Tau[id] = Tau[id] - 1;         }     } }  int main() {          int numElements = 5;     int N_mobilArray[] = {numElements};     int TauArray[] = {2, 0, 4, 1, 0};     int diaValue = 0;      printf(\"Tau \u6570\u7ec4\uff08\u521d\u59cb\uff09\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", TauArray[i]);     }           delay_kernel_cpu(N_mobilArray, TauArray, diaValue);      printf(\"\\n\u5ef6\u8fdf\u540e\u7684 Tau \u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", TauArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void delay_kernel(int* N_mobil, int* Tau, int dia) {     int N = N_mobil[0];     int id = blockIdx.x * blockDim.x + threadIdx.x;     if (id < N) {         if (Tau[id] > 0) {             Tau[id] = Tau[id] - 1;         }     } }  int main() {          const int N = 1000;           int* h_N_mobil = (int*)malloc(sizeof(int));     int* h_Tau = (int*)malloc(N * sizeof(int));           h_N_mobil[0] = N;     for (int i = 0; i < N; ++i) {         h_Tau[i] = static_cast<int>(i);     }           int* d_N_mobil;     int* d_Tau;     cudaMalloc((void**)&d_N_mobil, sizeof(int));     cudaMalloc((void**)&d_Tau, N * sizeof(int));           cudaMemcpy(d_N_mobil, h_N_mobil, sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_Tau, h_Tau, N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           delay_kernel<<<gridSize, blockSize>>>(d_N_mobil, d_Tau, 1);           cudaMemcpy(h_Tau, d_Tau, N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"Tau[%d]: %d\\n\", i, h_Tau[i]);     }           free(h_N_mobil);     free(h_Tau);     cudaFree(d_N_mobil);     cudaFree(d_Tau);      return 0; } "
    },
    {
        "id": "52",
        "c_code": "#include <stdio.h>  void resetHeap_cpu(int *heap, int *heapPtr, int numBlock) {     for (int index = 0; index < numBlock; index++) {         if (index == 0)             heapPtr[0] = numBlock - 1;         heap[index] = numBlock - index - 1;     } }  int main() {          int numBlocks = 4;     int heapArray[numBlocks];     int heapPtrArray[] = {0};      printf(\"\u521d\u59cb\u7684 heap \u6570\u7ec4\uff1a\");     for (int i = 0; i < numBlocks; i++) {         printf(\"%d \", heapArray[i]);     }      printf(\"\\n\u521d\u59cb\u7684 heapPtr \u6570\u7ec4\uff1a%d\", heapPtrArray[0]);           resetHeap_cpu(heapArray, heapPtrArray, numBlocks);      printf(\"\\n\u91cd\u7f6e\u540e\u7684 heap \u6570\u7ec4\uff1a\");     for (int i = 0; i < numBlocks; i++) {         printf(\"%d \", heapArray[i]);     }      printf(\"\\n\u91cd\u7f6e\u540e\u7684 heapPtr \u6570\u7ec4\uff1a%d\", heapPtrArray[0]);      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void delay_kernel(int* N_mobil, int* Tau, int dia) {     int N = N_mobil[0];     int id = blockIdx.x * blockDim.x + threadIdx.x;     if (id < N) {         if (Tau[id] > 0) {             Tau[id] = Tau[id] - 1;         }     } }  int main() {          const int N = 1000;           int* h_N_mobil = (int*)malloc(sizeof(int));     int* h_Tau = (int*)malloc(N * sizeof(int));           h_N_mobil[0] = N;     for (int i = 0; i < N; ++i) {         h_Tau[i] = static_cast<int>(i);     }           int* d_N_mobil;     int* d_Tau;     cudaMalloc((void**)&d_N_mobil, sizeof(int));     cudaMalloc((void**)&d_Tau, N * sizeof(int));           cudaMemcpy(d_N_mobil, h_N_mobil, sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_Tau, h_Tau, N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           delay_kernel<<<gridSize, blockSize>>>(d_N_mobil, d_Tau, 1);           cudaMemcpy(h_Tau, d_Tau, N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"Tau[%d]: %d\\n\", i, h_Tau[i]);     }           free(h_N_mobil);     free(h_Tau);     cudaFree(d_N_mobil);     cudaFree(d_Tau);      return 0; } "
    },
    {
        "id": "53",
        "c_code": "#include <stdio.h> #include <math.h>  void pow_cpu(int N, float ALPHA, float *X, int INCX, float *Y, int INCY) {     for (int i = 0; i < N; ++i) {         Y[i * INCY] = pow(X[i * INCX], ALPHA);     } }  int main() {          int arraySize = 4;     float inputArray[] = {2.0, 3.0, 4.0, 5.0};     float outputArray[arraySize];     float alphaValue = 3.0;      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           pow_cpu(arraySize, alphaValue, inputArray, 1, outputArray, 1);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h> #include <cmath>  __global__ void pow_kernel(int N, float ALPHA, float* X, int INCX, float* Y, int INCY) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N) {         Y[i * INCY] = pow(X[i * INCX], ALPHA);     } }  int main() {          const int N = 1000;           float* h_X = (float*)malloc(N * sizeof(float));     float* h_Y = (float*)malloc(N * sizeof(float));           for (int i = 0; i < N; ++i) {         h_X[i] = static_cast<float>(i);     }           float* d_X;     float* d_Y;     cudaMalloc((void**)&d_X, N * sizeof(float));     cudaMalloc((void**)&d_Y, N * sizeof(float));           cudaMemcpy(d_X, h_X, N * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           pow_kernel<<<gridSize, blockSize>>>(N, 2.0, d_X, 1, d_Y, 1);           cudaMemcpy(h_Y, d_Y, N * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"Y[%d]: %f\\n\", i, h_Y[i]);     }           free(h_X);     free(h_Y);     cudaFree(d_X);     cudaFree(d_Y);      return 0; } "
    },
    {
        "id": "54",
        "c_code": "#include <stdio.h> #include <math.h>  void kComputeActs(const float *d_nets, float *d_acts, int size) {     for (int un_idx = 0; un_idx < size; un_idx++) {         float tact = 1.0f / (1.0f + expf(-d_nets[un_idx]));         d_acts[un_idx] = tact;     } }  int main() {          int arraySize = 5;     float netsArray[] = {0.5, -1.0, 1.5, -2.0, 2.5};     float actsArray[arraySize];      printf(\"\u8f93\u5165\u6570\u7ec4\uff08nets\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", netsArray[i]);     }           kComputeActs(netsArray, actsArray, arraySize);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff08acts\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.4f \", actsArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h> #include <cmath>  __global__ void kComputeActs(const float* d_nets, float* d_acts) {     int un_idx = blockIdx.x * blockDim.x + threadIdx.x;     float tact = 1.0f / (1.0f + expf(-d_acts[un_idx]));     __syncthreads();     d_acts[un_idx] = tact; }  int main() {          const int N = 1000;           float* h_nets = (float*)malloc(N * sizeof(float));     float* h_acts = (float*)malloc(N * sizeof(float));           for (int i = 0; i < N; ++i) {         h_nets[i] = static_cast<float>(i);         h_acts[i] = static_cast<float>(i);     }           float* d_nets;     float* d_acts;     cudaMalloc((void**)&d_nets, N * sizeof(float));     cudaMalloc((void**)&d_acts, N * sizeof(float));           cudaMemcpy(d_nets, h_nets, N * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_acts, h_acts, N * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           kComputeActs<<<gridSize, blockSize>>>(d_nets, d_acts);           cudaMemcpy(h_acts, d_acts, N * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"acts[%d]: %f\\n\", i, h_acts[i]);     }           free(h_nets);     free(h_acts);     cudaFree(d_nets);     cudaFree(d_acts);      return 0; } "
    },
    {
        "id": "55",
        "c_code": "#include <stdio.h>  void transpositionCPU(int *vector, int *transposed, int size) {     for (int i = 0; i < size; i++) {         for (int j = 0; j < size; j++) {             transposed[i + j * size] = vector[j + i * size];         }     } }  int main() {          int matrixSize = 3;     int inputMatrix[] = {1, 2, 3, 4, 5, 6, 7, 8, 9};     int transposedMatrix[matrixSize * matrixSize];      printf(\"\u8f93\u5165\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < matrixSize; i++) {         for (int j = 0; j < matrixSize; j++) {             printf(\"%d \", inputMatrix[i * matrixSize + j]);         }         printf(\"\\n\");     }           transpositionCPU(inputMatrix, transposedMatrix, matrixSize);      printf(\"\\n\u8f6c\u7f6e\u540e\u7684\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < matrixSize; i++) {         for (int j = 0; j < matrixSize; j++) {             printf(\"%d \", transposedMatrix[i * matrixSize + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void transposeNaive(int* vector, int* transposed, int size) {     int column = threadIdx.x + blockDim.x * blockIdx.x;     int row = threadIdx.y + blockDim.y * blockIdx.y;      if (row < size && column < size) {         transposed[row + column * size] = vector[column + row * size];     } }  int main() {          const int size = 4;           int* h_vector = (int*)malloc(size * size * sizeof(int));     int* h_transposed = (int*)malloc(size * size * sizeof(int));           for (int i = 0; i < size * size; ++i) {         h_vector[i] = i;     }           int* d_vector;     int* d_transposed;     cudaMalloc((void**)&d_vector, size * size * sizeof(int));     cudaMalloc((void**)&d_transposed, size * size * sizeof(int));           cudaMemcpy(d_vector, h_vector, size * size * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(2, 2);       dim3 gridSize((size + blockSize.x - 1) / blockSize.x, (size + blockSize.y - 1) / blockSize.y);           transposeNaive<<<gridSize, blockSize>>>(d_vector, d_transposed, size);           cudaMemcpy(h_transposed, d_transposed, size * size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Original Matrix:\\n\");     for (int i = 0; i < size; ++i) {         for (int j = 0; j < size; ++j) {             printf(\"%d\\t\", h_vector[j + i * size]);         }         printf(\"\\n\");     }           printf(\"\\nTransposed Matrix:\\n\");     for (int i = 0; i < size; ++i) {         for (int j = 0; j < size; ++j) {             printf(\"%d\\t\", h_transposed[j + i * size]);         }         printf(\"\\n\");     }           free(h_vector);     free(h_transposed);     cudaFree(d_vector);     cudaFree(d_transposed);      return 0; } "
    },
    {
        "id": "56",
        "c_code": "#include <stdio.h>  void compute_array_square(float *array, float *outArray, int size) {     for (int i = 0; i < size; i++) {         outArray[i] = array[i] * array[i];     } }  int main() {          int arraySize = 4;     float inputArray[] = {2.0, 3.0, 4.0, 5.0};     float outputArray[arraySize];      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           compute_array_square(inputArray, outputArray, arraySize);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void compute_array_square(float* array, float* outArray, int size) {     int thread_index = threadIdx.x + blockIdx.x * blockDim.x;     int num_threads = blockDim.x * gridDim.x;      for (int i = 0; i < size; i += num_threads) {         int index = i + thread_index;          if (index < size) {             outArray[index] = array[index] * array[index];         }     } }  int main() {          const int size = 1000;           float* h_array = (float*)malloc(size * sizeof(float));     float* h_outArray = (float*)malloc(size * sizeof(float));           for (int i = 0; i < size; ++i) {         h_array[i] = static_cast<float>(i);     }           float* d_array;     float* d_outArray;     cudaMalloc((void**)&d_array, size * sizeof(float));     cudaMalloc((void**)&d_outArray, size * sizeof(float));           cudaMemcpy(d_array, h_array, size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((size + blockSize.x - 1) / blockSize.x, 1);           compute_array_square<<<gridSize, blockSize>>>(d_array, d_outArray, size);           cudaMemcpy(h_outArray, d_outArray, size * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"outArray[%d]: %f\\n\", i, h_outArray[i]);     }           free(h_array);     free(h_outArray);     cudaFree(d_array);     cudaFree(d_outArray);      return 0; } "
    },
    {
        "id": "57",
        "c_code": "#include <stdio.h>  void testInt1_cpu(const int *input, int dims) {     for (int tid = 0; tid < dims; tid++) {         int sum = 0;         for (int i = 0; i < 3000 * 4; i++) {             if (input[i] == 0) {                 sum++;             }         }     } }  int main() {          int arraySize = 3000 * 4;     int inputArray[arraySize];           for (int i = 0; i < arraySize; i++) {         inputArray[i] = 0;     }           testInt1_cpu(inputArray, arraySize);      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void testInt1(const int* input, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      int sum = 0;      for (int i = 0; i < 3000 * 4; i++) {         if (input[i] == 0) {             sum++;         }     } }  int main() {          const int dims = 3000 * 4;           int* h_input = (int*)malloc(dims * sizeof(int));           for (int i = 0; i < dims; ++i) {         h_input[i] = i % 2;      }           int* d_input;     cudaMalloc((void**)&d_input, dims * sizeof(int));           cudaMemcpy(d_input, h_input, dims * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((dims + blockSize.x - 1) / blockSize.x, 1);           testInt1<<<gridSize, blockSize>>>(d_input, dims);           cudaDeviceSynchronize();           free(h_input);     cudaFree(d_input);      return 0; } "
    },
    {
        "id": "58",
        "c_code": "#include <stdio.h>  void incKernel(int *g_out, int *g_in, int N, int inner_reps) {     for (int idx = 0; idx < N; idx++) {         for (int i = 0; i < inner_reps; ++i) {             g_out[idx] = g_in[idx] + 1;         }     } }  int main() {          int arraySize = 5;     int inputArray[] = {1, 2, 3, 4, 5};     int outputArray[arraySize];      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", inputArray[i]);     }           incKernel(outputArray, inputArray, arraySize, 3);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void incKernel(int* g_out, const int* g_in, int N, int inner_reps) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;      if (idx < N) {         for (int i = 0; i < inner_reps; ++i) {             g_out[idx] = g_in[idx] + 1;         }     } }  int main() {          const int N = 1000;     const int inner_reps = 1000;           int* h_in = (int*)malloc(N * sizeof(int));     int* h_out = (int*)malloc(N * sizeof(int));           for (int i = 0; i < N; ++i) {         h_in[i] = i;     }           int* d_in;     int* d_out;     cudaMalloc((void**)&d_in, N * sizeof(int));     cudaMalloc((void**)&d_out, N * sizeof(int));           cudaMemcpy(d_in, h_in, N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           incKernel<<<gridSize, blockSize>>>(d_out, d_in, N, inner_reps);           cudaMemcpy(h_out, d_out, N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_out[%d]: %d\\n\", i, h_out[i]);     }           free(h_in);     free(h_out);     cudaFree(d_in);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "59",
        "c_code": "#include <stdio.h>  void forward_dropout_layer(int batch, int inputs, float *input, float probability, float *rand, float scale) {     for (int i = 0; i < batch * inputs; ++i) {         if (rand[i] < probability) {             input[i] = 0;         } else {             input[i] *= scale;         }     } }  int main() {          int batchSize = 2;     int inputSize = 3;     float inputArray[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float randArray[] = {0.2, 0.8, 0.4, 0.1, 0.9, 0.5};     float probability = 0.5;     float scale = 2.0;      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < batchSize * inputSize; i++) {         printf(\"%.2f \", inputArray[i]);     }           forward_dropout_layer(batchSize, inputSize, inputArray, probability, randArray, scale);      printf(\"\\n\u5904\u7406\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < batchSize * inputSize; i++) {         printf(\"%.2f \", inputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <curand_kernel.h> #include <stdio.h>  __global__ void forward_dropout_layer(float* input, int size, float* rand, float prob, float scale) {     int id = blockIdx.x * blockDim.x + threadIdx.x;      if (id < size) {         input[id] = (rand[id] < prob) ? 0 : input[id] * scale;     } }  int main() {          const int size = 1000;           float* h_input = (float*)malloc(size * sizeof(float));     float* h_rand = (float*)malloc(size * sizeof(float));           for (int i = 0; i < size; ++i) {         h_input[i] = static_cast<float>(i);         h_rand[i] = static_cast<float>(i) / size;      }           float* d_input;     float* d_rand;     cudaMalloc((void**)&d_input, size * sizeof(float));     cudaMalloc((void**)&d_rand, size * sizeof(float));           cudaMemcpy(d_input, h_input, size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_rand, h_rand, size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((size + blockSize.x - 1) / blockSize.x, 1);           forward_dropout_layer<<<gridSize, blockSize>>>(d_input, size, d_rand, 0.5f, 2.0f);           cudaMemcpy(h_input, d_input, size * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_input[%d]: %f\\n\", i, h_input[i]);     }           free(h_input);     free(h_rand);     cudaFree(d_input);     cudaFree(d_rand);      return 0; } "
    },
    {
        "id": "6",
        "c_code": "#include <stdio.h>  void allAddInplace_cpu(double *arr, double alpha, int n) {     for (int i = 0; i < n; i++) {         arr[i] += alpha;     } }  int main() {          int numElements = 5;     double array[] = {1.1, 2.2, 3.3, 4.4, 5.5};     double alpha = 10.0;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", array[i]);     }           allAddInplace_cpu(array, alpha, numElements);      printf(\"\\n\u6240\u6709\u5143\u7d20\u52a0\u4e0a\u5e38\u6570\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void allAddInplaceKernel(double* arr, double alpha, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         arr[i] += alpha;     } }  int main() {          int arraySize = 1000;           double alpha = 5.0;           double* h_arr = (double*)malloc(arraySize * sizeof(double));           for (int i = 0; i < arraySize; ++i) {         h_arr[i] = static_cast<double>(i);     }           double* d_arr;     cudaMalloc((void**)&d_arr, arraySize * sizeof(double));           cudaMemcpy(d_arr, h_arr, arraySize * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           allAddInplaceKernel<<<gridSize, blockSize>>>(d_arr, alpha, arraySize);           cudaMemcpy(h_arr, d_arr, arraySize * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_arr[i]);     }           free(h_arr);     cudaFree(d_arr);      return 0; } "
    },
    {
        "id": "60",
        "c_code": "#include <stdio.h>  void boundaryCorrectIndexes_cpu(int *d_in, int *d_out, int length, int N) {     for (int idx = 0; idx < length; idx++) {         if (d_in[idx] > N) {             d_out[idx] = N;         } else {             d_out[idx] = d_in[idx];         }     } }  int main() {          int arraySize = 5;     int inputArray[] = {2, 8, 5, 12, 6};     int outputArray[arraySize];     int boundaryValue = 10;      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", inputArray[i]);     }           boundaryCorrectIndexes_cpu(inputArray, outputArray, arraySize, boundaryValue);      printf(\"\\n\u5904\u7406\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void boundaryCorrectIndexesKernel(int* d_in, int* d_out, int length, int N) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid < length) {         if (d_in[tid] > N) {             d_out[tid] = N;         } else {             d_out[tid] = d_in[tid];         }     } }  int main() {          const int length = 1000;     const int N = 500;           int* h_in = (int*)malloc(length * sizeof(int));     int* h_out = (int*)malloc(length * sizeof(int));           for (int i = 0; i < length; ++i) {         h_in[i] = i * 2;      }           int* d_in;     int* d_out;     cudaMalloc((void**)&d_in, length * sizeof(int));     cudaMalloc((void**)&d_out, length * sizeof(int));           cudaMemcpy(d_in, h_in, length * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((length + blockSize.x - 1) / blockSize.x, 1);           boundaryCorrectIndexesKernel<<<gridSize, blockSize>>>(d_in, d_out, length, N);           cudaMemcpy(h_out, d_out, length * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_out[%d]: %d\\n\", i, h_out[i]);     }           free(h_in);     free(h_out);     cudaFree(d_in);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "61",
        "c_code": "#include <stdio.h>  void upsweep_scan(int twod, int N, int *output) {     int twod1 = twod * 2;     int idx;     for (idx = 0; idx + twod1 - 1 < N; idx += twod1) {         output[idx + twod1 - 1] += output[idx + twod - 1];     } }  int main() {          int arraySize = 8;     int outputArray[] = {1, 2, 3, 4, 5, 6, 7, 8};     int twodValue = 1;      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", outputArray[i]);     }           upsweep_scan(twodValue, arraySize, outputArray);      printf(\"\\n\u5904\u7406\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void upsweep_scan(int twod, int N, int* output) {     int twod1 = twod * 2;     int idx = (blockIdx.x * blockDim.x + threadIdx.x) * twod1;      if (idx + twod1 - 1 < N) {         output[idx + twod1 - 1] += output[idx + twod - 1];     } }  int main() {          const int N = 1000;     const int twod = 32;             int* h_output = (int*)malloc(N * sizeof(int));           for (int i = 0; i < N; ++i) {         h_output[i] = i * 2;       }           int* d_output;     cudaMalloc((void**)&d_output, N * sizeof(int));           cudaMemcpy(d_output, h_output, N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           upsweep_scan<<<gridSize, blockSize>>>(twod, N, d_output);           cudaMemcpy(h_output, d_output, N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_output[%d]: %d\\n\", i, h_output[i]);     }           free(h_output);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "62",
        "c_code": "#include <stdio.h>  void Blend_CPU(unsigned char *aImg1, unsigned char *aImg2, unsigned char *aRS, int width, int height) {     for (int i = 0; i < width * height; ++i) {         aRS[i] = (unsigned char)(0.5 * aImg1[i] + 0.5 * aImg2[i]);     } }  int main() {          int width = 2;     int height = 2;     unsigned char img1[] = {100, 150, 200, 255};     unsigned char img2[] = {50, 75, 100, 255};     unsigned char result[width * height];      printf(\"\u8f93\u5165\u56fe\u50cf1\uff1a\");     for (int i = 0; i < width * height; i++) {         printf(\"%d \", img1[i]);     }      printf(\"\\n\u8f93\u5165\u56fe\u50cf2\uff1a\");     for (int i = 0; i < width * height; i++) {         printf(\"%d \", img2[i]);     }           Blend_CPU(img1, img2, result, width, height);      printf(\"\\n\u6df7\u5408\u540e\u7684\u56fe\u50cf\uff1a\");     for (int i = 0; i < width * height; i++) {         printf(\"%d \", result[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void Blending_Kernel(unsigned char* aR1, unsigned char* aR2, unsigned char* aRS, int size) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < size) {         aRS[index] = 0.5 * aR1[index] + 0.5 * aR2[index];     } }  int main() {          const int size = 1000;           unsigned char* h_aR1 = (unsigned char*)malloc(size * sizeof(unsigned char));     unsigned char* h_aR2 = (unsigned char*)malloc(size * sizeof(unsigned char));     unsigned char* h_aRS = (unsigned char*)malloc(size * sizeof(unsigned char));           for (int i = 0; i < size; ++i) {         h_aR1[i] = static_cast<unsigned char>(i * 2);          h_aR2[i] = static_cast<unsigned char>(i * 3);      }           unsigned char* d_aR1;     unsigned char* d_aR2;     unsigned char* d_aRS;     cudaMalloc((void**)&d_aR1, size * sizeof(unsigned char));     cudaMalloc((void**)&d_aR2, size * sizeof(unsigned char));     cudaMalloc((void**)&d_aRS, size * sizeof(unsigned char));           cudaMemcpy(d_aR1, h_aR1, size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_aR2, h_aR2, size * sizeof(unsigned char), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((size + blockSize.x - 1) / blockSize.x, 1);           Blending_Kernel<<<gridSize, blockSize>>>(d_aR1, d_aR2, d_aRS, size);           cudaMemcpy(h_aRS, d_aRS, size * sizeof(unsigned char), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_aRS[%d]: %u\\n\", i, h_aRS[i]);     }           free(h_aR1);     free(h_aR2);     free(h_aRS);     cudaFree(d_aR1);     cudaFree(d_aR2);     cudaFree(d_aRS);      return 0; } "
    },
    {
        "id": "63",
        "c_code": "#include <stdio.h>  void matVecRowSubInplace_cpu(double *mat, const double *vec, int m, int n) {     for (int index = 0; index < m * n; index++) {         int i = index / n;         int j = index % n;         mat[i * n + j] -= vec[j];     } }  int main() {          int rows = 3;     int cols = 4;     double matrix[] = {1.0, 2.0, 3.0, 4.0,                        5.0, 6.0, 7.0, 8.0,                        9.0, 10.0, 11.0, 12.0};      double vector[] = {0.5, 1.0, 1.5, 2.0};      printf(\"\u8f93\u5165\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < rows; i++) {         for (int j = 0; j < cols; j++) {             printf(\"%.2f \", matrix[i * cols + j]);         }         printf(\"\\n\");     }           matVecRowSubInplace_cpu(matrix, vector, rows, cols);      printf(\"\\n\u51cf\u53bb\u5411\u91cf\u540e\u7684\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < rows; i++) {         for (int j = 0; j < cols; j++) {             printf(\"%.2f \", matrix[i * cols + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void matVecRowSubInplaceKernel(double* mat, const double* vec, int m, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < m * n) {         int i = index / n;         int j = index % n;         mat[i * n + j] -= vec[j];     } }  int main() {          const int m = 5;     const int n = 3;           double* h_mat = (double*)malloc(m * n * sizeof(double));     double* h_vec = (double*)malloc(n * sizeof(double));           for (int i = 0; i < m * n; ++i) {         h_mat[i] = static_cast<double>(i);      }      for (int i = 0; i < n; ++i) {         h_vec[i] = static_cast<double>(i * 2);      }           double* d_mat;     double* d_vec;     cudaMalloc((void**)&d_mat, m * n * sizeof(double));     cudaMalloc((void**)&d_vec, n * sizeof(double));           cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec, h_vec, n * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((m * n + blockSize.x - 1) / blockSize.x, 1);           matVecRowSubInplaceKernel<<<gridSize, blockSize>>>(d_mat, d_vec, m, n);           cudaMemcpy(h_mat, d_mat, m * n * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < m; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"h_mat[%d][%d]: %f\\n\", i, j, h_mat[i * n + j]);         }     }           free(h_mat);     free(h_vec);     cudaFree(d_mat);     cudaFree(d_vec);      return 0; } "
    },
    {
        "id": "64",
        "c_code": "#include <stdio.h>  void matVecColAddInplace_cpu(double *mat, const double *vec, int m, int n) {     for (int index = 0; index < m * n; index++) {         int i = index / n;         int j = index % n;         mat[i * n + j] += vec[i];     } }  int main() {          int rows = 3;     int cols = 4;     double matrix[] = {1.0, 2.0, 3.0, 4.0,                        5.0, 6.0, 7.0, 8.0,                        9.0, 10.0, 11.0, 12.0};      double vector[] = {0.5, 1.0, 1.5};      printf(\"\u8f93\u5165\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < rows; i++) {         for (int j = 0; j < cols; j++) {             printf(\"%.2f \", matrix[i * cols + j]);         }         printf(\"\\n\");     }           matVecColAddInplace_cpu(matrix, vector, rows, cols);      printf(\"\\n\u6bcf\u5217\u52a0\u4e0a\u5411\u91cf\u540e\u7684\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < rows; i++) {         for (int j = 0; j < cols; j++) {             printf(\"%.2f \", matrix[i * cols + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void matVecColAddInplaceKernel(double* mat, const double* vec, int m, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < m * n) {         int i = index / n;         int j = index % n;         mat[i * n + j] += vec[i];     } }  int main() {          const int m = 5;     const int n = 3;           double* h_mat = (double*)malloc(m * n * sizeof(double));     double* h_vec = (double*)malloc(m * sizeof(double));           for (int i = 0; i < m * n; ++i) {         h_mat[i] = static_cast<double>(i);      }      for (int i = 0; i < m; ++i) {         h_vec[i] = static_cast<double>(i * 2);      }           double* d_mat;     double* d_vec;     cudaMalloc((void**)&d_mat, m * n * sizeof(double));     cudaMalloc((void**)&d_vec, m * sizeof(double));           cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec, h_vec, m * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((m * n + blockSize.x - 1) / blockSize.x, 1);           matVecColAddInplaceKernel<<<gridSize, blockSize>>>(d_mat, d_vec, m, n);           cudaMemcpy(h_mat, d_mat, m * n * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < m; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"h_mat[%d][%d]: %f\\n\", i, j, h_mat[i * n + j]);         }     }           free(h_mat);     free(h_vec);     cudaFree(d_mat);     cudaFree(d_vec);      return 0; } "
    },
    {
        "id": "65",
        "c_code": "#include <stdio.h>  void MMDOuterProdComputeWithSum(float *x_average, int size_x, float *x_outer_prod) {     for (int i = 0; i < size_x; i++) {         x_outer_prod[i] = x_average[i] * x_average[i];     } }  int main() {          int size = 4;     float averageValues[] = {1.5, 2.0, 3.5, 4.0};     float outerProdResult[size];      printf(\"\u5e73\u5747\u503c\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", averageValues[i]);     }           MMDOuterProdComputeWithSum(averageValues, size, outerProdResult);      printf(\"\\n\u5916\u79ef\u7ed3\u679c\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", outerProdResult[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void MMDOuterProdComputeWithSum(float* x_average, int size_x, float* x_outer_prod) {     int block_id = blockIdx.x;     int thread_id = threadIdx.x;      for (int i = block_id * blockDim.x + thread_id; i < size_x; i += gridDim.x * blockDim.x) {         x_outer_prod[i] = x_average[i] * x_average[i];     } }  int main() {          const int size_x = 100;           float* h_x_average = (float*)malloc(size_x * sizeof(float));     float* h_x_outer_prod = (float*)malloc(size_x * sizeof(float));           for (int i = 0; i < size_x; ++i) {         h_x_average[i] = static_cast<float>(i);      }           float* d_x_average;     float* d_x_outer_prod;     cudaMalloc((void**)&d_x_average, size_x * sizeof(float));     cudaMalloc((void**)&d_x_outer_prod, size_x * sizeof(float));           cudaMemcpy(d_x_average, h_x_average, size_x * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((size_x + blockSize.x - 1) / blockSize.x, 1);           MMDOuterProdComputeWithSum<<<gridSize, blockSize>>>(d_x_average, size_x, d_x_outer_prod);           cudaMemcpy(h_x_outer_prod, d_x_outer_prod, size_x * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < size_x; ++i) {         printf(\"h_x_outer_prod[%d]: %f\\n\", i, h_x_outer_prod[i]);     }           free(h_x_average);     free(h_x_outer_prod);     cudaFree(d_x_average);     cudaFree(d_x_outer_prod);      return 0; } "
    },
    {
        "id": "66",
        "c_code": "#include <stdio.h>  void saxpy_cpu(float *vecY, float *vecX, float alpha, int n) {     for (int i = 0; i < n; i++) {         vecY[i] = alpha * vecX[i] + vecY[i];     } }  int main() {          int size = 5;     float vecY[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float vecX[] = {0.5, 1.0, 1.5, 2.0, 2.5};     float alpha = 2.0;      printf(\"\u8f93\u5165\u5411\u91cf vecY\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", vecY[i]);     }      printf(\"\\n\u8f93\u5165\u5411\u91cf vecX\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", vecX[i]);     }           saxpy_cpu(vecY, vecX, alpha, size);      printf(\"\\n\u6267\u884c saxpy \u540e\u7684\u5411\u91cf vecY\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", vecY[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void saxpy_gpu(float* vecY, float* vecX, float alpha, int n) {     int x, y, i;     x = blockIdx.x * blockDim.x + threadIdx.x;     y = blockIdx.y * blockDim.y + threadIdx.y;     i = y * 1024 + x;      if (i < n) {         vecY[i] = alpha * vecX[i] + vecY[i];     } }  int main() {          const int n = 1024 * 1024;           float* h_vecY = (float*)malloc(n * sizeof(float));     float* h_vecX = (float*)malloc(n * sizeof(float));           for (int i = 0; i < n; ++i) {         h_vecY[i] = static_cast<float>(i);          h_vecX[i] = static_cast<float>(i * 2);      }           float* d_vecY;     float* d_vecX;     cudaMalloc((void**)&d_vecY, n * sizeof(float));     cudaMalloc((void**)&d_vecX, n * sizeof(float));           cudaMemcpy(d_vecY, h_vecY, n * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vecX, h_vecX, n * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(32, 32);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);           saxpy_gpu<<<gridSize, blockSize>>>(d_vecY, d_vecX, 2.0f, n);           cudaMemcpy(h_vecY, d_vecY, n * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_vecY[%d]: %f\\n\", i, h_vecY[i]);     }           free(h_vecY);     free(h_vecX);     cudaFree(d_vecY);     cudaFree(d_vecX);      return 0; } "
    },
    {
        "id": "67",
        "c_code": "#include <stdio.h>  void set_valid_mask_cpu(const float *score, float score_thr, int *valid_mask, int dims) {     for (int tid = 0; tid < dims; tid++) {         if (score[tid] > score_thr) {             valid_mask[tid] = 1;         } else {             valid_mask[tid] = 0;         }     } }  int main() {          int size = 6;     float scores[] = {0.8, 0.5, 0.9, 0.3, 0.7, 0.6};     float threshold = 0.6;     int validMask[size];      printf(\"\u8f93\u5165\u5206\u6570\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", scores[i]);     }           set_valid_mask_cpu(scores, threshold, validMask, size);      printf(\"\\n\u6709\u6548\u63a9\u7801\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%d \", validMask[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void set_valid_mask(const float* score, float score_thr, int* valid_mask, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid < dims) {         valid_mask[tid] = (score[tid] > score_thr) ? 1 : 0;     } }  int main() {          const int dims = 1024;           float* h_score = (float*)malloc(dims * sizeof(float));     int* h_valid_mask = (int*)malloc(dims * sizeof(int));           for (int i = 0; i < dims; ++i) {         h_score[i] = static_cast<float>(i);      }           float* d_score;     int* d_valid_mask;     cudaMalloc((void**)&d_score, dims * sizeof(float));     cudaMalloc((void**)&d_valid_mask, dims * sizeof(int));           cudaMemcpy(d_score, h_score, dims * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((dims + blockSize.x - 1) / blockSize.x, 1);           set_valid_mask<<<gridSize, blockSize>>>(d_score, 500.0f, d_valid_mask, dims);           cudaMemcpy(h_valid_mask, d_valid_mask, dims * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_valid_mask[%d]: %d\\n\", i, h_valid_mask[i]);     }           free(h_score);     free(h_valid_mask);     cudaFree(d_score);     cudaFree(d_valid_mask);      return 0; } "
    },
    {
        "id": "68",
        "c_code": "#include <stdio.h>  void copy_swap(float *f_in, float *f_target, const int L_x) {     for (int k_x = 0; k_x < L_x; k_x++) {         float tempval = 0.0f;         tempval = f_in[k_x];         f_in[k_x] = f_target[k_x];         f_target[k_x] = tempval;     } }  int main() {          int size = 5;     float array1[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float array2[] = {10.0, 20.0, 30.0, 40.0, 50.0};      printf(\"\u6570\u7ec41\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", array1[i]);     }      printf(\"\\n\u6570\u7ec42\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", array2[i]);     }           copy_swap(array1, array2, size);      printf(\"\\n\u4ea4\u6362\u540e\u7684\u6570\u7ec41\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", array1[i]);     }      printf(\"\\n\u4ea4\u6362\u540e\u7684\u6570\u7ec42\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", array2[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void copy_swap(float* f_in, float* f_target, const int L_x) {     const int k_x = threadIdx.x + blockIdx.x * blockDim.x;      if (k_x < L_x) {         float tempval = f_in[k_x];         f_in[k_x] = f_target[k_x];         f_target[k_x] = tempval;     } }  int main() {          const int L_x = 1024;           float* h_f_in = (float*)malloc(L_x * sizeof(float));     float* h_f_target = (float*)malloc(L_x * sizeof(float));           for (int i = 0; i < L_x; ++i) {         h_f_in[i] = static_cast<float>(i);          h_f_target[i] = static_cast<float>(i * 2);      }           float* d_f_in;     float* d_f_target;     cudaMalloc((void**)&d_f_in, L_x * sizeof(float));     cudaMalloc((void**)&d_f_target, L_x * sizeof(float));           cudaMemcpy(d_f_in, h_f_in, L_x * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_f_target, h_f_target, L_x * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((L_x + blockSize.x - 1) / blockSize.x, 1);           copy_swap<<<gridSize, blockSize>>>(d_f_in, d_f_target, L_x);           cudaMemcpy(h_f_in, d_f_in, L_x * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_f_target, d_f_target, L_x * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_f_in[%d]: %f, h_f_target[%d]: %f\\n\", i, h_f_in[i], i, h_f_target[i]);     }           free(h_f_in);     free(h_f_target);     cudaFree(d_f_in);     cudaFree(d_f_target);      return 0; } "
    },
    {
        "id": "69",
        "c_code": "#include <stdio.h>  void sum_backward(float *db, float *dout, int r, int c) {     for (int j = 0; j < c; j++) {         for (int i = 0; i < r; i++) {             db[j] += dout[i * c + j];         }     } }  int main() {          int rows = 3;     int cols = 4;     float dout[] = {1.0, 2.0, 3.0, 4.0,                     5.0, 6.0, 7.0, 8.0,                     9.0, 10.0, 11.0, 12.0};     float db[cols];      printf(\"\u8f93\u5165 dout \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < rows; i++) {         for (int j = 0; j < cols; j++) {             printf(\"%.2f \", dout[i * cols + j]);         }         printf(\"\\n\");     }           for (int i = 0; i < cols; i++) {         db[i] = 0.0;     }           sum_backward(db, dout, rows, cols);      printf(\"\\n\u8ba1\u7b97\u540e\u7684 db \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < cols; i++) {         printf(\"%.2f \", db[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void Kernel_Sum_backward_opt2(float* db, float* sum, int r_sum, int c) {     unsigned int j = blockDim.x * blockIdx.x + threadIdx.x;      if (j >= c)         return;      float temp = 0;      for (int i = 0; i < r_sum; i++) {         temp += sum[i * c + j];     }      db[j] = temp; }  int main() {          const int r_sum = 100;       const int c = 50;                  float* h_db = (float*)malloc(c * sizeof(float));     float* h_sum = (float*)malloc(r_sum * c * sizeof(float));           for (int i = 0; i < r_sum * c; ++i) {         h_sum[i] = static_cast<float>(i);       }           float* d_db;     float* d_sum;     cudaMalloc((void**)&d_db, c * sizeof(float));     cudaMalloc((void**)&d_sum, r_sum * c * sizeof(float));           cudaMemcpy(d_sum, h_sum, r_sum * c * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((c + blockSize.x - 1) / blockSize.x, 1);           Kernel_Sum_backward_opt2<<<gridSize, blockSize>>>(d_db, d_sum, r_sum, c);           cudaMemcpy(h_db, d_db, c * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_db[%d]: %f\\n\", i, h_db[i]);     }           free(h_db);     free(h_sum);     cudaFree(d_db);     cudaFree(d_sum);      return 0; } "
    },
    {
        "id": "7",
        "c_code": "#include <stdio.h>  void memsetCpuInt(int *data, int val, int N) {     for (int index = 0; index < N; index++) {         data[index] = val;     } }  int main() {          int numElements = 5;     int array[] = {1, 2, 3, 4, 5};     int value = 42;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }           memsetCpuInt(array, value, numElements);      printf(\"\\n\u8bbe\u7f6e\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void memsetCudaInt(int* data, int val, int N) {     unsigned int index = blockDim.x * blockIdx.x + threadIdx.x;     if (index < N) {         data[index] = val;     } }  int main() {          int arraySize = 1000;           int initialValue = 42;           int* h_data = (int*)malloc(arraySize * sizeof(int));           int* d_data;     cudaMalloc((void**)&d_data, arraySize * sizeof(int));           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           memsetCudaInt<<<gridSize, blockSize>>>(d_data, initialValue, arraySize);           cudaMemcpy(h_data, d_data, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_data[i]);     }           free(h_data);     cudaFree(d_data);      return 0; } "
    },
    {
        "id": "70",
        "c_code": "#include <stdio.h>  void is_repeat(int N, int *device_input, int *device_output) {     for (int idx = 0; idx < N; idx++) {         device_output[idx] = 0;         if (idx + 1 < N && device_input[idx] == device_input[idx + 1]) {             device_output[idx] = 1;         }     } }  int main() {          int size = 8;     int input[] = {1, 2, 2, 3, 4, 4, 4, 5};     int output[size];      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%d \", input[i]);     }           is_repeat(size, input, output);      printf(\"\\n\u91cd\u590d\u4f4d\u7f6e\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%d \", output[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void is_repeat(int N, int* device_input, int* device_output) {     int idx = blockDim.x * blockIdx.x + threadIdx.x;      if (idx < N) {         device_output[idx] = 0;          if (idx + 1 < N && device_input[idx] == device_input[idx + 1])             device_output[idx] = 1;     } }  int main() {          const int N = 100;             int* h_device_input = (int*)malloc(N * sizeof(int));     int* h_device_output = (int*)malloc(N * sizeof(int));           for (int i = 0; i < N; ++i) {         h_device_input[i] = i % 10;       }           int* d_device_input;     int* d_device_output;     cudaMalloc((void**)&d_device_input, N * sizeof(int));     cudaMalloc((void**)&d_device_output, N * sizeof(int));           cudaMemcpy(d_device_input, h_device_input, N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           is_repeat<<<gridSize, blockSize>>>(N, d_device_input, d_device_output);           cudaMemcpy(h_device_output, d_device_output, N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < N; ++i) {         printf(\"h_device_output[%d]: %d\\n\", i, h_device_output[i]);     }           free(h_device_input);     free(h_device_output);     cudaFree(d_device_input);     cudaFree(d_device_output);      return 0; } "
    },
    {
        "id": "71",
        "c_code": "#include <stdio.h>  void kmeans_average(int *means, int *counts, int BID, int DIM) {     for (int bid = 0; bid < BID; bid++) {         for (int tid = 0; tid < DIM; tid++) {             if (counts[bid] == 0) {                 means[bid * DIM + tid] = 0;             } else {                 means[bid * DIM + tid] /= counts[bid];             }         }     } }  int main() {          int BID = 3;     int DIM = 4;     int means[BID * DIM];     int counts[BID];           for (int i = 0; i < BID; i++) {         counts[i] = i + 1;           for (int j = 0; j < DIM; j++) {             means[i * DIM + j] = i * DIM + j + 1;           }     }      printf(\"\u8f93\u5165 means \u6570\u7ec4\u548c counts \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < BID; i++) {         for (int j = 0; j < DIM; j++) {             printf(\"%d \", means[i * DIM + j]);         }         printf(\" | Count: %d\\n\", counts[i]);     }           kmeans_average(means, counts, BID, DIM);      printf(\"\\n\u5e73\u5747\u5316\u540e\u7684 means \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < BID; i++) {         for (int j = 0; j < DIM; j++) {             printf(\"%d \", means[i * DIM + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void kmeans_average(int* means, int* counts) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (counts[index] == 0)         means[index] = 0;     else         means[index] /= counts[index]; }  int main() {     const int K = 10;       const int threadsPerBlock = 256;     const int blocksPerGrid = (K + threadsPerBlock - 1) / threadsPerBlock;           int* h_means = (int*)malloc(K * sizeof(int));     int* h_counts = (int*)malloc(K * sizeof(int));           for (int i = 0; i < K; ++i) {         h_means[i] = i * 10;         h_counts[i] = i + 1;     }           int* d_means;     int* d_counts;     cudaMalloc((void**)&d_means, K * sizeof(int));     cudaMalloc((void**)&d_counts, K * sizeof(int));           cudaMemcpy(d_means, h_means, K * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_counts, h_counts, K * sizeof(int), cudaMemcpyHostToDevice);           kmeans_average<<<blocksPerGrid, threadsPerBlock>>>(d_means, d_counts);           cudaMemcpy(h_means, d_means, K * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Means after averaging:\\n\");     for (int i = 0; i < K; ++i) {         printf(\"%d \", h_means[i]);     }           free(h_means);     free(h_counts);     cudaFree(d_means);     cudaFree(d_counts);      return 0; } "
    },
    {
        "id": "72",
        "c_code": "#include <stdio.h>  void matPerRowDivInplace_cpu(double *mat, const double *alphas, int m, int n) {     for (int index = 0; index < m * n; index++) {         int i = index / n;         int j = index % n;         mat[i * n + j] /= (alphas[i] + 10 * 3);     } }  int main() {          int m = 3;     int n = 4;     double mat[] = {1.0, 2.0, 3.0, 4.0,                     5.0, 6.0, 7.0, 8.0,                     9.0, 10.0, 11.0, 12.0};     double alphas[] = {2.0, 3.0, 4.0};      printf(\"\u8f93\u5165\u77e9\u9635 mat\uff1a\\n\");     for (int i = 0; i < m; i++) {         for (int j = 0; j < n; j++) {             printf(\"%.2f \", mat[i * n + j]);         }         printf(\"\\n\");     }      printf(\"\\n\u8f93\u5165 alphas \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < m; i++) {         printf(\"%.2f \", alphas[i]);     }           matPerRowDivInplace_cpu(mat, alphas, m, n);      printf(\"\\n\u6bcf\u884c\u9664\u4ee5 alphas \u540e\u7684\u77e9\u9635 mat\uff1a\\n\");     for (int i = 0; i < m; i++) {         for (int j = 0; j < n; j++) {             printf(\"%.2f \", mat[i * n + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void matPerRowDivInplaceKernel(double* mat, const double* alphas, int m, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < m * n) {         int i = index / n;         int j = index % n;         mat[i * n + j] /= (alphas[i] + 10 * 3);     } }  int main() {     const int m = 5;       const int n = 4;       const int threadsPerBlock = 256;     const int blocksPerGrid = (m * n + threadsPerBlock - 1) / threadsPerBlock;           double* h_mat = (double*)malloc(m * n * sizeof(double));     double* h_alphas = (double*)malloc(m * sizeof(double));           for (int i = 0; i < m * n; ++i) {         h_mat[i] = i + 1;     }      for (int i = 0; i < m; ++i) {         h_alphas[i] = i + 1;     }           double* d_mat;     double* d_alphas;     cudaMalloc((void**)&d_mat, m * n * sizeof(double));     cudaMalloc((void**)&d_alphas, m * sizeof(double));           cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_alphas, h_alphas, m * sizeof(double), cudaMemcpyHostToDevice);           matPerRowDivInplaceKernel<<<blocksPerGrid, threadsPerBlock>>>(d_mat, d_alphas, m, n);           cudaMemcpy(h_mat, d_mat, m * n * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Matrix after per row division:\\n\");     for (int i = 0; i < m; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"%f \", h_mat[i * n + j]);         }         printf(\"\\n\");     }           free(h_mat);     free(h_alphas);     cudaFree(d_mat);     cudaFree(d_alphas);      return 0; } "
    },
    {
        "id": "73",
        "c_code": "#include <stdio.h>   int max(int a, int b) {     return (a > b) ? a : b; }  void compute_new_means(float *mx, float *my, const float *sx, const float *sy, const int *c, int size) {     int cluster = 0;     const int count = max(1, c[cluster]);      for (cluster = 0; cluster < size; cluster++) {         mx[cluster] = sx[cluster] / count;         my[cluster] = sy[cluster] / count;     } }  int main() {          int size = 3;     float mx[] = {1.0, 2.0, 3.0};     float my[] = {4.0, 5.0, 6.0};     float sx[] = {7.0, 8.0, 9.0};     float sy[] = {10.0, 11.0, 12.0};     int c[] = {2, 0, 1};      printf(\"\u8f93\u5165 mx \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", mx[i]);     }      printf(\"\\n\u8f93\u5165 my \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", my[i]);     }      printf(\"\\n\u8f93\u5165 sx \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", sx[i]);     }      printf(\"\\n\u8f93\u5165 sy \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", sy[i]);     }      printf(\"\\n\u8f93\u5165 c \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", c[i]);     }           compute_new_means(mx, my, sx, sy, c, size);      printf(\"\\n\u8ba1\u7b97\u65b0\u5747\u503c\u540e\u7684 mx \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", mx[i]);     }      printf(\"\\n\u8ba1\u7b97\u65b0\u5747\u503c\u540e\u7684 my \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", my[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void compute_new_means(float* mx, float* my, const float* sx, const float* sy, const int* c) {     const int cluster = threadIdx.x;      if (cluster < blockDim.x) {         const int count = max(1, c[cluster]);         mx[cluster] = sx[cluster] / count;         my[cluster] = sy[cluster] / count;     } }  int main() {     const int clusters = 5;       const int threadsPerBlock = clusters;     const int blocksPerGrid = 1;             float* h_mx = (float*)malloc(clusters * sizeof(float));     float* h_my = (float*)malloc(clusters * sizeof(float));     float* h_sx = (float*)malloc(clusters * sizeof(float));     float* h_sy = (float*)malloc(clusters * sizeof(float));     int* h_c = (int*)malloc(clusters * sizeof(int));           for (int i = 0; i < clusters; ++i) {         h_sx[i] = i + 1;         h_sy[i] = i + 1;         h_c[i] = i + 1;     }           float* d_mx;     float* d_my;     float* d_sx;     float* d_sy;     int* d_c;     cudaMalloc((void**)&d_mx, clusters * sizeof(float));     cudaMalloc((void**)&d_my, clusters * sizeof(float));     cudaMalloc((void**)&d_sx, clusters * sizeof(float));     cudaMalloc((void**)&d_sy, clusters * sizeof(float));     cudaMalloc((void**)&d_c, clusters * sizeof(int));           cudaMemcpy(d_mx, h_mx, clusters * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_my, h_my, clusters * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_sx, h_sx, clusters * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_sy, h_sy, clusters * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_c, h_c, clusters * sizeof(int), cudaMemcpyHostToDevice);           compute_new_means<<<blocksPerGrid, threadsPerBlock>>>(d_mx, d_my, d_sx, d_sy, d_c);           cudaMemcpy(h_mx, d_mx, clusters * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_my, d_my, clusters * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"New means:\\n\");     for (int i = 0; i < clusters; ++i) {         printf(\"(%f, %f)\\n\", h_mx[i], h_my[i]);     }           free(h_mx);     free(h_my);     free(h_sx);     free(h_sy);     free(h_c);     cudaFree(d_mx);     cudaFree(d_my);     cudaFree(d_sx);     cudaFree(d_sy);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "74",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void copy_array_d2d(double **src, double **dst, int m, int n) {     int i, j;     for (i = 1; i < m + 1; i++)         for (j = 1; j < n + 1; j++)             dst[i][j] = src[i][j]; }  int main() {          int m = 3;     int n = 4;           double **src = (double **)malloc((m + 2) * sizeof(double *));     for (int i = 0; i < m + 2; i++) {         src[i] = (double *)malloc((n + 2) * sizeof(double));         for (int j = 0; j < n + 2; j++) {             src[i][j] = i * (n + 2) + j;          }     }           double **dst = (double **)malloc((m + 2) * sizeof(double *));     for (int i = 0; i < m + 2; i++) {         dst[i] = (double *)malloc((n + 2) * sizeof(double));     }           copy_array_d2d(src, dst, m, n);           printf(\"\u6e90\u6570\u7ec4 src\uff1a\\n\");     for (int i = 0; i < m + 2; i++) {         for (int j = 0; j < n + 2; j++) {             printf(\"%.2f \", src[i][j]);         }         printf(\"\\n\");     }      printf(\"\\n\u76ee\u6807\u6570\u7ec4 dst\uff08\u590d\u5236\u540e\uff09\uff1a\\n\");     for (int i = 0; i < m + 2; i++) {         for (int j = 0; j < n + 2; j++) {             printf(\"%.2f \", dst[i][j]);         }         printf(\"\\n\");     }           for (int i = 0; i < m + 2; i++) {         free(src[i]);         free(dst[i]);     }     free(src);     free(dst);      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void copy_array_d2d(double** src, double** dst, int m, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     int j = blockIdx.y * blockDim.y + threadIdx.y;      if (i < m && j < n) {         dst[i][j] = src[i][j];     } }  int main() {     const int m = 10;      const int n = 5;             double** h_src = new double*[m];     double** h_dst = new double*[m];     for (int i = 0; i < m; ++i) {         h_src[i] = new double[n];         h_dst[i] = new double[n];         for (int j = 0; j < n; ++j) {             h_src[i][j] = i * n + j;          }     }           double** d_src;     double** d_dst;     cudaMalloc((void**)&d_src, m * sizeof(double*));     cudaMalloc((void**)&d_dst, m * sizeof(double*));      for (int i = 0; i < m; ++i) {         cudaMalloc((void**)&d_src[i], n * sizeof(double));         cudaMalloc((void**)&d_dst[i], n * sizeof(double));         cudaMemcpy(d_src[i], h_src[i], n * sizeof(double), cudaMemcpyHostToDevice);     }           dim3 blockSize(16, 16);     dim3 gridSize((m + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);     copy_array_d2d<<<gridSize, blockSize>>>(d_src, d_dst, m, n);           for (int i = 0; i < m; ++i) {         cudaMemcpy(h_dst[i], d_dst[i], n * sizeof(double), cudaMemcpyDeviceToHost);     }           printf(\"Original array:\\n\");     for (int i = 0; i < m; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"%f \", h_src[i][j]);         }         printf(\"\\n\");     }      printf(\"\\nCopied array:\\n\");     for (int i = 0; i < m; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"%f \", h_dst[i][j]);         }         printf(\"\\n\");     }           for (int i = 0; i < m; ++i) {         cudaFree(d_src[i]);         cudaFree(d_dst[i]);         delete[] h_src[i];         delete[] h_dst[i];     }      cudaFree(d_src);     cudaFree(d_dst);     delete[] h_src;     delete[] h_dst;      return 0; } "
    },
    {
        "id": "75",
        "c_code": "#include <stdio.h>  void InitCCL(int labelList[], int reference[], int width, int height) {     int x, y;     for (x = 0; x < width; x++) {         for (y = 0; y < height; y++) {             int id = x + y * width;             labelList[id] = reference[id] = id;         }     } }  int main() {          int width = 3;     int height = 3;           int *labelList = new int[width * height];     int *reference = new int[width * height];           InitCCL(labelList, reference, width, height);           printf(\"\u521d\u59cb\u5316\u540e\u7684 labelList \u6570\u7ec4\uff1a\\n\");     for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             int id = x + y * width;             printf(\"%d \", labelList[id]);         }         printf(\"\\n\");     }      printf(\"\\n\u521d\u59cb\u5316\u540e\u7684 reference \u6570\u7ec4\uff1a\\n\");     for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             int id = x + y * width;             printf(\"%d \", reference[id]);         }         printf(\"\\n\");     }           delete[] labelList;     delete[] reference;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void InitCCL(int labelList[], int reference[], int width, int height) {     int x = blockIdx.x * blockDim.x + threadIdx.x;     int y = blockIdx.y * blockDim.y + threadIdx.y;      if (x >= width || y >= height) return;      int id = x + y * width;     labelList[id] = reference[id] = id; }  int main() {          int width = 512;     int height = 512;           dim3 gridSize((width + 15) / 16, (height + 15) / 16);     dim3 blockSize(16, 16);           int* h_labelList = (int*)malloc(width * height * sizeof(int));     int* h_reference = (int*)malloc(width * height * sizeof(int));           int* d_labelList, * d_reference;     cudaMalloc((void**)&d_labelList, width * height * sizeof(int));     cudaMalloc((void**)&d_reference, width * height * sizeof(int));           InitCCL<<<gridSize, blockSize>>>(d_labelList, d_reference, width, height);           cudaMemcpy(h_labelList, d_labelList, width * height * sizeof(int), cudaMemcpyDeviceToHost);     cudaMemcpy(h_reference, d_reference, width * height * sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_labelList);     cudaFree(d_reference);           free(h_labelList);     free(h_reference);      return 0; } "
    },
    {
        "id": "76",
        "c_code": "#include <stdio.h>  void cpu_set_sg(int *sxz, int sxbeg, int szbeg, int jsx, int jsz, int ns, int npml, int nnz) {     for (int id = 0; id < ns; id++) {         sxz[id] = nnz * (sxbeg + id * jsx + npml) + (szbeg + id * jsz + npml);     } }  int main() {          int ns = 3;        int *sxz = new int[ns];           cpu_set_sg(sxz, 1, 2, 3, 4, ns, 5, 6);           printf(\"\u521d\u59cb\u5316\u540e\u7684 sxz \u6570\u7ec4\uff1a\\n\");     for (int id = 0; id < ns; id++) {         printf(\"%d \", sxz[id]);     }           delete[] sxz;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void cuda_set_sg(int* sxz, int sxbeg, int szbeg, int jsx, int jsz, int ns, int npml, int nnz) {     int id = threadIdx.x + blockDim.x * blockIdx.x;      if (id < ns) {         sxz[id] = nnz * (sxbeg + id * jsx + npml) + (szbeg + id * jsz + npml);     } }  int main() {          int ns = 512;       int npml = 10;       int nnz = 100;       int sxbeg = 0;     int szbeg = 0;     int jsx = 1;     int jsz = 1;           int* h_sxz = (int*)malloc(ns * sizeof(int));           int* d_sxz;     cudaMalloc((void**)&d_sxz, ns * sizeof(int));           dim3 gridSize((ns + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           cuda_set_sg<<<gridSize, blockSize>>>(d_sxz, sxbeg, szbeg, jsx, jsz, ns, npml, nnz);           cudaMemcpy(h_sxz, d_sxz, ns * sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_sxz);           free(h_sxz);      return 0; } "
    },
    {
        "id": "77",
        "c_code": "#include <stdio.h>  void addMatrix(float *a, float *b, float *c, int N) {     int i, j, idx;     for (i = 0; i < N; i++) {         for (j = 0; j < N; j++) {             idx = i * N + j;             a[idx] = b[idx] + c[idx];         }     } }  int main() {          int N = 3;        float *a = new float[N * N];     float *b = new float[N * N];     float *c = new float[N * N];                 addMatrix(a, b, c, N);           printf(\"\u77e9\u9635\u76f8\u52a0\u540e\u7684\u7ed3\u679c\uff08a\u77e9\u9635\uff09\uff1a\\n\");     for (int i = 0; i < N; i++) {         for (int j = 0; j < N; j++) {             int idx = i * N + j;             printf(\"%.2f \", a[idx]);         }         printf(\"\\n\");     }           delete[] a;     delete[] b;     delete[] c;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void addMatrixGPU(float* a, float* b, float* c, int N) {     int j = threadIdx.x + blockIdx.x * blockDim.x;     int i = threadIdx.y + blockIdx.y * blockDim.y;      if ((i < N) && (j < N)) {         int idx = i * N + j;         a[idx] = b[idx] + c[idx];     } }  int main() {          int N = 512;           float* h_a = (float*)malloc(N * N * sizeof(float));     float* h_b = (float*)malloc(N * N * sizeof(float));     float* h_c = (float*)malloc(N * N * sizeof(float));                 float* d_a, * d_b, * d_c;     cudaMalloc((void**)&d_a, N * N * sizeof(float));     cudaMalloc((void**)&d_b, N * N * sizeof(float));     cudaMalloc((void**)&d_c, N * N * sizeof(float));                 dim3 gridSize((N + 15) / 16, (N + 15) / 16);     dim3 blockSize(16, 16);           addMatrixGPU<<<gridSize, blockSize>>>(d_a, d_b, d_c, N);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);           free(h_a);     free(h_b);     free(h_c);      return 0; } "
    },
    {
        "id": "78",
        "c_code": "#include <stdio.h>  void resizedClsScore_cpu(const float *score, const float *score_factors, float *output, int dims) {     for (int tid = 0; tid < dims; tid++) {         if (score[tid] == (-1)) {             output[tid] = -1;         } else {             output[tid] = score[tid] * score_factors[tid];         }     } }  int main() {          int dims = 5;        float *score = new float[dims];     float *score_factors = new float[dims];     float *output = new float[dims];                 resizedClsScore_cpu(score, score_factors, output, dims);           printf(\"\u5904\u7406\u540e\u7684 output \u6570\u7ec4\uff1a\\n\");     for (int tid = 0; tid < dims; tid++) {         printf(\"%.2f \", output[tid]);     }           delete[] score;     delete[] score_factors;     delete[] output;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void resizedClsScore(const float* score, const float* score_factors, float* output, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      if (score[tid] == (-1)) {         output[tid] = -1;     } else {         output[tid] = score[tid] * score_factors[tid];     } }  int main() {          int dims = 512;           float* h_score = (float*)malloc(dims * sizeof(float));     float* h_score_factors = (float*)malloc(dims * sizeof(float));     float* h_output = (float*)malloc(dims * sizeof(float));                 float* d_score, * d_score_factors, * d_output;     cudaMalloc((void**)&d_score, dims * sizeof(float));     cudaMalloc((void**)&d_score_factors, dims * sizeof(float));     cudaMalloc((void**)&d_output, dims * sizeof(float));                 dim3 gridSize((dims + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           resizedClsScore<<<gridSize, blockSize>>>(d_score, d_score_factors, d_output, dims);                 cudaFree(d_score);     cudaFree(d_score_factors);     cudaFree(d_output);           free(h_score);     free(h_score_factors);     free(h_output);      return 0; } "
    },
    {
        "id": "79",
        "c_code": "  #include <stdio.h> #include <math.h>  void l1_cpu(int n, float *pred, float *truth, float *delta, float *error) {     for (int i = 0; i < n; ++i) {         float diff = truth[i] - pred[i];         error[i] = fabs(diff);         delta[i] = diff > 0 ? 1 : -1;     } }  int main() {          int n = 5;        float *pred = new float[n];     float *truth = new float[n];     float *delta = new float[n];     float *error = new float[n];                 l1_cpu(n, pred, truth, delta, error);           printf(\"\u5904\u7406\u540e\u7684 delta \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < n; i++) {         printf(\"%.2f \", delta[i]);     }      printf(\"\\n\u5904\u7406\u540e\u7684 error \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < n; i++) {         printf(\"%.2f \", error[i]);     }           delete[] pred;     delete[] truth;     delete[] delta;     delete[] error;      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <cmath>   __global__ void l1_kernel(int n, float* pred, float* truth, float* delta, float* error) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i < n) {         float diff = truth[i] - pred[i];         error[i] = fabs(diff);         delta[i] = (diff > 0) ? 1 : -1;     } }  int main() {          int n = 512;           float* h_pred = (float*)malloc(n * sizeof(float));     float* h_truth = (float*)malloc(n * sizeof(float));     float* h_delta = (float*)malloc(n * sizeof(float));     float* h_error = (float*)malloc(n * sizeof(float));                 float* d_pred, * d_truth, * d_delta, * d_error;     cudaMalloc((void**)&d_pred, n * sizeof(float));     cudaMalloc((void**)&d_truth, n * sizeof(float));     cudaMalloc((void**)&d_delta, n * sizeof(float));     cudaMalloc((void**)&d_error, n * sizeof(float));                 dim3 gridSize((n + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           l1_kernel<<<gridSize, blockSize>>>(n, d_pred, d_truth, d_delta, d_error);                 cudaFree(d_pred);     cudaFree(d_truth);     cudaFree(d_delta);     cudaFree(d_error);           free(h_pred);     free(h_truth);     free(h_delta);     free(h_error);      return 0; } "
    },
    {
        "id": "8",
        "c_code": "#include <stdio.h>  void initialArray0_cpu(int tasks, int *f3) {     for (int i = 0; i < tasks; i++) {         f3[i] = 0;     } }  int main() {          int numTasks = 8;     int array[numTasks];      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numTasks; i++) {         printf(\"%d \", array[i]);     }           initialArray0_cpu(numTasks, array);      printf(\"\\n\u521d\u59cb\u5316\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numTasks; i++) {         printf(\"%d \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void initialArray0(int tasks, int* f3) {     for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < tasks; i += blockDim.x * gridDim.x) {         f3[i] = 0;     } }  int main() {          int numTasks = 1000;           int* h_f3 = (int*)malloc(numTasks * sizeof(int));           int* d_f3;     cudaMalloc((void**)&d_f3, numTasks * sizeof(int));           int blockSize = 256;     int gridSize = (numTasks + blockSize - 1) / blockSize;           initialArray0<<<gridSize, blockSize>>>(numTasks, d_f3);           cudaMemcpy(h_f3, d_f3, numTasks * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_f3[i]);     }           free(h_f3);     cudaFree(d_f3);      return 0; } "
    },
    {
        "id": "80",
        "c_code": "#include <stdio.h>  void AddMatrixOnCPU(int *A, int *B, int *C, int nx, int ny) {     int i, j;     int cnt = 0;     for (j = 0; j < ny; j++) {         for (i = 0; i < nx; i++) {             C[cnt] = A[cnt] + B[cnt];             cnt++;         }     } }  int main() {          int nx = 3;        int ny = 3;        int size = nx * ny;     int *A = new int[size];     int *B = new int[size];     int *C = new int[size];                 AddMatrixOnCPU(A, B, C, nx, ny);           printf(\"\u5904\u7406\u540e\u7684 C \u77e9\u9635\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", C[i]);     }           delete[] A;     delete[] B;     delete[] C;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void AddMatrixOnGPU(float* A, float* B, float* C, int nx, int ny) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     int j = threadIdx.y + blockIdx.y * blockDim.y;     int idx = i * nx + j;      if (i < nx && j < ny) {         C[idx] = A[idx] + B[idx];     } }  int main() {          int nx = 512;     int ny = 512;           float* h_A = (float*)malloc(nx * ny * sizeof(float));     float* h_B = (float*)malloc(nx * ny * sizeof(float));     float* h_C = (float*)malloc(nx * ny * sizeof(float));                 float* d_A, * d_B, * d_C;     cudaMalloc((void**)&d_A, nx * ny * sizeof(float));     cudaMalloc((void**)&d_B, nx * ny * sizeof(float));     cudaMalloc((void**)&d_C, nx * ny * sizeof(float));                 dim3 gridSize((nx + 15) / 16, (ny + 15) / 16);     dim3 blockSize(16, 16);           AddMatrixOnGPU<<<gridSize, blockSize>>>(d_A, d_B, d_C, nx, ny);                 cudaFree(d_A);     cudaFree(d_B);     cudaFree(d_C);           free(h_A);     free(h_B);     free(h_C);      return 0; } "
    },
    {
        "id": "81",
        "c_code": "#include <stdio.h>  void LreluForward(float *srcData, float *dstData, int data_size, float alpha) {     for (int i = 0; i < data_size; i++) {         dstData[i] = srcData[i] > 0 ? srcData[i] : srcData[i] * alpha;     } }  int main() {          int data_size = 5;        float alpha = 0.01;        float *srcData = new float[data_size];     float *dstData = new float[data_size];                 LreluForward(srcData, dstData, data_size, alpha);           printf(\"\u5904\u7406\u540e\u7684 dstData \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < data_size; i++) {         printf(\"%.2f \", dstData[i]);     }           delete[] srcData;     delete[] dstData;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void LreluForward(float* srcData, float* dstData, int data_size, float alpha) {     int thread_index = threadIdx.x + blockIdx.x * blockDim.x;     int num_threads = blockDim.x * gridDim.x;      for (int i = 0; i < data_size; i += num_threads) {         int index = i + thread_index;          if (index < data_size) {             dstData[index] = (srcData[index] > 0) ? srcData[index] : srcData[index] * alpha;         }     } }  int main() {          int data_size = 512;     float alpha = 0.01;            float* h_srcData = (float*)malloc(data_size * sizeof(float));     float* h_dstData = (float*)malloc(data_size * sizeof(float));                 float* d_srcData, * d_dstData;     cudaMalloc((void**)&d_srcData, data_size * sizeof(float));     cudaMalloc((void**)&d_dstData, data_size * sizeof(float));                 dim3 gridSize((data_size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           LreluForward<<<gridSize, blockSize>>>(d_srcData, d_dstData, data_size, alpha);                 cudaFree(d_srcData);     cudaFree(d_dstData);           free(h_srcData);     free(h_dstData);      return 0; } "
    },
    {
        "id": "82",
        "c_code": "#include <stdio.h>  void filterFFT_cpu(float *FFT, float *filter, int nxprj2, int nviews, float scale) {     for (int i = 0; i < nviews; i++) {         for (int j = 0; j < nxprj2; j++) {             FFT[i * nxprj2 + j] *= filter[i * nxprj2 + j] * scale;         }     } }  int main() {          int nxprj2 = 3;         int nviews = 2;         float scale = 0.5;      float *FFT = new float[nxprj2 * nviews];     float *filter = new float[nxprj2 * nviews];                 filterFFT_cpu(FFT, filter, nxprj2, nviews, scale);           printf(\"\u5904\u7406\u540e\u7684 FFT \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < nviews; i++) {         for (int j = 0; j < nxprj2; j++) {             printf(\"%.2f \", FFT[i * nxprj2 + j]);         }         printf(\"\\n\");     }           delete[] FFT;     delete[] filter;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void filterFFT(float* FFT, float* filter, int nxprj2, int nviews, float scale) {     int j = blockIdx.x * blockDim.x + threadIdx.x;     int i = blockIdx.y * blockDim.y + threadIdx.y;      if (i < nviews && j < nxprj2) {         FFT[i * nxprj2 + j] *= filter[i * nxprj2 + j] * scale;     } }  int main() {          int nxprj2 = 512;     int nviews = 512;     float scale = 0.5;            float* h_FFT = (float*)malloc(nxprj2 * nviews * sizeof(float));     float* h_filter = (float*)malloc(nxprj2 * nviews * sizeof(float));                 float* d_FFT, * d_filter;     cudaMalloc((void**)&d_FFT, nxprj2 * nviews * sizeof(float));     cudaMalloc((void**)&d_filter, nxprj2 * nviews * sizeof(float));                 dim3 gridSize((nxprj2 + 15) / 16, (nviews + 15) / 16);     dim3 blockSize(16, 16);           filterFFT<<<gridSize, blockSize>>>(d_FFT, d_filter, nxprj2, nviews, scale);                 cudaFree(d_FFT);     cudaFree(d_filter);           free(h_FFT);     free(h_filter);      return 0; } "
    },
    {
        "id": "83",
        "c_code": "#include <stdio.h>  void convertFloatToRGBA_cpu(char *out_image, const float *in_image, int width, int height) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < height; y++) {             int IND = (y * width + x) * 4;               float val = in_image[y * width + x];                           char temp = static_cast<char>(val * 255.0f);                           out_image[IND] = temp;                  out_image[IND + 1] = temp;              out_image[IND + 2] = temp;              out_image[IND + 3] = 255;           }     } }  int main() {          int width = 3;        int height = 2;       float *in_image = new float[width * height];       char *out_image = new char[width * height * 4];                  convertFloatToRGBA_cpu(out_image, in_image, width, height);           for (int i = 0; i < width * height * 4; i++) {         printf(\"%d \", out_image[i]);     }           delete[] in_image;     delete[] out_image;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void convertFloatToRGBA_kernel(char* out_image, const float* in_image, int width, int height) {     const int x = blockIdx.x * blockDim.x + threadIdx.x;     const int y = blockIdx.y * blockDim.y + threadIdx.y;      if (x < width && y < height) {         int IND = y * width + x;         float val = in_image[IND];         char temp = 255;         out_image[IND] = temp;     } }  int main() {          int width = 512;     int height = 512;           char* h_out_image = (char*)malloc(width * height * sizeof(char));     float* h_in_image = (float*)malloc(width * height * sizeof(float));                 char* d_out_image;     float* d_in_image;     cudaMalloc((void**)&d_out_image, width * height * sizeof(char));     cudaMalloc((void**)&d_in_image, width * height * sizeof(float));                 dim3 gridSize((width + 15) / 16, (height + 15) / 16);     dim3 blockSize(16, 16);           convertFloatToRGBA_kernel<<<gridSize, blockSize>>>(d_out_image, d_in_image, width, height);                 cudaFree(d_out_image);     cudaFree(d_in_image);           free(h_out_image);     free(h_in_image);      return 0; } "
    },
    {
        "id": "84",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void convertEdgeMaskToFloatCpu(float *d_output, unsigned char *d_input, unsigned int width, unsigned int height) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < height; y++) {             d_output[y * width + x] = fminf(d_input[y * width + x], d_input[width * height + y * width + x]);         }     } }  int main() {          unsigned int width = 5;     unsigned int height = 5;           unsigned char *d_input = (unsigned char *)malloc(width * height * 2 * sizeof(unsigned char));       float *d_output = (float *)malloc(width * height * sizeof(float));           for (int i = 0; i < width * height * 2; i++) {         d_input[i] = i % 256;       }           convertEdgeMaskToFloatCpu(d_output, d_input, width, height);           for (int i = 0; i < width * height; i++) {         printf(\"%f \", d_output[i]);     }           free(d_input);     free(d_output);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void convertEdgeMaskToFloatDevice(float* d_output, unsigned char* d_input, unsigned int width, unsigned int height) {     const int x = blockIdx.x * blockDim.x + threadIdx.x;     const int y = blockIdx.y * blockDim.y + threadIdx.y;      if (x >= width || y >= height) return;      d_output[y * width + x] = min(d_input[y * width + x], d_input[width * height + y * width + x]); }  int main() {          unsigned int width = 512;     unsigned int height = 512;           float* h_output = (float*)malloc(width * height * sizeof(float));     unsigned char* h_input = (unsigned char*)malloc(2 * width * height * sizeof(unsigned char));                 float* d_output;     unsigned char* d_input;     cudaMalloc((void**)&d_output, width * height * sizeof(float));     cudaMalloc((void**)&d_input, 2 * width * height * sizeof(unsigned char));                 dim3 gridSize((width + 15) / 16, (height + 15) / 16);     dim3 blockSize(16, 16);           convertEdgeMaskToFloatDevice<<<gridSize, blockSize>>>(d_output, d_input, width, height);                 cudaFree(d_output);     cudaFree(d_input);           free(h_output);     free(h_input);      return 0; } "
    },
    {
        "id": "85",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void gpu_matrix_transpose(int *mat_in, int *mat_out, unsigned int rows, unsigned int cols) {     unsigned int idx;     unsigned int idy;      for (idx = 0; idx < cols; idx++) {         for (idy = 0; idy < rows; idy++) {             unsigned int pos = idy * cols + idx;             unsigned int trans_pos = idx * rows + idy;             mat_out[trans_pos] = mat_in[pos];         }     } }  int main() {          unsigned int rows = 3;     unsigned int cols = 4;           int *mat_in = (int *)malloc(rows * cols * sizeof(int));     int *mat_out = (int *)malloc(rows * cols * sizeof(int));           for (unsigned int i = 0; i < rows * cols; i++) {         mat_in[i] = i;     }           gpu_matrix_transpose(mat_in, mat_out, rows, cols);           for (unsigned int i = 0; i < rows * cols; i++) {         printf(\"%d \", mat_out[i]);     }           free(mat_in);     free(mat_out);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gpu_matrix_transpose(int* mat_in, int* mat_out, unsigned int rows, unsigned int cols) {     unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;     unsigned int idy = blockIdx.y * blockDim.y + threadIdx.y;      if (idx < cols && idy < rows) {         unsigned int pos = idy * cols + idx;         unsigned int trans_pos = idx * rows + idy;         mat_out[trans_pos] = mat_in[pos];     } }  int main() {          unsigned int rows = 512;     unsigned int cols = 512;           int* h_mat_in = (int*)malloc(rows * cols * sizeof(int));     int* h_mat_out = (int*)malloc(rows * cols * sizeof(int));                 int* d_mat_in, * d_mat_out;     cudaMalloc((void**)&d_mat_in, rows * cols * sizeof(int));     cudaMalloc((void**)&d_mat_out, rows * cols * sizeof(int));                 dim3 gridSize((cols + 15) / 16, (rows + 15) / 16);     dim3 blockSize(16, 16);           gpu_matrix_transpose<<<gridSize, blockSize>>>(d_mat_in, d_mat_out, rows, cols);                 cudaFree(d_mat_in);     cudaFree(d_mat_out);           free(h_mat_in);     free(h_mat_out);      return 0; } "
    },
    {
        "id": "86",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void LreluBackward(float *srcDiff, float *dstDiff, float *srcData, int data_size, float alpha) {     for (int i = 0; i < data_size; i++) {         dstDiff[i] = (srcData[i] > 0) ? srcDiff[i] * 1.0 : srcDiff[i] * alpha;     } }  int main() {          int data_size = 5;           float *srcDiff = (float *)malloc(data_size * sizeof(float));     float *dstDiff = (float *)malloc(data_size * sizeof(float));     float *srcData = (float *)malloc(data_size * sizeof(float));           for (int i = 0; i < data_size; i++) {         srcDiff[i] = i;         srcData[i] = i - 2.0;     }           float alpha = 0.1;           LreluBackward(srcDiff, dstDiff, srcData, data_size, alpha);           printf(\"srcDiff: \");     for (int i = 0; i < data_size; i++) {         printf(\"%f \", srcDiff[i]);     }      printf(\"\\nsrcData: \");     for (int i = 0; i < data_size; i++) {         printf(\"%f \", srcData[i]);     }      printf(\"\\ndstDiff: \");     for (int i = 0; i < data_size; i++) {         printf(\"%f \", dstDiff[i]);     }           free(srcDiff);     free(dstDiff);     free(srcData);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void LreluBackward(float* srcDiff, float* dstDiff, float* srcData, int data_size, float alpha) {     int thread_index = threadIdx.x + blockIdx.x * blockDim.x;     int num_threads = blockDim.x * gridDim.x;      for (int i = 0; i < data_size; i += num_threads) {         int index = i + thread_index;          if (index < data_size) {             dstDiff[index] = srcDiff[index] * ((srcData[index] > 0) + (srcData[index] <= 0) * alpha);         }     } }  int main() {          int data_size = 512;     float alpha = 0.01;            float* h_srcDiff = (float*)malloc(data_size * sizeof(float));     float* h_dstDiff = (float*)malloc(data_size * sizeof(float));     float* h_srcData = (float*)malloc(data_size * sizeof(float));                 float* d_srcDiff, * d_dstDiff, * d_srcData;     cudaMalloc((void**)&d_srcDiff, data_size * sizeof(float));     cudaMalloc((void**)&d_dstDiff, data_size * sizeof(float));     cudaMalloc((void**)&d_srcData, data_size * sizeof(float));                 dim3 gridSize((data_size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           LreluBackward<<<gridSize, blockSize>>>(d_srcDiff, d_dstDiff, d_srcData, data_size, alpha);                 cudaFree(d_srcDiff);     cudaFree(d_dstDiff);     cudaFree(d_srcData);           free(h_srcDiff);     free(h_dstDiff);     free(h_srcData);      return 0; } "
    },
    {
        "id": "87",
        "c_code": "#include <stdio.h> #include <stdlib.h>  int cpuReduce(int *N, const int size) {     if (size == 1)         return N[0];      int stride = size / 2;      for (int i = 0; i < stride; i++)         N[i] += N[i + stride];      return cpuReduce(N, stride); }  int main() {          const int size = 8;           int *N = (int *)malloc(size * sizeof(int));           for (int i = 0; i < size; i++) {         N[i] = i + 1;     }           int result = cpuReduce(N, size);           printf(\"Reduced value: %d\\n\", result);           free(N);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gpuReduceRecursive(int* I, int* O, unsigned int n) {     unsigned int tid = threadIdx.x;     unsigned int idx = threadIdx.x + blockIdx.x * blockDim.x;      if (idx >= n) return;      int* N = I + blockIdx.x * blockDim.x;      for (int stride = 1; stride < blockDim.x; stride *= 2) {         if ((tid % (2 * stride)) == 0)             N[tid] += N[tid + stride];          __syncthreads();     }      if (tid == 0)         O[blockIdx.x] = N[0]; }  int main() {          unsigned int n = 512;           int* h_I = (int*)malloc(n * sizeof(int));     int* h_O = (int*)malloc((n + 255) / 256 * sizeof(int));                 int* d_I, * d_O;     cudaMalloc((void**)&d_I, n * sizeof(int));     cudaMalloc((void**)&d_O, (n + 255) / 256 * sizeof(int));                 dim3 gridSize((n + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           gpuReduceRecursive<<<gridSize, blockSize>>>(d_I, d_O, n);                 cudaFree(d_I);     cudaFree(d_O);           free(h_I);     free(h_O);      return 0; } "
    },
    {
        "id": "88",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void devidecountInnerCPU(long Xsize, long Ysize, long Zsize, double *p, double *pn, int *pcountinner) {     for (int tid = 0; tid < Xsize * Ysize * Zsize; tid++) {         if (pcountinner[tid] > 1) {             p[tid] = pn[tid] / pcountinner[tid];             pn[tid] = 0;         }     } }  int main() {          long Xsize = 3;     long Ysize = 3;     long Zsize = 3;           double *p = (double *)malloc(Xsize * Ysize * Zsize * sizeof(double));     double *pn = (double *)malloc(Xsize * Ysize * Zsize * sizeof(double));     int *pcountinner = (int *)malloc(Xsize * Ysize * Zsize * sizeof(int));           for (int i = 0; i < Xsize * Ysize * Zsize; i++) {         p[i] = i + 1;         pn[i] = 2 * i;         pcountinner[i] = i % 3;       }           devidecountInnerCPU(Xsize, Ysize, Zsize, p, pn, pcountinner);           printf(\"p: \");     for (int i = 0; i < Xsize * Ysize * Zsize; i++) {         printf(\"%f \", p[i]);     }      printf(\"\\npn: \");     for (int i = 0; i < Xsize * Ysize * Zsize; i++) {         printf(\"%f \", pn[i]);     }           free(p);     free(pn);     free(pcountinner);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void devidecountInner(long Xsize, long Ysize, long Zsize, double* p, double* pn, int* pcountinner) {     long tid = threadIdx.x + blockDim.x * blockIdx.x;      while (tid < Xsize * Ysize * Zsize) {         if (pcountinner[tid] > 1) {             p[tid] = pn[tid] / pcountinner[tid];             pn[tid] = 0;         }          tid += blockDim.x * gridDim.x;     } }  int main() {          long Xsize = 512;     long Ysize = 512;     long Zsize = 512;           double* h_p = (double*)malloc(Xsize * Ysize * Zsize * sizeof(double));     double* h_pn = (double*)malloc(Xsize * Ysize * Zsize * sizeof(double));     int* h_pcountinner = (int*)malloc(Xsize * Ysize * Zsize * sizeof(int));                 double* d_p, * d_pn;     int* d_pcountinner;     cudaMalloc((void**)&d_p, Xsize * Ysize * Zsize * sizeof(double));     cudaMalloc((void**)&d_pn, Xsize * Ysize * Zsize * sizeof(double));     cudaMalloc((void**)&d_pcountinner, Xsize * Ysize * Zsize * sizeof(int));                 dim3 gridSize((Xsize * Ysize * Zsize + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           devidecountInner<<<gridSize, blockSize>>>(Xsize, Ysize, Zsize, d_p, d_pn, d_pcountinner);                 cudaFree(d_p);     cudaFree(d_pn);     cudaFree(d_pcountinner);           free(h_p);     free(h_pn);     free(h_pcountinner);      return 0; } "
    },
    {
        "id": "89",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void cpuConvertToBits(int *bit_decisions, unsigned short *bit_stream, int dec_size) {     for (int dec_index = 0; dec_index < dec_size; dec_index++) {         int bit_index = dec_index * 2;         int curr_decision = bit_decisions[dec_index];         bit_stream[bit_index] = ((curr_decision & 2) >> 1);         bit_stream[bit_index + 1] = (curr_decision & 1);     } }  int main() {          int dec_size = 5;           int *bit_decisions = (int *)malloc(dec_size * sizeof(int));     unsigned short *bit_stream = (unsigned short *)malloc(dec_size * 2 * sizeof(unsigned short));           for (int i = 0; i < dec_size; i++) {         bit_decisions[i] = i % 4;       }           cpuConvertToBits(bit_decisions, bit_stream, dec_size);           printf(\"bit_decisions: \");     for (int i = 0; i < dec_size; i++) {         printf(\"%d \", bit_decisions[i]);     }      printf(\"\\nbit_stream: \");     for (int i = 0; i < dec_size * 2; i++) {         printf(\"%hu \", bit_stream[i]);     }           free(bit_decisions);     free(bit_stream);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void cudaConvertToBits(int* bit_decisions, unsigned short* bit_stream, int dec_size) {     int dec_index = (blockIdx.x * blockDim.x) + threadIdx.x;     int bit_index = dec_index * 2;      if (dec_index >= dec_size)         return;      int curr_decision = bit_decisions[dec_index];     bit_stream[bit_index] = ((curr_decision & 2) >> 1);     bit_stream[bit_index + 1] = (curr_decision & 1); }  int main() {          int dec_size = 512;           int* h_bit_decisions = (int*)malloc(dec_size * sizeof(int));     unsigned short* h_bit_stream = (unsigned short*)malloc(dec_size * 2 * sizeof(unsigned short));                 int* d_bit_decisions;     unsigned short* d_bit_stream;     cudaMalloc((void**)&d_bit_decisions, dec_size * sizeof(int));     cudaMalloc((void**)&d_bit_stream, dec_size * 2 * sizeof(unsigned short));                 dim3 gridSize((dec_size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           cudaConvertToBits<<<gridSize, blockSize>>>(d_bit_decisions, d_bit_stream, dec_size);                 cudaFree(d_bit_decisions);     cudaFree(d_bit_stream);           free(h_bit_decisions);     free(h_bit_stream);      return 0; } "
    },
    {
        "id": "9",
        "c_code": "#include <stdio.h>  void add_vector_cpu(float *a, float *b, float *c, int size) {     for (int i = 0; i < size; ++i) {         c[i] = a[i] + b[i];     } }  int main() {          int vectorSize = 5;     float vectorA[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float vectorB[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultVector[vectorSize];      printf(\"\u5411\u91cf A\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorA[i]);     }      printf(\"\\n\u5411\u91cf B\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorB[i]);     }           add_vector_cpu(vectorA, vectorB, resultVector, vectorSize);      printf(\"\\n\u76f8\u52a0\u540e\u7684\u5411\u91cf C\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", resultVector[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void VectorAdd(float* arrayA, float* arrayB, float* output) {     int idx = threadIdx.x;     output[idx] = arrayA[idx] + arrayB[idx]; }  int main() {          int arraySize = 1000;           float* h_arrayA = (float*)malloc(arraySize * sizeof(float));     float* h_arrayB = (float*)malloc(arraySize * sizeof(float));     float* h_output = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_arrayA[i] = static_cast<float>(i);         h_arrayB[i] = static_cast<float>(2 * i);     }           float* d_arrayA;     float* d_arrayB;     float* d_output;     cudaMalloc((void**)&d_arrayA, arraySize * sizeof(float));     cudaMalloc((void**)&d_arrayB, arraySize * sizeof(float));     cudaMalloc((void**)&d_output, arraySize * sizeof(float));           cudaMemcpy(d_arrayA, h_arrayA, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_arrayB, h_arrayB, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           VectorAdd<<<gridSize, blockSize>>>(d_arrayA, d_arrayB, d_output);           cudaMemcpy(h_output, d_output, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_output[i]);     }           free(h_arrayA);     free(h_arrayB);     free(h_output);     cudaFree(d_arrayA);     cudaFree(d_arrayB);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "90",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void copyAliasRow(int *devMat, int memWidth, int memHeight, int size) {     for (int devMatX = 0; devMatX < size; devMatX++) {         devMat[memWidth * 0 + devMatX] = devMat[memWidth * (memHeight - 2) + devMatX];         devMat[memWidth * (memHeight - 1) + devMatX] = devMat[memWidth * 1 + devMatX];     } }  int main() {          int memWidth = 4;     int memHeight = 4;     int size = memWidth;           int *devMat = (int *)malloc(memWidth * memHeight * sizeof(int));           for (int i = 0; i < memWidth * memHeight; i++) {         devMat[i] = i + 1;     }           copyAliasRow(devMat, memWidth, memHeight, size);           printf(\"devMat after copyAliasRow:\\n\");     for (int i = 0; i < memHeight; i++) {         for (int j = 0; j < memWidth; j++) {             printf(\"%d \", devMat[i * memWidth + j]);         }         printf(\"\\n\");     }           free(devMat);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void copyAliasRow(int* devMat, int memWidth, int memHeight) {     int devMatX = blockIdx.x * blockDim.x + threadIdx.x + 1;      devMat[memWidth * 0 + devMatX] = devMat[memWidth * (memHeight - 2) + devMatX];     devMat[memWidth * (memHeight - 1) + devMatX] = devMat[memWidth * 1 + devMatX]; }  int main() {          int memWidth = 512;     int memHeight = 512;           int* h_devMat = (int*)malloc(memWidth * memHeight * sizeof(int));                 int* d_devMat;     cudaMalloc((void**)&d_devMat, memWidth * memHeight * sizeof(int));                 dim3 gridSize((memWidth - 1 + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           copyAliasRow<<<gridSize, blockSize>>>(d_devMat, memWidth, memHeight);                 cudaFree(d_devMat);           free(h_devMat);      return 0; } "
    },
    {
        "id": "91",
        "c_code": "#include <stdio.h> #include <stdlib.h>  double *ObjFeatures_circularity(const int compCount, const int *areaRes, const double *perimeter) {     if (compCount > 0) {         double *circ = (double *)malloc(compCount * sizeof(double));         for (int i = 0; i < compCount; i++) {             circ[i] = (4.0 * 3.14159265359 * (double)areaRes[i]) / (perimeter[i] * perimeter[i]);         }         return circ;     }     return (double *)0; }  int main() {          const int compCount = 3;     int areaRes[] = {10, 15, 20};     double perimeter[] = {12.56, 18.85, 25.13};           double *circ = ObjFeatures_circularity(compCount, areaRes, perimeter);           printf(\"Circularity features:\\n\");     for (int i = 0; i < compCount; i++) {         printf(\"%f \", circ[i]);     }           free(circ);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void circularity(const int compCount, const int* areaRes, const float* perimeterRes, float* circ) {     int tid = blockDim.x * blockIdx.x + threadIdx.x;      if (tid < compCount) {         circ[tid] = (4.0 * 3.14159265359 * (float)areaRes[tid]) / (perimeterRes[tid] * perimeterRes[tid]);     } }  int main() {          int compCount = 512;           int* h_areaRes = (int*)malloc(compCount * sizeof(int));     float* h_perimeterRes = (float*)malloc(compCount * sizeof(float));     float* h_circ = (float*)malloc(compCount * sizeof(float));                 int* d_areaRes;     float* d_perimeterRes;     float* d_circ;     cudaMalloc((void**)&d_areaRes, compCount * sizeof(int));     cudaMalloc((void**)&d_perimeterRes, compCount * sizeof(float));     cudaMalloc((void**)&d_circ, compCount * sizeof(float));                 dim3 gridSize((compCount + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           circularity<<<gridSize, blockSize>>>(compCount, d_areaRes, d_perimeterRes, d_circ);                 cudaFree(d_areaRes);     cudaFree(d_perimeterRes);     cudaFree(d_circ);           free(h_areaRes);     free(h_perimeterRes);     free(h_circ);      return 0; } "
    },
    {
        "id": "92",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void devidecountCPU(long Xsize, long Ysize, long Zsize, double *pint, int *pcount) {     int n = Xsize * Ysize * 2 + (Ysize - 2) * Zsize * 2 + (Xsize - 2) * (Zsize - 2) * 2;          for (int tid = 0; tid < n * n; tid++) {         if (pcount[tid] > 1) {             pint[tid] /= pcount[tid];         }     } }  int main() {          long Xsize = 3;     long Ysize = 3;     long Zsize = 3;           double *pint = (double *)malloc(Xsize * Ysize * Zsize * 2 * sizeof(double));     int *pcount = (int *)malloc(Xsize * Ysize * Zsize * 2 * sizeof(int));           for (int i = 0; i < Xsize * Ysize * Zsize * 2; i++) {         pint[i] = i + 1;         pcount[i] = i % 3;       }           devidecountCPU(Xsize, Ysize, Zsize, pint, pcount);           printf(\"pint after devidecountCPU:\\n\");     for (int i = 0; i < Xsize * Ysize * Zsize * 2; i++) {         printf(\"%f \", pint[i]);     }           free(pint);     free(pcount);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void devidecount(long Xsize, long Ysize, long Zsize, double* pint, int* pcount) {     int n = Xsize * Ysize * 2 + (Ysize - 2) * Zsize * 2 + (Xsize - 2) * (Zsize - 2) * 2;     long tid = threadIdx.x + blockDim.x * blockIdx.x;      while (tid < n * n) {         if (pcount[tid] > 1) {             pint[tid] /= pcount[tid];         }          tid += blockDim.x * gridDim.x;     } }  int main() {          long Xsize = 512;     long Ysize = 512;     long Zsize = 512;           double* h_pint = (double*)malloc(Xsize * Ysize * Zsize * sizeof(double));     int* h_pcount = (int*)malloc(Xsize * Ysize * Zsize * sizeof(int));                 double* d_pint;     int* d_pcount;     cudaMalloc((void**)&d_pint, Xsize * Ysize * Zsize * sizeof(double));     cudaMalloc((void**)&d_pcount, Xsize * Ysize * Zsize * sizeof(int));                 dim3 gridSize((n + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           devidecount<<<gridSize, blockSize>>>(Xsize, Ysize, Zsize, d_pint, d_pcount);                 cudaFree(d_pint);     cudaFree(d_pcount);           free(h_pint);     free(h_pcount);      return 0; } "
    },
    {
        "id": "93",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void bubbleSort(int *p, const int size) {     for (int i = 0; i < size - 1; i++) {         for (int j = 0; j < size - i - 1; j++) {             if (p[j] > p[j + 1]) {                 int temp = p[j];                 p[j] = p[j + 1];                 p[j + 1] = temp;             }         }     } }  int main() {          const int size = 5;           int *p = (int *)malloc(size * sizeof(int));           p[0] = 5;     p[1] = 3;     p[2] = 1;     p[3] = 4;     p[4] = 2;           bubbleSort(p, size);           printf(\"Sorted array: \");     for (int i = 0; i < size; i++) {         printf(\"%d \", p[i]);     }           free(p);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void oddevenSort(int* d_in, int size, int oe_flag, int& d_ch_flag) {     int idx = threadIdx.x + blockIdx.x * blockDim.x;     int p = 2 * idx + oe_flag;      if (p + 1 < size) {         if (d_in[p] > d_in[p + 1]) {             int temp = d_in[p];             d_in[p] = d_in[p + 1];             d_in[p + 1] = temp;             d_ch_flag = 1;         }     } }  int main() {          int size = 512;           int* h_d_in = (int*)malloc(size * sizeof(int));                 int* d_d_in;     cudaMalloc((void**)&d_d_in, size * sizeof(int));                 int h_d_ch_flag = 0;           int* d_d_ch_flag;     cudaMalloc((void**)&d_d_ch_flag, sizeof(int));           cudaMemcpy(d_d_ch_flag, &h_d_ch_flag, sizeof(int), cudaMemcpyHostToDevice);           dim3 gridSize((size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           oddevenSort<<<gridSize, blockSize>>>(d_d_in, size, 0, *d_d_ch_flag);           cudaMemcpy(&h_d_ch_flag, d_d_ch_flag, sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_d_in);     cudaFree(d_d_ch_flag);           free(h_d_in);      return 0; } "
    },
    {
        "id": "94",
        "c_code": "#include <stdio.h>  void matmul(int a[100][100], int b[100][100], int c[100][100]) {     for (int i = 0; i < 100; i++) {         for (int j = 0; j < 100; j++) {             c[i][j] = 0;             for (int k = 0; k < 100; k++) {                 c[i][j] += a[i][k] * b[k][j];             }         }     } }  int main() {          int a[100][100];     int b[100][100];     int c[100][100];           for (int i = 0; i < 100; i++) {         for (int j = 0; j < 100; j++) {             a[i][j] = i + j;             b[i][j] = i - j;         }     }           matmul(a, b, c);           printf(\"Resultant matrix c:\\n\");     for (int i = 0; i < 100; i++) {         for (int j = 0; j < 100; j++) {             printf(\"%d \", c[i][j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void matmul(float* a, float* b, float* c, int width) {     float result = 0;     int row = blockIdx.y * blockDim.y + threadIdx.y;     int col = blockIdx.x * blockDim.x + threadIdx.x;      for (int k = 0; k < width; k++) {         result += a[row * width + k] * b[k * width + col];     }      c[row * width + col] = result; }  int main() {          int width = 512;           float* h_a = (float*)malloc(width * width * sizeof(float));     float* h_b = (float*)malloc(width * width * sizeof(float));     float* h_c = (float*)malloc(width * width * sizeof(float));                 float* d_a, * d_b, * d_c;     cudaMalloc((void**)&d_a, width * width * sizeof(float));     cudaMalloc((void**)&d_b, width * width * sizeof(float));     cudaMalloc((void**)&d_c, width * width * sizeof(float));                 dim3 gridSize((width + 15) / 16, (width + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           matmul<<<gridSize, blockSize>>>(d_a, d_b, d_c, width);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);           free(h_a);     free(h_b);     free(h_c);      return 0; } "
    },
    {
        "id": "95",
        "c_code": "#include <stdio.h>  void cudaKernel_estimateSnr_cpu(const float *corrSum, const int *corrValidCount, const float *maxval, float *snrValue, const int size) {     for (int idx = 0; idx < size; idx++) {         float mean = (corrSum[idx] - maxval[idx] * maxval[idx]) / (corrValidCount[idx] - 1);         snrValue[idx] = maxval[idx] * maxval[idx] / mean;     } }  int main() {          const int size = 5;     float corrSum[] = {10.0, 20.0, 30.0, 40.0, 50.0};     int corrValidCount[] = {2, 3, 4, 5, 6};     float maxval[] = {2.0, 4.0, 6.0, 8.0, 10.0};     float snrValue[size];           cudaKernel_estimateSnr_cpu(corrSum, corrValidCount, maxval, snrValue, size);           printf(\"SNR Values:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%f \", snrValue[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void cudaKernel_estimateSnr(const float* corrSum, const int* corrValidCount, const float* maxval, float* snrValue, const int size) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;      if (idx >= size)         return;      float mean = (corrSum[idx] - maxval[idx] * maxval[idx]) / (corrValidCount[idx] - 1);     snrValue[idx] = maxval[idx] * maxval[idx] / mean; }  int main() {          int size = 512;           float* h_corrSum = (float*)malloc(size * sizeof(float));     int* h_corrValidCount = (int*)malloc(size * sizeof(int));     float* h_maxval = (float*)malloc(size * sizeof(float));     float* h_snrValue = (float*)malloc(size * sizeof(float));                 float* d_corrSum, * d_maxval, * d_snrValue;     int* d_corrValidCount;     cudaMalloc((void**)&d_corrSum, size * sizeof(float));     cudaMalloc((void**)&d_corrValidCount, size * sizeof(int));     cudaMalloc((void**)&d_maxval, size * sizeof(float));     cudaMalloc((void**)&d_snrValue, size * sizeof(float));                 dim3 gridSize((size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           cudaKernel_estimateSnr<<<gridSize, blockSize>>>(d_corrSum, d_corrValidCount, d_maxval, d_snrValue, size);                 cudaFree(d_corrSum);     cudaFree(d_corrValidCount);     cudaFree(d_maxval);     cudaFree(d_snrValue);           free(h_corrSum);     free(h_corrValidCount);     free(h_maxval);     free(h_snrValue);      return 0; } "
    },
    {
        "id": "96",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void cpu_sgemm(float *C, float *A, float *B, long size) {     for (long i = 0; i < size; i++) {         for (long k = 0; k < size; k++) {             for (long j = 0; j < size; j++) {                 C[i * size + j] += A[i * size + k] * B[k * size + j];             }         }     } }  int main() {          const long size = 3;           float *A = (float *)malloc(size * size * sizeof(float));     float *B = (float *)malloc(size * size * sizeof(float));     float *C = (float *)malloc(size * size * sizeof(float));           for (long i = 0; i < size * size; i++) {         A[i] = i + 1;         B[i] = i - 1;         C[i] = 0.0;     }           cpu_sgemm(C, A, B, size);           printf(\"Resultant matrix C:\\n\");     for (long i = 0; i < size; i++) {         for (long j = 0; j < size; j++) {             printf(\"%f \", C[i * size + j]);         }         printf(\"\\n\");     }           free(A);     free(B);     free(C);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void naive_sgemm_kernel(float* C, float* A, float* B, long size) {     const long i = blockIdx.x * blockDim.x + threadIdx.x;     const long j = blockIdx.y * blockDim.y + threadIdx.y;      float val = 0.0;      if (i >= size || j >= size)         return;      for (long k = 0; k < size; k++) {         val += A[i * size + k] * B[k * size + j];     }      C[i * size + j] += val; }  int main() {          long size = 512;           float* h_C = (float*)malloc(size * size * sizeof(float));     float* h_A = (float*)malloc(size * size * sizeof(float));     float* h_B = (float*)malloc(size * size * sizeof(float));                 float* d_C, * d_A, * d_B;     cudaMalloc((void**)&d_C, size * size * sizeof(float));     cudaMalloc((void**)&d_A, size * size * sizeof(float));     cudaMalloc((void**)&d_B, size * size * sizeof(float));                 dim3 gridSize((size + 15) / 16, (size + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           naive_sgemm_kernel<<<gridSize, blockSize>>>(d_C, d_A, d_B, size);                 cudaFree(d_C);     cudaFree(d_A);     cudaFree(d_B);           free(h_C);     free(h_A);     free(h_B);      return 0; } "
    },
    {
        "id": "97",
        "c_code": "#include <stdio.h>  void kernelXor(unsigned int key, char *input_str_cuda, unsigned char *possible_plaintext_str_cuda, int input_length) {     int id;     char *keyCharPtr;      for (id = 0; id < input_length; id++) {         int keyIndex = id % 4;         keyCharPtr = ((char *)&key);         char keyChar = keyCharPtr[keyIndex];         possible_plaintext_str_cuda[id] = keyChar ^ input_str_cuda[id];     } }  int main() {          const int input_length = 10;     const unsigned int key = 12345;           char input_str[input_length];     unsigned char possible_plaintext_str[input_length];           for (int i = 0; i < input_length; i++) {         input_str[i] = 'A' + i;     }           kernelXor(key, input_str, possible_plaintext_str, input_length);           printf(\"Input String: %s\\n\", input_str);     printf(\"Possible Plaintext String after XOR: \");     for (int i = 0; i < input_length; i++) {         printf(\"%c \", possible_plaintext_str[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void kernelXor(unsigned int key, char* input_str_cuda, unsigned char* possible_plaintext_str_cuda, int input_length) {     int id = threadIdx.x + blockDim.x * blockIdx.x;      if (id >= input_length)         return;      int keyIndex = id % 4;     char* keyCharPtr = ((char*)&key);     char keyChar = keyCharPtr[keyIndex];      possible_plaintext_str_cuda[id] = keyChar ^ input_str_cuda[id]; }  int main() {          int input_length = 512;     unsigned int key = 0x12345678;            char* h_input_str = (char*)malloc(input_length * sizeof(char));     unsigned char* h_possible_plaintext_str = (unsigned char*)malloc(input_length * sizeof(unsigned char));                 char* d_input_str;     unsigned char* d_possible_plaintext_str;     cudaMalloc((void**)&d_input_str, input_length * sizeof(char));     cudaMalloc((void**)&d_possible_plaintext_str, input_length * sizeof(unsigned char));                 dim3 gridSize((input_length + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           kernelXor<<<gridSize, blockSize>>>(key, d_input_str, d_possible_plaintext_str, input_length);                 cudaFree(d_input_str);     cudaFree(d_possible_plaintext_str);           free(h_input_str);     free(h_possible_plaintext_str);      return 0; } "
    },
    {
        "id": "98",
        "c_code": "#include <stdio.h>  void envejecer_kernel_cpu(int *estado, int *edad, int *pupacion, int *N_mobil, int dia) {     int N = N_mobil[0];          for (int id = 0; id < N; id++) {         if (dia < 80 || dia > 320) {             if (edad[id] > pupacion[id]) {                 edad[id]++;             }         } else {             edad[id]++;         }     } }  int main() {          const int N = 5;     int estado[N] = {1, 1, 1, 0, 1};     int edad[N] = {75, 90, 100, 50, 60};     int pupacion[N] = {70, 80, 95, 45, 55};     int N_mobil[1] = {N};     int dia = 100;           envejecer_kernel_cpu(estado, edad, pupacion, N_mobil, dia);           printf(\"Edad after envejecer_kernel_cpu:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%d \", edad[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void envejecer_kernel(int* estado, int* edad, int* pupacion, int* N_mobil, int dia) {     int N = N_mobil[0];     int id = blockIdx.x * blockDim.x + threadIdx.x;      if (id < N) {         if (dia < 80 || dia > 320) {             if (edad[id] > pupacion[id])                 edad[id]++;         } else {             edad[id]++;         }     } }  int main() {          int N = 512;      int dia = 150;            int* h_estado = (int*)malloc(N * sizeof(int));     int* h_edad = (int*)malloc(N * sizeof(int));     int* h_pupacion = (int*)malloc(N * sizeof(int));     int* h_N_mobil = (int*)malloc(sizeof(int));                 int* d_estado, * d_edad, * d_pupacion, * d_N_mobil;     cudaMalloc((void**)&d_estado, N * sizeof(int));     cudaMalloc((void**)&d_edad, N * sizeof(int));     cudaMalloc((void**)&d_pupacion, N * sizeof(int));     cudaMalloc((void**)&d_N_mobil, sizeof(int));                 dim3 gridSize((N + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           envejecer_kernel<<<gridSize, blockSize>>>(d_estado, d_edad, d_pupacion, d_N_mobil, dia);                 cudaFree(d_estado);     cudaFree(d_edad);     cudaFree(d_pupacion);     cudaFree(d_N_mobil);           free(h_estado);     free(h_edad);     free(h_pupacion);     free(h_N_mobil);      return 0; } "
    },
    {
        "id": "99",
        "c_code": "#include <stdio.h> #include <math.h>  void globalCalculateKernel(float *c, float *a, float *b, int size) {     for (int i = 0; i < size; i++) {         for (int j = 0; j < size; j++) {             c[i * size + j] = sin(a[i * size + j]) * sin(a[i * size + j]) +                                cos(b[i * size + j]) * cos(b[i * size + j]) * cos(b[i * size + j]);         }     } }  int main() {          const int size = 3;     float a[size * size];     float b[size * size];     float c[size * size];           for (int i = 0; i < size * size; i++) {         a[i] = i + 1;         b[i] = i - 1;     }           globalCalculateKernel(c, a, b, size);           printf(\"Resultant matrix c:\\n\");     for (int i = 0; i < size; i++) {         for (int j = 0; j < size; j++) {             printf(\"%f \", c[i * size + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void globalCalculateKernel(float* c, float* a, float* b) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     int j = blockIdx.y * blockDim.y + threadIdx.y;      c[i * j] = sin(a[i * j]) * sin(a[i * j]) + cos(b[i * j]) * cos(b[i * j]) * cos(b[i * j]); }  int main() {          int width = 512;            float* h_c = (float*)malloc(width * width * sizeof(float));     float* h_a = (float*)malloc(width * width * sizeof(float));     float* h_b = (float*)malloc(width * width * sizeof(float));                 float* d_c, * d_a, * d_b;     cudaMalloc((void**)&d_c, width * width * sizeof(float));     cudaMalloc((void**)&d_a, width * width * sizeof(float));     cudaMalloc((void**)&d_b, width * width * sizeof(float));                 dim3 gridSize((width + 15) / 16, (width + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           globalCalculateKernel<<<gridSize, blockSize>>>(d_c, d_a, d_b);                 cudaFree(d_c);     cudaFree(d_a);     cudaFree(d_b);           free(h_c);     free(h_a);     free(h_b);      return 0; } "
    }
]