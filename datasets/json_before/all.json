[
    {
        "id": "1",
        "c_code": "#include <stdio.h>  void add_100(int numElements, int *data) {     for (int idx = 0; idx < numElements; idx++) {         data[idx] += 100;     } }  int main() {          int array[] = {1, 2, 3, 4, 5};     int numElements = sizeof(array) / sizeof(array[0]);      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }           add_100(numElements, array);      printf(\"\\n\u4fee\u6539\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void add_100(int numElements, int* data) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid < numElements) {         data[tid] += 100;     } }  int main() {          int numElements = 1000;           int* h_data = (int*)malloc(numElements * sizeof(int));           for (int i = 0; i < numElements; ++i) {         h_data[i] = i;     }           int* d_data;     cudaMalloc((void**)&d_data, numElements * sizeof(int));           cudaMemcpy(d_data, h_data, numElements * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (numElements + blockSize - 1) / blockSize;           add_100<<<gridSize, blockSize>>>(numElements, d_data);           cudaMemcpy(h_data, d_data, numElements * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < numElements; ++i) {         printf(\"%d \", h_data[i]);     }           free(h_data);     cudaFree(d_data);      return 0; } "
    },
    {
        "id": "10",
        "c_code": "#include <stdio.h>  void test_cpu(float *input, const int dims) {     for (int tid = 0; tid < dims; tid++) {         if (tid == 0) {             input[tid] = 0;         }     } }  int main() {          int arraySize = 5;     float array[arraySize];      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", array[i]);     }           test_cpu(array, arraySize);      printf(\"\\n\u6d4b\u8bd5\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void test(float* input, const int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }      if (tid == 0) {         input[tid] = 0;     } }  int main() {          int arraySize = 1000;           float* h_input = (float*)malloc(arraySize * sizeof(float));           float* d_input;     cudaMalloc((void**)&d_input, arraySize * sizeof(float));           cudaMemcpy(d_input, h_input, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           test<<<gridSize, blockSize>>>(d_input, arraySize);           cudaMemcpy(h_input, d_input, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_input[i]);     }           free(h_input);     cudaFree(d_input);      return 0; } "
    },
    {
        "id": "100",
        "c_code": "#include <stdio.h>  void cpu_matrix_mul(int *a, int *b, int *c, int N) {     for (int row = 0; row < N; row++) {         for (int col = 0; col < N; col++) {             int sum = 0;             for (int i = 0; i < N; i++) {                 sum += a[row * N + i] * b[i * N + col];             }             c[row * N + col] = sum;         }     } }  int main() {          const int N = 3;     int a[N * N] = {1, 2, 3, 4, 5, 6, 7, 8, 9};     int b[N * N] = {9, 8, 7, 6, 5, 4, 3, 2, 1};     int c[N * N];           cpu_matrix_mul(a, b, c, N);           printf(\"Resultant matrix c:\\n\");     for (int i = 0; i < N; i++) {         for (int j = 0; j < N; j++) {             printf(\"%d \", c[i * N + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gpu_matrix_mul(int* a, int* b, int* c, int N) {     int row = blockIdx.y * blockDim.y + threadIdx.y;     int col = blockIdx.x * blockDim.x + threadIdx.x;     int sum = 0;      if (col < N && row < N) {         for (int i = 0; i < N; i++) {             sum += a[row * N + i] * b[i * N + col];         }         c[row * N + col] = sum;     } }  int main() {          int N = 512;            int* h_a = (int*)malloc(N * N * sizeof(int));     int* h_b = (int*)malloc(N * N * sizeof(int));     int* h_c = (int*)malloc(N * N * sizeof(int));                 int* d_a, * d_b, * d_c;     cudaMalloc((void**)&d_a, N * N * sizeof(int));     cudaMalloc((void**)&d_b, N * N * sizeof(int));     cudaMalloc((void**)&d_c, N * N * sizeof(int));                 dim3 gridSize((N + 15) / 16, (N + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           gpu_matrix_mul<<<gridSize, blockSize>>>(d_a, d_b, d_c, N);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);           free(h_a);     free(h_b);     free(h_c);      return 0; } "
    },
    {
        "id": "101",
        "c_code": "#include <stdio.h>  void grayscale(unsigned char *input, unsigned char *output, int size) {     unsigned char r, g, b;          for (int i = 0; i < size; i++) {         r = input[3 * i];         g = input[3 * i + 1];         b = input[3 * i + 2];         output[i] = (unsigned char)(0.21 * (float)r + 0.71 * (float)g + 0.07 * (float)b);     } }  int main() {          const int size = 3;     unsigned char input[size * 3] = {255, 0, 0, 0, 255, 0, 0, 0, 255};     unsigned char output[size];           grayscale(input, output, size);           printf(\"Resultant grayscale values:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", output[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void grayscale(unsigned char* input, unsigned char* output, int size) {     int i = threadIdx.x + blockDim.x * blockIdx.x;      if (i < size) {         unsigned char r, g, b;         r = input[3 * i];         g = input[3 * i + 1];         b = input[3 * i + 2];          output[i] = (unsigned char)(0.21 * (float)r + 0.71 * (float)g + 0.07 * (float)b);     } }  int main() {          int size = 512;            unsigned char* h_input = (unsigned char*)malloc(3 * size * sizeof(unsigned char));     unsigned char* h_output = (unsigned char*)malloc(size * sizeof(unsigned char));                 unsigned char* d_input, * d_output;     cudaMalloc((void**)&d_input, 3 * size * sizeof(unsigned char));     cudaMalloc((void**)&d_output, size * sizeof(unsigned char));                 dim3 gridSize((size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           grayscale<<<gridSize, blockSize>>>(d_input, d_output, size);                 cudaFree(d_input);     cudaFree(d_output);           free(h_input);     free(h_output);      return 0; } "
    },
    {
        "id": "102",
        "c_code": "#include <stdio.h>  void subtractMean_cpu(double *images, const double *meanImage, int imageNum, int pixelNum) {     for (int col = 0; col < pixelNum; col++) {         for (int row = 0; row < imageNum; ++row) {             images[row * pixelNum + col] -= meanImage[col];             if (images[row * pixelNum + col] < 0.0) {                 images[row * pixelNum + col] = 0.0;             }         }     } }  int main() {          const int imageNum = 2;     const int pixelNum = 3;     double images[imageNum * pixelNum] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     double meanImage[pixelNum] = {2.0, 3.0, 4.0};           subtractMean_cpu(images, meanImage, imageNum, pixelNum);           printf(\"Resultant images after subtracting mean:\\n\");     for (int i = 0; i < imageNum; i++) {         for (int j = 0; j < pixelNum; j++) {             printf(\"%f \", images[i * pixelNum + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void subtractMean(double* images, const double* meanImage, size_t imageNum, size_t pixelNum) {     size_t col = blockIdx.x * blockDim.x + threadIdx.x;      if (col >= pixelNum) {         return;     }      for (size_t row = 0; row < imageNum; ++row) {         images[row * pixelNum + col] -= meanImage[col];          if (images[row * pixelNum + col] < 0.0) {             images[row * pixelNum + col] = 0.0;         }     } }  int main() {          size_t imageNum = 512;        size_t pixelNum = 1024;             double* h_images = (double*)malloc(imageNum * pixelNum * sizeof(double));     double* h_meanImage = (double*)malloc(pixelNum * sizeof(double));                 double* d_images, * d_meanImage;     cudaMalloc((void**)&d_images, imageNum * pixelNum * sizeof(double));     cudaMalloc((void**)&d_meanImage, pixelNum * sizeof(double));                 dim3 gridSize((pixelNum + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           subtractMean<<<gridSize, blockSize>>>(d_images, d_meanImage, imageNum, pixelNum);                 cudaFree(d_images);     cudaFree(d_meanImage);           free(h_images);     free(h_meanImage);      return 0; } "
    },
    {
        "id": "103",
        "c_code": "#include <stdio.h>  void kernelMaximum(float *maxhd, float *maxvd, int start, int size) {     int tx = start;     float max_hd = 1.175494351e-38F;     float max_vd = 1.175494351e-38F;      for (; tx < size; tx++) {         if (maxhd[tx] > max_hd)             max_hd = maxhd[tx];         if (maxvd[tx] > max_vd)             max_vd = maxvd[tx];     } }  int main() {          const int size = 5;     float maxhd[size] = {1.0, 2.0, 3.0, 4.0, 5.0};     float maxvd[size] = {5.0, 4.0, 3.0, 2.0, 1.0};           kernelMaximum(maxhd, maxvd, 0, size);           printf(\"Max_hd: %f\\n\", maxhd[0]);     printf(\"Max_vd: %f\\n\", maxvd[0]);      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void kernelMaximum(float* maxhd, float* maxvd, int start, int size) {     int tx = start + threadIdx.x;      for (int i = size >> 1; i > 0; i >>= 1) {         __syncthreads();          if (tx < i) {             if (maxhd[tx] < maxhd[tx + i]) maxhd[tx] = maxhd[tx + i];             if (maxvd[tx] < maxvd[tx + i]) maxvd[tx] = maxvd[tx + i];         }     } }  int main() {          int start = 0;         int size = 1024;             float* h_maxhd = (float*)malloc(size * sizeof(float));     float* h_maxvd = (float*)malloc(size * sizeof(float));                 float* d_maxhd, * d_maxvd;     cudaMalloc((void**)&d_maxhd, size * sizeof(float));     cudaMalloc((void**)&d_maxvd, size * sizeof(float));                 dim3 gridSize(1, 1, 1);     dim3 blockSize(size, 1, 1);           kernelMaximum<<<gridSize, blockSize>>>(d_maxhd, d_maxvd, start, size);                 cudaFree(d_maxhd);     cudaFree(d_maxvd);           free(h_maxhd);     free(h_maxvd);      return 0; } "
    },
    {
        "id": "104",
        "c_code": "#include <stdio.h>  void SparseMatmul_forward(float *a, float *b, float *c, int *indptr, int *indices, int p, int size) {     for (int i = 0; i < size - 1; i++) {         for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {             int j = indices[jj];             for (int k = 0; k < p; k++) {                 c[i * p + k] += a[jj] * b[j * p + k];             }         }     } }  int main() {          const int size = 3;     const int p = 2;     float a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float b[] = {2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0};     float c[size * p] = {0.0};      int indptr[] = {0, 2, 4};        int indices[] = {1, 2, 0, 1};              SparseMatmul_forward(a, b, c, indptr, indices, p, size);           printf(\"Resultant matrix c:\\n\");     for (int i = 0; i < size; i++) {         for (int j = 0; j < p; j++) {             printf(\"%f \", c[i * p + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void cuda_SparseMatmul_forward_kernel(float* a_in, float* b_in, float* c_in, int* indptr, int* indices, int p) {     int i = blockIdx.x;     int k = threadIdx.x;      for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {         int j = indices[jj];         c_in[i * p + k] += a_in[jj] * b_in[j * p + k];     } }  int main() {          int numRows = 512;       int numCols = 256;       int numNonZeros = 1024;             float* h_a_in = (float*)malloc(numNonZeros * sizeof(float));     float* h_b_in = (float*)malloc(numCols * p * sizeof(float));     float* h_c_in = (float*)malloc(numRows * p * sizeof(float));     int* h_indptr = (int*)malloc((numRows + 1) * sizeof(int));     int* h_indices = (int*)malloc(numNonZeros * sizeof(int));                 float* d_a_in, * d_b_in, * d_c_in;     int* d_indptr, * d_indices;     cudaMalloc((void**)&d_a_in, numNonZeros * sizeof(float));     cudaMalloc((void**)&d_b_in, numCols * p * sizeof(float));     cudaMalloc((void**)&d_c_in, numRows * p * sizeof(float));     cudaMalloc((void**)&d_indptr, (numRows + 1) * sizeof(int));     cudaMalloc((void**)&d_indices, numNonZeros * sizeof(int));                 dim3 gridSize(numRows, 1, 1);     dim3 blockSize(p, 1, 1);           cuda_SparseMatmul_forward_kernel<<<gridSize, blockSize>>>(d_a_in, d_b_in, d_c_in, d_indptr, d_indices, p);                 cudaFree(d_a_in);     cudaFree(d_b_in);     cudaFree(d_c_in);     cudaFree(d_indptr);     cudaFree(d_indices);           free(h_a_in);     free(h_b_in);     free(h_c_in);     free(h_indptr);     free(h_indices);      return 0; } "
    },
    {
        "id": "105",
        "c_code": "#include <stdio.h>  void vectorMatrixMult(long int totalPixels, int availablePixels, int outPixelOffset, float *matrix, float *vector, float *out) {     for (long int i = 0; i < availablePixels; i++) {         float sum = 0.0;         for (long int j = 0; j < totalPixels; j++) {             sum += matrix[i * totalPixels + j] * vector[j];         }         out[i + outPixelOffset] = sum;     } }  int main() {          const long int totalPixels = 4;     const int availablePixels = 2;     const int outPixelOffset = 1;     float matrix[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0};     float vector[] = {2.0, 1.0, 3.0, 4.0};     float out[availablePixels + outPixelOffset];           vectorMatrixMult(totalPixels, availablePixels, outPixelOffset, matrix, vector, out);           printf(\"Resultant vector out:\\n\");     for (int i = 0; i < availablePixels + outPixelOffset; i++) {         printf(\"%f \", out[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void vectorMatrixMult(long int totalPixels, int availablePixels, int outPixelOffset, float* matrix, float* vector, float* out) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = blockDim.x * gridDim.x;      for (long int i = index; i < availablePixels; i += stride) {         float sum = 0.0;          for (long int j = 0; j < totalPixels; j++) {             sum += matrix[i * totalPixels + j] * vector[j];         }          out[i + outPixelOffset] = sum;     } }  int main() {          long int totalPixels = 1024;           int availablePixels = 512;             int outPixelOffset = 256;                    float* h_matrix = (float*)malloc(availablePixels * totalPixels * sizeof(float));     float* h_vector = (float*)malloc(totalPixels * sizeof(float));     float* h_out = (float*)malloc(availablePixels * sizeof(float));                 float* d_matrix, * d_vector, * d_out;     cudaMalloc((void**)&d_matrix, availablePixels * totalPixels * sizeof(float));     cudaMalloc((void**)&d_vector, totalPixels * sizeof(float));     cudaMalloc((void**)&d_out, availablePixels * sizeof(float));                 dim3 gridSize((availablePixels + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           vectorMatrixMult<<<gridSize, blockSize>>>(totalPixels, availablePixels, outPixelOffset, d_matrix, d_vector, d_out);                 cudaFree(d_matrix);     cudaFree(d_vector);     cudaFree(d_out);           free(h_matrix);     free(h_vector);     free(h_out);      return 0; } "
    },
    {
        "id": "106",
        "c_code": "#include <stdio.h>  void convertKinectDisparityInPlace_cpu(float *d_disparity, int pitch, int width, int height, float depth_scale) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < height; y++) {             float *d_in = (float *)((char *)d_disparity + y * pitch) + x;             *d_in = (*d_in == 0.0f) ? 1 : (-depth_scale / *d_in);         }     } }  int main() {          const int width = 3;     const int height = 2;     const int pitch = width * sizeof(float);     float d_disparity[width * height] = {0.0, 2.0, 0.0, 4.0, 0.0, 6.0};     float depth_scale = 2.0;           convertKinectDisparityInPlace_cpu(d_disparity, pitch, width, height, depth_scale);           printf(\"Resultant disparity values:\\n\");     for (int i = 0; i < width * height; i++) {         printf(\"%f \", d_disparity[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void convertKinectDisparityInPlace_kernel(float* d_disparity, int pitch, int width, int height, float depth_scale) {     const int x = blockIdx.x * blockDim.x + threadIdx.x;     const int y = blockIdx.y * blockDim.y + threadIdx.y;      if ((x < width) && (y < height)) {         float* d_in = (float*)((char*)d_disparity + y * pitch) + x;         *d_in = (*d_in == 0.0f) ? 1 : (-depth_scale / *d_in);     } }  int main() {          int width = 640;        int height = 480;       float depth_scale = 0.001f;             float* h_disparity = (float*)malloc(width * height * sizeof(float));                 float* d_disparity;     cudaMalloc((void**)&d_disparity, width * height * sizeof(float));                 dim3 gridSize((width + 15) / 16, (height + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           convertKinectDisparityInPlace_kernel<<<gridSize, blockSize>>>(d_disparity, width * sizeof(float), width, height, depth_scale);                 cudaFree(d_disparity);           free(h_disparity);      return 0; } "
    },
    {
        "id": "107",
        "c_code": "#include <stdio.h>  void SparseMatmul_backward(float *a, float *b_grad, float *c_grad, int *indptr, int *indices, int p, int size, float *grad) {     for (int i = 0; i < size - 1; i++) {         for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {             int j = indices[jj];             for (int k = 0; k < p; k++) {                 b_grad[j * p + k] += c_grad[i * p + k] * a[jj];             }         }     } }  int main() {          const int size = 3;     const int p = 2;     float a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float b_grad[] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0};     float c_grad[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float grad[size * p] = {0.0};      int indptr[] = {0, 2, 4};        int indices[] = {1, 2, 0, 1};              SparseMatmul_backward(a, b_grad, c_grad, indptr, indices, p, size, grad);           printf(\"Resultant gradient b_grad:\\n\");     for (int i = 0; i < size * p; i++) {         printf(\"%f \", b_grad[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void cuda_SparseMatmul_backward_kernel(float* a_in, float* b_in, float* c_in, int* indptr, int* indices, int p) {     int i = blockIdx.x;     int k = threadIdx.x;      for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {         int j = indices[jj];         b_in[j * p + k] += c_in[i * p + k] * a_in[jj];     } }  int main() {          int p = 256;             float* h_a = nullptr;       float* h_b = nullptr;       float* h_c = nullptr;       int* h_indptr = nullptr;       int* h_indices = nullptr;             float* d_a, *d_b, *d_c;     int* d_indptr, *d_indices;     cudaMalloc((void**)&d_a, sizeof(float));       cudaMalloc((void**)&d_b, sizeof(float));       cudaMalloc((void**)&d_c, sizeof(float));       cudaMalloc((void**)&d_indptr, sizeof(int));       cudaMalloc((void**)&d_indices, sizeof(int));                   dim3 gridSize(1, 1, 1);       dim3 blockSize(1, 1, 1);             cuda_SparseMatmul_backward_kernel<<<gridSize, blockSize>>>(d_a, d_b, d_c, d_indptr, d_indices, p);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);     cudaFree(d_indptr);     cudaFree(d_indices);                 return 0; } "
    },
    {
        "id": "108",
        "c_code": "#include <stdio.h> #include <math.h>  void subsample_ind_and_labels_cpu(int *d_ind_sub, const int *d_ind, unsigned int *d_label_sub, const unsigned int *d_label, int n_out, float inv_sub_factor) {     for (int ind_out = 0; ind_out < n_out; ind_out++) {         int ind_in = (int)floorf((float)(ind_out) * inv_sub_factor);         d_ind_sub[ind_out] = d_ind[ind_in];         d_label_sub[ind_out] = d_label[ind_in];     } }  int main() {          const int n_out = 3;     float inv_sub_factor = 0.5;     int d_ind[] = {1, 2, 3, 4, 5, 6};     unsigned int d_label[] = {10, 20, 30, 40, 50, 60};     int d_ind_sub[n_out];     unsigned int d_label_sub[n_out];           subsample_ind_and_labels_cpu(d_ind_sub, d_ind, d_label_sub, d_label, n_out, inv_sub_factor);           printf(\"Resultant subsampled indices and labels:\\n\");     for (int i = 0; i < n_out; i++) {         printf(\"Index: %d, Label: %u\\n\", d_ind_sub[i], d_label_sub[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <math.h>  __global__ void subsample_ind_and_labels_GPU(int* d_ind_sub, const int* d_ind, unsigned int* d_label_sub, const unsigned int* d_label, int n_out, float inv_sub_factor) {     unsigned int ind_out = blockIdx.x * blockDim.x + threadIdx.x;      if (ind_out < n_out) {         int ind_in = (int)floorf((float)(ind_out) * inv_sub_factor);         d_ind_sub[ind_out] = d_ind[ind_in];         d_label_sub[ind_out] = d_label[ind_in];     } }  int main() {          int n_out = 512;       float inv_sub_factor = 0.5f;             int* h_ind = nullptr;       unsigned int* h_label = nullptr;             int* d_ind, *d_ind_sub;     unsigned int* d_label, *d_label_sub;     cudaMalloc((void**)&d_ind, sizeof(int));       cudaMalloc((void**)&d_ind_sub, sizeof(int));       cudaMalloc((void**)&d_label, sizeof(unsigned int));       cudaMalloc((void**)&d_label_sub, sizeof(unsigned int));                   dim3 gridSize((n_out + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           subsample_ind_and_labels_GPU<<<gridSize, blockSize>>>(d_ind_sub, d_ind, d_label_sub, d_label, n_out, inv_sub_factor);                 cudaFree(d_ind);     cudaFree(d_ind_sub);     cudaFree(d_label);     cudaFree(d_label_sub);                 return 0; } "
    },
    {
        "id": "109",
        "c_code": "#include <stdio.h>  void mxm_1d_cpu(double *a, const int m, double *b, const int n, double *c, const int p) {     for (int i = 0; i < m; i++) {         for (int k = 0; k < p; k++) {             double s = 0.0;             for (int j = 0; j < n; j++) {                 s += a[j * m + i] * b[k * n + j];             }             c[k * m + i] = s;         }     } }  int main() {          const int m = 2;     const int n = 3;     const int p = 4;     double a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     double b[] = {2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0};     double c[p * m];           mxm_1d_cpu(a, m, b, n, c, p);           printf(\"Resultant matrix c:\\n\");     for (int i = 0; i < p; i++) {         for (int j = 0; j < m; j++) {             printf(\"%f \", c[i * m + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void mxm_1d(double* a, const int m, double* b, const int n, double* c, const int p) {     const int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i < m) {         for (int k = 0; k < p; k++) {             double s = 0.0;              for (int j = 0; j < n; j++) {                 s += a[j * m + i] * b[k * n + j];             }              c[k * m + i] = s;         }     } }  int main() {          int m = 256;       int n = 128;       int p = 64;              double* h_a = nullptr;       double* h_b = nullptr;             double* d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, sizeof(double));       cudaMalloc((void**)&d_b, sizeof(double));       cudaMalloc((void**)&d_c, sizeof(double));                   dim3 gridSize((m + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           mxm_1d<<<gridSize, blockSize>>>(d_a, m, d_b, n, d_c, p);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);                 return 0; } "
    },
    {
        "id": "11",
        "c_code": "#include <stdio.h>  void set_sorting_offset(const int nrows, const int ncols, int *offsets) {     int tid;     for (tid = 0; tid <= ncols; tid++) {         offsets[tid] = tid * nrows;     } }  int main() {          int numRows = 3;     int numCols = 4;     int offsetArray[numCols + 1];      printf(\"\u539f\u59cb\u504f\u79fb\u6570\u7ec4\uff1a\");     for (int i = 0; i <= numCols; i++) {         printf(\"%d \", offsetArray[i]);     }           set_sorting_offset(numRows, numCols, offsetArray);      printf(\"\\n\u8bbe\u7f6e\u540e\u7684\u504f\u79fb\u6570\u7ec4\uff1a\");     for (int i = 0; i <= numCols; i++) {         printf(\"%d \", offsetArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void set_sorting_offset(const int nrows, const int ncols, int* offsets) {     int tid = threadIdx.x + blockIdx.x * blockDim.x;     if (tid <= ncols) {         offsets[tid] = tid * nrows;     } }  int main() {          int nrows = 100;     int ncols = 10;           int* h_offsets = (int*)malloc((ncols + 1) * sizeof(int));           int* d_offsets;     cudaMalloc((void**)&d_offsets, (ncols + 1) * sizeof(int));           int blockSize = 256;     int gridSize = (ncols + blockSize - 1) / blockSize;           set_sorting_offset<<<gridSize, blockSize>>>(nrows, ncols, d_offsets);           cudaMemcpy(h_offsets, d_offsets, (ncols + 1) * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < ncols + 1; ++i) {         printf(\"%d \", h_offsets[i]);     }           free(h_offsets);     cudaFree(d_offsets);      return 0; } "
    },
    {
        "id": "110",
        "c_code": "#include <stdio.h> #include <math.h>  void fabsf_clamp_cpu(int N, float *X, int INCX, float clamp_min, float clamp_max) {     for (int i = 0; i < N; ++i) {         if (X[i * INCX] >= 0) {             X[i * INCX] = fmin(clamp_max, fmax(clamp_min, X[i * INCX]));         } else {             X[i * INCX] = fmin(-clamp_min, fmax(-clamp_max, X[i * INCX]));         }     } }  int main() {          const int N = 5;     const float clamp_min = -1.0;     const float clamp_max = 1.0;     float X[] = {-2.0, -1.0, 0.0, 1.0, 2.0};           fabsf_clamp_cpu(N, X, 1, clamp_min, clamp_max);           printf(\"Resultant array X:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", X[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <math.h>  __global__ void fabsf_clamp_kernel(int N, float* X, int INCX, float clamp_min, float clamp_max) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i < N) {         if (X[i * INCX] >= 0)             X[i * INCX] = fminf(clamp_max, fmaxf(clamp_min, X[i * INCX]));         else             X[i * INCX] = fminf(-clamp_min, fmaxf(-clamp_max, X[i * INCX]));     } }  int main() {          int N = 1024;       float clamp_min = -1.0f;       float clamp_max = 1.0f;              float* h_X = nullptr;             float* d_X;     cudaMalloc((void**)&d_X, sizeof(float));                   dim3 gridSize((N + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           fabsf_clamp_kernel<<<gridSize, blockSize>>>(N, d_X, 1, clamp_min, clamp_max);                 cudaFree(d_X);                 return 0; } "
    },
    {
        "id": "111",
        "c_code": "#include <stdio.h>  void cpu_matrix_mult(int *h_a, int *h_b, int *h_result, int m, int n, int k) {     for (int i = 0; i < m; ++i) {         for (int j = 0; j < k; ++j) {             int tmp = 0.0;             for (int h = 0; h < n; ++h) {                 tmp += h_a[i * n + h] * h_b[h * k + j];             }             h_result[i * k + j] = tmp;         }     } }  int main() {          const int m = 2;     const int n = 3;     const int k = 2;     int h_a[] = {1, 2, 3, 4, 5, 6};     int h_b[] = {2, 3, 4, 5, 6, 7};     int h_result[m * k];           cpu_matrix_mult(h_a, h_b, h_result, m, n, k);           printf(\"Resultant matrix h_result:\\n\");     for (int i = 0; i < m; i++) {         for (int j = 0; j < k; j++) {             printf(\"%d \", h_result[i * k + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void gpu_matrix_mult(int* a, int* b, int* c, int m, int n, int k) {     int row = blockIdx.y * blockDim.y + threadIdx.y;     int col = blockIdx.x * blockDim.x + threadIdx.x;     int sum = 0;      if (col < k && row < m) {         for (int i = 0; i < n; i++) {             sum += a[row * n + i] * b[i * k + col];         }          c[row * k + col] = sum;     } }  int main() {          int m = 256;       int n = 128;       int k = 64;              int* h_a = nullptr;       int* h_b = nullptr;             int* d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, sizeof(int));       cudaMalloc((void**)&d_b, sizeof(int));       cudaMalloc((void**)&d_c, sizeof(int));                   dim3 gridSize((k + 15) / 16, (m + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           gpu_matrix_mult<<<gridSize, blockSize>>>(d_a, d_b, d_c, m, n, k);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);                 return 0; } "
    },
    {
        "id": "112",
        "c_code": "#include <stdio.h>  inline void MulMatrixOnCPU(float *A, float *B, float *C, int nx, int ny) {     int i, j, k;     float sum = 0.0;     for (i = 0; i < nx; i++) {         for (j = 0; j < ny; j++) {             sum = 0.0;             for (k = 0; k < nx; k++) {                 sum = sum + A[i * nx + k] * B[k * nx + j];             }             C[i * nx + j] = sum;         }     } }  int main() {          const int nx = 2;     const int ny = 2;     float A[] = {1.0, 2.0, 3.0, 4.0};     float B[] = {5.0, 6.0, 7.0, 8.0};     float C[nx * nx];           MulMatrixOnCPU(A, B, C, nx, ny);           printf(\"Resultant matrix C:\\n\");     for (int i = 0; i < nx; i++) {         for (int j = 0; j < nx; j++) {             printf(\"%f \", C[i * nx + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void MulMatrixOnGPU(float* A, float* B, float* C, int nx, int ny) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     int j = threadIdx.y + blockIdx.y * blockDim.y;      if (i < nx && j < ny) {         float sum = 0.0;          for (int k = 0; k < nx; k++) {             sum += A[i * nx + k] * B[k * nx + j];         }          C[i * nx + j] = sum;     } }  int main() {          int nx = 256;       int ny = 128;             float* h_A = nullptr;       float* h_B = nullptr;       float* h_C = new float[nx * ny];             float* d_A, *d_B, *d_C;     cudaMalloc((void**)&d_A, sizeof(float) * nx * nx);       cudaMalloc((void**)&d_B, sizeof(float) * nx * nx);       cudaMalloc((void**)&d_C, sizeof(float) * nx * nx);                   dim3 gridSize((nx + 15) / 16, (ny + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           MulMatrixOnGPU<<<gridSize, blockSize>>>(d_A, d_B, d_C, nx, ny);                 cudaFree(d_A);     cudaFree(d_B);     cudaFree(d_C);           delete[] h_C;      return 0; } "
    },
    {
        "id": "113",
        "c_code": "#include <stdio.h>  int matrixMulHost(float *h_M, float *h_N, float *h_P, int width) {     int Pvalue;     for (int row = 0; row < width; ++row) {         for (int col = 0; col < width; ++col) {             Pvalue = 0;             for (int k = 0; k < width; ++k) {                 Pvalue += h_M[row * width + k] * h_N[k * width + col];             }             h_P[row * width + col] = Pvalue;         }     }     return 0; }  int main() {          const int width = 2;     float h_M[] = {1.0, 2.0, 3.0, 4.0};     float h_N[] = {5.0, 6.0, 7.0, 8.0};     float h_P[width * width];           matrixMulHost(h_M, h_N, h_P, width);           printf(\"Resultant matrix h_P:\\n\");     for (int i = 0; i < width; i++) {         for (int j = 0; j < width; j++) {             printf(\"%f \", h_P[i * width + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void MatrixMulKernel(float* d_M, float* d_N, float* d_P, int width) {     int Row = blockIdx.y * blockDim.y + threadIdx.y;     int Col = blockIdx.x * blockDim.x + threadIdx.x;      if ((Row < width) && (Col < width)) {         float Pvalue = 0;         for (int i = 0; i < width; ++i) {             Pvalue += d_M[Row * width + i] * d_N[i * width + Col];         }         d_P[Row * width + Col] = Pvalue;     } }  int main() {                int width = 100;       float* h_M = (float*)malloc(width * width * sizeof(float));     float* h_N = (float*)malloc(width * width * sizeof(float));     float* h_P = (float*)malloc(width * width * sizeof(float));      float* d_M, * d_N, * d_P;     cudaMalloc((void**)&d_M, width * width * sizeof(float));     cudaMalloc((void**)&d_N, width * width * sizeof(float));     cudaMalloc((void**)&d_P, width * width * sizeof(float));           cudaMemcpy(d_M, h_M, width * width * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_N, h_N, width * width * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (width + blockSize.y - 1) / blockSize.y);     MatrixMulKernel<<<gridSize, blockSize>>>(d_M, d_N, d_P, width);           cudaMemcpy(h_P, d_P, width * width * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_M);     free(h_N);     free(h_P);     cudaFree(d_M);     cudaFree(d_N);     cudaFree(d_P);      return 0; } "
    },
    {
        "id": "114",
        "c_code": "#include <stdio.h>  void mmul_cpu(const float *A, const float *B, float *C, int r1, int c1, int r2, int c2) {     for (int idx = 0; idx < c2; idx++) {         for (int idy = 0; idy < r1; idy++) {             float temp = 0;             for (int i = 0; i < c1; i++) {                 temp += A[idy * c1 + i] * B[i * c2 + idx];             }             C[idy * c2 + idx] = temp;         }     } }  int main() {          const int r1 = 2;     const int c1 = 3;     const int r2 = 3;     const int c2 = 2;     float A[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float B[] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0};     float C[r1 * c2];           mmul_cpu(A, B, C, r1, c1, r2, c2);           printf(\"Resultant matrix C:\\n\");     for (int i = 0; i < r1; i++) {         for (int j = 0; j < c2; j++) {             printf(\"%f \", C[i * c2 + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>  __global__ void mmul(const float* A, const float* B, float* C, int r1, int c1, int r2, int c2) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;     int idy = threadIdx.y + blockDim.y * blockIdx.y;      if ((idx < c2) && (idy < c1)) {         float temp = 0;          for (int i = 0; i < c1; i++)             temp += A[idy * c1 + i] * B[i * c2 + idx];          C[idy * c2 + idx] = temp;     } }  int main() {          int r1 = 256;       int c1 = 128;       int r2 = 128;       int c2 = 64;              float* h_A = nullptr;       float* h_B = nullptr;       float* h_C = new float[r1 * c2];             float* d_A, *d_B, *d_C;     cudaMalloc((void**)&d_A, sizeof(float) * r1 * c1);       cudaMalloc((void**)&d_B, sizeof(float) * c1 * c2);       cudaMalloc((void**)&d_C, sizeof(float) * r1 * c2);                   dim3 gridSize((c2 + 15) / 16, (r1 + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           mmul<<<gridSize, blockSize>>>(d_A, d_B, d_C, r1, c1, r2, c2);                 cudaFree(d_A);     cudaFree(d_B);     cudaFree(d_C);           delete[] h_C;      return 0; } "
    },
    {
        "id": "115",
        "c_code": "#include <stdio.h>  void Dot(float *C, float *A, float *B, const int r, const int c, const int n) {     float temp;     for (int i = 0; i < r; i++) {         for (int j = 0; j < c; j++) {             temp = 0.0;             for (int k = 0; k < n; k++) {                 temp += A[i * n + k] * B[k * c + j];             }             C[i * c + j] = temp;         }     } }  int main() {          const int r = 2;     const int c = 2;     const int n = 3;     float A[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float B[] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0};     float C[r * c];           Dot(C, A, B, r, c, n);           printf(\"Resultant matrix C:\\n\");     for (int i = 0; i < r; i++) {         for (int j = 0; j < c; j++) {             printf(\"%f \", C[i * c + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void Kernel_Dot_reduction2(float* dev_c, float* reduction, int r, const int c, const int n, int size_block) {     unsigned int i = blockDim.x * blockIdx.x + threadIdx.x;     unsigned int j = blockDim.y * blockIdx.y + threadIdx.y;      if (i >= r || j >= c) return;      float temp = 0;     for (int k = 0; k < size_block; k++) {         temp += reduction[i * (c * size_block) + j * size_block + k];     }      dev_c[i * c + j] = temp; }  int main() {                int r = 100;      int c = 100;     int n = 100;     int size_block = 16;      float* h_reduction = (float*)malloc(r * c * n * sizeof(float));     float* h_dev_c = (float*)malloc(r * c * sizeof(float));      float* d_reduction, * d_dev_c;     cudaMalloc((void**)&d_reduction, r * c * n * sizeof(float));     cudaMalloc((void**)&d_dev_c, r * c * sizeof(float));           cudaMemcpy(d_reduction, h_reduction, r * c * n * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);     dim3 gridSize((r + blockSize.x - 1) / blockSize.x, (c + blockSize.y - 1) / blockSize.y);     Kernel_Dot_reduction2<<<gridSize, blockSize>>>(d_dev_c, d_reduction, r, c, n, size_block);           cudaMemcpy(h_dev_c, d_dev_c, r * c * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_reduction);     free(h_dev_c);     cudaFree(d_reduction);     cudaFree(d_dev_c);      return 0; } "
    },
    {
        "id": "116",
        "c_code": "#include <stdio.h>  void Forwardsub_cpu(double *RES, double *LS, double *LW, double *LPR, int NI, int NJ, int Start, int J, int n) {     for (int i = 0; i < n; i++) {         int IJ = ((Start + i) * NI) + (J - (Start + i));         RES[IJ] = (RES[IJ] - LS[IJ] * RES[IJ - 1] - LW[IJ] * RES[IJ - NJ]) * LPR[IJ];     } }  int main() {          const int NI = 4;     const int NJ = 4;     const int Start = 1;     const int J = 2;     const int n = 2;     double RES[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};     double LS[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6};     double LW[] = {2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5};     double LPR[] = {0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16};           Forwardsub_cpu(RES, LS, LW, LPR, NI, NJ, Start, J, n);           printf(\"Resultant array RES:\\n\");     for (int i = 0; i < NI * NJ; i++) {         printf(\"%f \", RES[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void Forwardsub(double* RES, double* LS, double* LW, double* LPR, int NI, int NJ, int Start, int J, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;          if (i < n) {         int IJ = ((Start + i) * NI) + (J - (Start + i));         RES[IJ] = (RES[IJ] - LS[IJ] * RES[IJ - 1] - LW[IJ] * RES[IJ - NJ]) * LPR[IJ];     } }  int main() {                int NI = 100;      int NJ = 100;     int Start = 0;     int J = 10;     int n = 50;      double* h_RES = (double*)malloc(NI * NJ * sizeof(double));     double* h_LS = (double*)malloc(NI * NJ * sizeof(double));     double* h_LW = (double*)malloc(NI * NJ * sizeof(double));     double* h_LPR = (double*)malloc(NI * NJ * sizeof(double));      double* d_RES, * d_LS, * d_LW, * d_LPR;     cudaMalloc((void**)&d_RES, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_LS, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_LW, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_LPR, NI * NJ * sizeof(double));           cudaMemcpy(d_RES, h_RES, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_LS, h_LS, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_LW, h_LW, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_LPR, h_LPR, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);     dim3 gridSize((n + blockSize.x - 1) / blockSize.x, 1);     Forwardsub<<<gridSize, blockSize>>>(d_RES, d_LS, d_LW, d_LPR, NI, NJ, Start, J, n);           cudaMemcpy(h_RES, d_RES, NI * NJ * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_RES);     free(h_LS);     free(h_LW);     free(h_LPR);     cudaFree(d_RES);     cudaFree(d_LS);     cudaFree(d_LW);     cudaFree(d_LPR);      return 0; } "
    },
    {
        "id": "117",
        "c_code": "#include <stdio.h>  void cpu_rows_dc_offset_remove_layer_kernel(float *output, float *input, unsigned int width, unsigned int height, unsigned int depth) {     for (unsigned int channel = 0; channel < depth; channel++)         for (unsigned int row = 0; row < height; row++)             for (unsigned int column = 0; column < (width - 1); column++) {                 unsigned int idx = (channel * height + row) * width + column;                 output[idx] = input[idx] - input[idx + 1];             } }  int main() {          const unsigned int width = 3;     const unsigned int height = 2;     const unsigned int depth = 2;     float input[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0};     float output[width * height * depth];           cpu_rows_dc_offset_remove_layer_kernel(output, input, width, height, depth);           printf(\"Resultant array output:\\n\");     for (unsigned int channel = 0; channel < depth; channel++) {         for (unsigned int row = 0; row < height; row++) {             for (unsigned int column = 0; column < width; column++) {                 unsigned int idx = (channel * height + row) * width + column;                 printf(\"%f \", output[idx]);             }             printf(\"\\n\");         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void cuda_rows_dc_offset_remove_layer_kernel(float* output, float* input, unsigned int width, unsigned int height, unsigned int depth) {     unsigned int column = threadIdx.x + blockIdx.x * blockDim.x;     unsigned int row = threadIdx.y + blockIdx.y * blockDim.y;     unsigned int channel = threadIdx.z + blockIdx.z * blockDim.z;      if (channel < depth && row < height && column < (width - 1)) {         unsigned int idx = (channel * height + row) * width + column;         output[idx] = input[idx] - input[idx + 1];     } }  int main() {                unsigned int width = 100;      unsigned int height = 100;     unsigned int depth = 3;      float* h_output = (float*)malloc(width * height * depth * sizeof(float));     float* h_input = (float*)malloc(width * height * depth * sizeof(float));      float* d_output, * d_input;     cudaMalloc((void**)&d_output, width * height * depth * sizeof(float));     cudaMalloc((void**)&d_input, width * height * depth * sizeof(float));           cudaMemcpy(d_output, h_output, width * height * depth * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_input, h_input, width * height * depth * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16, 1);      dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y, (depth + blockSize.z - 1) / blockSize.z);     cuda_rows_dc_offset_remove_layer_kernel<<<gridSize, blockSize>>>(d_output, d_input, width, height, depth);           cudaMemcpy(h_output, d_output, width * height * depth * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_output);     free(h_input);     cudaFree(d_output);     cudaFree(d_input);      return 0; } "
    },
    {
        "id": "118",
        "c_code": "#include <stdio.h>  void cpu_cross_correlate(float *Isg, float *Iss, float *sp, float *gp, int npml, int nnz, int nnx) {     for (int i1 = npml; i1 < nnz - npml; i1++) {         for (int i2 = npml; i2 < nnx - npml; i2++) {             int id = i1 + i2 * nnz;             float ps = sp[id];             float pg = gp[id];             Isg[id] += ps * pg;             Iss[id] += ps * ps;         }     } }  int main() {          const int npml = 1;     const int nnz = 4;     const int nnx = 3;     float sp[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0};     float gp[] = {12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0};     float Isg[nnz * nnx] = {0};     float Iss[nnz * nnx] = {0};           cpu_cross_correlate(Isg, Iss, sp, gp, npml, nnz, nnx);           printf(\"Resultant arrays Isg and Iss:\\n\");     for (int i2 = 0; i2 < nnx; i2++) {         for (int i1 = 0; i1 < nnz; i1++) {             int id = i1 + i2 * nnz;             printf(\"Isg[%d]: %f, Iss[%d]: %f\\n\", id, Isg[id], id, Iss[id]);         }     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void cuda_cross_correlate(float* Isg, float* Iss, float* sp, float* gp, int npml, int nnz, int nnx) {     int i1 = threadIdx.x + blockDim.x * blockIdx.x;     int i2 = threadIdx.y + blockDim.y * blockIdx.y;     int id = i1 + i2 * nnz;      if (i1 >= npml && i1 < nnz - npml && i2 >= npml && i2 < nnx - npml) {         float ps = sp[id];         float pg = gp[id];         Isg[id] += ps * pg;         Iss[id] += ps * ps;     } }  int main() {                int npml = 5;      int nnz = 100;     int nnx = 100;      float* h_Isg = (float*)malloc(nnz * nnx * sizeof(float));     float* h_Iss = (float*)malloc(nnz * nnx * sizeof(float));     float* h_sp = (float*)malloc(nnz * nnx * sizeof(float));     float* h_gp = (float*)malloc(nnz * nnx * sizeof(float));      float* d_Isg, * d_Iss, * d_sp, * d_gp;     cudaMalloc((void**)&d_Isg, nnz * nnx * sizeof(float));     cudaMalloc((void**)&d_Iss, nnz * nnx * sizeof(float));     cudaMalloc((void**)&d_sp, nnz * nnx * sizeof(float));     cudaMalloc((void**)&d_gp, nnz * nnx * sizeof(float));           cudaMemcpy(d_Isg, h_Isg, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Iss, h_Iss, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_sp, h_sp, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_gp, h_gp, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((nnz + blockSize.x - 1) / blockSize.x, (nnx + blockSize.y - 1) / blockSize.y);     cuda_cross_correlate<<<gridSize, blockSize>>>(d_Isg, d_Iss, d_sp, d_gp, npml, nnz, nnx);           cudaMemcpy(h_Isg, d_Isg, nnz * nnx * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_Iss, d_Iss, nnz * nnx * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_Isg);     free(h_Iss);     free(h_sp);     free(h_gp);     cudaFree(d_Isg);     cudaFree(d_Iss);     cudaFree(d_sp);     cudaFree(d_gp);      return 0; } "
    },
    {
        "id": "119",
        "c_code": "#include <stdio.h>  void colorConvert(unsigned char *grayImage, unsigned char *colorImage, int rows, int columns) {     for (int column = 0; column < columns; column++) {         for (int row = 0; row < rows; row++) {             int offset = column + (columns * row);             unsigned char grayValue = 0.07 * colorImage[offset * 3] + 0.71 * colorImage[offset * 3 + 1] + 0.21 * colorImage[offset * 3 + 2];             grayImage[offset] = grayValue;         }     } }  int main() {          const int rows = 2;     const int columns = 2;     unsigned char colorImage[] = {255, 0, 0, 0, 255, 0, 0, 0, 255, 128, 128, 128};     unsigned char grayImage[rows * columns];           colorConvert(grayImage, colorImage, rows, columns);           printf(\"Resultant array grayImage:\\n\");     for (int row = 0; row < rows; row++) {         for (int column = 0; column < columns; column++) {             int offset = column + (columns * row);             printf(\"%u \", grayImage[offset]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void colorConvert(unsigned char* grayImage, unsigned char* colorImage, int rows, int columns) {     int column = blockIdx.x * blockDim.x + threadIdx.x;     int row = blockIdx.y * blockDim.y + threadIdx.y;      if ((column < columns) && (row < rows)) {         int offset = column + (columns * row);         unsigned char grayValue = 0.07 * colorImage[offset * 3] + 0.71 * colorImage[offset * 3 + 1] + 0.21 * colorImage[offset * 3 + 2];         grayImage[offset] = grayValue;     } }  int main() {                int rows = 100;      int columns = 100;      unsigned char* h_grayImage = (unsigned char*)malloc(rows * columns * sizeof(unsigned char));     unsigned char* h_colorImage = (unsigned char*)malloc(rows * columns * 3 * sizeof(unsigned char));      unsigned char* d_grayImage, * d_colorImage;     cudaMalloc((void**)&d_grayImage, rows * columns * sizeof(unsigned char));     cudaMalloc((void**)&d_colorImage, rows * columns * 3 * sizeof(unsigned char));           cudaMemcpy(d_grayImage, h_grayImage, rows * columns * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_colorImage, h_colorImage, rows * columns * 3 * sizeof(unsigned char), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((columns + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y);     colorConvert<<<gridSize, blockSize>>>(d_grayImage, d_colorImage, rows, columns);           cudaMemcpy(h_grayImage, d_grayImage, rows * columns * sizeof(unsigned char), cudaMemcpyDeviceToHost);                 free(h_grayImage);     free(h_colorImage);     cudaFree(d_grayImage);     cudaFree(d_colorImage);      return 0; } "
    },
    {
        "id": "12",
        "c_code": "#include <stdio.h>  void dot_cpu(float *c, float *a, float *b, int size) {     int t_id;     for (t_id = 0; t_id < size; t_id++) {         c[t_id] = a[t_id] * b[t_id];     } }  int main() {          int vectorSize = 5;     float vectorA[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float vectorB[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultVector[vectorSize];      printf(\"\u5411\u91cf A\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorA[i]);     }      printf(\"\\n\u5411\u91cf B\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorB[i]);     }           dot_cpu(resultVector, vectorA, vectorB, vectorSize);      printf(\"\\n\u70b9\u4e58\u540e\u7684\u5411\u91cf C\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", resultVector[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void dotKernel(float* c, float* a, float* b) {     int t_id = blockIdx.x * blockDim.x + threadIdx.x;     c[t_id] = a[t_id] * b[t_id]; }  int main() {          int arraySize = 1000;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_b = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);         h_b[i] = static_cast<float>(2 * i);     }           float* d_a;     float* d_b;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_b, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           dotKernel<<<gridSize, blockSize>>>(d_c, d_a, d_b);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "120",
        "c_code": "#include <stdio.h>  void init_image_array_CPU(unsigned long long int *image, int pixels_per_image) {     for (int my_pixel = 0; my_pixel < pixels_per_image; my_pixel++) {         image[my_pixel] = (unsigned long long int)(0);         my_pixel += pixels_per_image;         image[my_pixel] = (unsigned long long int)(0);         my_pixel += pixels_per_image;         image[my_pixel] = (unsigned long long int)(0);         my_pixel += pixels_per_image;         image[my_pixel] = (unsigned long long int)(0);     } }  int main() {          const int pixels_per_image = 4;     unsigned long long int image[pixels_per_image * 4];            init_image_array_CPU(image, pixels_per_image);           printf(\"Resultant array image:\\n\");     for (int i = 0; i < pixels_per_image * 4; i++) {         printf(\"%llu \", image[i]);     }      return 0; } ",
        "cuda_code": "  #include <stdio.h>   __global__ void init_image_array_GPU(unsigned long long int* image, int pixels_per_image) {     int my_pixel = threadIdx.x + blockIdx.x * blockDim.x;      while (my_pixel < pixels_per_image * 4) {         image[my_pixel] = static_cast<unsigned long long int>(0);         my_pixel += blockDim.x * gridDim.x;     } }  int main() {                int pixels_per_image = 1000;      int num_blocks = 100;     int threads_per_block = 256;      unsigned long long int* h_image = (unsigned long long int*)malloc(pixels_per_image * 4 * sizeof(unsigned long long int));     unsigned long long int* d_image;     cudaMalloc((void**)&d_image, pixels_per_image * 4 * sizeof(unsigned long long int));           cudaMemcpy(d_image, h_image, pixels_per_image * 4 * sizeof(unsigned long long int), cudaMemcpyHostToDevice);           init_image_array_GPU<<<num_blocks, threads_per_block>>>(d_image, pixels_per_image);           cudaMemcpy(h_image, d_image, pixels_per_image * 4 * sizeof(unsigned long long int), cudaMemcpyDeviceToHost);                 free(h_image);     cudaFree(d_image);      return 0; } "
    },
    {
        "id": "121",
        "c_code": "#include <stdio.h>  void diffusion(const double *x0, double *x1, int nx, int ny, double dt) {     int i, j;     auto width = nx + 2;     for (j = 1; j < ny + 1; ++j) {         for (i = 1; i < nx + 1; ++i) {             auto pos = i + j * width;             x1[pos] = x0[pos] + dt * (-4. * x0[pos] + x0[pos - width] + x0[pos + width] + x0[pos - 1] + x0[pos + 1]);         }     } }  int main() {          const int nx = 2;     const int ny = 2;     const double dt = 0.1;     double x0[(nx + 2) * (ny + 2)] = {0.0};      double x1[(nx + 2) * (ny + 2)] = {0.0};           diffusion(x0, x1, nx, ny, dt);           printf(\"Resultant array x1:\\n\");     for (int j = 0; j < ny + 2; j++) {         for (int i = 0; i < nx + 2; i++) {             auto pos = i + j * (nx + 2);             printf(\"%f \", x1[pos]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void diffusion(double* x0, double* x1, int nx, int ny, double dt) {     int i = threadIdx.x + blockDim.x * blockIdx.x + 1;     int j = threadIdx.y + blockDim.y * blockIdx.y + 1;      if (i < nx - 1 && j < ny - 1) {         int pos = nx * j + i;         x1[pos] = x0[pos] + dt * (-4. * x0[pos] + x0[pos - 1] + x0[pos + 1] + x0[pos - nx] + x0[pos + nx]);     } }  int main() {                int nx = 100;      int ny = 100;     double dt = 0.01;      double* h_x0 = (double*)malloc(nx * ny * sizeof(double));     double* h_x1 = (double*)malloc(nx * ny * sizeof(double));      double* d_x0, * d_x1;     cudaMalloc((void**)&d_x0, nx * ny * sizeof(double));     cudaMalloc((void**)&d_x1, nx * ny * sizeof(double));           cudaMemcpy(d_x0, h_x0, nx * ny * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((nx + blockSize.x - 2) / blockSize.x, (ny + blockSize.y - 2) / blockSize.y);     diffusion<<<gridSize, blockSize>>>(d_x0, d_x1, nx, ny, dt);           cudaMemcpy(h_x1, d_x1, nx * ny * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_x0);     free(h_x1);     cudaFree(d_x0);     cudaFree(d_x1);      return 0; } "
    },
    {
        "id": "122",
        "c_code": "#include <stdio.h>  void compute_b_minus_Rx(double *out, double *x, double *b, double *cotans, int *neighbors, int meshStride, int n) {     for (int i = 0; i < n; i++) {         out[i] = b[i];         for (int iN = 0; iN < meshStride; ++iN) {             int neighbor = neighbors[i * meshStride + iN];             double weight = cotans[i * meshStride + iN];             out[i] += weight * x[neighbor];         }     } }  int main() {          const int n = 3;     const int meshStride = 2;     double x[] = {1.0, 2.0, 3.0};     double b[] = {4.0, 5.0, 6.0};     double cotans[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6};     int neighbors[] = {1, 2, 0, 2, 0, 1};     double out[n];           compute_b_minus_Rx(out, x, b, cotans, neighbors, meshStride, n);           printf(\"Resultant array out:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%f \", out[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void compute_b_minus_Rx(double* out, double* x, double* b, double* cotans, int* neighbors, int meshStride, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = gridDim.x * blockDim.x;      for (int i = index; i < n; i += stride) {         out[i] = b[i];          for (int iN = 0; iN < meshStride; ++iN) {             int neighbor = neighbors[i * meshStride + iN];             double weight = cotans[i * meshStride + iN];             out[i] += weight * x[neighbor];         }     } }  int main() {                int n = 100;      int meshStride = 5;       double* h_out = (double*)malloc(n * sizeof(double));     double* h_x = (double*)malloc(n * sizeof(double));     double* h_b = (double*)malloc(n * sizeof(double));     double* h_cotans = (double*)malloc(n * meshStride * sizeof(double));     int* h_neighbors = (int*)malloc(n * meshStride * sizeof(int));      double* d_out, * d_x, * d_b, * d_cotans;     int* d_neighbors;      cudaMalloc((void**)&d_out, n * sizeof(double));     cudaMalloc((void**)&d_x, n * sizeof(double));     cudaMalloc((void**)&d_b, n * sizeof(double));     cudaMalloc((void**)&d_cotans, n * meshStride * sizeof(double));     cudaMalloc((void**)&d_neighbors, n * meshStride * sizeof(int));           cudaMemcpy(d_x, h_x, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_cotans, h_cotans, n * meshStride * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_neighbors, h_neighbors, n * meshStride * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x);     compute_b_minus_Rx<<<gridSize, blockSize>>>(d_out, d_x, d_b, d_cotans, d_neighbors, meshStride, n);           cudaMemcpy(h_out, d_out, n * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_out);     free(h_x);     free(h_b);     free(h_cotans);     free(h_neighbors);     cudaFree(d_out);     cudaFree(d_x);     cudaFree(d_b);     cudaFree(d_cotans);     cudaFree(d_neighbors);      return 0; } "
    },
    {
        "id": "123",
        "c_code": "#include <stdio.h> #include <math.h>  void binarize_weights(float *weights, int n, int size, float *binary) {     int i, f;     for (f = 0; f < n; ++f) {         float mean = 0;         for (i = 0; i < size; ++i) {             mean += fabs(weights[f * size + i]);         }         mean = mean / size;         for (i = 0; i < size; ++i) {             binary[f * size + i] = (weights[f * size + i] > 0) ? mean : -mean;         }     } }  int main() {          const int n = 2;     const int size = 3;     float weights[] = {1.0, -2.0, 3.0, -4.0, 5.0, -6.0};     float binary[n * size];           binarize_weights(weights, n, size, binary);           printf(\"Resultant array binary:\\n\");     for (int f = 0; f < n; f++) {         for (int i = 0; i < size; i++) {             printf(\"%f \", binary[f * size + i]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void binarize_weights_kernel(float* weights, int n, int size, float* binary) {     int f = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (f >= n)         return;      int i = 0;     float mean = 0;      for (i = 0; i < size; ++i) {         mean += abs(weights[f * size + i]);     }      mean = mean / size;      for (i = 0; i < size; ++i) {         binary[f * size + i] = (weights[f * size + i] > 0) ? mean : -mean;     } }  int main() {                int n = 100;      int size = 50;       float* h_weights = (float*)malloc(n * size * sizeof(float));     float* h_binary = (float*)malloc(n * size * sizeof(float));      float* d_weights, * d_binary;     cudaMalloc((void**)&d_weights, n * size * sizeof(float));     cudaMalloc((void**)&d_binary, n * size * sizeof(float));           cudaMemcpy(d_weights, h_weights, n * size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n * size + blockSize.x - 1) / blockSize.x);     binarize_weights_kernel<<<gridSize, blockSize>>>(d_weights, n, size, d_binary);           cudaMemcpy(h_binary, d_binary, n * size * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_weights);     free(h_binary);     cudaFree(d_weights);     cudaFree(d_binary);      return 0; } "
    },
    {
        "id": "124",
        "c_code": "#include <stdio.h>  void gather_points_kernel(int b, int c, int n, int m, const float *points, const int *idx, float *out) {     for (int i = 0; i < b; i++) {         for (int l = 0; l < c; l++) {             for (int j = 0; j < m; j++) {                 int a = idx[i * m + j];                 out[(i * c + l) * m + j] = points[(i * c + l) * n + a];             }         }     } }  int main() {          const int b = 2;     const int c = 3;     const int n = 4;     const int m = 5;     float points[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};     int idx[] = {1, 3, 0, 2, 1, 3, 0, 2, 1, 3};     float out[b * c * m];           gather_points_kernel(b, c, n, m, points, idx, out);           printf(\"Resultant array out:\\n\");     for (int i = 0; i < b; i++) {         for (int l = 0; l < c; l++) {             for (int j = 0; j < m; j++) {                 printf(\"%f \", out[(i * c + l) * m + j]);             }             printf(\"\\n\");         }     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gather_points_kernel(int b, int c, int n, int m, const float* __restrict__ points, const int* __restrict__ idx, float* __restrict__ out) {     for (int i = blockIdx.x; i < b; i += gridDim.x) {         for (int l = blockIdx.y; l < c; l += gridDim.y) {             for (int j = threadIdx.x; j < m; j += blockDim.x) {                 int a = idx[i * m + j];                 out[(i * c + l) * m + j] = points[(i * c + l) * n + a];             }         }     } }  int main() {                int b = 100;      int c = 3;     int n = 500;     int m = 10;      float* h_points = (float*)malloc(b * c * n * sizeof(float));     int* h_idx = (int*)malloc(b * m * sizeof(int));     float* h_out = (float*)malloc(b * c * m * sizeof(float));      float* d_points, * d_out;     int* d_idx;      cudaMalloc((void**)&d_points, b * c * n * sizeof(float));     cudaMalloc((void**)&d_idx, b * m * sizeof(int));     cudaMalloc((void**)&d_out, b * c * m * sizeof(float));           cudaMemcpy(d_points, h_points, b * c * n * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_idx, h_idx, b * m * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize(b, c);       gather_points_kernel<<<gridSize, blockSize>>>(b, c, n, m, d_points, d_idx, d_out);           cudaMemcpy(h_out, d_out, b * c * m * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_points);     free(h_idx);     free(h_out);     cudaFree(d_points);     cudaFree(d_idx);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "125",
        "c_code": "#include <stdio.h>  void matrix_mult(int left_rows, int shared_dimensions, int right_columns, float *left, float *right, float *result) {     int row, column, cell;     for (row = 0; row < left_rows; row++) {         for (column = 0; column < right_columns; column++) {             result[row * right_columns + column] = 0;             for (cell = 0; cell < shared_dimensions; cell++) {                 result[row * right_columns + column] += left[row * shared_dimensions + cell] * right[cell * right_columns + column];             }         }     } }  int main() {          const int left_rows = 2;     const int shared_dimensions = 3;     const int right_columns = 4;     float left[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float right[] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0};     float result[left_rows * right_columns];           matrix_mult(left_rows, shared_dimensions, right_columns, left, right, result);           printf(\"Resultant array result:\\n\");     for (int i = 0; i < left_rows; i++) {         for (int j = 0; j < right_columns; j++) {             printf(\"%f \", result[i * right_columns + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gpu_matrix_mult(int left_rows, int shared_dimensions, int right_columns, float* left, float* right, float* result) {     int row = blockIdx.y * blockDim.y + threadIdx.y;     int column = blockIdx.x * blockDim.x + threadIdx.x;      if (row < left_rows && column < right_columns) {         int index = row * right_columns + column;         result[index] = 0;          for (int cell = 0; cell < shared_dimensions; cell++) {             result[index] += left[row * shared_dimensions + cell] * right[cell * right_columns + column];         }     } }  int main() {                int left_rows = 100;      int shared_dimensions = 50;     int right_columns = 200;      float* h_left = (float*)malloc(left_rows * shared_dimensions * sizeof(float));     float* h_right = (float*)malloc(shared_dimensions * right_columns * sizeof(float));     float* h_result = (float*)malloc(left_rows * right_columns * sizeof(float));      float* d_left, * d_right, * d_result;     cudaMalloc((void**)&d_left, left_rows * shared_dimensions * sizeof(float));     cudaMalloc((void**)&d_right, shared_dimensions * right_columns * sizeof(float));     cudaMalloc((void**)&d_result, left_rows * right_columns * sizeof(float));           cudaMemcpy(d_left, h_left, left_rows * shared_dimensions * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_right, h_right, shared_dimensions * right_columns * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((right_columns + blockSize.x - 1) / blockSize.x, (left_rows + blockSize.y - 1) / blockSize.y);     gpu_matrix_mult<<<gridSize, blockSize>>>(left_rows, shared_dimensions, right_columns, d_left, d_right, d_result);           cudaMemcpy(h_result, d_result, left_rows * right_columns * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_left);     free(h_right);     free(h_result);     cudaFree(d_left);     cudaFree(d_right);     cudaFree(d_result);      return 0; } "
    },
    {
        "id": "126",
        "c_code": "#include <stdio.h>  void matrixMultiplication_cpu(int *host_a, int *host_b, int *host_c, int row_a, int col_a, int col_b) {     for (int i = 0; i < row_a; ++i) {         for (int j = 0; j < col_b; ++j) {             int tmp = 0;             for (int k = 0; k < col_a; ++k) {                 tmp += host_a[i * col_a + k] * host_b[k * col_b + j];             }             host_c[i * col_b + j] = tmp;         }     } }  int main() {          const int row_a = 2;     const int col_a = 3;     const int col_b = 4;     int host_a[] = {1, 2, 3, 4, 5, 6};     int host_b[] = {7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18};     int host_c[row_a * col_b];           matrixMultiplication_cpu(host_a, host_b, host_c, row_a, col_a, col_b);           printf(\"Resultant array host_c:\\n\");     for (int i = 0; i < row_a; i++) {         for (int j = 0; j < col_b; j++) {             printf(\"%d \", host_c[i * col_b + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void matrixMultiplication(int* dev_a, int* dev_b, int* dev_c, int row_a, int col_a, int col_b) {     int row = threadIdx.y + blockIdx.y * blockDim.y;     int col = threadIdx.x + blockIdx.x * blockDim.x;     int ret = 0;      if (row < row_a && col < col_b) {         for (int i = 0; i < col_a; ++i) {             ret += dev_a[row * col_a + i] * dev_b[i * col_b + col];         }          dev_c[row * col_b + col] = ret;     } }  int main() {                int row_a = 100;      int col_a = 50;     int col_b = 200;      int* h_a = (int*)malloc(row_a * col_a * sizeof(int));     int* h_b = (int*)malloc(col_a * col_b * sizeof(int));     int* h_c = (int*)malloc(row_a * col_b * sizeof(int));      int* d_a, * d_b, * d_c;     cudaMalloc((void**)&d_a, row_a * col_a * sizeof(int));     cudaMalloc((void**)&d_b, col_a * col_b * sizeof(int));     cudaMalloc((void**)&d_c, row_a * col_b * sizeof(int));           cudaMemcpy(d_a, h_a, row_a * col_a * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, col_a * col_b * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((col_b + blockSize.x - 1) / blockSize.x, (row_a + blockSize.y - 1) / blockSize.y);     matrixMultiplication<<<gridSize, blockSize>>>(d_a, d_b, d_c, row_a, col_a, col_b);           cudaMemcpy(h_c, d_c, row_a * col_b * sizeof(int), cudaMemcpyDeviceToHost);                 free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "127",
        "c_code": "#include <stdio.h>  void Backwardsub(double *U, double *RES, double *UN, double *UE, double *LPR, int NI, int NJ, int End, int J, int n) {     for (int i = 0; i < n; i++) {         int IJ = ((End - i) * NI) + (J - (End - i));         RES[IJ] = RES[IJ] - UN[IJ] * RES[IJ + 1] - UE[IJ] * RES[IJ + NJ];         U[IJ] = U[IJ] + RES[IJ];     } }  int main() {          const int NI = 3;     const int NJ = 3;     const int End = 1;     const int J = 1;     const int n = 1;     double U[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};     double RES[] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};     double UN[] = {1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0};     double UE[] = {2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0};     double LPR[] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};           Backwardsub(U, RES, UN, UE, LPR, NI, NJ, End, J, n);           printf(\"Resultant array U:\\n\");     for (int i = 0; i < NI; i++) {         for (int j = 0; j < NJ; j++) {             printf(\"%f \", U[i * NJ + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void Backwardsub(double* U, double* RES, double* UN, double* UE, double* LPR, int NI, int NJ, int End, int J, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i < n) {         int IJ = ((End - i) * NI) + (J - (End - i));         RES[IJ] = RES[IJ] - UN[IJ] * RES[IJ + 1] - UE[IJ] * RES[IJ + NJ];         U[IJ] = U[IJ] + RES[IJ];     } }  int main() {                int NI = 100;      int NJ = 100;     int End = 50;     int J = 25;     int n = 10;      double* h_U = (double*)malloc(NI * NJ * sizeof(double));     double* h_RES = (double*)malloc(NI * NJ * sizeof(double));     double* h_UN = (double*)malloc(NI * NJ * sizeof(double));     double* h_UE = (double*)malloc(NI * NJ * sizeof(double));     double* h_LPR = (double*)malloc(NI * NJ * sizeof(double));      double* d_U, * d_RES, * d_UN, * d_UE, * d_LPR;     cudaMalloc((void**)&d_U, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_RES, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_UN, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_UE, NI * NJ * sizeof(double));     cudaMalloc((void**)&d_LPR, NI * NJ * sizeof(double));           cudaMemcpy(d_U, h_U, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_RES, h_RES, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_UN, h_UN, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_UE, h_UE, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_LPR, h_LPR, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x);     Backwardsub<<<gridSize, blockSize>>>(d_U, d_RES, d_UN, d_UE, d_LPR, NI, NJ, End, J, n);           cudaMemcpy(h_U, d_U, NI * NJ * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_U);     free(h_RES);     free(h_UN);     free(h_UE);     free(h_LPR);     cudaFree(d_U);     cudaFree(d_RES);     cudaFree(d_UN);     cudaFree(d_UE);     cudaFree(d_LPR);      return 0; } "
    },
    {
        "id": "128",
        "c_code": "#include <stdio.h>  void convolution_cpu_1d(float *input, const float *mask, float *output, int array_size, int mask_size) {     int MASK_RADIUS = mask_size / 2;     float temp = 0.0f;     int ELEMENT_INDEX = 0;      for (int i = 0; i < array_size; i++) {         temp = 0;          for (int j = 0; j < mask_size; j++) {             ELEMENT_INDEX = i - MASK_RADIUS + j;              if (!(ELEMENT_INDEX < 0 || ELEMENT_INDEX > (array_size - 1))) {                 temp += input[ELEMENT_INDEX] * mask[j];             }         }          output[i] = temp;     } }  int main() {          const int array_size = 10;     const int mask_size = 3;     float input[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0};     float mask[] = {0.1, 0.2, 0.1};     float output[array_size];           convolution_cpu_1d(input, mask, output, array_size, mask_size);           printf(\"Resultant array output:\\n\");     for (int i = 0; i < array_size; i++) {         printf(\"%f \", output[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void convolution_gpu_1d_naive(float* input, float* mask, float* output, int array_size, int mask_size) {     int gid = blockIdx.x * blockDim.x + threadIdx.x;     int MASK_RADIUS = mask_size / 2;     int ELEMENT_INDEX = 0;     float temp = 0.0f;      if (gid < array_size) {         for (int j = 0; j < mask_size; j++) {             ELEMENT_INDEX = gid - MASK_RADIUS + j;             if (!(ELEMENT_INDEX < 0 || ELEMENT_INDEX > (array_size - 1))) {                 temp += input[ELEMENT_INDEX] * mask[j];             }         }          output[gid] = temp;     } }  int main() {                int array_size = 100;      int mask_size = 5;          float* h_input = (float*)malloc(array_size * sizeof(float));     float* h_mask = (float*)malloc(mask_size * sizeof(float));     float* h_output = (float*)malloc(array_size * sizeof(float));      float* d_input, * d_mask, * d_output;     cudaMalloc((void**)&d_input, array_size * sizeof(float));     cudaMalloc((void**)&d_mask, mask_size * sizeof(float));     cudaMalloc((void**)&d_output, array_size * sizeof(float));           cudaMemcpy(d_input, h_input, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_mask, h_mask, mask_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((array_size + blockSize.x - 1) / blockSize.x);     convolution_gpu_1d_naive<<<gridSize, blockSize>>>(d_input, d_mask, d_output, array_size, mask_size);           cudaMemcpy(h_output, d_output, array_size * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_input);     free(h_mask);     free(h_output);     cudaFree(d_input);     cudaFree(d_mask);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "129",
        "c_code": "#include <stdio.h>  void getRho(const int numOfNucl, const double *psi, const double *occNo, double *rho, const char debug) {     *rho = 0;      for (int i = 0; i < numOfNucl; ++i)         *rho += occNo[i] * psi[i] * psi[i];      if (debug == 1)         printf(\"DEBUG: Print of RHO:\\nRHO = %f\\nThis is the last line (RHO).\\n\\n\", *rho); }  int main() {          const int numOfNucl = 3;     const char debug = 1;     double psi[] = {0.1, 0.2, 0.3};     double occNo[] = {1.0, 2.0, 3.0};     double rho;           getRho(numOfNucl, psi, occNo, &rho, debug);           printf(\"Resultant RHO: %f\\n\", rho);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void getRho_cuda(const double* psi, const double* occNo, double* rho) {     extern __shared__ double dcopy[];      dcopy[threadIdx.x] = occNo[threadIdx.x] * psi[threadIdx.x] * psi[threadIdx.x];      __syncthreads();      for (int tc = blockDim.x, stepSize = 1; tc > 0; tc >>= 1, stepSize <<= 1) {         int pa = threadIdx.x * stepSize;         int pb = pa + stepSize;          if (pb < blockDim.x) {             dcopy[pa] += dcopy[pb];         }     }      if (threadIdx.x == 0) {         *rho = dcopy[0];     } }  int main() {                int array_size = 100;       double* h_psi = (double*)malloc(array_size * sizeof(double));     double* h_occNo = (double*)malloc(array_size * sizeof(double));     double* h_rho = (double*)malloc(sizeof(double));      double* d_psi, * d_occNo, * d_rho;     cudaMalloc((void**)&d_psi, array_size * sizeof(double));     cudaMalloc((void**)&d_occNo, array_size * sizeof(double));     cudaMalloc((void**)&d_rho, sizeof(double));           cudaMemcpy(d_psi, h_psi, array_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_occNo, h_occNo, array_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize(1);         int sharedMemorySize = blockSize.x * sizeof(double);      getRho_cuda<<<gridSize, blockSize, sharedMemorySize>>>(d_psi, d_occNo, d_rho);           cudaMemcpy(h_rho, d_rho, sizeof(double), cudaMemcpyDeviceToHost);                 free(h_psi);     free(h_occNo);     free(h_rho);     cudaFree(d_psi);     cudaFree(d_occNo);     cudaFree(d_rho);      return 0; } "
    },
    {
        "id": "13",
        "c_code": "#include <stdio.h>  void matDiagAddInplace_cpu(double *mat, double alpha, int dim) {     for (int i = 0; i < dim; i++) {         mat[i * dim + i] += alpha;     } }  int main() {          int matrixDim = 3;     double matrix[3][3] = {{1.1, 2.2, 3.3},                            {4.4, 5.5, 6.6},                            {7.7, 8.8, 9.9}};     double alpha = 10.0;      printf(\"\u539f\u59cb\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < matrixDim; i++) {         for (int j = 0; j < matrixDim; j++) {             printf(\"%.2f \", matrix[i][j]);         }         printf(\"\\n\");     }           matDiagAddInplace_cpu((double *)matrix, alpha, matrixDim);      printf(\"\\n\u5bf9\u89d2\u7ebf\u5143\u7d20\u52a0\u4e0a\u5e38\u6570\u540e\u7684\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < matrixDim; i++) {         for (int j = 0; j < matrixDim; j++) {             printf(\"%.2f \", matrix[i][j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void matDiagAddInplaceKernel(double* mat, double alpha, int dim) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < dim) {         mat[i * dim + i] += alpha;     } }  int main() {          int matrixDim = 5;           double* h_mat = (double*)malloc(matrixDim * matrixDim * sizeof(double));           for (int i = 0; i < matrixDim * matrixDim; ++i) {         h_mat[i] = static_cast<double>(i);     }           double* d_mat;     cudaMalloc((void**)&d_mat, matrixDim * matrixDim * sizeof(double));           cudaMemcpy(d_mat, h_mat, matrixDim * matrixDim * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (matrixDim * matrixDim + blockSize - 1) / blockSize;           matDiagAddInplaceKernel<<<gridSize, blockSize>>>(d_mat, 2.0, matrixDim);           cudaMemcpy(h_mat, d_mat, matrixDim * matrixDim * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < matrixDim; ++i) {         for (int j = 0; j < matrixDim; ++j) {             printf(\"%f \", h_mat[i * matrixDim + j]);         }         printf(\"\\n\");     }           free(h_mat);     cudaFree(d_mat);      return 0; } "
    },
    {
        "id": "130",
        "c_code": "#include <stdio.h> #include <math.h>  void colLog2SumExp2_cpu(const double *mat, double *buf, int m, int n) {     for (int j = 0; j < n; j++) {         double maximum = mat[j];          for (int i = 1; i < m; i++) {             if (mat[i * n + j] > maximum) {                 maximum = mat[i * n + j];             }         }          double res = 0.0;          for (int i = 0; i < m; i++) {             res += exp(mat[i * n + j] - maximum);         }          buf[j] = log2(res) + maximum;     } }  int main() {          const int m = 3;     const int n = 2;     double mat[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     double buf[n];           colLog2SumExp2_cpu(mat, buf, m, n);           for (int j = 0; j < n; j++) {         printf(\"Resultant buf[%d]: %f\\n\", j, buf[j]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void colLog2SumExp2Kernel(const double* mat, double* buf, int m, int n) {     int j = blockIdx.x * blockDim.x + threadIdx.x;      if (j < n) {         double maximum = mat[j];          for (int i = 1; i < m; i++) {             if (mat[i * n + j] > maximum) {                 maximum = mat[i * n + j];             }         }          double res = 0.0;          for (int i = 0; i < m; i++) {             res += mat[i * n + j] - maximum;         }          buf[j] = res + maximum;     } }  int main() {                int m = 100;      int n = 50;        double* h_mat = (double*)malloc(m * n * sizeof(double));     double* h_buf = (double*)malloc(n * sizeof(double));      double* d_mat, * d_buf;     cudaMalloc((void**)&d_mat, m * n * sizeof(double));     cudaMalloc((void**)&d_buf, n * sizeof(double));           cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x);      colLog2SumExp2Kernel<<<gridSize, blockSize>>>(d_mat, d_buf, m, n);           cudaMemcpy(h_buf, d_buf, n * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_mat);     free(h_buf);     cudaFree(d_mat);     cudaFree(d_buf);      return 0; } "
    },
    {
        "id": "131",
        "c_code": "#include <stdio.h>  void bitPrune_cpu(unsigned char *out, float *in, int frontPrune, int outputlength, int inputLength, int n) {     for (int i = 0; i < n; i++) {         int batch = i / outputlength;         int indexInBatch = i % outputlength;         int batchInJump = batch * inputLength;         int indexOutBatch = i % outputlength;         int batchOutJump = batch * outputlength;         int frontJump = frontPrune;         out[batchOutJump + indexOutBatch] = (char)(in[batchInJump + frontJump + indexInBatch] > 0);     } }  int main() {          const int outputlength = 4;     const int inputLength = 6;     const int n = 8;     float in[] = {1.0, -2.0, 3.0, -4.0, 5.0, -6.0, 7.0, -8.0};     unsigned char out[n];           bitPrune_cpu(out, in, 1, outputlength, inputLength, n);           for (int i = 0; i < n; i++) {         printf(\"Resultant out[%d]: %d\\n\", i, out[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void bitPrune(unsigned char *out, float *in, int frontPrune, int outputLength, int inputLength, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i >= n) {         return;     }      int batch = i / outputLength;     int indexInBatch = i % outputLength;      int batchInJump = batch * inputLength;     int indexOutBatch = i % outputLength;     int batchOutJump = batch * outputLength;      int frontJump = frontPrune;     out[batchOutJump + indexOutBatch] = (char)(in[batchInJump + frontJump + indexInBatch] > 0); }  int main() {          int frontPrune = 10;      int outputLength = 100;      int inputLength = 120;      int n = 1000;       unsigned char *out;      float *in;            cudaSetDevice(0);           unsigned char *d_out;     float *d_in;      cudaMalloc((void **)&d_out, n * outputLength * sizeof(unsigned char));     cudaMalloc((void **)&d_in, n * inputLength * sizeof(float));           cudaMemcpy(d_in, in, n * inputLength * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           bitPrune<<<blocksPerGrid, threadsPerBlock>>>(d_out, d_in, frontPrune, outputLength, inputLength, n);           cudaDeviceSynchronize();           cudaMemcpy(out, d_out, n * outputLength * sizeof(unsigned char), cudaMemcpyDeviceToHost);           cudaFree(d_out);     cudaFree(d_in);      return 0; } "
    },
    {
        "id": "132",
        "c_code": "#include <stdio.h>  void residual(double *out, double *x, double *b, double *cotans, int *neighbors, double *diag, int meshStride, int n) {     for (int i = 0; i < n; i++) {         out[i] = diag[i] * x[i] - b[i];         for (int iN = 0; iN < meshStride; ++iN) {             int neighbor = neighbors[i * meshStride + iN];             double weight = cotans[i * meshStride + iN];             out[i] -= weight * x[neighbor];         }     } }  int main() {          const int n = 5;     double x[] = {1.0, 2.0, 3.0, 4.0, 5.0};     double b[] = {10.0, 20.0, 30.0, 40.0, 50.0};     double cotans[] = {0.1, 0.2, 0.3, 0.4, 0.5};     int neighbors[] = {1, 0, 2, 1, 3, 2, 4, 3, 0, 4, 3, 2};     double diag[] = {2.0, 3.0, 4.0, 5.0, 6.0};     double out[n];           residual(out, x, b, cotans, neighbors, diag, 3, n);           for (int i = 0; i < n; i++) {         printf(\"Resultant out[%d]: %f\\n\", i, out[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void residual(double* out, double* x, double* b, double* cotans, int* neighbors, double* diag, int meshStride, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = gridDim.x * blockDim.x;      for (int i = index; i < n; i += stride) {         out[i] = diag[i] * x[i] - b[i];          for (int iN = 0; iN < meshStride; ++iN) {             int neighbor = neighbors[i * meshStride + iN];             double weight = cotans[i * meshStride + iN];             out[i] -= weight * x[neighbor];         }     } }  int main() {                int n = 100;      int meshStride = 6;       double* h_out = (double*)malloc(n * sizeof(double));     double* h_x = (double*)malloc(n * sizeof(double));     double* h_b = (double*)malloc(n * sizeof(double));     double* h_cotans = (double*)malloc(n * meshStride * sizeof(double));     int* h_neighbors = (int*)malloc(n * meshStride * sizeof(int));     double* h_diag = (double*)malloc(n * sizeof(double));      double* d_out, * d_x, * d_b, * d_cotans, * d_diag;     int* d_neighbors;      cudaMalloc((void**)&d_out, n * sizeof(double));     cudaMalloc((void**)&d_x, n * sizeof(double));     cudaMalloc((void**)&d_b, n * sizeof(double));     cudaMalloc((void**)&d_cotans, n * meshStride * sizeof(double));     cudaMalloc((void**)&d_neighbors, n * meshStride * sizeof(int));     cudaMalloc((void**)&d_diag, n * sizeof(double));           cudaMemcpy(d_out, h_out, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_x, h_x, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_cotans, h_cotans, n * meshStride * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_neighbors, h_neighbors, n * meshStride * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_diag, h_diag, n * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x);      residual<<<gridSize, blockSize>>>(d_out, d_x, d_b, d_cotans, d_neighbors, d_diag, meshStride, n);           cudaMemcpy(h_out, d_out, n * sizeof(double), cudaMemcpyDeviceToHost);                 free(h_out);     free(h_x);     free(h_b);     free(h_cotans);     free(h_neighbors);     free(h_diag);      cudaFree(d_out);     cudaFree(d_x);     cudaFree(d_b);     cudaFree(d_cotans);     cudaFree(d_neighbors);     cudaFree(d_diag);      return 0; } "
    },
    {
        "id": "133",
        "c_code": "#include <stdio.h>  void forward_avgpool_layer(int batch, int c, int h, int w, float *input, float *output) {     int b, i, k;     for (b = 0; b < batch; ++b) {         for (k = 0; k < c; ++k) {             int out_index = k + b * c;             output[out_index] = 0;             for (i = 0; i < h * w; ++i) {                 int in_index = i + h * w * (k + b * c);                 output[out_index] += input[in_index];             }             output[out_index] /= h * w;         }     } }  int main() {          const int batch = 2;     const int channels = 3;     const int height = 4;     const int width = 4;      float input[batch * channels * height * width];     float output[batch * channels];                 forward_avgpool_layer(batch, channels, height, width, input, output);           for (int b = 0; b < batch; ++b) {         for (int c = 0; c < channels; ++c) {             printf(\"Resultant output[%d][%d]: %f\\n\", b, c, output[c + b * channels]);         }     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void forward_avgpool_layer_kernel(int n, int w, int h, int c, float* input, float* output) {     int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (id >= n)         return;      int k = id % c;     id /= c;     int b = id;      int i;     int out_index = (k + c * b);     output[out_index] = 0;      for (i = 0; i < w * h; ++i) {         int in_index = i + h * w * (k + b * c);         output[out_index] += input[in_index];     }      output[out_index] /= w * h; }  int main() {                int n = 100;      int w = 32;       int h = 32;       int c = 3;         float* h_input = (float*)malloc(n * w * h * c * sizeof(float));     float* h_output = (float*)malloc(n * c * sizeof(float));      float* d_input, * d_output;     cudaMalloc((void**)&d_input, n * w * h * c * sizeof(float));     cudaMalloc((void**)&d_output, n * c * sizeof(float));           cudaMemcpy(d_input, h_input, n * w * h * c * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x, 1);       forward_avgpool_layer_kernel<<<gridSize, blockSize>>>(n, w, h, c, d_input, d_output);           cudaMemcpy(h_output, d_output, n * c * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_input);     free(h_output);     cudaFree(d_input);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "134",
        "c_code": "#include <stdio.h>  void convolutionColumnCPU(float *h_Dst, float *h_Src, float *h_Filter, int imageW, int imageH, int filterR) {     int x, y, k;     for (y = 0; y < imageH; y++) {         for (x = 0; x < imageW; x++) {             float sum = 0;             for (k = -filterR; k <= filterR; k++) {                 int d = y + k;                 if (d >= 0 && d < imageH) {                     sum += h_Src[d * imageW + x] * h_Filter[filterR - k];                 }             }             h_Dst[y * imageW + x] = sum;         }     } }  int main() {          const int imageW = 4;     const int imageH = 4;     const int filterR = 1;      float h_Src[imageH * imageW];     float h_Filter[2 * filterR + 1];     float h_Dst[imageH * imageW];                 convolutionColumnCPU(h_Dst, h_Src, h_Filter, imageW, imageH, filterR);           for (int y = 0; y < imageH; ++y) {         for (int x = 0; x < imageW; ++x) {             printf(\"Resultant h_Dst[%d][%d]: %f\\n\", y, x, h_Dst[y * imageW + x]);         }     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void kernel_columns(const float* filter, const float* buffer, float* output, int imageW, int imageH, int filterR) {     int idx_x = threadIdx.x + blockDim.x * blockIdx.x;     int idx_y = threadIdx.y + blockDim.y * blockIdx.y;     int grid_width = gridDim.x * blockDim.x;     int idx = grid_width * idx_y + idx_x;      float sum = 0;      for (int k = -filterR; k <= filterR; k++) {         int d = idx_y + k;          if (d >= 0 && d < imageH) {             sum += buffer[d * imageW + idx_x] * filter[filterR - k];         }     }      output[idx] = sum; }  int main() {                int imageW = 512;         int imageH = 512;         int filterR = 3;           float* h_filter = (float*)malloc((2 * filterR + 1) * sizeof(float));     float* h_buffer = (float*)malloc(imageW * imageH * sizeof(float));     float* h_output = (float*)malloc(imageW * imageH * sizeof(float));      float* d_filter, * d_buffer, * d_output;     cudaMalloc((void**)&d_filter, (2 * filterR + 1) * sizeof(float));     cudaMalloc((void**)&d_buffer, imageW * imageH * sizeof(float));     cudaMalloc((void**)&d_output, imageW * imageH * sizeof(float));           cudaMemcpy(d_filter, h_filter, (2 * filterR + 1) * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_buffer, h_buffer, imageW * imageH * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((imageW + blockSize.x - 1) / blockSize.x, (imageH + blockSize.y - 1) / blockSize.y);      kernel_columns<<<gridSize, blockSize>>>(d_filter, d_buffer, d_output, imageW, imageH, filterR);           cudaMemcpy(h_output, d_output, imageW * imageH * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_filter);     free(h_buffer);     free(h_output);     cudaFree(d_filter);     cudaFree(d_buffer);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "135",
        "c_code": "#include <stdio.h>  void matrMult(float *A, float *B, float *C, int rowsA, int colsA, int colsB) {     for (int i = 0; i < rowsA; ++i) {         for (int j = 0; j < colsB; ++j) {             for (int k = 0; k < colsA; ++k) {                 C[i * colsB + j] += A[i * colsA + k] * B[k * colsB + j];             }         }     } }  int main() {          const int rowsA = 2;     const int colsA = 3;     const int colsB = 2;      float A[rowsA * colsA] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float B[colsA * colsB] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0};     float C[rowsA * colsB] = {0.0};           matrMult(A, B, C, rowsA, colsA, colsB);           for (int i = 0; i < rowsA; ++i) {         for (int j = 0; j < colsB; ++j) {             printf(\"Resultant C[%d][%d]: %f\\n\", i, j, C[i * colsB + j]);         }     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gpuMatrMultD(float* Ad, float* Bd, float* Cd, int rowsA, int colsA, int colsB) {     int bIndx = blockIdx.x;     int bIndy = blockIdx.y;     int tIndx = threadIdx.x;     int tIndy = threadIdx.y;      Cd[(blockDim.x * bIndx + tIndx) * colsB + blockDim.y * bIndy + tIndy] = 0;      for (int k = 0; k < colsA; ++k) {         Cd[(blockDim.x * bIndx + tIndx) * colsB + blockDim.y * bIndy + tIndy] +=             Ad[(blockDim.x * bIndx + tIndx) * colsA + k] * Bd[k * colsB + blockDim.y * bIndy + tIndy];     } }  int main() {                int rowsA = 512;         int colsA = 256;         int colsB = 128;          float* h_Ad = (float*)malloc(rowsA * colsA * sizeof(float));     float* h_Bd = (float*)malloc(colsA * colsB * sizeof(float));     float* h_Cd = (float*)malloc(rowsA * colsB * sizeof(float));      float* d_Ad, * d_Bd, * d_Cd;     cudaMalloc((void**)&d_Ad, rowsA * colsA * sizeof(float));     cudaMalloc((void**)&d_Bd, colsA * colsB * sizeof(float));     cudaMalloc((void**)&d_Cd, rowsA * colsB * sizeof(float));           cudaMemcpy(d_Ad, h_Ad, rowsA * colsA * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Bd, h_Bd, colsA * colsB * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((colsB + blockSize.x - 1) / blockSize.x, (rowsA + blockSize.y - 1) / blockSize.y);      gpuMatrMultD<<<gridSize, blockSize>>>(d_Ad, d_Bd, d_Cd, rowsA, colsA, colsB);           cudaMemcpy(h_Cd, d_Cd, rowsA * colsB * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_Ad);     free(h_Bd);     free(h_Cd);     cudaFree(d_Ad);     cudaFree(d_Bd);     cudaFree(d_Cd);      return 0; } "
    },
    {
        "id": "136",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void add_sources_d(const float *const model, float *wfp, const float *const source_amplitude,                    const int *const sources_z, const int *const sources_x,                    const int nz, const int nx, const int nt, const int ns, const int it) {     int x, b;      for (x = 0; x < nx; x++) {         for (b = 0; b < ns; b++) {             int i = sources_z[b * ns + x] * nx + sources_x[b * ns + x];             int ib = b * nz * nx + i;             wfp[ib] += source_amplitude[b * ns * nt + x * nt + it] * model[i];         }     } }  int main() {          const int nz = 3;     const int nx = 4;     const int nt = 5;     const int ns = 2;     const int it = 3;      float *model = (float *)malloc(nz * nx * sizeof(float));     float *wfp = (float *)malloc(ns * nz * nx * sizeof(float));     float *source_amplitude = (float *)malloc(ns * nt * nx * sizeof(float));     int *sources_z = (int *)malloc(ns * nx * sizeof(int));     int *sources_x = (int *)malloc(ns * nx * sizeof(int));           for (int i = 0; i < nz * nx; ++i) {         model[i] = i + 1.0;     }      for (int i = 0; i < ns * nz * nx; ++i) {         wfp[i] = 0.0;     }      for (int i = 0; i < ns * nt * nx; ++i) {         source_amplitude[i] = i + 0.5;     }      for (int i = 0; i < ns * nx; ++i) {         sources_z[i] = i % nz;         sources_x[i] = i % nx;     }           add_sources_d(model, wfp, source_amplitude, sources_z, sources_x, nz, nx, nt, ns, it);           for (int i = 0; i < ns * nz * nx; ++i) {         printf(\"Resultant wfp[%d]: %f\\n\", i, wfp[i]);     }           free(model);     free(wfp);     free(source_amplitude);     free(sources_z);     free(sources_x);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void add_sources_d(const float* const model, float* wfp, const float* const source_amplitude,                                const int* const sources_z, const int* const sources_x, const int nz, const int nx,                                const int nt, const int ns, const int it) {     int x = threadIdx.x;     int b = blockIdx.x;     int i = sources_z[b * ns + x] * nx + sources_x[b * ns + x];     int ib = b * nz * nx + i;     wfp[ib] += source_amplitude[b * ns * nt + x * nt + it] * model[i]; }  int main() {                int nz = 100;         int nx = 100;         int nt = 100;         int ns = 10;           float* h_model = (float*)malloc(nz * nx * sizeof(float));     float* h_wfp = (float*)malloc(nz * nx * ns * sizeof(float));     float* h_source_amplitude = (float*)malloc(ns * nt * sizeof(float));     int* h_sources_z = (int*)malloc(ns * sizeof(int));     int* h_sources_x = (int*)malloc(ns * sizeof(int));      float* d_model, * d_wfp, * d_source_amplitude;     int* d_sources_z, * d_sources_x;      cudaMalloc((void**)&d_model, nz * nx * sizeof(float));     cudaMalloc((void**)&d_wfp, nz * nx * ns * sizeof(float));     cudaMalloc((void**)&d_source_amplitude, ns * nt * sizeof(float));     cudaMalloc((void**)&d_sources_z, ns * sizeof(int));     cudaMalloc((void**)&d_sources_x, ns * sizeof(int));           cudaMemcpy(d_model, h_model, nz * nx * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_wfp, h_wfp, nz * nx * ns * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_source_amplitude, h_source_amplitude, ns * nt * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_sources_z, h_sources_z, ns * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_sources_x, h_sources_x, ns * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(16);      dim3 gridSize(ns);      int it = 0;       add_sources_d<<<gridSize, blockSize>>>(d_model, d_wfp, d_source_amplitude, d_sources_z, d_sources_x, nz, nx, nt, ns, it);           cudaMemcpy(h_wfp, d_wfp, nz * nx * ns * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_model);     free(h_wfp);     free(h_source_amplitude);     free(h_sources_z);     free(h_sources_x);      cudaFree(d_model);     cudaFree(d_wfp);     cudaFree(d_source_amplitude);     cudaFree(d_sources_z);     cudaFree(d_sources_x);      return 0; } "
    },
    {
        "id": "137",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>  void variance_cpu(float *x, float *mean, int batch, int filters, int spatial, float *variance) {     float scale = 1. / (batch * spatial - 1);     int i, j, k;      for (i = 0; i < filters; ++i) {         variance[i] = 0;          for (j = 0; j < batch; ++j) {             for (k = 0; k < spatial; ++k) {                 int index = j * filters * spatial + i * spatial + k;                 variance[i] += pow((x[index] - mean[i]), 2);             }         }          variance[i] *= scale;     } }  int main() {          const int batch = 2;     const int filters = 3;     const int spatial = 4;      float *x = (float *)malloc(batch * filters * spatial * sizeof(float));     float *mean = (float *)malloc(filters * sizeof(float));     float *variance = (float *)malloc(filters * sizeof(float));           for (int i = 0; i < batch * filters * spatial; ++i) {         x[i] = i + 1.0;     }      for (int i = 0; i < filters; ++i) {         mean[i] = i + 0.5;     }           variance_cpu(x, mean, batch, filters, spatial, variance);           for (int i = 0; i < filters; ++i) {         printf(\"Resultant variance[%d]: %f\\n\", i, variance[i]);     }           free(x);     free(mean);     free(variance);      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void variance_kernel(float* x, float* mean, int batch, int filters, int spatial, float* variance) {     float scale = 1.f / (batch * spatial - 1);     int j, k;     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i >= filters)         return;      variance[i] = 0;      for (j = 0; j < batch; ++j) {         for (k = 0; k < spatial; ++k) {             int index = j * filters * spatial + i * spatial + k;             variance[i] += powf((x[index] - mean[i]), 2);         }     }      variance[i] *= scale; }  int main() {                int batch = 32;          int filters = 64;        int spatial = 128;        float* h_x = (float*)malloc(batch * filters * spatial * sizeof(float));     float* h_mean = (float*)malloc(filters * sizeof(float));     float* h_variance = (float*)malloc(filters * sizeof(float));      float* d_x, * d_mean, * d_variance;     cudaMalloc((void**)&d_x, batch * filters * spatial * sizeof(float));     cudaMalloc((void**)&d_mean, filters * sizeof(float));     cudaMalloc((void**)&d_variance, filters * sizeof(float));           cudaMemcpy(d_x, h_x, batch * filters * spatial * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_mean, h_mean, filters * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((filters + blockSize.x - 1) / blockSize.x, 1);      variance_kernel<<<gridSize, blockSize>>>(d_x, d_mean, batch, filters, spatial, d_variance);           cudaMemcpy(h_variance, d_variance, filters * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_x);     free(h_mean);     free(h_variance);     cudaFree(d_x);     cudaFree(d_mean);     cudaFree(d_variance);      return 0; } "
    },
    {
        "id": "138",
        "c_code": "#include <stdio.h>  void grad_y_cpu(const float *u, float *grad, long depth, long rows, long cols) {     for (int x = 0; x < cols; x++) {         for (int y = 0; y < rows; y++) {             for (int z = 0; z < depth; z++) {                 unsigned long size2d = rows * cols;                 unsigned long long idx = z * size2d + y * cols + x;                 float uidx = u[idx];                  if (y > 0) {                     grad[idx] = (uidx - u[z * size2d + (y - 1) * cols + x]);                 }             }         }     } }  int main() {          long depth = 3;     long rows = 4;     long cols = 5;           float u[depth * rows * cols];           for (int i = 0; i < depth * rows * cols; i++) {         u[i] = 1.0f;     }           float grad[depth * rows * cols];           grad_y_cpu(u, grad, depth, rows, cols);           for (int i = 0; i < depth * rows * cols; i++) {         printf(\"%f \", grad[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void grad_y(const float* u, float* grad, long depth, long rows, long cols) {     unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;     unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;     unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;      if (x >= cols || y >= rows || z >= depth)         return;      unsigned long size2d = rows * cols;     unsigned long long idx = z * size2d + y * cols + x;     float uidx = u[idx];      if (y - 1 >= 0 && y < rows) {         grad[idx] = (uidx - u[z * size2d + (y - 1) * cols + x]);     } }  int main() {                long depth = 16;       long rows = 128;       long cols = 128;        float* h_u = (float*)malloc(depth * rows * cols * sizeof(float));     float* h_grad = (float*)malloc(depth * rows * cols * sizeof(float));      float* d_u, *d_grad;     cudaMalloc((void**)&d_u, depth * rows * cols * sizeof(float));     cudaMalloc((void**)&d_grad, depth * rows * cols * sizeof(float));           cudaMemcpy(d_u, h_u, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16, 1);      dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y, (depth + blockSize.z - 1) / blockSize.z);      grad_y<<<gridSize, blockSize>>>(d_u, d_grad, depth, rows, cols);           cudaMemcpy(h_grad, d_grad, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_u);     free(h_grad);     cudaFree(d_u);     cudaFree(d_grad);      return 0; } "
    },
    {
        "id": "139",
        "c_code": "#include <stdio.h>  void grad_x_cpu(const float *u, float *grad, long depth, long rows, long cols) {     for (int x = 0; x < cols; x++) {         for (int y = 0; y < rows; y++) {             for (int z = 0; z < depth; z++) {                 unsigned long size2d = rows * cols;                 unsigned long long idx = z * size2d + y * cols + x;                 float uidx = u[idx];                  if (x > 0) {                     grad[idx] = (uidx - u[z * size2d + y * cols + (x - 1)]);                 }             }         }     } }  int main() {          long depth = 3;     long rows = 4;     long cols = 5;           float u[depth * rows * cols];           for (int i = 0; i < depth * rows * cols; i++) {         u[i] = 1.0f;     }           float grad[depth * rows * cols];           grad_x_cpu(u, grad, depth, rows, cols);           for (int i = 0; i < depth * rows * cols; i++) {         printf(\"%f \", grad[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void grad_x(const float* u, float* grad, long depth, long rows, long cols) {     unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;     unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;     unsigned long z = threadIdx.z + blockIdx.z *blockDim.z;      if (x >= cols || y >= rows || z >= depth)         return;      unsigned long size2d = rows * cols;     unsigned long long idx = z * size2d + y * cols + x;     float uidx = u[idx];      if (x - 1 >= 0 && x < cols) {         grad[idx] = (uidx - u[z * size2d + y * cols + (x - 1)]);     } }  int main() {                long depth = 16;       long rows = 128;       long cols = 128;        float* h_u = (float*)malloc(depth * rows * cols * sizeof(float));     float* h_grad = (float*)malloc(depth * rows * cols * sizeof(float));      float* d_u, *d_grad;     cudaMalloc((void**)&d_u, depth * rows * cols * sizeof(float));     cudaMalloc((void**)&d_grad, depth * rows * cols * sizeof(float));           cudaMemcpy(d_u, h_u, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16, 1);      dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y, (depth + blockSize.z - 1) / blockSize.z);      grad_x<<<gridSize, blockSize>>>(d_u, d_grad, depth, rows, cols);           cudaMemcpy(h_grad, d_grad, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_u);     free(h_grad);     cudaFree(d_u);     cudaFree(d_grad);      return 0; } "
    },
    {
        "id": "14",
        "c_code": "#include <stdio.h>  void cpuAddCorrAndCorrection(float *L, float *r, int N) {     for (int u = 0; u < N; u++) {         L[u] -= r[u];     } }  int main() {          int arraySize = 5;     float arrayL[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayR[] = {0.5, 1.5, 2.5, 3.5, 4.5};      printf(\"\u6570\u7ec4 L\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayL[i]);     }      printf(\"\\n\u6570\u7ec4 R\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayR[i]);     }           cpuAddCorrAndCorrection(arrayL, arrayR, arraySize);      printf(\"\\n\u76f8\u52a0\u540e\u7684\u6570\u7ec4 L\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayL[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void cudaAddCorrAndCorrection(float* L, float* r, int N) {     int u = (blockIdx.x * blockDim.x) + threadIdx.x;     if (u >= N)         return;          L[u] -= r[u]; }  int main() {          int arraySize = 1000;           float* h_L = (float*)malloc(arraySize * sizeof(float));     float* h_r = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_L[i] = static_cast<float>(i);         h_r[i] = static_cast<float>(2 * i);     }           float* d_L;     float* d_r;     cudaMalloc((void**)&d_L, arraySize * sizeof(float));     cudaMalloc((void**)&d_r, arraySize * sizeof(float));           cudaMemcpy(d_L, h_L, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_r, h_r, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           cudaAddCorrAndCorrection<<<gridSize, blockSize>>>(d_L, d_r, arraySize);           cudaMemcpy(h_L, d_L, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_L[i]);     }           free(h_L);     free(h_r);     cudaFree(d_L);     cudaFree(d_r);      return 0; } "
    },
    {
        "id": "140",
        "c_code": "#include <stdio.h> #include <math.h>  void GraphSum_forward(float *in, float *out, int *indptr, int *indices, int dim, int size) {     for (int src = 0; src < size - 1; src++) {         for (int i = indptr[src]; i < indptr[src + 1]; i++) {             int dst = indices[i];             float coef = 1.0 / sqrtf((indptr[src + 1] - indptr[src]) * (indptr[dst + 1] - indptr[dst]));              for (int j = 0; j < dim; j++) {                 out[src * dim + j] += coef * in[dst * dim + j];             }         }     } }  int main() {          int dim = 3;      int size = 4;            int indptr[5] = {0, 2, 3, 5, 7};     int indices[7] = {1, 2, 0, 3, 0, 2, 3};           float in[size * dim];     float out[size * dim];           for (int i = 0; i < size * dim; i++) {         in[i] = 1.0f;         out[i] = 0.0f;      }           GraphSum_forward(in, out, indptr, indices, dim, size);           for (int i = 0; i < size * dim; i++) {         printf(\"%f \", out[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void cuda_GraphSum_forward_kernel(float* d_in_data, float* d_out_data, int* d_indptr, int* d_indices, int dim, int numNodes) {     int src = blockIdx.x;     int j = threadIdx.x;     int ptr_src_0 = d_indptr[src];     int ptr_stc_1 = d_indptr[src + 1];      for (int i = ptr_src_0; i < ptr_stc_1; i++) {         int dst = d_indices[i];         float coef = 1.0 / sqrtf((ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst]));         d_out_data[src * dim + j] += coef * d_in_data[dst * dim + j];     } }  int main() {                int dim = 256;       int numNodes = 128;        float* h_d_in_data = (float*)malloc(numNodes * dim * sizeof(float));     float* h_d_out_data = (float*)malloc(numNodes * dim * sizeof(float));     int* h_d_indptr = ;     int* h_d_indices = ;      float* d_d_in_data, *d_d_out_data;     int* d_d_indptr, *d_d_indices;     cudaMalloc((void**)&d_d_in_data, numNodes * dim * sizeof(float));     cudaMalloc((void**)&d_d_out_data, numNodes * dim * sizeof(float));     cudaMalloc((void**)&d_d_indptr, );     cudaMalloc((void**)&d_d_indices, );           cudaMemcpy(d_d_in_data, h_d_in_data, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_out_data, h_d_out_data, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_indptr, h_d_indptr, , cudaMemcpyHostToDevice);     cudaMemcpy(d_d_indices, h_d_indices, , cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize(numNodes);      cuda_GraphSum_forward_kernel<<<gridSize, blockSize>>>(d_d_in_data, d_d_out_data, d_d_indptr, d_d_indices, dim, numNodes);           cudaMemcpy(h_d_out_data, d_d_out_data, numNodes * dim * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_d_in_data);     free(h_d_out_data);     cudaFree(d_d_in_data);     cudaFree(d_d_out_data);     cudaFree(d_d_indptr);     cudaFree(d_d_indices);      return 0; } "
    },
    {
        "id": "141",
        "c_code": "#include <stdio.h>  void apply_grayscale(const unsigned char *image, unsigned char *grayimg, int width, int height);  int main() {               int width = 100;       int height = 100;            unsigned char image[width * height * 3];           unsigned char grayimg[width * height];           apply_grayscale(image, grayimg, width, height);                for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             printf(\"%u \", grayimg[y * width + x]);         }         printf(\"\\n\");     }      return 0; }  void apply_grayscale(const unsigned char *image, unsigned char *grayimg, int width, int height) {     for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             const unsigned char R = image[(y * width + x) * 3 + 0];             const unsigned char G = image[(y * width + x) * 3 + 1];             const unsigned char B = image[(y * width + x) * 3 + 2];             unsigned char gray = (307 * R + 604 * G + 113 * B) >> 10;             grayimg[y * width + x] = gray;         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void apply_grayscale(unsigned char* grayimg, const unsigned char* image, int width, int height) {     unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;     unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;      if (x < width && y < height) {         const unsigned char R = image[(y * width + x) * 3 + 0];         const unsigned char G = image[(y * width + x) * 3 + 1];         const unsigned char B = image[(y * width + x) * 3 + 2];         unsigned char gray = (307 * R + 604 * G + 113 * B) >> 10;         grayimg[y * width + x] = gray;     } }  int main() {                int width = 512;       int height = 512;        unsigned char* h_image = ;     unsigned char* h_grayimg = (unsigned char*)malloc(width * height * sizeof(unsigned char));      unsigned char* d_image, *d_grayimg;     cudaMalloc((void**)&d_image, width * height * 3 * sizeof(unsigned char));     cudaMalloc((void**)&d_grayimg, width * height * sizeof(unsigned char));           cudaMemcpy(d_image, h_image, width * height * 3 * sizeof(unsigned char), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y);      apply_grayscale<<<gridSize, blockSize>>>(d_grayimg, d_image, width, height);           cudaMemcpy(h_grayimg, d_grayimg, width * height * sizeof(unsigned char), cudaMemcpyDeviceToHost);                 free(h_grayimg);     cudaFree(d_image);     cudaFree(d_grayimg);      return 0; } "
    },
    {
        "id": "142",
        "c_code": "#include <stdio.h>  void getOffsetBox_cpu(const int *clsIndex, const float *max_coordinate, float *offset, int dims, int batchSize, const float *before_nms_boxes);  int main() {               int dims = 10;              int batchSize = 5;                int clsIndex[batchSize * dims];     float max_coordinate[batchSize * dims * 4];     float offset[batchSize * dims];     float before_nms_boxes[batchSize * dims * 4];           getOffsetBox_cpu(clsIndex, max_coordinate, offset, dims, batchSize, before_nms_boxes);                for (int i = 0; i < batchSize; i++) {         for (int j = 0; j < dims; j++) {             printf(\"%f \", offset[i * dims + j]);         }         printf(\"\\n\");     }      return 0; }  void getOffsetBox_cpu(const int *clsIndex, const float *max_coordinate, float *offset, int dims, int batchSize, const float *before_nms_boxes) {     for (int tid = 0; tid < dims; tid++) {         int numPerbatch = dims;         for (int i = 0; i < batchSize; i++) {             if (before_nms_boxes[i * dims * 4 + tid * 4] == -1) {                 offset[i * numPerbatch + tid] = 0;             } else {                 offset[i * numPerbatch + tid] = clsIndex[i * numPerbatch + tid] * (max_coordinate[i * dims * 4] + 1);             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void getOffsetBox(const int* clsIndex, const float* max_coordinate, float* offset, int dims, int batchSize, const float* before_nms_boxes) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      int numPerbatch = dims;      for (int i = 0; i < batchSize; i++) {         if (before_nms_boxes[i * dims * 4 + tid * 4] == (-1)) {             offset[i * numPerbatch + tid] = 0;         } else {             offset[i * numPerbatch + tid] = clsIndex[i * numPerbatch + tid] * (max_coordinate[i * dims * 4] + 1);         }     } }  int main() {                int dims = 256;       int batchSize = 128;        int* h_clsIndex = ;     float* h_max_coordinate = ;     float* h_offset = (float*)malloc(batchSize * dims * sizeof(float));     float* h_before_nms_boxes = ;      int* d_clsIndex;     float* d_max_coordinate, *d_offset, *d_before_nms_boxes;     cudaMalloc((void**)&d_clsIndex, batchSize * dims * sizeof(int));     cudaMalloc((void**)&d_max_coordinate, batchSize * dims * 4 * sizeof(float));     cudaMalloc((void**)&d_offset, batchSize * dims * sizeof(float));     cudaMalloc((void**)&d_before_nms_boxes, batchSize * dims * 4 * sizeof(float));           cudaMemcpy(d_clsIndex, h_clsIndex, batchSize * dims * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_max_coordinate, h_max_coordinate, batchSize * dims * 4 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_before_nms_boxes, h_before_nms_boxes, batchSize * dims * 4 * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((dims + blockSize.x - 1) / blockSize.x, 1);      getOffsetBox<<<gridSize, blockSize>>>(d_clsIndex, d_max_coordinate, d_offset, dims, batchSize, d_before_nms_boxes);           cudaMemcpy(h_offset, d_offset, batchSize * dims * sizeof(float), cudaMemcpyDeviceToHost);                 free(h_offset);     cudaFree(d_clsIndex);     cudaFree(d_max_coordinate);     cudaFree(d_offset);     cudaFree(d_before_nms_boxes);      return 0; } "
    },
    {
        "id": "143",
        "c_code": "#include <stdio.h>  void sgemm_kernelCPU(const float *host_inputArray1, const float *host_inputArray2, float *host_inputArray3, int M, int N, int K, float alpha, float beta);  int main() {               int M = 3;       int N = 4;     int K = 5;           float host_inputArray1[M * K];     float host_inputArray2[K * N];     float host_inputArray3[M * N];           for (int i = 0; i < M * K; i++) {         host_inputArray1[i] = i + 1;     }      for (int i = 0; i < K * N; i++) {         host_inputArray2[i] = i + 1;     }      for (int i = 0; i < M * N; i++) {         host_inputArray3[i] = 0;     }           sgemm_kernelCPU(host_inputArray1, host_inputArray2, host_inputArray3, M, N, K, 1.0, 0.0);                for (int i = 0; i < M; i++) {         for (int j = 0; j < N; j++) {             printf(\"%f \", host_inputArray3[i * N + j]);         }         printf(\"\\n\");     }      return 0; }  void sgemm_kernelCPU(const float *host_inputArray1, const float *host_inputArray2, float *host_inputArray3, int M, int N, int K, float alpha, float beta) {     for (int row = 0; row < M; row++) {         for (int column = 0; column < N; column++) {             float element_c = 0.f;             for (int e = 0; e < K; e++) {                 element_c += host_inputArray1[row * K + e] * host_inputArray2[e * N + column];             }             host_inputArray3[row * N + column] = alpha * element_c + beta * host_inputArray3[row * N + column];         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void sgemm_kernelGPU(const float* host_inputArray1, const float* host_inputArray2, float* host_inputArray3, int M, int N, int K, float alpha, float beta) {     int column = blockIdx.x * blockDim.x + threadIdx.x;     int row = blockIdx.y * blockDim.y + threadIdx.y;      if (row < M && column < N) {         float element_c = 0.f;          for (int eachElement = 0; eachElement < K; eachElement++) {             element_c += host_inputArray1[row * K + eachElement] * host_inputArray2[eachElement * N + column];         }          host_inputArray3[row * N + column] = alpha * element_c + beta * host_inputArray3[row * N + column];     } }  int main() {                int M = 512;       int N = 512;       int K = 256;        float* h_inputArray1 = ;     float* h_inputArray2 = ;     float* h_inputArray3 = ;      float* d_inputArray1, *d_inputArray2, *d_inputArray3;     cudaMalloc((void**)&d_inputArray1, M * K * sizeof(float));     cudaMalloc((void**)&d_inputArray2, K * N * sizeof(float));     cudaMalloc((void**)&d_inputArray3, M * N * sizeof(float));           cudaMemcpy(d_inputArray1, h_inputArray1, M * K * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_inputArray2, h_inputArray2, K * N * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_inputArray3, h_inputArray3, M * N * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);       dim3 gridSize((N + blockSize.x - 1) / blockSize.x, (M + blockSize.y - 1) / blockSize.y);      sgemm_kernelGPU<<<gridSize, blockSize>>>(d_inputArray1, d_inputArray2, d_inputArray3, M, N, K, 1.0f, 0.0f);           cudaMemcpy(h_inputArray3, d_inputArray3, M * N * sizeof(float), cudaMemcpyDeviceToHost);                 cudaFree(d_inputArray1);     cudaFree(d_inputArray2);     cudaFree(d_inputArray3);      return 0; } "
    },
    {
        "id": "144",
        "c_code": "#include <stdio.h> #include <math.h>  void GraphSum_backward(float *in_grad, float *out_grad, int *indptr, int *indices, int size, int dim);  int main() {               int size = 5;       int dim = 3;              float in_grad[size * dim];     float out_grad[size * dim];     int indptr[size + 1];     int indices[10] = {0, 1, 1, 2, 0, 2, 3, 4, 4, 3};             for (int i = 0; i < size * dim; i++) {         in_grad[i] = 0;         out_grad[i] = i + 1;     }      for (int i = 0; i < size + 1; i++) {         indptr[i] = i * 2;       }           GraphSum_backward(in_grad, out_grad, indptr, indices, size, dim);                for (int i = 0; i < size; i++) {         for (int j = 0; j < dim; j++) {             printf(\"%f \", in_grad[i * dim + j]);         }         printf(\"\\n\");     }      return 0; }  void GraphSum_backward(float *in_grad, float *out_grad, int *indptr, int *indices, int size, int dim) {     for (int src = 0; src < size - 1; src++) {         for (int i = indptr[src]; i < indptr[src + 1]; i++) {             int dst = indices[i];             float coef = 1.0 / sqrtf((indptr[src + 1] - indptr[src]) * (indptr[dst + 1] - indptr[dst]));             for (int j = 0; j < dim; j++) {                 in_grad[src * dim + j] += coef * out_grad[dst * dim + j];             }         }     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void cuda_GraphSum_backward_kernel(float* d_in_grad, float* d_out_grad, int* d_indptr, int* d_indices, int dim, int numNodes) {     int src = blockIdx.x;     int j = threadIdx.x;     int ptr_src_0 = d_indptr[src];     int ptr_stc_1 = d_indptr[src + 1];      #pragma unroll     for (int i = ptr_src_0; i < ptr_stc_1; i++) {         int dst = d_indices[i];         float coef = 1.0 / sqrtf((ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst]));          d_in_grad[src * dim + j] += coef * d_out_grad[dst * dim + j];     } }  int main() {                int dim = 256;       int numNodes = 128;        float* h_d_in_grad = ;     float* h_d_out_grad = ;     int* h_d_indptr = ;     int* h_d_indices = ;      float* d_d_in_grad, *d_d_out_grad;     int* d_d_indptr, *d_d_indices;      cudaMalloc((void**)&d_d_in_grad, numNodes * dim * sizeof(float));     cudaMalloc((void**)&d_d_out_grad, numNodes * dim * sizeof(float));     cudaMalloc((void**)&d_d_indptr, (numNodes + 1) * sizeof(int));     cudaMalloc((void**)&d_d_indices, );           cudaMemcpy(d_d_in_grad, h_d_in_grad, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_out_grad, h_d_out_grad, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_indptr, h_d_indptr, (numNodes + 1) * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_indices, h_d_indices, , cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize(numNodes);      cuda_GraphSum_backward_kernel<<<gridSize, blockSize>>>(d_d_in_grad, d_d_out_grad, d_d_indptr, d_d_indices, dim, numNodes);           cudaMemcpy(h_d_in_grad, d_d_in_grad, numNodes * dim * sizeof(float), cudaMemcpyDeviceToHost);                 cudaFree(d_d_in_grad);     cudaFree(d_d_out_grad);     cudaFree(d_d_indptr);     cudaFree(d_d_indices);      return 0; } "
    },
    {
        "id": "145",
        "c_code": "#include <stdio.h> #include <math.h>  void CDFfunction(float *median, float *stdvLogNormalFrame, float *MeanLogNormalFrame, unsigned char *currentFrame, int pixelsPerFrame);  int main() {               int pixelsPerFrame = 100;             float median[pixelsPerFrame];     float stdvLogNormalFrame[pixelsPerFrame];     float MeanLogNormalFrame[pixelsPerFrame];     unsigned char currentFrame[pixelsPerFrame];           for (int i = 0; i < pixelsPerFrame; i++) {         median[i] = 10.0;         stdvLogNormalFrame[i] = 2.0;         MeanLogNormalFrame[i] = 5.0;         currentFrame[i] = i % 256;       }           CDFfunction(median, stdvLogNormalFrame, MeanLogNormalFrame, currentFrame, pixelsPerFrame);                for (int i = 0; i < pixelsPerFrame; i++) {         printf(\"%u \", currentFrame[i]);     }      return 0; }  void CDFfunction(float *median, float *stdvLogNormalFrame, float *MeanLogNormalFrame, unsigned char *currentFrame, int pixelsPerFrame) {     int pixel;     for (pixel = 0; pixel < pixelsPerFrame; pixel++) {         float newvalue;         float x = currentFrame[pixel];         newvalue = -((log(x) - median[pixel]) - MeanLogNormalFrame[pixel]) / (sqrt(2.0) * stdvLogNormalFrame[pixel]);         float summ = 0.5f + 0.5f * erf(newvalue);         if (summ >= 0.3) {             currentFrame[pixel] = (unsigned char)255;         } else {             currentFrame[pixel] = (unsigned char)0;         }     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void CDFfunction(float* median, float* stdvLogNormalFrame, float* MeanLogNormalFrame, unsigned char* currentFrame, int pixelsPerFrame) {     int pixel = threadIdx.x + blockIdx.x * blockDim.x;      if (pixel < pixelsPerFrame) {         float newvalue;         float x = currentFrame[pixel];          newvalue = -((logf(x) - median[pixel]) - MeanLogNormalFrame[pixel]) / (sqrtf(2) * stdvLogNormalFrame[pixel]);          float summ = 0.5f + 0.5f * erff(newvalue);          if (summ >= 0.3) {             currentFrame[pixel] = (unsigned char)255;         } else {             currentFrame[pixel] = (unsigned char)0;         }     } }  int main() {                int pixelsPerFrame = 1024;        float* h_median = ;     float* h_stdvLogNormalFrame = ;     float* h_MeanLogNormalFrame = ;     unsigned char* h_currentFrame = ;      float* d_median, *d_stdvLogNormalFrame, *d_MeanLogNormalFrame;     unsigned char* d_currentFrame;      cudaMalloc((void**)&d_median, pixelsPerFrame * sizeof(float));     cudaMalloc((void**)&d_stdvLogNormalFrame, pixelsPerFrame * sizeof(float));     cudaMalloc((void**)&d_MeanLogNormalFrame, pixelsPerFrame * sizeof(float));     cudaMalloc((void**)&d_currentFrame, pixelsPerFrame * sizeof(unsigned char));           cudaMemcpy(d_median, h_median, pixelsPerFrame * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_stdvLogNormalFrame, h_stdvLogNormalFrame, pixelsPerFrame * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_MeanLogNormalFrame, h_MeanLogNormalFrame, pixelsPerFrame * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_currentFrame, h_currentFrame, pixelsPerFrame * sizeof(unsigned char), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((pixelsPerFrame + blockSize.x - 1) / blockSize.x);      CDFfunction<<<gridSize, blockSize>>>(d_median, d_stdvLogNormalFrame, d_MeanLogNormalFrame, d_currentFrame, pixelsPerFrame);           cudaMemcpy(h_currentFrame, d_currentFrame, pixelsPerFrame * sizeof(unsigned char), cudaMemcpyDeviceToHost);                 cudaFree(d_median);     cudaFree(d_stdvLogNormalFrame);     cudaFree(d_MeanLogNormalFrame);     cudaFree(d_currentFrame);      return 0; } "
    },
    {
        "id": "146",
        "c_code": "#include <stdio.h>  void mul(float *M, float *N, float *K, float height_M, float width_N, float width_M);  int main() {               float height_M = 3;     float width_N = 4;     float width_M = 2;           float M[height_M * width_M];     float N[width_M * width_N];     float K[height_M * width_N];           for (int i = 0; i < height_M * width_M; i++) {         M[i] = i + 1;     }      for (int i = 0; i < width_M * width_N; i++) {         N[i] = i + 2;     }           mul(M, N, K, height_M, width_N, width_M);                for (int i = 0; i < height_M; i++) {         for (int j = 0; j < width_N; j++) {             printf(\"%f \", K[i * (int)width_N + j]);         }         printf(\"\\n\");     }      return 0; }  void mul(float *M, float *N, float *K, float height_M, float width_N, float width_M) {     for (int i = 0; i < height_M; i++) {         for (int j = 0; j < width_N; j++) {             float sum = 0;             for (int k = 0; k < width_M; k++) {                 float a = M[i * (int)width_M + k];                 float b = N[k * (int)width_N + j];                 sum += a * b;             }             K[i * (int)width_N + j] = sum;         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void matrixmul(float* Md, float* Nd, float* Pd, float width, float width_blk, float height_blk, float width_M, float width_N, float height_M, int m, int n) {     int bx = blockIdx.x;     int by = blockIdx.y;     int tx = threadIdx.x;     int ty = threadIdx.y;     int Row = by * width_blk + ty;     int Col = bx * height_blk + tx;     float pValue = 0;      if (Col < (int)width_N && Row < (int)height_M) {         for (int i = 0; i < width; i++) {             float Melement = Md[Row * (int)width_M + i];             float Nelement = Nd[i * (int)width_N + Col];             pValue += Melement * Nelement;         }         Pd[Row * (int)width_N + Col] = pValue;     } }  int main() {                float* h_Md = ;     float* h_Nd = ;     float* h_Pd = ;      float* d_Md, *d_Nd, *d_Pd;      cudaMalloc((void**)&d_Md, );     cudaMalloc((void**)&d_Nd, );     cudaMalloc((void**)&d_Pd, );           cudaMemcpy(d_Md, h_Md, , cudaMemcpyHostToDevice);     cudaMemcpy(d_Nd, h_Nd, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      matrixmul<<<gridSize, blockSize>>>(d_Md, d_Nd, d_Pd, );           cudaMemcpy(h_Pd, d_Pd, , cudaMemcpyDeviceToHost);                 cudaFree(d_Md);     cudaFree(d_Nd);     cudaFree(d_Pd);      return 0; } "
    },
    {
        "id": "147",
        "c_code": "#include <stdio.h> #include <math.h>  void softmax_x_ent_cpu(int n, float *pred, float *truth, float *delta, float *error);  int main() {               int n = 5;             float pred[n];     float truth[n];     float delta[n];     float error[n];           for (int i = 0; i < n; i++) {         pred[i] = 0.2;         truth[i] = (i == 2) ? 1.0 : 0.0;       }           softmax_x_ent_cpu(n, pred, truth, delta, error);                printf(\"Error: \");     for (int i = 0; i < n; i++) {         printf(\"%f \", error[i]);     }     printf(\"\\n\");      printf(\"Delta: \");     for (int i = 0; i < n; i++) {         printf(\"%f \", delta[i]);     }     printf(\"\\n\");      return 0; }  void softmax_x_ent_cpu(int n, float *pred, float *truth, float *delta, float *error) {     int i;     for (i = 0; i < n; ++i) {         float t = truth[i];         float p = pred[i];         error[i] = (t) ? -log(p) : 0;         delta[i] = t - p;     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void softmax_kernel(float* input, int n, int batch, int batch_offset, int groups, int group_offset, int stride, float temp, float* output) {     int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (id >= batch * groups)         return;      int b = id / groups;     int g = id % groups;     int i;     float sum = 0;     float largest = -INFINITY;      for (i = 0; i < n; ++i) {         int val = (input + b * batch_offset + g * group_offset)[i * stride];         largest = (val > largest) ? val : largest;     }      for (i = 0; i < n; ++i) {         float e = expf((input + b * batch_offset + g * group_offset)[i * stride] / temp - largest / temp);         sum += e;         (output + b * batch_offset + g * group_offset)[i * stride] = e;     }      for (i = 0; i < n; ++i) {         (output + b * batch_offset + g * group_offset)[i * stride] /= sum;     } }  int main() {                float* h_input = ;     float* h_output = ;      float* d_input, *d_output;      cudaMalloc((void**)&d_input, );     cudaMalloc((void**)&d_output, );           cudaMemcpy(d_input, h_input, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      softmax_kernel<<<gridSize, blockSize>>>(d_input, , d_output);           cudaMemcpy(h_output, d_output, , cudaMemcpyDeviceToHost);                 cudaFree(d_input);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "148",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>  void normalize_img(double *image, long int image_size, int bands);  int main() {               long int image_size = 10;       int bands = 3;                        double *image = (double *)malloc(image_size * bands * sizeof(double));           for (long int i = 0; i < image_size * bands; i++) {         image[i] = i + 1;     }           normalize_img(image, image_size, bands);                for (int i = 0; i < bands; i++) {         for (long int j = 0; j < image_size; j++) {             printf(\"%f \", image[i * image_size + j]);         }         printf(\"\\n\");     }      free(image);      return 0; }  void normalize_img(double *image, long int image_size, int bands) {     long int i, j;     long int row;     double *D = (double *)calloc(image_size, sizeof(double));      for (i = 0; i < image_size * bands; i++) {         D[i % image_size] += image[i];     }      for (i = 0; i < image_size; i++) {         D[i] = pow(D[i] + 1.0e-16, -1);     }      for (i = 0; i < bands; i++) {         row = i * image_size;         for (j = 0; j < image_size; j++) {             image[row + j] = image[row + j] * D[j];         }     }      free(D); } ",
        "cuda_code": "#include <stdio.h>   __global__ void normalizacion(float* image_c, int bands, long int image_size, float* normM_c, float* normM1_c) {     long int j, i;     float norm_val = 0, aux = 0, pixel = 0;      i = blockIdx.x * blockDim.x + threadIdx.x;      if (i < image_size) {         for (j = 0; j < bands; j++) {             norm_val += image_c[j * image_size + i];         }          norm_val = 1.0 / (norm_val + 1.0e-16);          for (j = 0; j < bands; j++) {             pixel = image_c[j * image_size + i] * norm_val;             image_c[j * image_size + i] = pixel;             aux += pixel * pixel;         }          normM_c[i] = aux;         normM1_c[i] = aux;     } }  int main() {                float* h_image = ;     float* h_normM = ;     float* h_normM1 = ;      float* d_image, *d_normM, *d_normM1;      cudaMalloc((void**)&d_image, );     cudaMalloc((void**)&d_normM, );     cudaMalloc((void**)&d_normM1, );           cudaMemcpy(d_image, h_image, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      normalizacion<<<gridSize, blockSize>>>(d_image, , d_normM, d_normM1);           cudaMemcpy(h_normM, d_normM, , cudaMemcpyDeviceToHost);     cudaMemcpy(h_normM1, d_normM1, , cudaMemcpyDeviceToHost);                 cudaFree(d_image);     cudaFree(d_normM);     cudaFree(d_normM1);      return 0; } "
    },
    {
        "id": "149",
        "c_code": "#include <stdio.h>  void permuteData_cpu(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize);  int main() {               int num = 2;                int devideNum = 3;          int featureSize = 4;        int priorNum = 2;           int batchSize = 2;                float *input = (float *)malloc(batchSize * num * devideNum * priorNum * featureSize * sizeof(float));     float *output = (float *)malloc(batchSize * num * devideNum * priorNum * sizeof(float));           for (int i = 0; i < batchSize * num * devideNum * priorNum * featureSize; i++) {         input[i] = i + 1;     }           permuteData_cpu(input, output, num, devideNum, featureSize, priorNum, batchSize);                for (int i = 0; i < batchSize; i++) {         for (int j = 0; j < num * devideNum * priorNum; j++) {             printf(\"%f \", output[i * num * devideNum * priorNum + j]);         }         printf(\"\\n\");     }      free(input);     free(output);      return 0; }  void permuteData_cpu(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize) {     for (int tid = 0; tid < num; tid++) {         int numPerbatch = num * devideNum * priorNum;         for (int s = 0; s < batchSize; s++) {             for (int i = 0; i < priorNum; i++) {                 for (int j = 0; j < devideNum; j++) {                     output[s * numPerbatch + tid * priorNum * devideNum + i * devideNum + j] =                         input[s * numPerbatch + (i * devideNum * featureSize) + (j * featureSize) + tid];                 }             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void permuteData(const float* input, float* output, int num, int devideNum, int featureSize, int priorNum, int batchSize) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= num) {         return;     }      int numPerbatch = num * devideNum * priorNum;      for (int s = 0; s < batchSize; s++) {         for (int i = 0; i < priorNum; i++) {             for (int j = 0; j < devideNum; j++) {                 output[s * numPerbatch + tid * priorNum * devideNum + i * devideNum + j] = input[s * numPerbatch + (i * devideNum * featureSize) + (j * featureSize) + tid];             }         }     } }  int main() {                float* h_input = ;     float* h_output = ;      float* d_input, *d_output;      cudaMalloc((void**)&d_input, );     cudaMalloc((void**)&d_output, );           cudaMemcpy(d_input, h_input, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      permuteData<<<gridSize, blockSize>>>(d_input, d_output, );           cudaMemcpy(h_output, d_output, , cudaMemcpyDeviceToHost);                 cudaFree(d_input);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "15",
        "c_code": "#include <stdio.h>  void fill_cpu(int N, float ALPHA, float *X, int INCX) {     int i;     for (i = 0; i < N; ++i) {         X[i * INCX] = ALPHA;     } }  int main() {          int arraySize = 5;     float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float alpha = 2.0;     int incX = 2;      printf(\"\u539f\u59cb\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }           fill_cpu(arraySize, alpha, arrayX, incX);      printf(\"\\n\u586b\u5145\u540e\u7684\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void fill_kernel(int N, float ALPHA, float* X, int INCX) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N)         X[i * INCX] = ALPHA; }  int main() {          int arraySize = 1000;           float ALPHA = 2.0;     int INCX = 2;           float* h_X = (float*)malloc(arraySize * sizeof(float));           float* d_X;     cudaMalloc((void**)&d_X, arraySize * sizeof(float));           dim3 blockSize(256, 1, 1);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1, 1);           fill_kernel<<<gridSize, blockSize>>>(arraySize, ALPHA, d_X, INCX);           cudaMemcpy(h_X, d_X, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_X[i]);     }           free(h_X);     cudaFree(d_X);      return 0; } "
    },
    {
        "id": "150",
        "c_code": "#include <stdio.h> #include <math.h>  void cpuSimpleCorrelator(float *xi, float *xq, float *sr, float *si, int sLength, float *L, int uLength);  int main() {               int sLength = 5;        int uLength = 8;              float xi[uLength + sLength];     float xq[uLength + sLength];     float sr[uLength];     float si[uLength];     float L[uLength];           for (int i = 0; i < uLength + sLength; i++) {         xi[i] = i + 1;         xq[i] = i + 2;     }      for (int i = 0; i < uLength; i++) {         sr[i] = i + 3;         si[i] = i + 4;     }           cpuSimpleCorrelator(xi, xq, sr, si, sLength, L, uLength);                for (int i = 0; i < uLength; i++) {         printf(\"%f \", L[i]);     }      return 0; }  void cpuSimpleCorrelator(float *xi, float *xq, float *sr, float *si, int sLength, float *L, int uLength) {     for (int u = 0; u < uLength; u++) {         float real = 0;         float imag = 0;         float a, b, c, d;          for (int n = u; n < u + sLength; n++) {             a = xi[n];             b = xq[n];             c = sr[n - u];             d = si[n - u] * (-1);             real += (a * c) - (b * d);             imag += (a * d) + (b * c);         }          L[u] = sqrt(real * real + imag * imag);     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void cudaSimpleCorrelator(float* xi, float* xq, float* sr, float* si, int sLength, float* L, int uLength) {     int u = (blockIdx.x * blockDim.x) + threadIdx.x;      if (u >= uLength)         return;      float real = 0;     float imag = 0;     float a, b, c, d;      for (int n = u; n < u + sLength; n++) {         a = xi[n];         b = xq[n];         c = sr[n - u];         d = si[n - u] * (-1);          real += (a * c) - (b * d);         imag += (a * d) + (b * c);     }      L[u] = sqrt(real * real + imag * imag); }  int main() {                float* h_xi = ;     float* h_xq = ;     float* h_sr = ;     float* h_si = ;     float* h_L = ;      float* d_xi, *d_xq, *d_sr, *d_si, *d_L;      cudaMalloc((void**)&d_xi, );     cudaMalloc((void**)&d_xq, );     cudaMalloc((void**)&d_sr, );     cudaMalloc((void**)&d_si, );     cudaMalloc((void**)&d_L, );           cudaMemcpy(d_xi, h_xi, , cudaMemcpyHostToDevice);     cudaMemcpy(d_xq, h_xq, , cudaMemcpyHostToDevice);     cudaMemcpy(d_sr, h_sr, , cudaMemcpyHostToDevice);     cudaMemcpy(d_si, h_si, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      cudaSimpleCorrelator<<<gridSize, blockSize>>>(d_xi, d_xq, d_sr, d_si, );           cudaMemcpy(h_L, d_L, , cudaMemcpyDeviceToHost);                 cudaFree(d_xi);     cudaFree(d_xq);     cudaFree(d_sr);     cudaFree(d_si);     cudaFree(d_L);      return 0; } "
    },
    {
        "id": "151",
        "c_code": "#include <stdio.h>  void convertKinectDisparityToRegularDisparity_cpu(float *d_regularDisparity, int d_regularDisparityPitch, const float *d_KinectDisparity, int d_KinectDisparityPitch, int width, int height);  int main() {               int width = 5;     int height = 3;           float d_KinectDisparity[height][width];     float d_regularDisparity[height][width];           for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             d_KinectDisparity[y][x] = x + y + 1;         }     }           convertKinectDisparityToRegularDisparity_cpu((float *)d_regularDisparity, width * sizeof(float), (float *)d_KinectDisparity, width * sizeof(float), width, height);                for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             printf(\"%f \", d_regularDisparity[y][x]);         }         printf(\"\\n\");     }      return 0; }  void convertKinectDisparityToRegularDisparity_cpu(float *d_regularDisparity, int d_regularDisparityPitch, const float *d_KinectDisparity, int d_KinectDisparityPitch, int width, int height) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < height; y++) {             float d_in = *((float *)((char *)d_KinectDisparity + y * d_KinectDisparityPitch) + x);             float d_out = (d_in == 0.0f) ? 1 : -d_in;             *((float *)((char *)d_regularDisparity + y * d_regularDisparityPitch) + x) = d_out;         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void convertKinectDisparityToRegularDisparity_kernel(float* d_regularDisparity, int d_regularDisparityPitch,                                                                const float* d_KinectDisparity, int d_KinectDisparityPitch,                                                                int width, int height) {     const int x = blockIdx.x * blockDim.x + threadIdx.x;     const int y = blockIdx.y * blockDim.y + threadIdx.y;      if ((x < width) && (y < height)) {         float d_in = *((float*)((char*)d_KinectDisparity + y * d_KinectDisparityPitch) + x);         float d_out = (d_in == 0.0f) ? 1 : -d_in;         *((float*)((char*)d_regularDisparity + y * d_regularDisparityPitch) + x) = d_out;     } }  int main() {                float* h_KinectDisparity = ;     float* h_regularDisparity = ;      float* d_KinectDisparity, *d_regularDisparity;      cudaMalloc((void**)&d_KinectDisparity, );     cudaMalloc((void**)&d_regularDisparity, );           cudaMemcpy(d_KinectDisparity, h_KinectDisparity, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      convertKinectDisparityToRegularDisparity_kernel<<<gridSize, blockSize>>>(d_regularDisparity, );           cudaMemcpy(h_regularDisparity, d_regularDisparity, , cudaMemcpyDeviceToHost);                 cudaFree(d_KinectDisparity);     cudaFree(d_regularDisparity);      return 0; } "
    },
    {
        "id": "152",
        "c_code": "#include <stdio.h>  void runFilterCpu(float *I, float *Q, int samplesLength, float *filter, int filterLength, float *filtered_I, float *filtered_Q, int convLength);  int main() {               int samplesLength = 10;     int filterLength = 3;     int convLength = samplesLength - filterLength + 1;           float I[samplesLength];     float Q[samplesLength];     float filter[filterLength];     float filtered_I[convLength];     float filtered_Q[convLength];           for (int i = 0; i < samplesLength; i++) {         I[i] = i + 1;         Q[i] = i + 2;     }      for (int i = 0; i < filterLength; i++) {         filter[i] = i + 1;     }           runFilterCpu(I, Q, samplesLength, filter, filterLength, filtered_I, filtered_Q, convLength);                printf(\"Filtered I: \");     for (int i = 0; i < convLength; i++) {         printf(\"%f \", filtered_I[i]);     }     printf(\"\\n\");      printf(\"Filtered Q: \");     for (int i = 0; i < convLength; i++) {         printf(\"%f \", filtered_Q[i]);     }     printf(\"\\n\");      return 0; }  void runFilterCpu(float *I, float *Q, int samplesLength, float *filter, int filterLength, float *filtered_I, float *filtered_Q, int convLength) {     for (int sampleIndex = 0; sampleIndex < convLength; sampleIndex++) {         int index;         float sumI, sumQ;         sumI = 0;         sumQ = 0;          for (int j = sampleIndex - filterLength + 1; j <= sampleIndex; j++) {             index = sampleIndex - j;              if ((j < samplesLength) && (j >= 0)) {                 sumI += filter[index] * I[j];                 sumQ += filter[index] * Q[j];             }         }          filtered_I[sampleIndex] = sumI;         filtered_Q[sampleIndex] = sumQ;     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void runFilterCuda(float* I, float* Q, int samplesLength, float* filter, int filterLength,                                float* filtered_I, float* filtered_Q, int convLength) {     int sampleIndex = (blockIdx.x * blockDim.x) + threadIdx.x;      if (sampleIndex >= convLength)         return;      int index;     float sumI, sumQ;      sumI = 0;     sumQ = 0;      for (int j = sampleIndex - filterLength + 1; j <= sampleIndex; j++) {         index = sampleIndex - j;          if ((j < samplesLength) && (j >= 0)) {             sumI += filter[index] * I[j];             sumQ += filter[index] * Q[j];         }     }      filtered_I[sampleIndex] = sumI;     filtered_Q[sampleIndex] = sumQ; }  int main() {                float* h_I = ;     float* h_Q = ;     float* h_filter = ;     float* h_filtered_I = ;     float* h_filtered_Q = ;      float* d_I, *d_Q, *d_filter, *d_filtered_I, *d_filtered_Q;      cudaMalloc((void**)&d_I, );     cudaMalloc((void**)&d_Q, );     cudaMalloc((void**)&d_filter, );     cudaMalloc((void**)&d_filtered_I, );     cudaMalloc((void**)&d_filtered_Q, );           cudaMemcpy(d_I, h_I, , cudaMemcpyHostToDevice);     cudaMemcpy(d_Q, h_Q, , cudaMemcpyHostToDevice);     cudaMemcpy(d_filter, h_filter, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      runFilterCuda<<<gridSize, blockSize>>>(d_I, d_Q, );           cudaMemcpy(h_filtered_I, d_filtered_I, , cudaMemcpyDeviceToHost);     cudaMemcpy(h_filtered_Q, d_filtered_Q, , cudaMemcpyDeviceToHost);                 cudaFree(d_I);     cudaFree(d_Q);     cudaFree(d_filter);     cudaFree(d_filtered_I);     cudaFree(d_filtered_Q);      return 0; } "
    },
    {
        "id": "153",
        "c_code": "#include <stdio.h> #include <math.h>  void l2normalize_cpu(float *x, float *dx, int batch, int filters, int spatial);  int main() {               int batch = 2;     int filters = 3;     int spatial = 4;           float x[batch * filters * spatial];     float dx[batch * filters * spatial];           for (int i = 0; i < batch * filters * spatial; i++) {         x[i] = i + 1;     }           l2normalize_cpu(x, dx, batch, filters, spatial);                printf(\"Normalized x: \");     for (int i = 0; i < batch * filters * spatial; i++) {         printf(\"%f \", x[i]);     }     printf(\"\\n\");      printf(\"dx: \");     for (int i = 0; i < batch * filters * spatial; i++) {         printf(\"%f \", dx[i]);     }     printf(\"\\n\");      return 0; }  void l2normalize_cpu(float *x, float *dx, int batch, int filters, int spatial) {     int b, f, i;      for (b = 0; b < batch; ++b) {         for (i = 0; i < spatial; ++i) {             float sum = 0;              for (f = 0; f < filters; ++f) {                 int index = b * filters * spatial + f * spatial + i;                 sum += powf(x[index], 2);             }              sum = sqrtf(sum);              for (f = 0; f < filters; ++f) {                 int index = b * filters * spatial + f * spatial + i;                 x[index] /= sum;                 dx[index] = (1 - x[index]) / sum;             }         }     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void l2normalize_kernel(int N, float* x, float* dx, int batch, int filters, int spatial) {     int index = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (index >= N)         return;      int b = index / spatial;     int i = index % spatial;     int f;     float sum = 0;      for (f = 0; f < filters; ++f) {         int index = b * filters * spatial + f * spatial + i;         sum += powf(x[index], 2);     }      sum = sqrtf(sum);      if (sum == 0)         sum = 1;      for (f = 0; f < filters; ++f) {         int index = b * filters * spatial + f * spatial + i;         x[index] /= sum;         dx[index] = (1 - x[index]) / sum;     } }  int main() {                float* h_x = ;     float* h_dx = ;      float* d_x, *d_dx;      cudaMalloc((void**)&d_x, );     cudaMalloc((void**)&d_dx, );           cudaMemcpy(d_x, h_x, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      int N = ;     int batch = ;     int filters = ;     int spatial = ;      l2normalize_kernel<<<gridSize, blockSize>>>(N, d_x, d_dx, batch, filters, spatial);           cudaMemcpy(h_dx, d_dx, , cudaMemcpyDeviceToHost);                 cudaFree(d_x);     cudaFree(d_dx);      return 0; } "
    },
    {
        "id": "154",
        "c_code": "#include <stdio.h> #include <math.h>  void distanceMatCalc(long int totalPixels, int availablePixels, int outPixelOffset, int patchSize, float *distMat, float *data, float filtSig);  int main() {               long int totalPixels = 3;     int availablePixels = 2;     int outPixelOffset = 1;     int patchSize = 2;           float distMat[availablePixels * totalPixels];     float data[totalPixels * patchSize * patchSize];           for (long int i = 0; i < totalPixels * patchSize * patchSize; i++) {         data[i] = i + 1;     }           distanceMatCalc(totalPixels, availablePixels, outPixelOffset, patchSize, distMat, data, 1.0);                for (long int i = 0; i < availablePixels * totalPixels; i++) {         printf(\"%f \", distMat[i]);     }     printf(\"\\n\");      return 0; }  void distanceMatCalc(long int totalPixels, int availablePixels, int outPixelOffset, int patchSize, float *distMat, float *data, float filtSig) {     for (long int i = 0; i < availablePixels * totalPixels; i++) {         int data_i = i / totalPixels + outPixelOffset;         int data_j = i % totalPixels;         float tmp = 0.0;          if (data_i != data_j) {             for (int elem = 0; elem < patchSize * patchSize; elem++) {                 float diff = data[data_i * patchSize * patchSize + elem] - data[data_j * patchSize * patchSize + elem];                 tmp += diff * diff;             }             tmp = exp(-tmp / filtSig);         }          distMat[i] = tmp;     } } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void distanceMatCalc(long int totalPixels, int availablePixels, int outPixelOffset, int patchSize, float* distMat, float* data, float filtSig) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = blockDim.x * gridDim.x;      for (long int i = index; i < availablePixels * totalPixels; i += stride) {         int data_i = i / totalPixels + outPixelOffset;         int data_j = i % totalPixels;         float tmp = 0.0;          if (data_i != data_j) {             for (int elem = 0; elem < patchSize * patchSize; elem++) {                 float diff = (data[data_i * patchSize * patchSize + elem] - data[data_j * patchSize * patchSize + elem]);                 tmp += diff * diff;             }              tmp = exp(-tmp / filtSig);         }          distMat[i] = tmp;     } }  int main() {                float* h_distMat = ;     float* h_data = ;      float* d_distMat, *d_data;      cudaMalloc((void**)&d_distMat, );     cudaMalloc((void**)&d_data, );           cudaMemcpy(d_data, h_data, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      long int totalPixels = ;     int availablePixels = ;     int outPixelOffset = ;     int patchSize = ;     float filtSig = ;      distanceMatCalc<<<gridSize, blockSize>>>(totalPixels, availablePixels, outPixelOffset, patchSize, d_distMat, d_data, filtSig);           cudaMemcpy(h_distMat, d_distMat, , cudaMemcpyDeviceToHost);                 cudaFree(d_distMat);     cudaFree(d_data);      return 0; } "
    },
    {
        "id": "155",
        "c_code": "#include <stdio.h>  void shortcut_kernel_cpu(int size, int minw, int minh, int minc, int stride, int sample, int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out);  int main() {               int size = 3;     int minw = 2;     int minh = 2;     int minc = 2;     int stride = 2;     int sample = 3;     int batch = 4;     int w1 = 1;     int h1 = 1;     int c1 = 1;     int w2 = 2;     int h2 = 2;     int c2 = 2;           float add[size * stride * w1 * h1 * c1 * batch];     float out[sample * w2 * h2 * c2 * batch];           for (int i = 0; i < size * stride * w1 * h1 * c1 * batch; i++) {         add[i] = i + 1;     }      for (int i = 0; i < sample * w2 * h2 * c2 * batch; i++) {         out[i] = i + 2;     }           shortcut_kernel_cpu(size, minw, minh, minc, stride, sample, batch, w1, h1, c1, add, w2, h2, c2, out);                for (int i = 0; i < sample * w2 * h2 * c2 * batch; i++) {         printf(\"%f \", out[i]);     }     printf(\"\\n\");      return 0; }  void shortcut_kernel_cpu(int size, int minw, int minh, int minc, int stride, int sample, int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out) {     for (int id = 0; id < size; id++) {         int i = id % minw;         id /= minw;         int j = id % minh;         id /= minh;         int k = id % minc;         id /= minc;         int b = id % batch;          int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));         int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));          out[out_index] += add[add_index];     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void shortcut_kernel(int size, int minw, int minh, int minc, int stride, int sample, int batch,                                  int w1, int h1, int c1, float* add, int w2, int h2, int c2, float* out) {     int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (id >= size)         return;      int i = id % minw;     id /= minw;     int j = id % minh;     id /= minh;     int k = id % minc;     id /= minc;     int b = id % batch;      int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));     int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));      atomicAdd(&out[out_index], add[add_index]); }  int main() {                float* h_add = ;     float* h_out = ;      float* d_add, *d_out;      cudaMalloc((void**)&d_add, );     cudaMalloc((void**)&d_out, );           cudaMemcpy(d_add, h_add, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      int size = ;     int minw = ;     int minh = ;     int minc = ;     int stride = ;     int sample = ;     int batch = ;     int w1 = ;     int h1 = ;     int c1 = ;     int w2 = ;     int h2 = ;     int c2 = ;      shortcut_kernel<<<gridSize, blockSize>>>(size, minw, minh, minc, stride, sample, batch, w1, h1, c1, d_add, w2, h2, c2, d_out);           cudaMemcpy(h_out, d_out, , cudaMemcpyDeviceToHost);                 cudaFree(d_add);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "156",
        "c_code": "#include <stdio.h>  float dot_cpu(int N, float *X, int INCX, float *Y, int INCY);  int main() {               int N = 5;     int INCX = 1;     int INCY = 1;           float X[N * INCX];     float Y[N * INCY];           for (int i = 0; i < N; i++) {         X[i * INCX] = i + 1;         Y[i * INCY] = i + 2;     }           float result = dot_cpu(N, X, INCX, Y, INCY);                printf(\"Dot Product: %f\\n\", result);      return 0; }  float dot_cpu(int N, float *X, int INCX, float *Y, int INCY) {     int i;     float dot = 0;      for (i = 0; i < N; ++i) {         dot += X[i * INCX] * Y[i * INCY];     }      return dot; } ",
        "cuda_code": "#include <stdio.h>   __global__ void dot_kernel(float* output, float scale, int batch, int n, int size, float* delta) {     int index = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     int f1 = index / n;     int f2 = index % n;      if (f2 <= f1)         return;      float sum = 0;     float norm1 = 0;     float norm2 = 0;     int b, i;      for (b = 0; b < batch; ++b) {         for (i = 0; i < size; ++i) {             int i1 = b * size * n + f1 * size + i;             int i2 = b * size * n + f2 * size + i;             sum += output[i1] * output[i2];             norm1 += output[i1] * output[i1];             norm2 += output[i2] * output[i2];         }     }      norm1 = sqrt(norm1);     norm2 = sqrt(norm2);     float norm = norm1 * norm2;     sum = sum / norm;      for (b = 0; b < batch; ++b) {         for (i = 0; i < size; ++i) {             int i1 = b * size * n + f1 * size + i;             int i2 = b * size * n + f2 * size + i;             delta[i1] += -scale * sum * output[i2] / norm;             delta[i2] += -scale * sum * output[i1] / norm;         }     } }  int main() {                float* h_output = ;     float* h_delta = ;      float* d_output, *d_delta;      cudaMalloc((void**)&d_output, );     cudaMalloc((void**)&d_delta, );           cudaMemcpy(d_output, h_output, , cudaMemcpyHostToDevice);           dim3 blockSize();     dim3 gridSize();      int batch = ;     int n = ;     int size = ;     float scale = ;      dot_kernel<<<gridSize, blockSize>>>(d_output, scale, batch, n, size, d_delta);           cudaMemcpy(h_delta, d_delta, , cudaMemcpyDeviceToHost);                 cudaFree(d_output);     cudaFree(d_delta);      return 0; } "
    },
    {
        "id": "157",
        "c_code": "#include <stdio.h> #include <math.h>  void k_adam_kernel(float *m, float *v, float *w, const float *d, int max_size, float beta1, float beta2, float beta1_tpower, float beta2_tpower, float learning_rate);  int main() {               int max_size = 5;     float beta1 = 0.9;     float beta2 = 0.999;     float beta1_tpower = 1.0;     float beta2_tpower = 1.0;     float learning_rate = 0.001;           float m[max_size];     float v[max_size];     float w[max_size];     float d[max_size];           for (int i = 0; i < max_size; i++) {         m[i] = i + 1;         v[i] = i + 2;         w[i] = i + 3;         d[i] = i + 4;     }           k_adam_kernel(m, v, w, d, max_size, beta1, beta2, beta1_tpower, beta2_tpower, learning_rate);                printf(\"Updated w: \");     for (int i = 0; i < max_size; i++) {         printf(\"%f \", w[i]);     }     printf(\"\\n\");      return 0; }  void k_adam_kernel(float *m, float *v, float *w, const float *d, int max_size, float beta1, float beta2, float beta1_tpower, float beta2_tpower, float learning_rate) {     const float eps = 1e-8;      for (int i = 0; i < max_size; i++) {         float d_temp = d[i];         m[i] = m[i] * beta1 + d_temp * (1 - beta1);         v[i] = v[i] * beta2 + d_temp * d_temp * (1 - beta2);          float m_hat = m[i] / (1 - beta1_tpower);         float v_hat = sqrt(v[i] / (1 - beta2_tpower)) + eps;          w[i] += (m_hat / v_hat) * (-learning_rate);     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void k_adam_kernel(float *m, float *v, float *w, const float *d, int max_size, float beta1, float beta2, float beta1_tpower, float beta2_tpower, float learning_rate) {     const float eps = 1e-8;          for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < max_size; i += blockDim.x * gridDim.x) {         float d_temp = d[i];         m[i] = m[i] * beta1 + d_temp * (1 - beta1);         v[i] = v[i] * beta2 + d_temp * d_temp * (1 - beta2);         float m_hat = m[i] / (1 - beta1_tpower);         float v_hat = __fsqrt_rn(v[i] / (1 - beta2_tpower)) + eps;         w[i] += (m_hat / v_hat) * (-learning_rate);     } }  int main() {          int max_size = 1000;     float *m, *v, *w, *d;             cudaSetDevice(0);           float *d_m, *d_v, *d_w, *d_d;     cudaMalloc((void **)&d_m, max_size * sizeof(float));     cudaMalloc((void **)&d_v, max_size * sizeof(float));     cudaMalloc((void **)&d_w, max_size * sizeof(float));     cudaMalloc((void **)&d_d, max_size * sizeof(float));           cudaMemcpy(d_m, m, max_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_v, v, max_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_w, w, max_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_d, d, max_size * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (max_size + threadsPerBlock - 1) / threadsPerBlock;           k_adam_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_m, d_v, d_w, d_d, max_size, 0.9, 0.999, 0.9, 0.999, 0.001);           cudaDeviceSynchronize();           cudaMemcpy(w, d_w, max_size * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_m);     cudaFree(d_v);     cudaFree(d_w);     cudaFree(d_d);      return 0; } "
    },
    {
        "id": "158",
        "c_code": "#include <stdio.h>  void convLayer_forward(int N, int M, int C, int H, int W, int K, float *X, float *Wk, float *Y);  int main() {               int N = 1;     int M = 1;     int C = 1;     int H = 5;     int W = 5;     int K = 3;           float X[N * C * H * W];     float Wk[M * C * K * K];     float Y[N * M * (H - K + 1) * (W - K + 1)];           for (int i = 0; i < N * C * H * W; i++) {         X[i] = i + 1;     }      for (int i = 0; i < M * C * K * K; i++) {         Wk[i] = i + 2;     }           convLayer_forward(N, M, C, H, W, K, X, Wk, Y);                for (int i = 0; i < N * M * (H - K + 1) * (W - K + 1); i++) {         printf(\"%f \", Y[i]);     }     printf(\"\\n\");      return 0; }  void convLayer_forward(int N, int M, int C, int H, int W, int K, float *X, float *Wk, float *Y) {     int n, m, c, h, w, p, q;     int H_out = H - K + 1;     int W_out = W - K + 1;      for (n = 0; n < N; n++)         for (m = 0; m < M; m++)             for (h = 0; h < H_out; h++)                 for (w = 0; w < W_out; w++) {                     Y[n * M * H_out * W_out + m * H_out * W_out + h * W_out + w] = 0;                      for (c = 0; c < C; c++)                         for (p = 0; p < K; p++)                             for (q = 0; q < K; q++)                                 Y[n * M * H_out * W_out + m * H_out * W_out + h * W_out + w] +=                                     X[n * C * H * W + c * H * W + (h + p) * W + (w + q)] * Wk[m * C * K * K + c * K * K + p * K + q];                 } } ",
        "cuda_code": "#include <stdio.h>   __global__ void ConvLayerForward_Kernel(int C, int W_grid, int K, float *X, float *W, float *Y) {     int n, m, h, w, c, p, q;          n = blockIdx.x;     m = blockIdx.y;     h = blockIdx.z / W_grid + threadIdx.y;     w = blockIdx.z % W_grid + threadIdx.x;      float acc = 0;      for (c = 0; c < C; c++) {         for (p = 0; p < K; p++) {             for (q = 0; q < K; q++) {                 acc += X[n * C * W_grid * W_grid + c * W_grid * W_grid + (h + p) * W_grid + (w + q)] * W[m * C * K * K + c * K * K + p * K + q];             }         }     }      Y[n * W_grid * W_grid * W_grid + m * W_grid * W_grid + h * W_grid + w] = acc; }  int main() {          int C = 3, W_grid = 4, K = 3;       float *X, *W, *Y;             cudaSetDevice(0);           float *d_X, *d_W, *d_Y;     cudaMalloc((void **)&d_X, C * W_grid * W_grid * sizeof(float));     cudaMalloc((void **)&d_W, C * K * K * sizeof(float));     cudaMalloc((void **)&d_Y, W_grid * W_grid * W_grid * sizeof(float));           cudaMemcpy(d_X, X, C * W_grid * W_grid * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_W, W, C * K * K * sizeof(float), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(K, K);     dim3 blocksPerGrid(W_grid, W_grid, W_grid);           ConvLayerForward_Kernel<<<blocksPerGrid, threadsPerBlock>>>(C, W_grid, K, d_X, d_W, d_Y);           cudaDeviceSynchronize();           cudaMemcpy(Y, d_Y, W_grid * W_grid * W_grid * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_X);     cudaFree(d_W);     cudaFree(d_Y);      return 0; } "
    },
    {
        "id": "159",
        "c_code": "#include <stdio.h>  void opL23_cpu(float *vec, float *vec1, long depth, long rows, long cols);  int main() {               long depth = 2;     long rows = 3;     long cols = 4;           float vec[depth * rows * cols];     float vec1[depth * rows * cols];           for (long i = 0; i < depth * rows * cols; i++) {         vec[i] = i + 1;         vec1[i] = i + 2;     }           opL23_cpu(vec, vec1, depth, rows, cols);                for (long i = 0; i < depth * rows * cols; i++) {         printf(\"%f \", vec[i]);     }     printf(\"\\n\");      return 0; }  void opL23_cpu(float *vec, float *vec1, long depth, long rows, long cols) {     for (int x = 0; x < cols; x++) {         for (int y = 0; y < rows; y++) {             for (int z = 0; z < depth; z++) {                 unsigned long long i = z * rows * cols + y * cols + x;                 unsigned long long j = z * rows * cols + y * cols;                 unsigned long size2d = cols;                 unsigned long size3d = depth * rows * cols + rows * cols + cols;                  if (i + cols + 1 >= size3d)                     return;                  vec[i + cols] = 0.5 * (vec1[i + cols] + vec1[i]);                  if (j + 1 >= size2d)                     return;                  vec[j] = 0.5 * (vec1[j]);             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void opL23(float *vec, float *vec1, long depth, long rows, long cols) {     unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;     unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;     unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;     unsigned long long i = z * rows * cols + y * cols + x;     unsigned long long j = z * rows * cols + y * cols;     unsigned long size2d = cols;     unsigned long size3d = depth * rows * cols + rows * cols + cols;      if (x >= cols || y >= rows || z >= depth)         return;      if (i + cols + 1 >= size3d)         return;      vec[i + cols] = 0.5 * (vec1[i + cols] + vec1[i]);      if (j + 1 >= size2d)         return;      vec[j] = 0.5 * (vec1[j]); }  int main() {          long depth = 3, rows = 4, cols = 5;       float *vec, *vec1;             cudaSetDevice(0);           float *d_vec, *d_vec1;     cudaMalloc((void **)&d_vec, depth * rows * cols * sizeof(float));     cudaMalloc((void **)&d_vec1, depth * rows * cols * sizeof(float));           cudaMemcpy(d_vec, vec, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec1, vec1, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(16, 16, 1);     dim3 blocksPerGrid((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,                        (rows + threadsPerBlock.y - 1) / threadsPerBlock.y,                        (depth + threadsPerBlock.z - 1) / threadsPerBlock.z);           opL23<<<blocksPerGrid, threadsPerBlock>>>(d_vec, d_vec1, depth, rows, cols);           cudaDeviceSynchronize();           cudaMemcpy(vec, d_vec, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_vec);     cudaFree(d_vec1);      return 0; } "
    },
    {
        "id": "16",
        "c_code": "#include <stdio.h>  void scal_cpu(int N, float ALPHA, float *X, int INCX) {     int i;     for (i = 0; i < N; ++i) {         X[i * INCX] *= ALPHA;     } }  int main() {          int arraySize = 5;     float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float alpha = 2.0;     int incX = 2;      printf(\"\u539f\u59cb\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }           scal_cpu(arraySize, alpha, arrayX, incX);      printf(\"\\n\u7f29\u653e\u540e\u7684\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void scal_kernel(int N, float ALPHA, float* X, int INCX) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N)         X[i * INCX] *= ALPHA; }  int main() {          int arraySize = 1000;           float ALPHA = 2.0;     int INCX = 2;           float* h_X = (float*)malloc(arraySize * sizeof(float));           float* d_X;     cudaMalloc((void**)&d_X, arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_X[i] = static_cast<float>(i);     }           cudaMemcpy(d_X, h_X, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256, 1, 1);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1, 1);           scal_kernel<<<gridSize, blockSize>>>(arraySize, ALPHA, d_X, INCX);           cudaMemcpy(h_X, d_X, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_X[i]);     }           free(h_X);     cudaFree(d_X);      return 0; } "
    },
    {
        "id": "160",
        "c_code": "#include <stdio.h>  void upsample_cpu(float *in, int w, int h, int c, int batch, int stride, int forward, float scale, float *out);  int main() {               int w = 2;     int h = 2;     int c = 3;     int batch = 1;     int stride = 2;     int forward = 1;      float scale = 2.0;           float in[batch * w * h * c];     float out[batch * w * h * c * stride * stride];           for (int i = 0; i < batch * w * h * c; i++) {         in[i] = i + 1;     }           upsample_cpu(in, w, h, c, batch, stride, forward, scale, out);                for (int i = 0; i < batch * w * h * c * stride * stride; i++) {         printf(\"%f \", out[i]);     }     printf(\"\\n\");      return 0; }  void upsample_cpu(float *in, int w, int h, int c, int batch, int stride, int forward, float scale, float *out) {     int i, j, k, b;      for (b = 0; b < batch; ++b) {         for (k = 0; k < c; ++k) {             for (j = 0; j < h * stride; ++j) {                 for (i = 0; i < w * stride; ++i) {                     int in_index = b * w * h * c + k * w * h + (j / stride) * w + i / stride;                     int out_index = b * w * h * c * stride * stride + k * w * h * stride * stride + j * w * stride + i;                      if (forward)                         out[out_index] = scale * in[in_index];                     else                         in[in_index] += scale * out[out_index];                 }             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void upsample_kernel(size_t N, float *x, int w, int h, int c, int batch, int stride, int forward, float scale, float *out) {     size_t i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i >= N)         return;      int out_index = i;     int out_w = i % (w * stride);     i = i / (w * stride);     int out_h = i % (h * stride);     i = i / (h * stride);     int out_c = i % c;     i = i / c;     int b = i % batch;     int in_w = out_w / stride;     int in_h = out_h / stride;     int in_c = out_c;     int in_index = b * w * h * c + in_c * w * h + in_h * w + in_w;      if (forward)         atomicAdd(out + out_index, scale * x[in_index]);     else         atomicAdd(x + in_index, scale * out[out_index]); }  int main() {          size_t N = 1000;     int w = 16, h = 16, c = 3, batch = 4, stride = 2, forward = 1;     float scale = 0.5;       float *x, *out;             cudaSetDevice(0);           float *d_x, *d_out;     cudaMalloc((void **)&d_x, N * sizeof(float));     cudaMalloc((void **)&d_out, N * sizeof(float));           cudaMemcpy(d_x, x, N * sizeof(float), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(256);     dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x, 1);           upsample_kernel<<<blocksPerGrid, threadsPerBlock>>>(N, d_x, w, h, c, batch, stride, forward, scale, d_out);           cudaDeviceSynchronize();           cudaMemcpy(out, d_out, N * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_x);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "161",
        "c_code": "#include <stdio.h>  void rgb2yuv_kernel(int img_size, unsigned char *gpu_img_in_r, unsigned char *gpu_img_in_g, unsigned char *gpu_img_in_b,                     unsigned char *gpu_img_out_y, unsigned char *gpu_img_out_u, unsigned char *gpu_img_out_v);  int main() {               int img_size = 5;           unsigned char gpu_img_in_r[img_size];     unsigned char gpu_img_in_g[img_size];     unsigned char gpu_img_in_b[img_size];     unsigned char gpu_img_out_y[img_size];     unsigned char gpu_img_out_u[img_size];     unsigned char gpu_img_out_v[img_size];           for (int i = 0; i < img_size; i++) {         gpu_img_in_r[i] = i + 1;         gpu_img_in_g[i] = i + 2;         gpu_img_in_b[i] = i + 3;     }           rgb2yuv_kernel(img_size, gpu_img_in_r, gpu_img_in_g, gpu_img_in_b, gpu_img_out_y, gpu_img_out_u, gpu_img_out_v);                printf(\"Y: \");     for (int i = 0; i < img_size; i++) {         printf(\"%u \", gpu_img_out_y[i]);     }     printf(\"\\n\");      printf(\"U: \");     for (int i = 0; i < img_size; i++) {         printf(\"%u \", gpu_img_out_u[i]);     }     printf(\"\\n\");      printf(\"V: \");     for (int i = 0; i < img_size; i++) {         printf(\"%u \", gpu_img_out_v[i]);     }     printf(\"\\n\");      return 0; }  void rgb2yuv_kernel(int img_size, unsigned char *gpu_img_in_r, unsigned char *gpu_img_in_g, unsigned char *gpu_img_in_b,                     unsigned char *gpu_img_out_y, unsigned char *gpu_img_out_u, unsigned char *gpu_img_out_v) {     unsigned char r, g, b;      for (int index = 0; index < img_size; index++) {         r = gpu_img_in_r[index];         g = gpu_img_in_g[index];         b = gpu_img_in_b[index];          gpu_img_out_y[index] = (unsigned char)(0.299 * r + 0.587 * g + 0.114 * b);         gpu_img_out_u[index] = (unsigned char)(-0.169 * r - 0.331 * g + 0.499 * b + 128);         gpu_img_out_v[index] = (unsigned char)(0.499 * r - 0.418 * g - 0.0813 * b + 128);     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void rgb2yuv_kernel(int img_size, unsigned char *gpu_img_in_r, unsigned char *gpu_img_in_g, unsigned char *gpu_img_in_b,                                 unsigned char *gpu_img_out_y, unsigned char *gpu_img_out_u, unsigned char *gpu_img_out_v) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < img_size) {         unsigned char r = gpu_img_in_r[index];         unsigned char g = gpu_img_in_g[index];         unsigned char b = gpu_img_in_b[index];          gpu_img_out_y[index] = (unsigned char)(0.299 * r + 0.587 * g + 0.114 * b);         gpu_img_out_u[index] = (unsigned char)(-0.169 * r - 0.331 * g + 0.499 * b + 128);         gpu_img_out_v[index] = (unsigned char)(0.499 * r - 0.418 * g - 0.0813 * b + 128);     } }  int main() {          int img_size = 1000;       unsigned char *gpu_img_in_r, *gpu_img_in_g, *gpu_img_in_b, *gpu_img_out_y, *gpu_img_out_u, *gpu_img_out_v;                cudaSetDevice(0);           unsigned char *d_gpu_img_in_r, *d_gpu_img_in_g, *d_gpu_img_in_b, *d_gpu_img_out_y, *d_gpu_img_out_u, *d_gpu_img_out_v;     cudaMalloc((void **)&d_gpu_img_in_r, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_in_g, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_in_b, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_y, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_u, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_v, img_size * sizeof(unsigned char));           cudaMemcpy(d_gpu_img_in_r, gpu_img_in_r, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_gpu_img_in_g, gpu_img_in_g, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_gpu_img_in_b, gpu_img_in_b, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (img_size + threadsPerBlock - 1) / threadsPerBlock;           rgb2yuv_kernel<<<blocksPerGrid, threadsPerBlock>>>(img_size, d_gpu_img_in_r, d_gpu_img_in_g, d_gpu_img_in_b,                                                        d_gpu_img_out_y, d_gpu_img_out_u, d_gpu_img_out_v);           cudaDeviceSynchronize();           cudaMemcpy(gpu_img_out_y, d_gpu_img_out_y, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);     cudaMemcpy(gpu_img_out_u, d_gpu_img_out_u, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);     cudaMemcpy(gpu_img_out_v, d_gpu_img_out_v, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);           cudaFree(d_gpu_img_in_r);     cudaFree(d_gpu_img_in_g);     cudaFree(d_gpu_img_in_b);     cudaFree(d_gpu_img_out_y);     cudaFree(d_gpu_img_out_u);     cudaFree(d_gpu_img_out_v);      return 0; } "
    },
    {
        "id": "162",
        "c_code": "#include <stdio.h>  void getDRho(const int numOfNucl, const double *psi, const double **dpsi, const double *occNo, double *drho, const char debug);  int main() {               int numOfNucl = 3;     double psi[] = {1.0, 2.0, 3.0};     double *dpsi[numOfNucl];     for (int i = 0; i < numOfNucl; ++i) {         dpsi[i] = new double[3];          for (int j = 0; j < 3; ++j) {             dpsi[i][j] = i + j + 1.0;         }     }     double occNo[] = {0.5, 0.7, 0.9};     double drho[3];     char debug = 1;            getDRho(numOfNucl, psi, (const double **)dpsi, occNo, drho, debug);                printf(\"DRHO: %f %f %f\\n\", drho[0], drho[1], drho[2]);           for (int i = 0; i < numOfNucl; ++i) {         delete[] dpsi[i];     }      return 0; }  void getDRho(const int numOfNucl, const double *psi, const double **dpsi, const double *occNo, double *drho, const char debug) {     drho[0] = 0;     drho[1] = 0;     drho[2] = 0;      for (int i = 0; i < numOfNucl; ++i) {         drho[0] = drho[0] + 2 * occNo[i] * psi[i] * dpsi[i][0];         drho[1] = drho[1] + 2 * occNo[i] * psi[i] * dpsi[i][1];         drho[2] = drho[2] + 2 * occNo[i] * psi[i] * dpsi[i][2];     }      if (debug == 1) {         printf(\"DEBUG \u2581 print \u2581 of \u2581 DRHO:\\n\");         printf(\"\\t%f\\t%f\\t%f\\n\", drho[0], drho[1], drho[2]);         printf(\"This \u2581 is \u2581 the \u2581 last \u2581 line ( DRHO ).\\n\\n\");     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void getDRho_cuda(const double *psi, const double *dpsi, const double *occNo, double *drho) {     extern __shared__ double dcopy[];      unsigned int idx = blockIdx.x + gridDim.x * threadIdx.x;      dcopy[threadIdx.x] = 2 * occNo[threadIdx.x] * psi[threadIdx.x] * dpsi[idx];      __syncthreads();      for (int tc = blockDim.x, stepSize = 1; tc > 0; tc >>= 1, stepSize <<= 1) {         int pa = threadIdx.x * stepSize;         int pb = pa + stepSize;          if (pb < blockDim.x)             dcopy[pa] += dcopy[pb];     }      if (threadIdx.x == 0) {         drho[blockIdx.x] = dcopy[0];     } }  int main() {          int block_size = 256;      int grid_size = 1000;      int shared_memory_size = block_size * sizeof(double);      double *psi, *dpsi, *occNo, *drho;            cudaSetDevice(0);           double *d_psi, *d_dpsi, *d_occNo, *d_drho;     cudaMalloc((void **)&d_psi, grid_size * block_size * sizeof(double));     cudaMalloc((void **)&d_dpsi, grid_size * block_size * sizeof(double));     cudaMalloc((void **)&d_occNo, block_size * sizeof(double));     cudaMalloc((void **)&d_drho, grid_size * sizeof(double));           cudaMemcpy(d_psi, psi, grid_size * block_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_dpsi, dpsi, grid_size * block_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_occNo, occNo, block_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(block_size);     dim3 blocksPerGrid(grid_size);           getDRho_cuda<<<blocksPerGrid, threadsPerBlock, shared_memory_size>>>(d_psi, d_dpsi, d_occNo, d_drho);           cudaDeviceSynchronize();           cudaMemcpy(drho, d_drho, grid_size * sizeof(double), cudaMemcpyDeviceToHost);           cudaFree(d_psi);     cudaFree(d_dpsi);     cudaFree(d_occNo);     cudaFree(d_drho);      return 0; } "
    },
    {
        "id": "163",
        "c_code": "#include <stdio.h>  void opL12_cpu(float *vec, float *vec1, long depth, long rows, long cols);  int main() {               long depth = 3;     long rows = 4;     long cols = 5;           float vec[depth * rows * cols];     float vec1[depth * rows * cols];           for (long i = 0; i < depth * rows * cols; i++) {         vec[i] = i + 1;         vec1[i] = i + 2;     }           opL12_cpu(vec, vec1, depth, rows, cols);                for (long i = 0; i < depth * rows * cols; i++) {         printf(\"%f \", vec[i]);     }     printf(\"\\n\");      return 0; }  void opL12_cpu(float *vec, float *vec1, long depth, long rows, long cols) {     for (int x = 0; x < cols; x++) {         for (int y = 0; y < rows; y++) {             for (int z = 0; z < depth; x++) {                 unsigned long long i = z * rows * cols + y * cols + x;                 unsigned long long j = z * rows * cols + y * cols;                 unsigned long size2d = cols;                 unsigned long size3d = depth * rows * cols + rows * cols + cols;                  if (i + cols + 1 >= size3d)                     return;                  vec[i + 1] = 0.25 * (vec1[i + 1] + vec1[i] + vec1[i + cols + 1] + vec1[i + cols]);                  if (j + 1 >= size2d)                     return;                  vec[j] = 0.25 * (vec1[j] + vec1[j + cols]);             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void opL12(float *vec, float *vec1, long depth, long rows, long cols) {     unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;     unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;     unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;     unsigned long long i = z * rows * cols + y * cols + x;     unsigned long long j = z * rows * cols + y * cols;     unsigned long size2d = cols;     unsigned long size3d = depth * rows * cols + rows * cols + cols;      if (x >= cols || y >= rows || z >= depth)         return;      if (i + cols + 1 >= size3d)         return;      vec[i + 1] = 0.25 * (vec1[i + 1] + vec1[i] + vec1[i + cols + 1] + vec1[i + cols]);      if (j + 1 >= size2d)         return;      vec[j] = 0.25 * (vec1[j] + vec1[j + cols]); }  int main() {          long depth = 3, rows = 4, cols = 5;       float *vec, *vec1;             cudaSetDevice(0);           float *d_vec, *d_vec1;     cudaMalloc((void **)&d_vec, depth * rows * cols * sizeof(float));     cudaMalloc((void **)&d_vec1, depth * rows * cols * sizeof(float));           cudaMemcpy(d_vec, vec, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec1, vec1, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(16, 16, 1);     dim3 blocksPerGrid((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,                        (rows + threadsPerBlock.y - 1) / threadsPerBlock.y,                        (depth + threadsPerBlock.z - 1) / threadsPerBlock.z);           opL12<<<blocksPerGrid, threadsPerBlock>>>(d_vec, d_vec1, depth, rows, cols);           cudaDeviceSynchronize();           cudaMemcpy(vec, d_vec, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_vec);     cudaFree(d_vec1);      return 0; } "
    },
    {
        "id": "164",
        "c_code": "#include <stdio.h>  void cpuBYUSimplified(float *xi, float *xq, float *sr, float *si, int N, int Lq, float *L);  int main() {               int N = 10;     int Lq = 5;           float xi[N * 8 * Lq];     float xq[N * 8 * Lq];     float sr[Lq];     float si[Lq];     float L[N];           for (int i = 0; i < N * 8 * Lq; i++) {         xi[i] = i + 1;         xq[i] = i + 2;     }      for (int i = 0; i < Lq; i++) {         sr[i] = i + 3;         si[i] = i + 4;     }           cpuBYUSimplified(xi, xq, sr, si, N, Lq, L);                for (int i = 0; i < N; i++) {         printf(\"%f \", L[i]);     }     printf(\"\\n\");      return 0; }  void cpuBYUSimplified(float *xi, float *xq, float *sr, float *si, int N, int Lq, float *L) {     for (int u = 0; u < N; u++) {         float uSum = 0;         float r_i, r_q, q_i, q_q;         float realPart, imagPart;          for (int k = 0; k <= 7; k++) {             realPart = 0;             imagPart = 0;              for (int l = 0; l < Lq; l++) {                 r_i = xi[u + k * Lq + l];                 r_q = xq[u + k * Lq + l];                 q_i = sr[l];                 q_q = si[l] * (-1);                  realPart += (r_i * q_i) - (r_q * q_q);                 imagPart += (r_i * q_q) + (r_q * q_i);             }              uSum += (realPart * realPart) + (imagPart * imagPart);         }          L[u] = uSum;     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void cudaBYUSimplified(float *xi, float *xq, float *sr, float *si, int N, int Lq, float *L) {     int u = (blockIdx.x * blockDim.x) + threadIdx.x;      if (u >= N)         return;      float uSum = 0;     float r_i, r_q, q_i, q_q;     float realPart, imagPart;      for (int k = 0; k <= 7; k++) {         realPart = 0;         imagPart = 0;          for (int l = 0; l < Lq; l++) {             r_i = xi[u + k * Lq + l];             r_q = xq[u + k * Lq + l];             q_i = sr[l];             q_q = si[l] * (-1);              realPart += (r_i * q_i) - (r_q * q_q);             imagPart += (r_i * q_q) + (r_q * q_i);         }          uSum += (realPart * realPart) + (imagPart * imagPart);     }      L[u] = uSum; }  int main() {          int N = 1000;       int Lq = 10;        float *xi, *xq, *sr, *si, *L;             cudaSetDevice(0);           float *d_xi, *d_xq, *d_sr, *d_si, *d_L;     cudaMalloc((void **)&d_xi, N * 8 * Lq * sizeof(float));     cudaMalloc((void **)&d_xq, N * 8 * Lq * sizeof(float));     cudaMalloc((void **)&d_sr, Lq * sizeof(float));     cudaMalloc((void **)&d_si, Lq * sizeof(float));     cudaMalloc((void **)&d_L, N * sizeof(float));           cudaMemcpy(d_xi, xi, N * 8 * Lq * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_xq, xq, N * 8 * Lq * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_sr, sr, Lq * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_si, si, Lq * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;           cudaBYUSimplified<<<blocksPerGrid, threadsPerBlock>>>(d_xi, d_xq, d_sr, d_si, N, Lq, d_L);           cudaDeviceSynchronize();           cudaMemcpy(L, d_L, N * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_xi);     cudaFree(d_xq);     cudaFree(d_sr);     cudaFree(d_si);     cudaFree(d_L);      return 0; } "
    },
    {
        "id": "165",
        "c_code": "#include <stdio.h> #include <assert.h>  void shortcut_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float s1, float s2, float *out);  int main() {               int batch = 2;     int w1 = 4, h1 = 4, c1 = 3;     int w2 = 2, h2 = 2, c2 = 2;     float s1 = 0.5, s2 = 0.7;           float add[w1 * h1 * c1 * batch];     float out[w2 * h2 * c2 * batch];           for (int i = 0; i < w1 * h1 * c1 * batch; i++) {         add[i] = i + 1;     }           shortcut_cpu(batch, w1, h1, c1, add, w2, h2, c2, s1, s2, out);                for (int i = 0; i < w2 * h2 * c2 * batch; i++) {         printf(\"%f \", out[i]);     }     printf(\"\\n\");      return 0; }  void shortcut_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float s1, float s2, float *out) {     int stride = w1 / w2;     int sample = w2 / w1;      assert(stride == h1 / h2);     assert(sample == h2 / h1);      if (stride < 1)         stride = 1;     if (sample < 1)         sample = 1;      int minw = (w1 < w2) ? w1 : w2;     int minh = (h1 < h2) ? h1 : h2;     int minc = (c1 < c2) ? c1 : c2;      int i, j, k, b;      for (b = 0; b < batch; ++b) {         for (k = 0; k < minc; ++k) {             for (j = 0; j < minh; ++j) {                 for (i = 0; i < minw; ++i) {                     int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));                     int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));                     out[out_index] = s1 * out[out_index] + s2 * add[add_index];                 }             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void shortcut_kernel(int size, int minw, int minh, int minc, int stride, int sample, int batch, int w1, int h1, int c1,                                 float *add, int w2, int h2, int c2, float s1, float s2, float *out) {     int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (id >= size)         return;      int i = id % minw;     id /= minw;     int j = id % minh;     id /= minh;     int k = id % minc;     id /= minc;     int b = id % batch;      int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));     int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));      out[out_index] = s1 * out[out_index] + s2 * add[add_index]; }  int main() {          int size = 1000;       int minw = 16, minh = 16, minc = 3, stride = 2, sample = 2, batch = 4;     int w1 = 8, h1 = 8, c1 = 3, w2 = 8, h2 = 8, c2 = 3;     float s1 = 0.5, s2 = 0.5;       float *add, *out;                     cudaSetDevice(0);           float *d_add, *d_out;     cudaMalloc((void **)&d_add, minw * stride * sizeof(float));     cudaMalloc((void **)&d_out, size * sizeof(float));           cudaMemcpy(d_add, add, minw * stride * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;           shortcut_kernel<<<blocksPerGrid, threadsPerBlock>>>(size, minw, minh, minc, stride, sample, batch, w1, h1, c1, d_add,                                                         w2, h2, c2, s1, s2, d_out);           cudaDeviceSynchronize();           cudaMemcpy(out, d_out, size * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_add);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "166",
        "c_code": "#include <stdio.h>  void get_before_nms_data_cpu(const float *boxes, const float *scores, const int *labels, const int *index, float *boxes_out, float *scores_out, int *labels_out, int dims);  int main() {               int dims = 5;           float boxes[dims * 4];     float scores[dims];     int labels[dims];     int index[dims];     float boxes_out[dims * 4];     float scores_out[dims];     int labels_out[dims];           for (int i = 0; i < dims * 4; i++) {         boxes[i] = i + 1;     }      for (int i = 0; i < dims; i++) {         scores[i] = i + 0.1;         labels[i] = i;         index[i] = i % 2;      }           get_before_nms_data_cpu(boxes, scores, labels, index, boxes_out, scores_out, labels_out, dims);                for (int i = 0; i < dims; i++) {         printf(\"Box %d: (%f, %f, %f, %f) - Score: %f - Label: %d\\n\", i,                boxes_out[i * 4], boxes_out[i * 4 + 1], boxes_out[i * 4 + 2], boxes_out[i * 4 + 3],                scores_out[i], labels_out[i]);     }      return 0; }  void get_before_nms_data_cpu(const float *boxes, const float *scores, const int *labels, const int *index, float *boxes_out, float *scores_out, int *labels_out, int dims) {     for (int tid = 0; tid < dims; tid++) {         if (index[tid] == 0) {             boxes_out[tid * 4 + 0] = -1;             boxes_out[tid * 4 + 1] = -1;             boxes_out[tid * 4 + 2] = -1;             boxes_out[tid * 4 + 3] = -1;             scores_out[tid] = -1;             labels_out[tid] = -1;         } else {             boxes_out[tid * 4 + 0] = boxes[tid * 4 + 0];             boxes_out[tid * 4 + 1] = boxes[tid * 4 + 1];             boxes_out[tid * 4 + 2] = boxes[tid * 4 + 2];             boxes_out[tid * 4 + 3] = boxes[tid * 4 + 3];             scores_out[tid] = scores[tid];             labels_out[tid] = labels[tid];         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void get_before_nms_data(const float *boxes, const float *scores, const int *labels, const int *index,                                      float *boxes_out, float *scores_out, int *labels_out, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      if (index[tid] == 0) {         boxes_out[tid * 4 + 0] = -1;         boxes_out[tid * 4 + 1] = -1;         boxes_out[tid * 4 + 2] = -1;         boxes_out[tid * 4 + 3] = -1;         scores_out[tid] = -1;         labels_out[tid] = -1;     } else {         boxes_out[tid * 4 + 0] = boxes[tid * 4 + 0];         boxes_out[tid * 4 + 1] = boxes[tid * 4 + 1];         boxes_out[tid * 4 + 2] = boxes[tid * 4 + 2];         boxes_out[tid * 4 + 3] = boxes[tid * 4 + 3];         scores_out[tid] = scores[tid];         labels_out[tid] = labels[tid];     } }  int main() {          int dims = 1000;       float *boxes, *scores, *boxes_out, *scores_out;       int *labels, *index, *labels_out;                           cudaSetDevice(0);           float *d_boxes, *d_scores, *d_boxes_out, *d_scores_out;     int *d_labels, *d_index, *d_labels_out;      cudaMalloc((void **)&d_boxes, dims * 4 * sizeof(float));     cudaMalloc((void **)&d_scores, dims * sizeof(float));     cudaMalloc((void **)&d_labels, dims * sizeof(int));     cudaMalloc((void **)&d_index, dims * sizeof(int));     cudaMalloc((void **)&d_boxes_out, dims * 4 * sizeof(float));     cudaMalloc((void **)&d_scores_out, dims * sizeof(float));     cudaMalloc((void **)&d_labels_out, dims * sizeof(int));           cudaMemcpy(d_boxes, boxes, dims * 4 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_scores, scores, dims * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_labels, labels, dims * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_index, index, dims * sizeof(int), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;           get_before_nms_data<<<blocksPerGrid, threadsPerBlock>>>(d_boxes, d_scores, d_labels, d_index,                                                             d_boxes_out, d_scores_out, d_labels_out, dims);           cudaDeviceSynchronize();           cudaMemcpy(boxes_out, d_boxes_out, dims * 4 * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(scores_out, d_scores_out, dims * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(labels_out, d_labels_out, dims * sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_boxes);     cudaFree(d_scores);     cudaFree(d_labels);     cudaFree(d_index);     cudaFree(d_boxes_out);     cudaFree(d_scores_out);     cudaFree(d_labels_out);      return 0; } "
    },
    {
        "id": "167",
        "c_code": "#include <stdio.h>   float im2col_get_pixel(const float *data_im, int height, int width, int channels, int row, int col, int channel, int pad) {               return 1.0; }  void im2col_cpu(float *data_im, int channels, int height, int width, int ksize, int stride, int pad, float *data_col);  int main() {               int channels = 3;     int height = 4;     int width = 4;     int ksize = 2;     int stride = 2;     int pad = 0;           float data_im[channels * height * width];     float data_col[channels * ksize * ksize * ((height - ksize + 2 * pad) / stride + 1) * ((width - ksize + 2 * pad) / stride + 1)];           for (int i = 0; i < channels * height * width; i++) {         data_im[i] = i + 1;     }           im2col_cpu(data_im, channels, height, width, ksize, stride, pad, data_col);                for (int i = 0; i < channels * ksize * ksize * ((height - ksize + 2 * pad) / stride + 1) * ((width - ksize + 2 * pad) / stride + 1); i++) {         printf(\"data_col[%d] = %f\\n\", i, data_col[i]);     }      return 0; }  void im2col_cpu(float *data_im, int channels, int height, int width, int ksize, int stride, int pad, float *data_col) {     int c, h, w;     int height_col = (height + 2 * pad - ksize) / stride + 1;     int width_col = (width + 2 * pad - ksize) / stride + 1;     int channels_col = channels * ksize * ksize;      for (c = 0; c < channels_col; ++c) {         int w_offset = c % ksize;         int h_offset = (c / ksize) % ksize;         int c_im = c / ksize / ksize;          for (h = 0; h < height_col; ++h) {             for (w = 0; w < width_col; ++w) {                 int im_row = h_offset + h * stride;                 int im_col = w_offset + w * stride;                 int col_index = (c * height_col + h) * width_col + w;                 data_col[col_index] = im2col_get_pixel(data_im, height, width, channels, im_row, im_col, c_im, pad);             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void im2col_gpu_kernel(const int n, const float *data_im, const int height, const int width, const int ksize,                                   const int pad, const int stride, const int height_col, const int width_col,                                   float *data_col) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      for (; index < n; index += blockDim.x * gridDim.x) {         int w_out = index % width_col;         int h_index = index / width_col;         int h_out = h_index % height_col;         int channel_in = h_index / height_col;         int channel_out = channel_in * ksize * ksize;         int h_in = h_out * stride - pad;         int w_in = w_out * stride - pad;          float *data_col_ptr = data_col;         data_col_ptr += (channel_out * height_col + h_out) * width_col + w_out;          const float *data_im_ptr = data_im;         data_im_ptr += (channel_in * height + h_in) * width + w_in;          for (int i = 0; i < ksize; ++i) {             for (int j = 0; j < ksize; ++j) {                 int h = h_in + i;                 int w = w_in + j;                  *data_col_ptr = (h >= 0 && w >= 0 && h < height && w < width) ? data_im_ptr[i * width + j] : 0;                 data_col_ptr += height_col * width_col;             }         }     } }  int main() {          int n = 1000;            int height = 32;         int width = 32;          int ksize = 3;           int pad = 1;             int stride = 1;          int height_col = 30;      int width_col = 30;       float *data_im, *data_col;            cudaSetDevice(0);           float *d_data_im, *d_data_col;     cudaMalloc((void **)&d_data_im, height * width * sizeof(float));     cudaMalloc((void **)&d_data_col, height_col * width_col * ksize * ksize * n * sizeof(float));           cudaMemcpy(d_data_im, data_im, height * width * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           im2col_gpu_kernel<<<blocksPerGrid, threadsPerBlock>>>(n, d_data_im, height, width, ksize, pad, stride,                                                           height_col, width_col, d_data_col);           cudaDeviceSynchronize();           cudaMemcpy(data_col, d_data_col, height_col * width_col * ksize * ksize * n * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_data_im);     cudaFree(d_data_col);      return 0; } "
    },
    {
        "id": "168",
        "c_code": "#include <stdio.h>  void getTopkNum(const float *inputScore, const int *inputIndex, float *outputScore, int *outputIndex, float threshold, const int dims, int *anchorIndex, int *classIndex, const int classNum, int batchSize, int totalScoreNum);  int main() {               int dims = 10;     int batchSize = 3;     int totalScoreNum = 5;     int classNum = 2;     float threshold = 0.5;           float inputScore[batchSize * totalScoreNum];     int inputIndex[batchSize * totalScoreNum];     float outputScore[batchSize * dims];     int outputIndex[batchSize * dims];     int anchorIndex[batchSize * dims];     int classIndex[batchSize * dims];           for (int i = 0; i < batchSize * totalScoreNum; i++) {         inputScore[i] = 0.1 * i;         inputIndex[i] = i;     }           getTopkNum(inputScore, inputIndex, outputScore, outputIndex, threshold, dims, anchorIndex, classIndex, classNum, batchSize, totalScoreNum);                for (int i = 0; i < batchSize * dims; i++) {         printf(\"outputScore[%d] = %f, outputIndex[%d] = %d, anchorIndex[%d] = %d, classIndex[%d] = %d\\n\", i, outputScore[i], i, outputIndex[i], i, anchorIndex[i], i, classIndex[i]);     }      return 0; }  void getTopkNum(const float *inputScore, const int *inputIndex, float *outputScore, int *outputIndex, float threshold, const int dims, int *anchorIndex, int *classIndex, const int classNum, int batchSize, int totalScoreNum) {     for (int tid = 0; tid < dims; tid++) {         for (int i = 0; i < batchSize; i++) {             if (inputScore[i * totalScoreNum + tid] >= threshold) {                 outputScore[i * dims + tid] = inputScore[i * totalScoreNum + tid];                 outputIndex[i * dims + tid] = inputIndex[i * totalScoreNum + tid];                 anchorIndex[i * dims + tid] = outputIndex[i * dims + tid] / classNum;                 classIndex[i * dims + tid] = outputIndex[i * dims + tid] % classNum;             } else {                 outputScore[i * dims + tid] = 0.0f;                 outputIndex[i * dims + tid] = -1;                 anchorIndex[i * dims + tid] = -1;                 classIndex[i * dims + tid] = -1;             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void getTopkNum(const float *inputScore, const int *inputIndex, float *outputScore, int *outputIndex,                             float threshold, const int dims, int *anchorIndex, int *classIndex, const int classNum,                             int batchSize, int totalScoreNum) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      for (int i = 0; i < batchSize; i++) {         if (inputScore[i * totalScoreNum + tid] >= threshold) {             outputScore[i * dims + tid] = inputScore[i * totalScoreNum + tid];             outputIndex[i * dims + tid] = inputIndex[i * totalScoreNum + tid];             anchorIndex[i * dims + tid] = outputIndex[i * dims + tid] / classNum;             classIndex[i * dims + tid] = outputIndex[i * dims + tid] % classNum;         } else {             outputScore[i * dims + tid] = 0.0f;             outputIndex[i * dims + tid] = -1;             anchorIndex[i * dims + tid] = -1;             classIndex[i * dims + tid] = -1;         }     } }  int main() {          int dims = 1000;             float threshold = 0.5;       int classNum = 10;           int batchSize = 4;           int totalScoreNum = 100;      float *inputScore, *outputScore;      int *inputIndex, *outputIndex, *anchorIndex, *classIndex;            cudaSetDevice(0);           float *d_inputScore, *d_outputScore;     int *d_inputIndex, *d_outputIndex, *d_anchorIndex, *d_classIndex;      cudaMalloc((void **)&d_inputScore, batchSize * totalScoreNum * sizeof(float));     cudaMalloc((void **)&d_inputIndex, batchSize * totalScoreNum * sizeof(int));     cudaMalloc((void **)&d_outputScore, batchSize * dims * sizeof(float));     cudaMalloc((void **)&d_outputIndex, batchSize * dims * sizeof(int));     cudaMalloc((void **)&d_anchorIndex, batchSize * dims * sizeof(int));     cudaMalloc((void **)&d_classIndex, batchSize * dims * sizeof(int));           cudaMemcpy(d_inputScore, inputScore, batchSize * totalScoreNum * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_inputIndex, inputIndex, batchSize * totalScoreNum * sizeof(int), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;           getTopkNum<<<blocksPerGrid, threadsPerBlock>>>(d_inputScore, d_inputIndex, d_outputScore, d_outputIndex, threshold,                                                    dims, d_anchorIndex, d_classIndex, classNum, batchSize,                                                    totalScoreNum);           cudaDeviceSynchronize();           cudaMemcpy(outputScore, d_outputScore, batchSize * dims * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(outputIndex, d_outputIndex, batchSize * dims * sizeof(int), cudaMemcpyDeviceToHost);     cudaMemcpy(anchorIndex, d_anchorIndex, batchSize * dims * sizeof(int), cudaMemcpyDeviceToHost);     cudaMemcpy(classIndex, d_classIndex, batchSize * dims * sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_inputScore);     cudaFree(d_inputIndex);     cudaFree(d_outputScore);     cudaFree(d_outputIndex);     cudaFree(d_anchorIndex);     cudaFree(d_classIndex);      return 0; } "
    },
    {
        "id": "169",
        "c_code": "#include <stdio.h> #include <math.h>  void fractal_cpu(const int width, const int frames, unsigned char *const pic);  int main() {          const int width = 800;     const int frames = 30;     unsigned char pic[width * width * frames];           fractal_cpu(width, frames, pic);           for (int frame = 0; frame < frames; frame++) {         printf(\"Frame %d:\\n\", frame);         for (int row = 0; row < width; row++) {             for (int col = 0; col < width; col++) {                 printf(\"%4d \", pic[frame * width * width + row * width + col]);             }             printf(\"\\n\");         }         printf(\"\\n\");     }      return 0; }  void fractal_cpu(const int width, const int frames, unsigned char *const pic) {     for (int i = 0; i < width * width * frames; i++) {         const float Delta = 0.00304f;         const float xMid = -0.055846456f;         const float yMid = -0.668311119f;         const int frame = i / (width * width);         float delta = Delta * powf(0.975f, frame);         const int col = i % width;         const float xMin = xMid - delta;         const float yMin = yMid - delta;         const float dw = 2.0f * delta / width;         const int row = (i / width) % width;         const float cy = yMin + row * dw;         const float cx = xMin + col * dw;         float x = cx;         float y = cy;         float x2, y2;         int count = 256;          do {             x2 = x * x;             y2 = y * y;             y = 2.0 * x * y + cy;             x = x2 - y2 + cx;             count--;         } while ((count > 0) && ((x2 + y2) <= 5.0));          pic[frame * width * width + row * width + col] = (unsigned char)count;     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void fractal(const int width, const int frames, unsigned char *const pic) {     const long i = threadIdx.x + blockIdx.x * (long)blockDim.x;      if (i > width * width * frames) {         return;     }      const float Delta = 0.00304f;     const float xMid = -0.055846456f;     const float yMid = -0.668311119f;      const int frame = i / (width * width);     float delta = Delta * powf(0.975f, frame);      const int col = i % width;     const float xMin = xMid - delta;     const float yMin = yMid - delta;      const float dw = 2.0f * delta / width;     const int row = (i / width) % width;      const float cy = yMin + row * dw;     const float cx = xMin + col * dw;      float x = cx;     float y = cy;     float x2, y2;     int count = 256;      do {         x2 = x * x;         y2 = y * y;         y = 2.0 * x * y + cy;         x = x2 - y2 + cx;         count--;     } while ((count > 0) && ((x2 + y2) <= 5.0));      pic[frame * width * width + row * width + col] = (unsigned char)count; }  int main() {          int width = 800;       int frames = 100;      unsigned char *pic;            cudaSetDevice(0);           unsigned char *d_pic;     cudaMalloc((void **)&d_pic, frames * width * width * sizeof(unsigned char));           int threadsPerBlock = 256;     int blocksPerGrid = (width * width * frames + threadsPerBlock - 1) / threadsPerBlock;           fractal<<<blocksPerGrid, threadsPerBlock>>>(width, frames, d_pic);           cudaDeviceSynchronize();           cudaMemcpy(pic, d_pic, frames * width * width * sizeof(unsigned char), cudaMemcpyDeviceToHost);           cudaFree(d_pic);      return 0; } "
    },
    {
        "id": "17",
        "c_code": "#include <stdio.h>  void PSIfill_cpu(float *array, int conv_length, int n) {     for (int i = 0; i < n; i++) {         array[i] = array[i % conv_length];     } }  int main() {          int arraySize = 8;     float inputArray[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8};     int convLength = 3;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           PSIfill_cpu(inputArray, convLength, arraySize);      printf(\"\\nPSI \u586b\u5145\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void PSIfill(float* array, int conv_length, int maxThreads) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i >= maxThreads)         return;          array[i] = array[i % conv_length]; }  int main() {          int arraySize = 1000;     int convLength = 10;           float* h_array = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_array[i] = static_cast<float>(i);     }           float* d_array;     cudaMalloc((void**)&d_array, arraySize * sizeof(float));           cudaMemcpy(d_array, h_array, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           PSIfill<<<gridSize, blockSize>>>(d_array, convLength, arraySize);           cudaMemcpy(h_array, d_array, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_array[i]);     }           free(h_array);     cudaFree(d_array);      return 0; } "
    },
    {
        "id": "170",
        "c_code": "#include <stdio.h>  void bit8Channels_cpu(unsigned char *out, unsigned char *in, int channel, int n);  int main() {          const int n = 5;     const int channels = 3;     unsigned char in[n * 8] = {0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,                                0xFE, 0xDC, 0xBA, 0x98, 0x76, 0x54, 0x32, 0x10,                                0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88,                                0x99, 0xAA, 0xBB, 0xCC, 0xDD, 0xEE, 0xFF, 0x00,                                0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77};           unsigned char out[n * channels];           for (int ch = 1; ch <= channels; ++ch) {         bit8Channels_cpu(out, in, ch, n);         printf(\"Output for Channel %d:\\n\", ch);         for (int i = 0; i < n; ++i) {             printf(\"%02X \", out[i * channels + ch - 1]);         }         printf(\"\\n\\n\");     }      return 0; }  void bit8Channels_cpu(unsigned char *out, unsigned char *in, int channel, int n) {     for (int i = 0; i < n; ++i) {         int firstIndexToGrab = i * 8;         unsigned char bit0 = (in[firstIndexToGrab + 0] & 0x01) << 0;         unsigned char bit1 = (in[firstIndexToGrab + 1] & 0x01) << 1;         unsigned char bit2 = (in[firstIndexToGrab + 2] & 0x01) << 2;         unsigned char bit3 = (in[firstIndexToGrab + 3] & 0x01) << 3;         unsigned char bit4 = (in[firstIndexToGrab + 4] & 0x01) << 4;         unsigned char bit5 = (in[firstIndexToGrab + 5] & 0x01) << 5;         unsigned char bit6 = (in[firstIndexToGrab + 6] & 0x01) << 6;         unsigned char bit7 = (in[firstIndexToGrab + 7] & 0x01) << 7;         unsigned char output = bit7 | bit6 | bit5 | bit4 | bit3 | bit2 | bit1 | bit0;         int outputIndex = i * 8 + channel - 1;         out[outputIndex] = output;     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void bit8Channels(unsigned char *out, unsigned char *in, int channel, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i >= n) {         return;     }      int firstIndexToGrab = i * 8;     unsigned char bit0 = (in[firstIndexToGrab + 0] & 0x01) << 0;     unsigned char bit1 = (in[firstIndexToGrab + 1] & 0x01) << 1;     unsigned char bit2 = (in[firstIndexToGrab + 2] & 0x01) << 2;     unsigned char bit3 = (in[firstIndexToGrab + 3] & 0x01) << 3;     unsigned char bit4 = (in[firstIndexToGrab + 4] & 0x01) << 4;     unsigned char bit5 = (in[firstIndexToGrab + 5] & 0x01) << 5;     unsigned char bit6 = (in[firstIndexToGrab + 6] & 0x01) << 6;     unsigned char bit7 = (in[firstIndexToGrab + 7] & 0x01) << 7;      unsigned char output = bit7 | bit6 | bit5 | bit4 | bit3 | bit2 | bit1 | bit0;      int outputIndex = i * 8 + channel - 1;     out[outputIndex] = output; }  int main() {          int n = 1000;      int channel = 3;      unsigned char *out, *in;            cudaSetDevice(0);           unsigned char *d_out, *d_in;     cudaMalloc((void **)&d_out, n * 8 * sizeof(unsigned char));     cudaMalloc((void **)&d_in, n * 8 * sizeof(unsigned char));           cudaMemcpy(d_in, in, n * 8 * sizeof(unsigned char), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           bit8Channels<<<blocksPerGrid, threadsPerBlock>>>(d_out, d_in, channel, n);           cudaDeviceSynchronize();           cudaMemcpy(out, d_out, n * 8 * sizeof(unsigned char), cudaMemcpyDeviceToHost);           cudaFree(d_out);     cudaFree(d_in);      return 0; } "
    },
    {
        "id": "171",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void *Match(int num_points, float *P, float *Q, int q_points, int *idx, int start, int end);  int main() {          const int num_points = 3;     const int q_points = 3;     const int points_per_coordinate = 3;     const int array_size = num_points * points_per_coordinate;     const int start = 0;     const int end = num_points;           float P[array_size] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f, 9.0f};     float Q[array_size] = {10.0f, 11.0f, 12.0f, 13.0f, 14.0f, 15.0f, 16.0f, 17.0f, 18.0f};               int idx[num_points];           Match(num_points, P, Q, q_points, idx, start, end);           printf(\"Matching Indices:\\n\");     for (int i = 0; i < num_points; ++i) {         printf(\"P[%d] matches with Q[%d]\\n\", i, idx[i]);     }      return 0; }  void *Match(int num_points, float *P, float *Q, int q_points, int *idx, int start, int end) {     float dist;     float max_dist;      for (int i = start; i < end; i++) {         max_dist = 1000000000.0f;          for (int j = 0; j < num_points; j++) {             dist = (P[0 + i * 3] - Q[0 + j * 3]) * (P[0 + i * 3] - Q[0 + j * 3]) +                    (P[1 + i * 3] - Q[1 + j * 3]) * (P[1 + i * 3] - Q[1 + j * 3]) +                    (P[2 + i * 3] - Q[2 + j * 3]) * (P[2 + i * 3] - Q[2 + j * 3]);              if (dist < max_dist) {                 max_dist = dist;                 idx[i] = j;             }         }     }      return (void *)0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void Match(float *P, float *Q, int q_points, int *idx) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     float min = 100000;     float d;     float xp = P[0 + i * 3];     float yp = P[1 + i * 3];     float zp = P[2 + i * 3];     float xq, yq, zq;     int j;      for (j = 0; j < q_points / 2; j++) {         xq = Q[0 + j * 3];         yq = Q[1 + j * 3];         zq = Q[2 + j * 3];         d = (xp - xq) * (xp - xq) + (yp - yq) * (yp - yq) + (zp - zq) * (zp - zq);         if (d < min) {             min = d;             idx[i] = j;         }     }      for (j = j; j < q_points; j++) {         xq = Q[0 + j * 3];         yq = Q[1 + j * 3];         zq = Q[2 + j * 3];         d = (xp - xq) * (xp - xq) + (yp - yq) * (yp - yq) + (zp - zq) * (zp - zq);         if (d < min) {             min = d;             idx[i] = j;         }     } }  int main() {          int q_points = 100;      float *P, *Q;      int *idx;            cudaSetDevice(0);           float *d_P, *d_Q;     int *d_idx;      cudaMalloc((void **)&d_P, 3 * sizeof(float));     cudaMalloc((void **)&d_Q, 3 * q_points * sizeof(float));     cudaMalloc((void **)&d_idx, sizeof(int));           cudaMemcpy(d_P, P, 3 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Q, Q, 3 * q_points * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = 1;            Match<<<blocksPerGrid, threadsPerBlock>>>(d_P, d_Q, q_points, d_idx);           cudaDeviceSynchronize();           cudaMemcpy(idx, d_idx, sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_P);     cudaFree(d_Q);     cudaFree(d_idx);      return 0; } "
    },
    {
        "id": "172",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void col2im_add_pixel(float *data_im, int height, int width, int channels, int im_row, int im_col, int c_im, int pad, float val) {      }  void col2im_cpu(float *data_col, int channels, int height, int width, int ksize, int stride, int pad, float *data_im);  int main() {          const int channels = 3;     const int height = 4;     const int width = 4;     const int ksize = 2;     const int stride = 2;     const int pad = 0;           float data_col[channels * ksize * ksize * ((height + 2 * pad - ksize) / stride + 1) * ((width + 2 * pad - ksize) / stride + 1)];               float data_im[channels * height * width];           col2im_cpu(data_col, channels, height, width, ksize, stride, pad, data_im);            return 0; }  void col2im_cpu(float *data_col, int channels, int height, int width, int ksize, int stride, int pad, float *data_im) {     int c, h, w;     int height_col = (height + 2 * pad - ksize) / stride + 1;     int width_col = (width + 2 * pad - ksize) / stride + 1;     int channels_col = channels * ksize * ksize;      for (c = 0; c < channels_col; ++c) {         int w_offset = c % ksize;         int h_offset = (c / ksize) % ksize;         int c_im = c / ksize / ksize;          for (h = 0; h < height_col; ++h) {             for (w = 0; w < width_col; ++w) {                 int im_row = h_offset + h * stride;                 int im_col = w_offset + w * stride;                 int col_index = (c * height_col + h) * width_col + w;                 float val = data_col[col_index];                                   col2im_add_pixel(data_im, height, width, channels, im_row, im_col, c_im, pad, val);             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void col2im_gpu_kernel(const int n, const float *data_col, const int height, const int width, const int ksize,                                   const int pad, const int stride, const int height_col, const int width_col,                                   float *data_im) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      for (; index < n; index += blockDim.x * gridDim.x) {         float val = 0;         int w = index % width + pad;         int h = (index / width) % height + pad;         int c = index / (width * height);         int w_col_start = (w < ksize) ? 0 : (w - ksize) / stride + 1;         int w_col_end = min(w / stride + 1, width_col);         int h_col_start = (h < ksize) ? 0 : (h - ksize) / stride + 1;         int h_col_end = min(h / stride + 1, height_col);         int offset = (c * ksize * ksize + h * ksize + w) * height_col * width_col;         int coeff_h_col = (1 - stride * ksize * height_col) * width_col;         int coeff_w_col = (1 - stride * height_col * width_col);          for (int h_col = h_col_start; h_col < h_col_end; ++h_col) {             for (int w_col = w_col_start; w_col < w_col_end; ++w_col) {                 val += data_col[offset + h_col * coeff_h_col + w_col * coeff_w_col];             }         }          data_im[index] += val;     } }  int main() {          int n = 1000;      int height = 64;      int width = 64;      int ksize = 3;      int pad = 1;      int stride = 1;      int height_col = (height + 2 * pad - ksize) / stride + 1;     int width_col = (width + 2 * pad - ksize) / stride + 1;      float *data_col;      float *data_im;            cudaSetDevice(0);           float *d_data_col, *d_data_im;      cudaMalloc((void **)&d_data_col, n * sizeof(float));     cudaMalloc((void **)&d_data_im, n * sizeof(float));           cudaMemcpy(d_data_col, data_col, n * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           col2im_gpu_kernel<<<blocksPerGrid, threadsPerBlock>>>(n, d_data_col, height, width, ksize, pad, stride,                                                            height_col, width_col, d_data_im);           cudaDeviceSynchronize();           cudaMemcpy(data_im, d_data_im, n * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_data_col);     cudaFree(d_data_im);      return 0; } "
    },
    {
        "id": "173",
        "c_code": "#include <stdio.h>  void yuv2rgb_kernel(int img_size, unsigned char *gpu_img_in_y, unsigned char *gpu_img_in_u, unsigned char *gpu_img_in_v,                      unsigned char *gpu_img_out_r, unsigned char *gpu_img_out_g, unsigned char *gpu_img_out_b);  int main() {          const int img_size = 10;     unsigned char gpu_img_in_y[img_size];     unsigned char gpu_img_in_u[img_size];     unsigned char gpu_img_in_v[img_size];     unsigned char gpu_img_out_r[img_size];     unsigned char gpu_img_out_g[img_size];     unsigned char gpu_img_out_b[img_size];           for (int i = 0; i < img_size; ++i) {         gpu_img_in_y[i] = 100;         gpu_img_in_u[i] = 50;         gpu_img_in_v[i] = 150;     }           yuv2rgb_kernel(img_size, gpu_img_in_y, gpu_img_in_u, gpu_img_in_v, gpu_img_out_r, gpu_img_out_g, gpu_img_out_b);           for (int i = 0; i < img_size; ++i) {         printf(\"(%d, %d, %d) -> (%d, %d, %d)\\n\", gpu_img_in_y[i], gpu_img_in_u[i], gpu_img_in_v[i],                gpu_img_out_r[i], gpu_img_out_g[i], gpu_img_out_b[i]);     }      return 0; }  void yuv2rgb_kernel(int img_size, unsigned char *gpu_img_in_y, unsigned char *gpu_img_in_u, unsigned char *gpu_img_in_v,                      unsigned char *gpu_img_out_r, unsigned char *gpu_img_out_g, unsigned char *gpu_img_out_b) {     int rt, gt, bt;     int rt2, gt2, bt2;          for (int index = 0; index < img_size; index++) {         rt = (int)(gpu_img_in_y[index] + 1.402 * (gpu_img_in_v[index] - 128));         gt = (int)(gpu_img_in_y[index] - 0.344 * (gpu_img_in_u[index] - 128) - 0.714 * (gpu_img_in_v[index] - 128));         bt = (int)gpu_img_in_y[index] + 1.772 * (gpu_img_in_u[index] - 128);          rt2 = (rt > 255) ? 255 : rt;         gt2 = (gt > 255) ? 255 : gt;         bt2 = (bt > 255) ? 255 : bt;          gpu_img_out_r[index] = (rt2 < 0) ? 0 : rt2;         gpu_img_out_g[index] = (gt2 < 0) ? 0 : gt2;         gpu_img_out_b[index] = (bt2 < 0) ? 0 : bt2;     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void yuv2rgb_kernel(int img_size, unsigned char *gpu_img_in_y, unsigned char *gpu_img_in_u,                                unsigned char *gpu_img_in_v, unsigned char *gpu_img_out_r,                                unsigned char *gpu_img_out_g, unsigned char *gpu_img_out_b) {     int rt, gt, bt;     int rt2, gt2, bt2;     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < img_size) {         rt = (int)(gpu_img_in_y[index] + 1.402 * (gpu_img_in_v[index] - 128));         gt = (int)(gpu_img_in_y[index] - 0.344 * (gpu_img_in_u[index] - 128) - 0.714 * (gpu_img_in_v[index] - 128));         bt = (int)gpu_img_in_y[index] + 1.772 * (gpu_img_in_u[index] - 128);          rt2 = (rt > 255) ? 255 : rt;         gt2 = (gt > 255) ? 255 : gt;         bt2 = (bt > 255) ? 255 : bt;          gpu_img_out_r[index] = (rt2 < 0) ? 0 : rt2;         gpu_img_out_b[index] = (bt2 < 0) ? 0 : bt2;         gpu_img_out_g[index] = (gt2 < 0) ? 0 : gt2;     } }  int main() {          int img_size = 1000;       unsigned char *gpu_img_in_y, *gpu_img_in_u, *gpu_img_in_v;     unsigned char *gpu_img_out_r, *gpu_img_out_g, *gpu_img_out_b;                      cudaSetDevice(0);           unsigned char *d_gpu_img_in_y, *d_gpu_img_in_u, *d_gpu_img_in_v;     unsigned char *d_gpu_img_out_r, *d_gpu_img_out_g, *d_gpu_img_out_b;      cudaMalloc((void **)&d_gpu_img_in_y, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_in_u, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_in_v, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_r, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_g, img_size * sizeof(unsigned char));     cudaMalloc((void **)&d_gpu_img_out_b, img_size * sizeof(unsigned char));           cudaMemcpy(d_gpu_img_in_y, gpu_img_in_y, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_gpu_img_in_u, gpu_img_in_u, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_gpu_img_in_v, gpu_img_in_v, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (img_size + threadsPerBlock - 1) / threadsPerBlock;           yuv2rgb_kernel<<<blocksPerGrid, threadsPerBlock>>>(img_size, d_gpu_img_in_y, d_gpu_img_in_u, d_gpu_img_in_v,                                                       d_gpu_img_out_r, d_gpu_img_out_g, d_gpu_img_out_b);           cudaDeviceSynchronize();           cudaMemcpy(gpu_img_out_r, d_gpu_img_out_r, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);     cudaMemcpy(gpu_img_out_g, d_gpu_img_out_g, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);     cudaMemcpy(gpu_img_out_b, d_gpu_img_out_b, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);           cudaFree(d_gpu_img_in_y);     cudaFree(d_gpu_img_in_u);     cudaFree(d_gpu_img_in_v);     cudaFree(d_gpu_img_out_r);     cudaFree(d_gpu_img_out_g);     cudaFree(d_gpu_img_out_b);      return 0; } "
    },
    {
        "id": "174",
        "c_code": "#include <stdio.h>  void get_boxes_for_nms_cpu(const float *boxes_before_nms, const float *offset, float *boxes_for_nms, int dims);  int main() {          const int dims = 5;       float boxes_before_nms[dims * 4];       float offset[dims];       float boxes_for_nms[dims * 4];           for (int i = 0; i < dims * 4; ++i) {         boxes_before_nms[i] = i + 1;     }     for (int i = 0; i < dims; ++i) {         offset[i] = 0.5;     }           get_boxes_for_nms_cpu(boxes_before_nms, offset, boxes_for_nms, dims);           for (int i = 0; i < dims * 4; ++i) {         printf(\"%f \", boxes_for_nms[i]);     }      return 0; }  void get_boxes_for_nms_cpu(const float *boxes_before_nms, const float *offset, float *boxes_for_nms, int dims) {     for (int tid = 0; tid < dims; tid++) {         if (boxes_before_nms[tid * 4] == -1 && boxes_before_nms[tid * 4 + 1] == -1 &&             boxes_before_nms[tid * 4 + 2] == -1 && boxes_before_nms[tid * 4 + 3] == -1) {             boxes_for_nms[tid * 4] = -1;             boxes_for_nms[tid * 4 + 1] = -1;             boxes_for_nms[tid * 4 + 2] = -1;             boxes_for_nms[tid * 4 + 3] = -1;         } else {             boxes_for_nms[tid * 4] = boxes_before_nms[tid * 4] + offset[tid];             boxes_for_nms[tid * 4 + 1] = boxes_before_nms[tid * 4 + 1] + offset[tid];             boxes_for_nms[tid * 4 + 2] = boxes_before_nms[tid * 4 + 2] + offset[tid];             boxes_for_nms[tid * 4 + 3] = boxes_before_nms[tid * 4 + 3] + offset[tid];         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void get_boxes_for_nms(const float *boxes_before_nms, const float *offset, float *boxes_for_nms, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      if (boxes_before_nms[tid * 4 + 0] == (-1) && boxes_before_nms[tid * 4 + 1] == (-1) &&         boxes_before_nms[tid * 4 + 2] == (-1) && boxes_before_nms[tid * 4 + 3] == (-1)) {         boxes_for_nms[tid * 4 + 0] = (-1);         boxes_for_nms[tid * 4 + 1] = (-1);         boxes_for_nms[tid * 4 + 2] = (-1);         boxes_for_nms[tid * 4 + 3] = (-1);     } else {         boxes_for_nms[tid * 4 + 0] = boxes_before_nms[tid * 4 + 0] + offset[tid];         boxes_for_nms[tid * 4 + 1] = boxes_before_nms[tid * 4 + 1] + offset[tid];         boxes_for_nms[tid * 4 + 2] = boxes_before_nms[tid * 4 + 2] + offset[tid];         boxes_for_nms[tid * 4 + 3] = boxes_before_nms[tid * 4 + 3] + offset[tid];     } }  int main() {          int dims = 1000;       float *boxes_before_nms, *offset, *boxes_for_nms;                      cudaSetDevice(0);           float *d_boxes_before_nms, *d_offset, *d_boxes_for_nms;      cudaMalloc((void **)&d_boxes_before_nms, dims * 4 * sizeof(float));     cudaMalloc((void **)&d_offset, dims * sizeof(float));     cudaMalloc((void **)&d_boxes_for_nms, dims * 4 * sizeof(float));           cudaMemcpy(d_boxes_before_nms, boxes_before_nms, dims * 4 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_offset, offset, dims * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;           get_boxes_for_nms<<<blocksPerGrid, threadsPerBlock>>>(d_boxes_before_nms, d_offset, d_boxes_for_nms, dims);           cudaDeviceSynchronize();           cudaMemcpy(boxes_for_nms, d_boxes_for_nms, dims * 4 * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_boxes_before_nms);     cudaFree(d_offset);     cudaFree(d_boxes_for_nms);      return 0; } "
    },
    {
        "id": "175",
        "c_code": "#include <stdio.h> #include <assert.h>  void eltwise_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out, int sum, int mult);  int main() {          const int batch = 2;     const int w1 = 4, h1 = 3, c1 = 2;     const int w2 = 2, h2 = 3, c2 = 1;     const int sum = 1, mult = 0;           float add[batch * w1 * h1 * c1];     float out[w2 * h2 * c2 * batch];           for (int i = 0; i < batch * w1 * h1 * c1; ++i) {         add[i] = i + 1;     }           eltwise_cpu(batch, w1, h1, c1, add, w2, h2, c2, out, sum, mult);           for (int i = 0; i < w2 * h2 * c2 * batch; ++i) {         printf(\"%f \", out[i]);     }      return 0; }  void eltwise_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out, int sum, int mult) {     int stride = w1 / w2;     int sample = w2 / w1;     assert(stride == h1 / h2);     assert(sample == h2 / h1);      if (stride < 1) stride = 1;     if (sample < 1) sample = 1;      int minw = (w1 < w2) ? w1 : w2;     int minh = (h1 < h2) ? h1 : h2;     int minc = (c1 < c2) ? c1 : c2;      int i, j, k, b;      if (mult == 1) {         for (b = 0; b < batch; ++b) {             for (k = 0; k < minc; ++k) {                 for (j = 0; j < minh; ++j) {                     for (i = 0; i < minw; ++i) {                         int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));                         int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));                         out[out_index] = out[out_index] * add[add_index];                     }                 }             }         }     } else if (sum == 1) {         for (b = 0; b < batch; ++b) {             for (k = 0; k < minc; ++k) {                 for (j = 0; j < minh; ++j) {                     for (i = 0; i < minw; ++i) {                         int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));                         int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));                         out[out_index] = out[out_index] + add[add_index];                     }                 }             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void eltwise_kernel(int size, int minw, int minh, int minc, int stride, int sample, int batch,                                int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out,                                int sum, int mult) {     int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (id >= size) {         return;     }      int i = id % minw;     id /= minw;     int j = id % minh;     id /= minh;     int k = id % minc;     id /= minc;     int b = id % batch;      int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));     int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));      if (mult == 1)         out[out_index] = out[out_index] * add[add_index];     else if (sum == 1)         out[out_index] = out[out_index] + add[add_index]; }  int main() {          int size = 1000;       float *add, *out;                      cudaSetDevice(0);           float *d_add, *d_out;      cudaMalloc((void **)&d_add, size * sizeof(float));     cudaMalloc((void **)&d_out, size * sizeof(float));           cudaMemcpy(d_add, add, size * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;           eltwise_kernel<<<blocksPerGrid, threadsPerBlock>>>(size,  d_add, );           cudaDeviceSynchronize();           cudaMemcpy(out, d_out, size * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_add);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "176",
        "c_code": "#include <stdio.h>  void decode_cpu(const float *anchor, const float *locData, float *predictBox, int dims, float scaleClamp, int batchSize);  int main() {          const int dims = 4;     const int batchSize = 2;     const float scaleClamp = 5.0;           float anchor[batchSize * dims * 4];     float locData[batchSize * dims * 4];     float predictBox[batchSize * dims * 4];           for (int i = 0; i < batchSize * dims * 4; ++i) {         anchor[i] = i + 1;         locData[i] = (i + 1) * 0.1;     }           decode_cpu(anchor, locData, predictBox, dims, scaleClamp, batchSize);           for (int i = 0; i < batchSize * dims * 4; ++i) {         printf(\"%f \", predictBox[i]);     }      return 0; }  void decode_cpu(const float *anchor, const float *locData, float *predictBox, int dims, float scaleClamp, int batchSize) {     for (int tid = 0; tid < dims; tid++) {         for (int i = 0; i < batchSize; i++) {             float anchorW = anchor[i * dims * 4 + tid * 4 + 2] - anchor[i * dims * 4 + tid * 4];             float anchorH = anchor[i * dims * 4 + tid * 4 + 3] - anchor[i * dims * 4 + tid * 4 + 1];             float anchorCx = anchor[i * dims * 4 + tid * 4] + 0.5 * anchorW;             float anchorCy = anchor[i * dims * 4 + tid * 4 + 1] + 0.5 * anchorH;              float dx = locData[i * dims * 4 + tid * 4];             float dy = locData[i * dims * 4 + tid * 4 + 1];             float dw = locData[i * dims * 4 + tid * 4 + 2];             float dh = locData[i * dims * 4 + tid * 4 + 3];              if (dw > scaleClamp) {                 dw = scaleClamp;             }             if (dh > scaleClamp) {                 dh = scaleClamp;             }              float preCx = dx * anchorW + anchorCx;             float preCy = dy * anchorH + anchorCy;             float preW = anchorW * 0.5;             float preH = anchorH * 0.5;              predictBox[i * dims * 4 + tid * 4] = preCx - 0.5 * preW;             predictBox[i * dims * 4 + tid * 4 + 1] = preCy - 0.5 * preH;             predictBox[i * dims * 4 + tid * 4 + 2] = preCx + 0.5 * preW;             predictBox[i * dims * 4 + tid * 4 + 3] = preCy + 0.5 * preH;         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void decode(const float *anchor, const float *locData, float *predictBox,                        int dims, float scaleClamp, int batchSize) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      for (int i = 0; i < batchSize; i++) {         float anchorW = anchor[i * dims * 4 + tid * 4 + 2] - anchor[i * dims * 4 + tid * 4];         float anchorH = anchor[i * dims * 4 + tid * 4 + 3] - anchor[i * dims * 4 + tid * 4 + 1];         float anchorCx = anchor[i * dims * 4 + tid * 4] + 0.5 * anchorW;         float anchorCy = anchor[i * dims * 4 + tid * 4 + 1] + 0.5 * anchorH;          float dx = locData[i * dims * 4 + tid * 4];         float dy = locData[i * dims * 4 + tid * 4 + 1];         float dw = locData[i * dims * 4 + tid * 4 + 2];         float dh = locData[i * dims * 4 + tid * 4 + 3];          if (dw > scaleClamp) {             dw = scaleClamp;         }          if (dh > scaleClamp) {             dh = scaleClamp;         }          float preCx = dx * anchorW + anchorCx;         float preCy = dy * anchorH + anchorCy;         float preW = anchorW * 0.5;         float preH = anchorH * 0.5;          predictBox[i * dims * 4 + tid * 4] = preCx - 0.5 * preW;         predictBox[i * dims * 4 + tid * 4 + 1] = preCy - 0.5 * preH;         predictBox[i * dims * 4 + tid * 4 + 2] = preCx + 0.5 * preW;         predictBox[i * dims * 4 + tid * 4 + 3] = preCy + 0.5 * preH;     } }  int main() {          int dims = 1000;       float scaleClamp = 1.0;       int batchSize = 1;        float *anchor, *locData, *predictBox;                      cudaSetDevice(0);           float *d_anchor, *d_locData, *d_predictBox;      cudaMalloc((void **)&d_anchor, dims * 4 * batchSize * sizeof(float));     cudaMalloc((void **)&d_locData, dims * 4 * batchSize * sizeof(float));     cudaMalloc((void **)&d_predictBox, dims * 4 * batchSize * sizeof(float));           cudaMemcpy(d_anchor, anchor, dims * 4 * batchSize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_locData, locData, dims * 4 * batchSize * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;           decode<<<blocksPerGrid, threadsPerBlock>>>(d_anchor, d_locData, d_predictBox, dims, scaleClamp, batchSize);           cudaDeviceSynchronize();           cudaMemcpy(predictBox, d_predictBox, dims * 4 * batchSize * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_anchor);     cudaFree(d_locData);     cudaFree(d_predictBox);      return 0; } "
    },
    {
        "id": "177",
        "c_code": "#include <stdio.h>  void nlf_down_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data);  int main() {          const int n = 2;     const int channel = 3;     const int height = 4;     const int width = 4;     const int wsize = 5;           float filters[n / channel * wsize * height * width];     float top_data[n * height * width];           for (int i = 0; i < n / channel * wsize * height * width; ++i) {         filters[i] = i + 1;     }      for (int i = 0; i < n * height * width; ++i) {         top_data[i] = i + 1;     }           nlf_down_forward_cpu(n, filters, channel, height, width, wsize, top_data);           for (int i = 0; i < n * height * width; ++i) {         printf(\"%f \", top_data[i]);     }      return 0; }  void nlf_down_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index * step;         int fbase = index / channel * wsize * step;          for (int row = 0; row < height; row++) {             for (int col = 0; col < width; col++) {                 float temp = 0;                 int r, c, shift;                  r = row;                 c = col;                 shift = 0 * step + row * width + col;                 temp += top_data[base + r * width + c] * filters[fbase + shift];                  r = row - 1;                 c = col;                 shift = 1 * step + row * width + col;                 if (r >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];                 else temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row - 1;                 c = col - 1;                 shift = 2 * step + row * width + col;                 if (r >= 0 && c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];                 else temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row - 1;                 c = col + 1;                 shift = 3 * step + row * width + col;                 if (r >= 0 && c < width) temp += top_data[base + r * width + c] * filters[fbase + shift];                 else temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row;                 c = col - 1;                 shift = 4 * step + row * width + col;                 if (c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];                 else temp += top_data[base + row * width + col] * filters[fbase + shift];                  top_data[base + row * width + col] = temp;             }         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void nlf_down_forward(const int n, const float *filters, const int channel,                                  const int height, const int width, const int wsize, float *top_data) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index >= n) {         return;     }      int step = height * width;     int base = index * step;     int fbase = index / channel * wsize * step;      for (int row = 0; row < height; row++) {         for (int col = 0; col < width; col++) {             float temp = 0;             int r, c, shift;                           r = row;             c = col;             shift = 0 * step + row * width + col;             temp += top_data[base + r * width + c] * filters[fbase + shift];                           r = row - 1;             c = col;             shift = 1 * step + row * width + col;             if (r >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];             else temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row - 1;             c = col - 1;             shift = 2 * step + row * width + col;             if (r >= 0 && c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];             else temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row - 1;             c = col + 1;             shift = 3 * step + row * width + col;             if (r >= 0 && c < width) temp += top_data[base + r * width + c] * filters[fbase + shift];             else temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row;             c = col - 1;             shift = 4 * step + row * width + col;             if (c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];             else temp += top_data[base + row * width + col] * filters[fbase + shift];              top_data[base + row * width + col] = temp;         }     } }  int main() {          int n = 1000;       int channel = 3;       int height = 64;       int width = 64;       int wsize = 5;        float *filters, *top_data;                      cudaSetDevice(0);           float *d_filters, *d_top_data;      cudaMalloc((void **)&d_filters, n / channel * wsize * height * width * sizeof(float));     cudaMalloc((void **)&d_top_data, n * height * width * sizeof(float));           cudaMemcpy(d_filters, filters, n / channel * wsize * height * width * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_top_data, top_data, n * height * width * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           nlf_down_forward<<<blocksPerGrid, threadsPerBlock>>>(n, d_filters, channel, height, width, wsize, d_top_data);           cudaDeviceSynchronize();           cudaMemcpy(top_data, d_top_data, n * height * width * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_filters);     cudaFree(d_top_data);      return 0; } "
    },
    {
        "id": "178",
        "c_code": "#include <stdio.h>  void nlf_filter_left_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff);  int main() {          const int n = 2;     const int channel = 3;     const int height = 4;     const int width = 4;     const int wsize = 5;           float bottom_data[n * channel * height * width];     float top_data[n * channel * height * width];     float temp_diff[n * channel * height * width];     float filters_diff[n / height * height * wsize];           for (int i = 0; i < n * channel * height * width; ++i) {         bottom_data[i] = i + 1;         top_data[i] = i + 1;         temp_diff[i] = i + 1;     }      for (int i = 0; i < n / height * height * wsize; ++i) {         filters_diff[i] = i + 1;     }           nlf_filter_left_backward_cpu(n, bottom_data, top_data, temp_diff, channel, height, width, wsize, filters_diff);           for (int i = 0; i < n / height * height * wsize; ++i) {         printf(\"%f \", filters_diff[i]);     }      return 0; }  void nlf_filter_left_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index / step * step * channel + index % step;         int fbase = index / step * step * wsize + index % step;         int row = index % step / width;         int col = index % step % width;          for (int i = 0; i < channel; i++) {             filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col + 1 < width)                 filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base + 1 + i * step];             else                 filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col + 1 < width && row - 1 >= 0)                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * top_data[base - width + 1 + i * step];             else                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col + 1 < width && row + 1 < height)                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * top_data[base + width + 1 + i * step];             else                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row + 1 < height)                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base + width + i * step];             else                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void nlf_filter_left_backward(const int n, const float *bottom_data, const float *top_data,                                           const float *temp_diff, const int channel,                                           const int height, const int width, const int wsize,                                           float *filters_diff) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index >= n) {         return;     }      int step = height * width;     int base = index / step * step * channel + index % step;     int fbase = index / step * step * wsize + index % step;     int row = index % step / width;     int col = index % step % width;      for (int i = 0; i < channel; i++) {         filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col + 1 < width)             filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base + 1 + i * step];         else             filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col + 1 < width && row - 1 >= 0)             filters_diff[fbase + 2 * step] +=                 temp_diff[base + i * step] * top_data[base - width + 1 + i * step];         else             filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col + 1 < width && row + 1 < height)             filters_diff[fbase + 3 * step] +=                 temp_diff[base + i * step] * top_data[base + width + 1 + i * step];         else             filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row + 1 < height)             filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base + width + i * step];         else             filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];     } }  int main() {          int n = 1000;       int channel = 3;       int height = 64;       int width = 64;       int wsize = 5;        float *bottom_data, *top_data, *temp_diff, *filters_diff;                      cudaSetDevice(0);           float *d_bottom_data, *d_top_data, *d_temp_diff, *d_filters_diff;      cudaMalloc((void **)&d_bottom_data, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_top_data, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_temp_diff, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_filters_diff, n * height * width * wsize * sizeof(float));           cudaMemcpy(d_bottom_data, bottom_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_top_data, top_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_temp_diff, temp_diff, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           nlf_filter_left_backward<<<blocksPerGrid, threadsPerBlock>>>(n, d_bottom_data, d_top_data, d_temp_diff,                                                                  channel, height, width, wsize, d_filters_diff);           cudaDeviceSynchronize();           cudaMemcpy(filters_diff, d_filters_diff, n * height * width * wsize * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_bottom_data);     cudaFree(d_top_data);     cudaFree(d_temp_diff);     cudaFree(d_filters_diff);      return 0; } "
    },
    {
        "id": "179",
        "c_code": "#include <stdio.h>  void nlf_filter_down_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff);  int main() {          const int n = 2;     const int channel = 3;     const int height = 4;     const int width = 4;     const int wsize = 5;           float bottom_data[n * channel * height * width];     float top_data[n * channel * height * width];     float temp_diff[n * channel * height * width];     float filters_diff[n / height * height * wsize];           for (int i = 0; i < n * channel * height * width; ++i) {         bottom_data[i] = i + 1;         top_data[i] = i + 1;         temp_diff[i] = i + 1;     }      for (int i = 0; i < n / height * height * wsize; ++i) {         filters_diff[i] = i + 1;     }           nlf_filter_down_backward_cpu(n, bottom_data, top_data, temp_diff, channel, height, width, wsize, filters_diff);           for (int i = 0; i < n / height * height * wsize; ++i) {         printf(\"%f \", filters_diff[i]);     }      return 0; }  void nlf_filter_down_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index / step * step * channel + index % step;         int fbase = index / step * step * wsize + index % step;         int row = index % step / width;         int col = index % step % width;          for (int i = 0; i < channel; i++) {             filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row - 1 >= 0)                 filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base - width + i * step];             else                 filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row - 1 >= 0 && col - 1 >= 0)                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * top_data[base - width - 1 + i * step];             else                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row - 1 >= 0 && col + 1 < width)                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * top_data[base - width + 1 + i * step];             else                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col - 1 >= 0)                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base - 1 + i * step];             else                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];         }     } } ",
        "cuda_code": "#include <stdio.h>   __global__ void nlf_filter_down_backward(const int n, const float *bottom_data, const float *top_data,                                          const float *temp_diff, const int channel,                                          const int height, const int width, const int wsize,                                          float *filters_diff) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index >= n) {         return;     }      int step = height * width;     int base = index / step * step * channel + index % step;     int fbase = index / step * step * wsize + index % step;     int row = index % step / width;     int col = index % step % width;      for (int i = 0; i < channel; i++) {         filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row - 1 >= 0)             filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base - width + i * step];         else             filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row - 1 >= 0 && col - 1 >= 0)             filters_diff[fbase + 2 * step] +=                 temp_diff[base + i * step] * top_data[base - width - 1 + i * step];         else             filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row - 1 >= 0 && col + 1 < width)             filters_diff[fbase + 3 * step] +=                 temp_diff[base + i * step] * top_data[base - width + 1 + i * step];         else             filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col - 1 >= 0)             filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base - 1 + i * step];         else             filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];     } }  int main() {          int n = 1000;       int channel = 3;       int height = 64;       int width = 64;       int wsize = 5;        float *bottom_data, *top_data, *temp_diff, *filters_diff;                      cudaSetDevice(0);           float *d_bottom_data, *d_top_data, *d_temp_diff, *d_filters_diff;      cudaMalloc((void **)&d_bottom_data, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_top_data, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_temp_diff, n * height * width * channel * sizeof(float));     cudaMalloc((void **)&d_filters_diff, n * height * width * wsize * sizeof(float));           cudaMemcpy(d_bottom_data, bottom_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_top_data, top_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_temp_diff, temp_diff, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           nlf_filter_down_backward<<<blocksPerGrid, threadsPerBlock>>>(n, d_bottom_data, d_top_data, d_temp_diff,                                                                 channel, height, width, wsize, d_filters_diff);           cudaDeviceSynchronize();           cudaMemcpy(filters_diff, d_filters_diff, n * height * width * wsize * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_bottom_data);     cudaFree(d_top_data);     cudaFree "
    },
    {
        "id": "18",
        "c_code": "#include <stdio.h>  void host_add(float *c, float *a, float *b, int n) {     for (int k = 0; k < n; k++) {         c[k] = a[k] + b[k];     } }  int main() {          int arraySize = 5;     float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           host_add(resultArray, arrayA, arrayB, arraySize);      printf(\"\\n\u76f8\u52a0\u540e\u7684\u6570\u7ec4 C\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void gpu_add(float* c, float* a, float* b, int n) {     int j = blockIdx.x * blockDim.x + threadIdx.x;     if (j < n) {         c[j] = a[j] + b[j];     } }  int main() {          int arraySize = 1000;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_b = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);         h_b[i] = static_cast<float>(2 * i);     }           float* d_a;     float* d_b;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_b, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           gpu_add<<<gridSize, blockSize>>>(d_c, d_a, d_b, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "180",
        "c_code": "#include <stdio.h>  void nlf_up_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index * step;         int fbase = index / channel * wsize * step;                  for (int row = height - 1; row >= 0; row--) {             for (int col = width - 1; col >= 0; col--) {                 float temp = 0;                 int r = row;                 int c = col;                  int shift = 0 * step + row * width + col;                 temp += top_data[base + r * width + c] * filters[fbase + shift];                  r = row + 1;                 c = col;                 shift = 1 * step + row * width + col;                 if (r < height)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row + 1;                 c = col - 1;                 shift = 2 * step + row * width + col;                 if (r < height && c >= 0)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row + 1;                 c = col + 1;                 shift = 3 * step + row * width + col;                 if (r < height && c < width)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row;                 c = col + 1;                 shift = 4 * step + row * width + col;                 if (c < width)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  top_data[base + row * width + col] = temp;             }         }     } }  int main() {          int n = 1;      int channel = 3;      int height = 4;      int width = 4;      int wsize = 3;            float filters[n * wsize * channel * height * width];     float top_data[n * channel * height * width];           nlf_up_forward_cpu(n, filters, channel, height, width, wsize, top_data);            return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void nlf_up_forward(const int n, const float *filters, const int channel,                                const int height, const int width, const int wsize,                                float *top_data) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index >= n) {         return;     }      int step = height * width;     int base = index * step;     int fbase = index / channel * wsize * step;      for (int row = height - 1; row >= 0; row--) {         for (int col = width - 1; col >= 0; col--) {             float temp = 0;             int r = row;             int c = col;             int shift = 0 * step + row * width + col;             temp += top_data[base + r * width + c] * filters[fbase + shift];              r = row + 1;             c = col;             shift = 1 * step + row * width + col;             if (r < height)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];              r = row + 1;             c = col - 1;             shift = 2 * step + row * width + col;             if (r < height && c >= 0)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];              r = row + 1;             c = col + 1;             shift = 3 * step + row * width + col;             if (r < height && c < width)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];              r = row;             c = col + 1;             shift = 4 * step + row * width + col;             if (c < width)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];              top_data[base + row * width + col] = temp;         }     } }  int main() {          int n = 1000;       int channel = 3;       int height = 64;       int width = 64;       int wsize = 5;        float *filters, *top_data;                      cudaSetDevice(0);           float *d_filters, *d_top_data;      cudaMalloc((void **)&d_filters, n * height * width * channel * wsize * sizeof(float));     cudaMalloc((void **)&d_top_data, n * height * width * channel * sizeof(float));           cudaMemcpy(d_filters, filters, n * height * width * channel * wsize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_top_data, top_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;           nlf_up_forward<<<blocksPerGrid, threadsPerBlock>>>(n, d_filters, channel, height, width, wsize, d_top_data);           cudaDeviceSynchronize();           cudaMemcpy(top_data, d_top_data, n * height * width * channel * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_filters);     cudaFree(d_top_data);      return 0; } "
    },
    {
        "id": "181",
        "c_code": "#include <stdio.h>   void kmeans_set_zero(int *means, int size);  int main() {          int means[] = {1, 2, 3, 4, 5};     int size = sizeof(means) / sizeof(means[0]);           kmeans_set_zero(means, size);           printf(\"Array after setting all elements to zero:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", means[i]);     }      return 0; }   void kmeans_set_zero(int *means, int size) {     for (int id = 0; id < size; id++) {         means[id] = 0;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void kmeans_set_zero(int *means) {     means[blockIdx.x * blockDim.x + threadIdx.x] = 0; }  int main() {          const int data_size = 100;           int *means_host = (int *)malloc(data_size * sizeof(int));     for (int i = 0; i < data_size; ++i) {         means_host[i] = i;     }           int *means_device;     cudaMalloc((void**)&means_device, data_size * sizeof(int));     cudaMemcpy(means_device, means_host, data_size * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            kmeans_set_zero<<<gridDim, blockDim>>>(means_device);           cudaMemcpy(means_host, means_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%d \", means_host[i]);     }     printf(\"\\n\");           free(means_host);     cudaFree(means_device);      return 0; }   "
    },
    {
        "id": "182",
        "c_code": "#include <stdio.h>   void Mul_half_cpu(float *src, float *dst);  int main() {          float src[] = {2.0, 4.0, 6.0};     float dst[3];           Mul_half_cpu(src, dst);           printf(\"Array after multiplying each element by 0.5:\\n\");     for (int i = 0; i < 3; i++) {         printf(\"%f \", dst[i]);     }      return 0; }   void Mul_half_cpu(float *src, float *dst) {     for (int index = 0; index < 3; index++) {         dst[index] = src[index] * 0.5;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void Mul_half(float *src, float *dst) {     int index = threadIdx.x;     if (index < 3) {         dst[index] = src[index] * 0.5;     } }  int main() {          const int data_size = 3;           float *src_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         src_host[i] = i + 1.0;      }           float *src_device, *dst_device;     cudaMalloc((void**)&src_device, data_size * sizeof(float));     cudaMalloc((void**)&dst_device, data_size * sizeof(float));     cudaMemcpy(src_device, src_host, data_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim(1);               Mul_half<<<gridDim, blockDim>>>(src_device, dst_device);           float *dst_host = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(dst_host, dst_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.2f \", dst_host[i]);     }     printf(\"\\n\");           free(src_host);     free(dst_host);     cudaFree(src_device);     cudaFree(dst_device);      return 0; }   "
    },
    {
        "id": "183",
        "c_code": "#include <stdio.h>   void resetIndices_cpu(long *vec_out, const long N);  int main() {          const long N = 5;     long vec_out[N];           resetIndices_cpu(vec_out, N);           printf(\"Array after resetting indices:\\n\");     for (long i = 0; i < N; i++) {         printf(\"%ld \", vec_out[i]);     }      return 0; }   void resetIndices_cpu(long *vec_out, const long N) {     for (long idx = 0; idx < N; idx++) {         vec_out[idx] = idx;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void resetIndices(long *vec_out, const long N) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;     if (idx < N) {         vec_out[idx] = idx;     } }  int main() {          const long data_size = 100;           long *vec_out_device;     cudaMalloc((void**)&vec_out_device, data_size * sizeof(long));           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            resetIndices<<<gridDim, blockDim>>>(vec_out_device, data_size);           long *vec_out_host = (long *)malloc(data_size * sizeof(long));     cudaMemcpy(vec_out_host, vec_out_device, data_size * sizeof(long), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (long i = 0; i < data_size; ++i) {         printf(\"%ld \", vec_out_host[i]);     }     printf(\"\\n\");           free(vec_out_host);     cudaFree(vec_out_device);      return 0; }   "
    },
    {
        "id": "184",
        "c_code": "#include <stdio.h>   void set_offset_kernel(int stride, int size, int *output);  int main() {          int stride = 2;     int size = 5;     int output[size];           set_offset_kernel(stride, size, output);           printf(\"Array after setting offset values:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", output[i]);     }      return 0; }   void set_offset_kernel(int stride, int size, int *output) {     for (int i = 0; i < size; i++) {         output[i] = i * stride;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void set_offset_kernel(int stride, int size, int *output) {     for (int i = threadIdx.x; i < size; i += blockDim.x) {         output[i] = i * stride;     } }  int main() {          const int data_size = 100;     const int stride = 2;           int *output_device;     cudaMalloc((void**)&output_device, data_size * sizeof(int));           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            set_offset_kernel<<<gridDim, blockDim>>>(stride, data_size, output_device);           int *output_host = (int *)malloc(data_size * sizeof(int));     cudaMemcpy(output_host, output_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%d \", output_host[i]);     }     printf(\"\\n\");           free(output_host);     cudaFree(output_device);      return 0; }   "
    },
    {
        "id": "185",
        "c_code": "#include <stdio.h>   void setSuppressed_cpu(int *suppressed, int dims);  int main() {          int dims = 4;     int suppressed[dims];           setSuppressed_cpu(suppressed, dims);           printf(\"Array after setting all elements to zero:\\n\");     for (int i = 0; i < dims; i++) {         printf(\"%d \", suppressed[i]);     }      return 0; }   void setSuppressed_cpu(int *suppressed, int dims) {     for (int tid = 0; tid < dims; tid++) {         suppressed[tid] = 0;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void setSuppressed(int *suppressed, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }     suppressed[tid] = 0; }  int main() {          const int data_size = 100;           int *suppressed_device;     cudaMalloc((void**)&suppressed_device, data_size * sizeof(int));           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            setSuppressed<<<gridDim, blockDim>>>(suppressed_device, data_size);           int *suppressed_host = (int *)malloc(data_size * sizeof(int));     cudaMemcpy(suppressed_host, suppressed_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%d \", suppressed_host[i]);     }     printf(\"\\n\");           free(suppressed_host);     cudaFree(suppressed_device);      return 0; }   "
    },
    {
        "id": "186",
        "c_code": "#include <stdio.h>   void allDivInplace_cpu(double *arr, double alpha, int n);  int main() {          int n = 6;     double arr[] = {2.0, 4.0, 6.0, 8.0, 10.0, 12.0};     double alpha = 2.0;           allDivInplace_cpu(arr, alpha, n);           printf(\"Array after dividing each element by %f:\\n\", alpha);     for (int i = 0; i < n; i++) {         printf(\"%f \", arr[i]);     }      return 0; }   void allDivInplace_cpu(double *arr, double alpha, int n) {     for (int i = 0; i < n; i++) {         arr[i] /= alpha;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void allDivInplaceKernel(double *arr, double alpha, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         arr[i] /= alpha;     } }  int main() {          const int data_size = 100;     const double alpha = 2.0;           double *arr_device;     cudaMalloc((void**)&arr_device, data_size * sizeof(double));           double *arr_host = (double *)malloc(data_size * sizeof(double));     for (int i = 0; i < data_size; ++i) {         arr_host[i] = i + 1.0;      }           cudaMemcpy(arr_device, arr_host, data_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            allDivInplaceKernel<<<gridDim, blockDim>>>(arr_device, alpha, data_size);           cudaMemcpy(arr_host, arr_device, data_size * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.2f \", arr_host[i]);     }     printf(\"\\n\");           free(arr_host);     cudaFree(arr_device);      return 0; }   "
    },
    {
        "id": "187",
        "c_code": "#include <stdio.h>   void incrementArrayOnHost(float *a, int N);  int main() {          int N = 5;     float a[] = {1.0, 2.0, 3.0, 4.0, 5.0};           incrementArrayOnHost(a, N);           printf(\"Array after incrementing each element by 1.0:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", a[i]);     }      return 0; }   void incrementArrayOnHost(float *a, int N) {     for (int i = 0; i < N; i++) {         a[i] = a[i] + 1.0f;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void incrementArrayOnDevice(float *a, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         a[idx] = a[idx] + 1.0f;     } }  int main() {          const int data_size = 100;           float *a_device;     cudaMalloc((void**)&a_device, data_size * sizeof(float));           float *a_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         a_host[i] = i + 1.0;      }           cudaMemcpy(a_device, a_host, data_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            incrementArrayOnDevice<<<gridDim, blockDim>>>(a_device, data_size);           cudaMemcpy(a_host, a_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.2f \", a_host[i]);     }     printf(\"\\n\");           free(a_host);     cudaFree(a_device);      return 0; }   "
    },
    {
        "id": "188",
        "c_code": "#include <stdio.h>   void allMulInplace_cpu(double *arr, double alpha, int n);  int main() {          int n = 6;     double arr[] = {2.0, 4.0, 6.0, 8.0, 10.0, 12.0};     double alpha = 1.5;           allMulInplace_cpu(arr, alpha, n);           printf(\"Array after multiplying each element by %f:\\n\", alpha);     for (int i = 0; i < n; i++) {         printf(\"%f \", arr[i]);     }      return 0; }   void allMulInplace_cpu(double *arr, double alpha, int n) {     for (int i = 0; i < n; i++) {         arr[i] *= alpha;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void allMulInplaceKernel(double *arr, double alpha, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         arr[i] *= alpha;     } }  int main() {          const int data_size = 100;     const double alpha = 2.0;           double *arr_device;     cudaMalloc((void**)&arr_device, data_size * sizeof(double));           double *arr_host = (double *)malloc(data_size * sizeof(double));     for (int i = 0; i < data_size; ++i) {         arr_host[i] = i + 1.0;      }           cudaMemcpy(arr_device, arr_host, data_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            allMulInplaceKernel<<<gridDim, blockDim>>>(arr_device, alpha, data_size);           cudaMemcpy(arr_host, arr_device, data_size * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.2f \", arr_host[i]);     }     printf(\"\\n\");           free(arr_host);     cudaFree(arr_device);      return 0; }   "
    },
    {
        "id": "189",
        "c_code": "#include <stdio.h>   void Init(const long long size, const double *in, double *out);  int main() {          const long long size = 5;     double in[] = {1.0, 2.0, 3.0, 4.0, 5.0};     double out[size];           Init(size, in, out);           printf(\"Array after initialization:\\n\");     for (long long i = 0; i < size; i++) {         printf(\"%f \", out[i]);     }      return 0; }   void Init(const long long size, const double *in, double *out) {     for (long long i = 0; i < size; i++) {         out[i] = in[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void Init(const long long size, const double *in, double *out) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < size) {         out[i] = in[i];     } }  int main() {          const long long data_size = 100;           double *in_device, *out_device;     cudaMalloc((void**)&in_device, data_size * sizeof(double));     cudaMalloc((void**)&out_device, data_size * sizeof(double));           double *in_host = (double *)malloc(data_size * sizeof(double));     for (long long i = 0; i < data_size; ++i) {         in_host[i] = i + 1.0;      }           cudaMemcpy(in_device, in_host, data_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            Init<<<gridDim, blockDim>>>(data_size, in_device, out_device);           double *out_host = (double *)malloc(data_size * sizeof(double));     cudaMemcpy(out_host, out_device, data_size * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (long long i = 0; i < data_size; ++i) {         printf(\"%.2f \", out_host[i]);     }     printf(\"\\n\");           free(in_host);     free(out_host);     cudaFree(in_device);     cudaFree(out_device);      return 0; }   "
    },
    {
        "id": "19",
        "c_code": "#include <stdio.h>  void mul_Scalar_matrix(float *a, float value, float *c, int N) {     for (int idx = 0; idx < N; idx++) {         c[idx] = a[idx] * value;     } }  int main() {          int arraySize = 6;     float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};     float scalarValue = 2.0;     float resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }           mul_Scalar_matrix(arrayA, scalarValue, resultArray, arraySize);      printf(\"\\n\u6807\u91cf\u4e58\u6cd5\u540e\u7684\u6570\u7ec4 C\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void mul_Scalar_matrix(float* a, float value, float* c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] * value;     } }  int main() {          int arraySize = 1000;           float value = 2.0;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);     }           float* d_a;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           mul_Scalar_matrix<<<gridSize, blockSize>>>(d_a, value, d_c, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_c);     cudaFree(d_a);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "190",
        "c_code": "#include <stdio.h>   void subAvg_cpu(int *input, int count, int avg);  int main() {          int count = 5;     int input[] = {2, 4, 6, 8, 10};     int avg = 6;           subAvg_cpu(input, count, avg);           printf(\"Array after subtracting average value %d:\\n\", avg);     for (int i = 0; i < count; i++) {         printf(\"%d \", input[i]);     }      return 0; }   void subAvg_cpu(int *input, int count, int avg) {     for (int index = 0; index < count; index++) {         input[index] = input[index] - avg;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void subAvg(int *input, int count, int avg) {     int index = blockDim.x * blockIdx.x + threadIdx.x;     if (index < count) {         input[index] = input[index] - avg;     } }  int main() {          const int data_size = 100;           int *input_device;     cudaMalloc((void**)&input_device, data_size * sizeof(int));           int *input_host = (int *)malloc(data_size * sizeof(int));     for (int i = 0; i < data_size; ++i) {         input_host[i] = i + 1;      }           cudaMemcpy(input_device, input_host, data_size * sizeof(int), cudaMemcpyHostToDevice);           int sum = 0;     for (int i = 0; i < data_size; ++i) {         sum += input_host[i];     }     int avg = sum / data_size;           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            subAvg<<<gridDim, blockDim>>>(input_device, data_size, avg);           cudaMemcpy(input_host, input_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%d \", input_host[i]);     }     printf(\"\\n\");           free(input_host);     cudaFree(input_device);      return 0; }   "
    },
    {
        "id": "191",
        "c_code": "#include <stdio.h>   void allExp2Inplace_cpu(double *arr, int n);  int main() {          int n = 4;     double arr[] = {1.0, 2.0, 3.0, 4.0};           allExp2Inplace_cpu(arr, n);           printf(\"Array after multiplying each element by 9:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%f \", arr[i]);     }      return 0; }   void allExp2Inplace_cpu(double *arr, int n) {     for (int i = 0; i < n; i++) {         arr[i] = arr[i] * 9.0;     } }   ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void allExp2InplaceKernel(double *arr, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         arr[i] = exp2(arr[i]) * 9.0;     } }  int main() {          const int data_size = 100;           double *arr_device;     cudaMalloc((void**)&arr_device, data_size * sizeof(double));           double *arr_host = (double *)malloc(data_size * sizeof(double));     for (int i = 0; i < data_size; ++i) {         arr_host[i] = i + 1.0;      }           cudaMemcpy(arr_device, arr_host, data_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            allExp2InplaceKernel<<<gridDim, blockDim>>>(arr_device, data_size);           cudaMemcpy(arr_host, arr_device, data_size * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.2f \", arr_host[i]);     }     printf(\"\\n\");           free(arr_host);     cudaFree(arr_device);      return 0; }   "
    },
    {
        "id": "192",
        "c_code": "#include <stdio.h>   void vector_add_cpu(float a[], float b[], float *c);  int main() {          float a[10000], b[10000], c[10000];           for (int i = 0; i < 10000; i++) {         a[i] = i;         b[i] = i * 2;     }           vector_add_cpu(a, b, c);           printf(\"Resultant array after vector addition:\\n\");     for (int i = 0; i < 10; i++) {         printf(\"%f \", c[i]);     }      return 0; }   void vector_add_cpu(float a[], float b[], float *c) {     for (int i = 0; i < 10000; i++) {         c[i] = a[i] + b[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void vector_add(float *a, float *b, float *c) {     int index = threadIdx.x + blockDim.x * blockIdx.x;     c[index] = a[index] + b[index]; }  int main() {          const int data_size = 100;           float *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, data_size * sizeof(float));     cudaMalloc((void**)&b_device, data_size * sizeof(float));     cudaMalloc((void**)&c_device, data_size * sizeof(float));           float *a_host = (float *)malloc(data_size * sizeof(float));     float *b_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         a_host[i] = i + 1.0;          b_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(a_device, a_host, data_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, data_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            vector_add<<<gridDim, blockDim>>>(a_device, b_device, c_device);           float *c_host = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(c_host, c_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.2f \", c_host[i]);     }     printf(\"\\n\");           free(a_host);     free(b_host);     free(c_host);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   "
    },
    {
        "id": "193",
        "c_code": "#include <stdio.h>   void setLabels_cpu(int *output, int dims, int clsNum);  int main() {          int dims = 10;     int clsNum = 3;     int output[10];           setLabels_cpu(output, dims, clsNum);           printf(\"Array after setting labels:\\n\");     for (int i = 0; i < dims; i++) {         printf(\"%d \", output[i]);     }      return 0; }   void setLabels_cpu(int *output, int dims, int clsNum) {     for (int tid = 0; tid < dims; tid++) {         output[tid] = tid % clsNum;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void setLabels(int *output, int dims, int clsNum) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }     output[tid] = tid % clsNum; }  int main() {          const int data_size = 100;     const int clsNum = 5;           int *output_device;     cudaMalloc((void**)&output_device, data_size * sizeof(int));           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            setLabels<<<gridDim, blockDim>>>(output_device, data_size, clsNum);           int *output_host = (int *)malloc(data_size * sizeof(int));     cudaMemcpy(output_host, output_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%d \", output_host[i]);     }     printf(\"\\n\");           free(output_host);     cudaFree(output_device);      return 0; }   "
    },
    {
        "id": "194",
        "c_code": "#include <stdio.h>   void histogram_cpu(int n, int *color, int *bucket);  int main() {          int n = 8;     int color[] = {1, 2, 1, 3, 2, 3, 1, 2};     int bucket[4] = {0};            histogram_cpu(n, color, bucket);           printf(\"Histogram:\\n\");     for (int i = 0; i < 4; i++) {         printf(\"Bucket %d: %d\\n\", i, bucket[i]);     }      return 0; }   void histogram_cpu(int n, int *color, int *bucket) {     for (int i = 0; i < n; i++) {         int c = color[i];         bucket[c] += 1;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void histogram(int n, int *color, int *bucket) {     int i = threadIdx.x + blockDim.x * blockIdx.x;     if (i < n) {         int c = color[i];         atomicAdd(&bucket[c], 1);     } }  int main() {          const int data_size = 100;     const int num_bins = 256;            int *color_device, *bucket_device;     cudaMalloc((void**)&color_device, data_size * sizeof(int));     cudaMalloc((void**)&bucket_device, num_bins * sizeof(int));           int *color_host = (int *)malloc(data_size * sizeof(int));     for (int i = 0; i < data_size; ++i) {         color_host[i] = i % num_bins;      }           cudaMemcpy(color_device, color_host, data_size * sizeof(int), cudaMemcpyHostToDevice);           int *bucket_host = (int *)malloc(num_bins * sizeof(int));     memset(bucket_host, 0, num_bins * sizeof(int));            cudaMemcpy(bucket_device, bucket_host, num_bins * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            histogram<<<gridDim, blockDim>>>(data_size, color_device, bucket_device);           cudaMemcpy(bucket_host, bucket_device, num_bins * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Histogram Result after CUDA kernel execution:\\n\");     for (int i = 0; i < num_bins; ++i) {         printf(\"Bucket %d: %d\\n\", i, bucket_host[i]);     }           free(color_host);     free(bucket_host);     cudaFree(color_device);     cudaFree(bucket_device);      return 0; }   "
    },
    {
        "id": "195",
        "c_code": "#include <stdio.h> #include <math.h>   void sigmoid_kernel(float *input, float *output, int n);  int main() {          int n = 5;     float input[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float output[5];           sigmoid_kernel(input, output, n);           printf(\"Array after applying sigmoid function:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%f \", output[i]);     }      return 0; }   void sigmoid_kernel(float *input, float *output, int n) {     for (int tid = 0; tid < n; tid++) {         output[tid] = 1.0 / (1.0 + expf(-input[tid]));     } }   ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void sigmoid_kernel(float *input, float *output) {     int tid = threadIdx.x + blockIdx.x * blockDim.x;     output[tid] = 1.0 / (1.0 + expf(-input[tid])); }  int main() {          const int data_size = 100;           float *input_device, *output_device;     cudaMalloc((void**)&input_device, data_size * sizeof(float));     cudaMalloc((void**)&output_device, data_size * sizeof(float));           float *input_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         input_host[i] = i + 1.0;      }           cudaMemcpy(input_device, input_host, data_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            sigmoid_kernel<<<gridDim, blockDim>>>(input_device, output_device);           float *output_host = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(output_host, output_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.6f \", output_host[i]);     }     printf(\"\\n\");           free(input_host);     free(output_host);     cudaFree(input_device);     cudaFree(output_device);      return 0; }   "
    },
    {
        "id": "196",
        "c_code": "#include <stdio.h>   void kernelUpdateHead(int *head, int *d_idxs_out, int n);  int main() {          int n = 5;     int head[10] = {0};      int d_idxs_out[] = {1, 3, 5, 7, 9};           kernelUpdateHead(head, d_idxs_out, n);           printf(\"Head array after updating:\\n\");     for (int i = 0; i < 10; i++) {         printf(\"%d \", head[i]);     }      return 0; }   void kernelUpdateHead(int *head, int *d_idxs_out, int n) {     for (int i = 0; i < n; i++) {         head[d_idxs_out[i]] = 1;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void kernelUpdateHead(int *head, int *d_idxs_out, int n) {     int i = threadIdx.x + blockDim.x * blockIdx.x;     if (i < n) {         head[d_idxs_out[i]] = 1;     } }  int main() {          const int data_size = 100;           int *head_device, *d_idxs_out_device;     cudaMalloc((void**)&head_device, data_size * sizeof(int));     cudaMalloc((void**)&d_idxs_out_device, data_size * sizeof(int));           int *d_idxs_out_host = (int *)malloc(data_size * sizeof(int));     for (int i = 0; i < data_size; ++i) {         d_idxs_out_host[i] = i % data_size;      }           cudaMemcpy(d_idxs_out_device, d_idxs_out_host, data_size * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            kernelUpdateHead<<<gridDim, blockDim>>>(head_device, d_idxs_out_device, data_size);           int *head_host = (int *)malloc(data_size * sizeof(int));     cudaMemcpy(head_host, head_device, data_size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%d \", head_host[i]);     }     printf(\"\\n\");           free(d_idxs_out_host);     free(head_host);     cudaFree(d_idxs_out_device);     cudaFree(head_device);      return 0; }   "
    },
    {
        "id": "197",
        "c_code": "#include <stdio.h>   void const_cpu(int N, float ALPHA, float *X, int INCX);  int main() {          int N = 5;     float ALPHA = 2.0;     float X[] = {1.0, 2.0, 3.0, 4.0, 5.0};     int INCX = 1;           const_cpu(N, ALPHA, X, INCX);           printf(\"Array after setting each element to ALPHA:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", X[i]);     }      return 0; }   void const_cpu(int N, float ALPHA, float *X, int INCX) {     for (int i = 0; i < N; ++i) {         X[i * INCX] = ALPHA;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void const_kernel(int N, float ALPHA, float *X, int INCX) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N) {         X[i * INCX] = ALPHA;     } }  int main() {          const int data_size = 100;     const float ALPHA = 2.0;            float *X_device;     cudaMalloc((void**)&X_device, data_size * sizeof(float));           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            const_kernel<<<gridDim, blockDim>>>(data_size, ALPHA, X_device, 1);            float *X_host = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(X_host, X_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.2f \", X_host[i]);     }     printf(\"\\n\");           free(X_host);     cudaFree(X_device);      return 0; }   "
    },
    {
        "id": "198",
        "c_code": "#include <stdio.h>   void allLog2_cpu(const double *arr, double *buf, int n);  int main() {          int n = 4;     double arr[] = {2.0, 4.0, 8.0, 16.0};     double buf[4];           allLog2_cpu(arr, buf, n);           printf(\"Array after dividing each element by 2:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%f \", buf[i]);     }      return 0; }   void allLog2_cpu(const double *arr, double *buf, int n) {     for (int i = 0; i < n; i++) {         buf[i] = arr[i] / 2.0;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void allLog2Kernel(const double *arr, double *buf, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         buf[i] = arr[i] / 2.0;     } }  int main() {          const int data_size = 100;           double *arr_device, *buf_device;     cudaMalloc((void**)&arr_device, data_size * sizeof(double));     cudaMalloc((void**)&buf_device, data_size * sizeof(double));           double *arr_host = (double *)malloc(data_size * sizeof(double));     for (int i = 0; i < data_size; ++i) {         arr_host[i] = i + 1.0;      }           cudaMemcpy(arr_device, arr_host, data_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            allLog2Kernel<<<gridDim, blockDim>>>(arr_device, buf_device, data_size);           double *buf_host = (double *)malloc(data_size * sizeof(double));     cudaMemcpy(buf_host, buf_device, data_size * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.2f \", buf_host[i]);     }     printf(\"\\n\");           free(arr_host);     free(buf_host);     cudaFree(arr_device);     cudaFree(buf_device);      return 0; }   "
    },
    {
        "id": "199",
        "c_code": "#include <stdio.h>   void clearArray_cpu(unsigned char *arr, const unsigned int length);  int main() {          const unsigned int length = 6;     unsigned char arr[] = {1, 2, 3, 4, 5, 6};           clearArray_cpu(arr, length);           printf(\"Array after clearing elements:\\n\");     for (unsigned int i = 0; i < length; i++) {         printf(\"%u \", arr[i]);     }      return 0; }   void clearArray_cpu(unsigned char *arr, const unsigned int length) {     unsigned int offset = 0;     while (offset < length) {         arr[offset] = 0;         offset += 1;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void clearArray(unsigned char *arr, const unsigned int length) {     unsigned int offset = blockDim.x * blockIdx.x + threadIdx.x;     unsigned int skip = gridDim.x * blockDim.x;          while (offset < length) {         arr[offset] = 0;         offset += skip;     } }  int main() {          const unsigned int data_size = 100;           unsigned char *arr_device;     cudaMalloc((void**)&arr_device, data_size * sizeof(unsigned char));           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            clearArray<<<gridDim, blockDim>>>(arr_device, data_size);           unsigned char *arr_host = (unsigned char *)malloc(data_size * sizeof(unsigned char));     cudaMemcpy(arr_host, arr_device, data_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (unsigned int i = 0; i < data_size; ++i) {         printf(\"%d \", arr_host[i]);     }     printf(\"\\n\");           free(arr_host);     cudaFree(arr_device);      return 0; }   "
    },
    {
        "id": "2",
        "c_code": "#include <stdio.h>  void get_ev(double *old_arr, double *new_arr, int size) {     int tid;     for (tid = 0; tid < size; tid++) {         new_arr[tid] = old_arr[tid];     } }  int main() {          double old_array[] = {1.5, 2.3, 3.7, 4.2, 5.8};     int numElements = sizeof(old_array) / sizeof(old_array[0]);      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", old_array[i]);     }           double new_array[numElements];           get_ev(old_array, new_array, numElements);      printf(\"\\n\u590d\u5236\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", new_array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void get_ev(double* old_arr, double* new_arr) {     int tid = threadIdx.x + blockIdx.x * blockDim.x;     new_arr[tid] = old_arr[tid]; }  int main() {          int numElements = 1000;           double* h_old_arr = (double*)malloc(numElements * sizeof(double));     double* h_new_arr = (double*)malloc(numElements * sizeof(double));           for (int i = 0; i < numElements; ++i) {         h_old_arr[i] = static_cast<double>(i);     }           double* d_old_arr;     double* d_new_arr;     cudaMalloc((void**)&d_old_arr, numElements * sizeof(double));     cudaMalloc((void**)&d_new_arr, numElements * sizeof(double));           cudaMemcpy(d_old_arr, h_old_arr, numElements * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (numElements + blockSize - 1) / blockSize;           get_ev<<<gridSize, blockSize>>>(d_old_arr, d_new_arr);           cudaMemcpy(h_new_arr, d_new_arr, numElements * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_new_arr[i]);     }           free(h_old_arr);     free(h_new_arr);     cudaFree(d_old_arr);     cudaFree(d_new_arr);      return 0; } "
    },
    {
        "id": "20",
        "c_code": "#include <stdio.h>  void initWith_cpu(float num, float *a, int N) {     for (int i = 0; i < N; i++) {         a[i] = num;     } }  int main() {          int arraySize = 5;     float arrayA[arraySize];     float initialValue = 3.14;           initWith_cpu(initialValue, arrayA, arraySize);      printf(\"\u521d\u59cb\u5316\u540e\u7684\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void initWith(float num, float* a, int N) {     int index = threadIdx.x + blockIdx.x * blockDim.x;     int stride = blockDim.x * gridDim.x;     for (int i = index; i < N; i += stride) {         a[i] = num;     } }  int main() {          int arraySize = 1000;           float initialValue = 3.0;           float* h_a = (float*)malloc(arraySize * sizeof(float));           float* d_a;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           initWith<<<gridSize, blockSize>>>(initialValue, d_a, arraySize);           cudaMemcpy(h_a, d_a, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_a[i]);     }           free(h_a);     cudaFree(d_a);      return 0; } "
    },
    {
        "id": "200",
        "c_code": "#include <stdio.h>   void Copy_List_cpu(const int element_numbers, const float *origin_list, float *list);  int main() {          const int element_numbers = 5;     float origin_list[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float list[5];           Copy_List_cpu(element_numbers, origin_list, list);           printf(\"Copied list:\\n\");     for (int i = 0; i < element_numbers; i++) {         printf(\"%f \", list[i]);     }      return 0; }   void Copy_List_cpu(const int element_numbers, const float *origin_list, float *list) {     for (int i = 0; i < element_numbers; i++) {         list[i] = origin_list[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void Copy_List(const int element_numbers, const float *origin_list, float *list) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < element_numbers) {         list[i] = origin_list[i];     } }  int main() {          const int data_size = 100;           float *origin_list_device, *list_device;     cudaMalloc((void**)&origin_list_device, data_size * sizeof(float));     cudaMalloc((void**)&list_device, data_size * sizeof(float));           float *origin_list_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         origin_list_host[i] = i + 1.0;      }           cudaMemcpy(origin_list_device, origin_list_host, data_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            Copy_List<<<gridDim, blockDim>>>(data_size, origin_list_device, list_device);           float *list_host = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(list_host, list_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.2f \", list_host[i]);     }     printf(\"\\n\");           free(origin_list_host);     free(list_host);     cudaFree(origin_list_device);     cudaFree(list_device);      return 0; }   "
    },
    {
        "id": "201",
        "c_code": "#include <stdio.h>   void add(int n, float *x, float *y);  int main() {          int n = 3;     float x[] = {1.0, 2.0, 3.0};     float y[] = {4.0, 5.0, 6.0};           add(n, x, y);           printf(\"Array y after adding elements from x:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%f \", y[i]);     }      return 0; }   void add(int n, float *x, float *y) {     for (int i = 0; i < n; i++) {         y[i] = x[i] + y[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void add(int n, float *x, float *y) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     for (int i = index; i < n; i++) {         y[i] = x[i] + y[i];     } }  int main() {          const int data_size = 100;           float *x_device, *y_device;     cudaMalloc((void**)&x_device, data_size * sizeof(float));     cudaMalloc((void**)&y_device, data_size * sizeof(float));           float *x_host = (float *)malloc(data_size * sizeof(float));     float *y_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         x_host[i] = i + 1.0;          y_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(x_device, x_host, data_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(y_device, y_host, data_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((data_size + blockDim.x - 1) / blockDim.x);            add<<<gridDim, blockDim>>>(data_size, x_device, y_device);           float *y_result = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(y_result, y_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.2f \", y_result[i]);     }     printf(\"\\n\");           free(x_host);     free(y_host);     free(y_result);     cudaFree(x_device);     cudaFree(y_device);      return 0; }   "
    },
    {
        "id": "202",
        "c_code": "#include <stdio.h>   void host_add(float *c, float *a, float *b, int n);  int main() {          int n = 4;     float a[] = {1.0, 2.0, 3.0, 4.0};     float b[] = {5.0, 6.0, 7.0, 8.0};     float c[4];           host_add(c, a, b, n);           printf(\"Array c after adding elements from a and b:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%f \", c[i]);     }      return 0; }   void host_add(float *c, float *a, float *b, int n) {     for (int k = 0; k < n; k++) {         c[k] = a[k] + b[k];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void gpu_add(float *c, float *a, float *b, int n) {     for (int k = threadIdx.x; k < n; k += blockDim.x) {         c[k] = a[k] + b[k];     } }  int main() {          const int data_size = 100;           float *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, data_size * sizeof(float));     cudaMalloc((void**)&b_device, data_size * sizeof(float));     cudaMalloc((void**)&c_device, data_size * sizeof(float));           float *a_host = (float *)malloc(data_size * sizeof(float));     float *b_host = (float *)malloc(data_size * sizeof(float));     for (int i = 0; i < data_size; ++i) {         a_host[i] = i + 1.0;          b_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(a_device, a_host, data_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, data_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim(1);            gpu_add<<<gridDim, blockDim>>>(c_device, a_device, b_device, data_size);           float *c_result = (float *)malloc(data_size * sizeof(float));     cudaMemcpy(c_result, c_device, data_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < data_size; ++i) {         printf(\"%.2f \", c_result[i]);     }     printf(\"\\n\");           free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   "
    },
    {
        "id": "203",
        "c_code": "#include <stdio.h>   void subtract_matrix(float *a, float *b, float *c, int N);  int main() {          int N = 9;     float a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};     float b[] = {9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0};     float c[9];           subtract_matrix(a, b, c, N);           printf(\"Resultant matrix after subtraction:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", c[i]);         if ((i + 1) % 3 == 0) {             printf(\"\\n\");         }     }      return 0; }   void subtract_matrix(float *a, float *b, float *c, int N) {     for (int idx = 0; idx < N; idx++) {         c[idx] = a[idx] - b[idx];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void subtract_matrix(float *a, float *b, float *c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] - b[idx];     } }  int main() {          const int matrix_size = 100;           float *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, matrix_size * sizeof(float));     cudaMalloc((void**)&b_device, matrix_size * sizeof(float));     cudaMalloc((void**)&c_device, matrix_size * sizeof(float));           float *a_host = (float *)malloc(matrix_size * sizeof(float));     float *b_host = (float *)malloc(matrix_size * sizeof(float));     for (int i = 0; i < matrix_size; ++i) {         a_host[i] = i + 1.0;          b_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(a_device, a_host, matrix_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, matrix_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((matrix_size + blockDim.x - 1) / blockDim.x);            subtract_matrix<<<gridDim, blockDim>>>(a_device, b_device, c_device, matrix_size);           float *c_result = (float *)malloc(matrix_size * sizeof(float));     cudaMemcpy(c_result, c_device, matrix_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < matrix_size; ++i) {         printf(\"%.2f \", c_result[i]);     }     printf(\"\\n\");           free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   "
    },
    {
        "id": "204",
        "c_code": "#include <stdio.h>   void add_matrix_cpu(float *a, float *b, float *c, int N);  int main() {          int N = 9;     float a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};     float b[] = {9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0};     float c[9];           add_matrix_cpu(a, b, c, N);           printf(\"Resultant matrix after addition:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", c[i]);         if ((i + 1) % 3 == 0) {             printf(\"\\n\");         }     }      return 0; }   void add_matrix_cpu(float *a, float *b, float *c, int N) {     for (int idx = 0; idx < N; idx++) {         c[idx] = a[idx] + b[idx];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void add_matrix(float *a, float *b, float *c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] + b[idx];     } }  int main() {          const int matrix_size = 100;           float *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, matrix_size * sizeof(float));     cudaMalloc((void**)&b_device, matrix_size * sizeof(float));     cudaMalloc((void**)&c_device, matrix_size * sizeof(float));           float *a_host = (float *)malloc(matrix_size * sizeof(float));     float *b_host = (float *)malloc(matrix_size * sizeof(float));     for (int i = 0; i < matrix_size; ++i) {         a_host[i] = i + 1.0;          b_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(a_device, a_host, matrix_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, matrix_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((matrix_size + blockDim.x - 1) / blockDim.x);            add_matrix<<<gridDim, blockDim>>>(a_device, b_device, c_device, matrix_size);           float *c_result = (float *)malloc(matrix_size * sizeof(float));     cudaMemcpy(c_result, c_device, matrix_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < matrix_size; ++i) {         printf(\"%.2f \", c_result[i]);     }     printf(\"\\n\");           free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   "
    },
    {
        "id": "205",
        "c_code": "#include <stdio.h>   void vecAdd_cpu(float *in1, float *in2, float *out, int len);  int main() {          int len = 5;     float in1[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float in2[] = {5.0, 4.0, 3.0, 2.0, 1.0};     float out[5];           vecAdd_cpu(in1, in2, out, len);           printf(\"Resultant vector after addition:\\n\");     for (int i = 0; i < len; i++) {         printf(\"%f \", out[i]);     }      return 0; }   void vecAdd_cpu(float *in1, float *in2, float *out, int len) {     for (int i = 0; i < len; i++) {         out[i] = in1[i] + in2[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void vecAdd(float *in1, float *in2, float *out, int len) {     int i = threadIdx.x + blockDim.x * blockIdx.x;     if (i < len) {         out[i] = in1[i] + in2[i];     } }  int main() {          const int vector_size = 100;           float *in1_device, *in2_device, *out_device;     cudaMalloc((void**)&in1_device, vector_size * sizeof(float));     cudaMalloc((void**)&in2_device, vector_size * sizeof(float));     cudaMalloc((void**)&out_device, vector_size * sizeof(float));           float *in1_host = (float *)malloc(vector_size * sizeof(float));     float *in2_host = (float *)malloc(vector_size * sizeof(float));     for (int i = 0; i < vector_size; ++i) {         in1_host[i] = i + 1.0;          in2_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(in1_device, in1_host, vector_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(in2_device, in2_host, vector_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((vector_size + blockDim.x - 1) / blockDim.x);            vecAdd<<<gridDim, blockDim>>>(in1_device, in2_device, out_device, vector_size);           float *out_result = (float *)malloc(vector_size * sizeof(float));     cudaMemcpy(out_result, out_device, vector_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < vector_size; ++i) {         printf(\"%.2f \", out_result[i]);     }     printf(\"\\n\");           free(in1_host);     free(in2_host);     free(out_result);     cudaFree(in1_device);     cudaFree(in2_device);     cudaFree(out_device);      return 0; }   "
    },
    {
        "id": "206",
        "c_code": "#include <stdio.h>   void doubleArrayScalarAdd_cpu(double *d_in, double *d_out, int length, double scalar);  int main() {          int length = 5;     double d_in[] = {1.0, 2.0, 3.0, 4.0, 5.0};     double d_out[5];     double scalar = 10.0;           doubleArrayScalarAdd_cpu(d_in, d_out, length, scalar);           printf(\"Resultant array after adding scalar:\\n\");     for (int i = 0; i < length; i++) {         printf(\"%f \", d_out[i]);     }      return 0; }   void doubleArrayScalarAdd_cpu(double *d_in, double *d_out, int length, double scalar) {     for (int idx = 0; idx < length; idx++) {         d_out[idx] = d_in[idx] + scalar;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void doubleArrayScalarAddKernel(double *d_in, double *d_out, int length, double scalar) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = d_in[tid] + scalar;     } }  int main() {          const int array_size = 100;           double *d_in_device, *d_out_device;     cudaMalloc((void**)&d_in_device, array_size * sizeof(double));     cudaMalloc((void**)&d_out_device, array_size * sizeof(double));           double *d_in_host = (double *)malloc(array_size * sizeof(double));     for (int i = 0; i < array_size; ++i) {         d_in_host[i] = i + 1.0;      }           cudaMemcpy(d_in_device, d_in_host, array_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            double scalar = 5.0;           doubleArrayScalarAddKernel<<<gridDim, blockDim>>>(d_in_device, d_out_device, array_size, scalar);           double *d_out_result = (double *)malloc(array_size * sizeof(double));     cudaMemcpy(d_out_result, d_out_device, array_size * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", d_out_result[i]);     }     printf(\"\\n\");           free(d_in_host);     free(d_out_result);     cudaFree(d_in_device);     cudaFree(d_out_device);      return 0; }   "
    },
    {
        "id": "207",
        "c_code": "#include <stdio.h>   void add_matrix_cpu(double *a, double *b, double *c, int N);  int main() {          int N = 9;     double a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};     double b[] = {9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0};     double c[9];           add_matrix_cpu(a, b, c, N);           printf(\"Resultant matrix after addition:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", c[i]);         if ((i + 1) % 3 == 0) {             printf(\"\\n\");         }     }      return 0; }   void add_matrix_cpu(double *a, double *b, double *c, int N) {     for (int idx = 0; idx < N; idx++) {         c[idx] = a[idx] + b[idx];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void dadd_matrix(double *a, double *b, double *c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] + b[idx];     } }  int main() {          const int matrix_size = 100;           double *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, matrix_size * sizeof(double));     cudaMalloc((void**)&b_device, matrix_size * sizeof(double));     cudaMalloc((void**)&c_device, matrix_size * sizeof(double));           double *a_host = (double *)malloc(matrix_size * sizeof(double));     double *b_host = (double *)malloc(matrix_size * sizeof(double));     for (int i = 0; i < matrix_size; ++i) {         a_host[i] = i + 1.0;          b_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(a_device, a_host, matrix_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, matrix_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((matrix_size + blockDim.x - 1) / blockDim.x);            dadd_matrix<<<gridDim, blockDim>>>(a_device, b_device, c_device, matrix_size);           double *c_result = (double *)malloc(matrix_size * sizeof(double));     cudaMemcpy(c_result, c_device, matrix_size * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < matrix_size; ++i) {         printf(\"%.2f \", c_result[i]);     }     printf(\"\\n\");           free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   "
    },
    {
        "id": "208",
        "c_code": "#include <stdio.h>   void test1_cpu(float *input, int dims);  int main() {          int dims = 5;     float input[] = {1.0, 2.0, 3.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 10.0};           test1_cpu(input, dims);           printf(\"Resultant array after test1_cpu:\\n\");     for (int i = 0; i < dims * 4; i++) {         printf(\"%f \", input[i]);     }      return 0; }   void test1_cpu(float *input, int dims) {     for (int tid = 0; tid < dims; tid++) {         if (input[tid * 4] != 0) {             input[tid * 4] = 0;         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void test1(float *input, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }     if (input[tid * 4] != 0) {         input[tid * 4] = 0;     } }  int main() {          const int array_size = 100;           float *input_device;     cudaMalloc((void**)&input_device, array_size * 4 * sizeof(float));           float *input_host = (float *)malloc(array_size * 4 * sizeof(float));     for (int i = 0; i < array_size * 4; ++i) {         input_host[i] = i + 1.0;      }           cudaMemcpy(input_device, input_host, array_size * 4 * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            test1<<<gridDim, blockDim>>>(input_device, array_size);           float *output_result = (float *)malloc(array_size * 4 * sizeof(float));     cudaMemcpy(output_result, input_device, array_size * 4 * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size * 4; ++i) {         printf(\"%.2f \", output_result[i]);     }     printf(\"\\n\");           free(input_host);     free(output_result);     cudaFree(input_device);      return 0; }   "
    },
    {
        "id": "209",
        "c_code": "#include <stdio.h>   #define VecSize 5   void vecAddCPU(double *pdbA, double *pdbB, double *pdbC);  int main() {          double pdbA[VecSize] = {1.0, 2.0, 3.0, 4.0, 5.0};     double pdbB[VecSize] = {5.0, 4.0, 3.0, 2.0, 1.0};     double pdbC[VecSize];           vecAddCPU(pdbA, pdbB, pdbC);           printf(\"Resultant vector after addition:\\n\");     for (int i = 0; i < VecSize; i++) {         printf(\"%f \", pdbC[i]);     }      return 0; }   void vecAddCPU(double *pdbA, double *pdbB, double *pdbC) {     for (int i = 0; i < VecSize; ++i) {         pdbC[i] = pdbA[i] + pdbB[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void vecAddGPU(double *pdbA, double *pdbB, double *pdbC) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     pdbC[i] = pdbA[i] + pdbB[i]; }  int main() {          const int vector_size = 100;           double *pdbA_device, *pdbB_device, *pdbC_device;     cudaMalloc((void**)&pdbA_device, vector_size * sizeof(double));     cudaMalloc((void**)&pdbB_device, vector_size * sizeof(double));     cudaMalloc((void**)&pdbC_device, vector_size * sizeof(double));           double *pdbA_host = (double *)malloc(vector_size * sizeof(double));     double *pdbB_host = (double *)malloc(vector_size * sizeof(double));     for (int i = 0; i < vector_size; ++i) {         pdbA_host[i] = i + 1.0;          pdbB_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(pdbA_device, pdbA_host, vector_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(pdbB_device, pdbB_host, vector_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((vector_size + blockDim.x - 1) / blockDim.x);            vecAddGPU<<<gridDim, blockDim>>>(pdbA_device, pdbB_device, pdbC_device);           double *pdbC_result = (double *)malloc(vector_size * sizeof(double));     cudaMemcpy(pdbC_result, pdbC_device, vector_size * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < vector_size; ++i) {         printf(\"%.2f \", pdbC_result[i]);     }     printf(\"\\n\");           free(pdbA_host);     free(pdbB_host);     free(pdbC_result);     cudaFree(pdbA_device);     cudaFree(pdbB_device);     cudaFree(pdbC_device);      return 0; }   "
    },
    {
        "id": "21",
        "c_code": "#include <stdio.h>  void zeroIndices_cpu(long *vec_out, const long N) {     for (int idx = 0; idx < N; idx++) {         vec_out[idx] = vec_out[idx] - vec_out[0];     } }  int main() {          int arraySize = 6;     long vector[arraySize] = {10, 20, 30, 40, 50, 60};      printf(\"\u539f\u59cb\u5411\u91cf\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%ld \", vector[i]);     }           zeroIndices_cpu(vector, arraySize);      printf(\"\\n\u96f6\u5316\u540e\u7684\u5411\u91cf\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%ld \", vector[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void zeroIndices(long* vec_out, const long N) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;     if (idx < N) {         vec_out[idx] = vec_out[idx] - vec_out[0];     } }  int main() {          long arraySize = 1000;           long* h_vec_out = (long*)malloc(arraySize * sizeof(long));           for (long i = 0; i < arraySize; ++i) {         h_vec_out[i] = static_cast<long>(i);     }           long* d_vec_out;     cudaMalloc((void**)&d_vec_out, arraySize * sizeof(long));           cudaMemcpy(d_vec_out, h_vec_out, arraySize * sizeof(long), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           zeroIndices<<<gridSize, blockSize>>>(d_vec_out, arraySize);           cudaMemcpy(h_vec_out, d_vec_out, arraySize * sizeof(long), cudaMemcpyDeviceToHost);           for (long i = 0; i < 10; ++i) {         printf(\"%ld \", h_vec_out[i]);     }           free(h_vec_out);     cudaFree(d_vec_out);      return 0; } "
    },
    {
        "id": "210",
        "c_code": "#include <stdio.h>   void doubleArrayScalarMultiply_cpu(double *d_in, double *d_out, int length, double scalar);  int main() {          int length = 5;     double d_in[] = {1.0, 2.0, 3.0, 4.0, 5.0};     double d_out[5];     double scalar = 2.0;           doubleArrayScalarMultiply_cpu(d_in, d_out, length, scalar);           printf(\"Resultant array after scalar multiplication:\\n\");     for (int i = 0; i < length; i++) {         printf(\"%f \", d_out[i]);     }      return 0; }   void doubleArrayScalarMultiply_cpu(double *d_in, double *d_out, int length, double scalar) {     for (int idx = 0; idx < length; idx++) {         d_out[idx] = d_in[idx] * scalar;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void doubleArrayScalarMultiplyKernel(double *d_in, double *d_out, int length, double scalar) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = d_in[tid] * scalar;     } }  int main() {          const int array_size = 100;           double *d_in_device, *d_out_device;     cudaMalloc((void**)&d_in_device, array_size * sizeof(double));     cudaMalloc((void**)&d_out_device, array_size * sizeof(double));           double *d_in_host = (double *)malloc(array_size * sizeof(double));     for (int i = 0; i < array_size; ++i) {         d_in_host[i] = i + 1.0;      }           cudaMemcpy(d_in_device, d_in_host, array_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            double scalar = 2.0;           doubleArrayScalarMultiplyKernel<<<gridDim, blockDim>>>(d_in_device, d_out_device, array_size, scalar);           double *d_out_result = (double *)malloc(array_size * sizeof(double));     cudaMemcpy(d_out_result, d_out_device, array_size * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", d_out_result[i]);     }     printf(\"\\n\");           free(d_in_host);     free(d_out_result);     cudaFree(d_in_device);     cudaFree(d_out_device);      return 0; }   "
    },
    {
        "id": "211",
        "c_code": "#include <stdio.h>   void addV_cpu(int *a, int *b, int *c, int N);  int main() {          int N = 5;     int a[] = {1, 2, 3, 4, 5};     int b[] = {5, 4, 3, 2, 1};     int c[5];           addV_cpu(a, b, c, N);           printf(\"Resultant array after addition:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%d \", c[i]);     }      return 0; }   void addV_cpu(int *a, int *b, int *c, int N) {     for (int index = 0; index < N; index++) {         c[index] = a[index] + b[index];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void addV(int *a, int *b, int *c, int N) {     int index = threadIdx.x + blockIdx.x * blockDim.x;     if (index < N) {         c[index] = a[index] + b[index];     } }  int main() {          const int array_size = 100;           int *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, array_size * sizeof(int));     cudaMalloc((void**)&b_device, array_size * sizeof(int));     cudaMalloc((void**)&c_device, array_size * sizeof(int));           int *a_host = (int *)malloc(array_size * sizeof(int));     int *b_host = (int *)malloc(array_size * sizeof(int));     for (int i = 0; i < array_size; ++i) {         a_host[i] = i + 1;          b_host[i] = (i + 1) * 2;      }           cudaMemcpy(a_device, a_host, array_size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, array_size * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            addV<<<gridDim, blockDim>>>(a_device, b_device, c_device, array_size);           int *c_result = (int *)malloc(array_size * sizeof(int));     cudaMemcpy(c_result, c_device, array_size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%d \", c_result[i]);     }     printf(\"\\n\");           free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   "
    },
    {
        "id": "212",
        "c_code": "#include <stdio.h>   void VecAdd_cpu(float *A, float *B, float *C, int N);  int main() {          int N = 5;     float A[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float B[] = {5.0, 4.0, 3.0, 2.0, 1.0};     float C[5];           VecAdd_cpu(A, B, C, N);           printf(\"Resultant array after addition:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", C[i]);     }      return 0; }   void VecAdd_cpu(float *A, float *B, float *C, int N) {     for (int i = 0; i < N; i++) {         C[i] = A[i] + B[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void VecAdd(float *A, float *B, float *C, int N) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < N) {         C[i] = A[i] + B[i];     } }  int main() {          const int array_size = 100;           float *A_device, *B_device, *C_device;     cudaMalloc((void**)&A_device, array_size * sizeof(float));     cudaMalloc((void**)&B_device, array_size * sizeof(float));     cudaMalloc((void**)&C_device, array_size * sizeof(float));           float *A_host = (float *)malloc(array_size * sizeof(float));     float *B_host = (float *)malloc(array_size * sizeof(float));     for (int i = 0; i < array_size; ++i) {         A_host[i] = i + 1.0;          B_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(A_device, A_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(B_device, B_host, array_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            VecAdd<<<gridDim, blockDim>>>(A_device, B_device, C_device, array_size);           float *C_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(C_result, C_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", C_result[i]);     }     printf(\"\\n\");           free(A_host);     free(B_host);     free(C_result);     cudaFree(A_device);     cudaFree(B_device);     cudaFree(C_device);      return 0; }   "
    },
    {
        "id": "213",
        "c_code": "#include <stdio.h>   void saxpy_cpu(float *x, float *y, float alpha, int n);  int main() {          int n = 5;     float x[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float y[] = {5.0, 4.0, 3.0, 2.0, 1.0};     float alpha = 2.0;           saxpy_cpu(x, y, alpha, n);           printf(\"Resultant vector after saxpy operation:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%f \", y[i]);     }      return 0; }   void saxpy_cpu(float *x, float *y, float alpha, int n) {     for (int i = 0; i < n; i++) {         y[i] = alpha * x[i] + y[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void saxpy_gpu_kernel(float *x, float *y, float alpha, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         y[i] = alpha * x[i] + y[i];     } }  int main() {          const int array_size = 100;           float *x_device, *y_device;     cudaMalloc((void**)&x_device, array_size * sizeof(float));     cudaMalloc((void**)&y_device, array_size * sizeof(float));           float *x_host = (float *)malloc(array_size * sizeof(float));     float *y_host = (float *)malloc(array_size * sizeof(float));     for (int i = 0; i < array_size; ++i) {         x_host[i] = i + 1.0;          y_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(x_device, x_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(y_device, y_host, array_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            float alpha = 0.5;           saxpy_gpu_kernel<<<gridDim, blockDim>>>(x_device, y_device, alpha, array_size);           float *y_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(y_result, y_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", y_result[i]);     }     printf(\"\\n\");           free(x_host);     free(y_host);     free(y_result);     cudaFree(x_device);     cudaFree(y_device);      return 0; }   "
    },
    {
        "id": "214",
        "c_code": "#include <stdio.h>   void sumArrays_cpu(float *A, float *B, float *C, const int N);  int main() {          const int N = 5;     float A[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float B[] = {5.0, 4.0, 3.0, 2.0, 1.0};     float C[5];           sumArrays_cpu(A, B, C, N);           printf(\"Resultant array after sumArrays_cpu:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", C[i]);     }      return 0; }   void sumArrays_cpu(float *A, float *B, float *C, const int N) {     for (int i = 0; i < N; i++) {         C[i] = A[i] + B[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void sumArrays(float *A, float *B, float *C, const int N) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < N) {         C[i] = A[i] + B[i];     } }  int main() {          const int array_size = 100;           float *A_device, *B_device, *C_device;     cudaMalloc((void**)&A_device, array_size * sizeof(float));     cudaMalloc((void**)&B_device, array_size * sizeof(float));     cudaMalloc((void**)&C_device, array_size * sizeof(float));           float *A_host = (float *)malloc(array_size * sizeof(float));     float *B_host = (float *)malloc(array_size * sizeof(float));     for (int i = 0; i < array_size; ++i) {         A_host[i] = i + 1.0;          B_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(A_device, A_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(B_device, B_host, array_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            sumArrays<<<gridDim, blockDim>>>(A_device, B_device, C_device, array_size);           float *C_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(C_result, C_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", C_result[i]);     }     printf(\"\\n\");           free(A_host);     free(B_host);     free(C_result);     cudaFree(A_device);     cudaFree(B_device);     cudaFree(C_device);      return 0; }   "
    },
    {
        "id": "215",
        "c_code": "#include <stdio.h>   void doubleArrayScalarSubstract_cpu(double *d_in, double *d_out, int length, double scalar);  int main() {          int length = 5;     double d_in[] = {1.0, 2.0, 3.0, 4.0, 5.0};     double d_out[5];     double scalar = 2.0;           doubleArrayScalarSubstract_cpu(d_in, d_out, length, scalar);           printf(\"Resultant array after scalar subtraction:\\n\");     for (int i = 0; i < length; i++) {         printf(\"%f \", d_out[i]);     }      return 0; }   void doubleArrayScalarSubstract_cpu(double *d_in, double *d_out, int length, double scalar) {     for (int idx = 0; idx < length; idx++) {         d_out[idx] = d_in[idx] - scalar;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void doubleArrayScalarSubtractKernel(double *d_in, double *d_out, int length, double scalar) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = d_in[tid] - scalar;     } }  int main() {          const int array_size = 100;           double *d_in_device, *d_out_device;     cudaMalloc((void**)&d_in_device, array_size * sizeof(double));     cudaMalloc((void**)&d_out_device, array_size * sizeof(double));           double *d_in_host = (double *)malloc(array_size * sizeof(double));     for (int i = 0; i < array_size; ++i) {         d_in_host[i] = i + 1.0;      }           cudaMemcpy(d_in_device, d_in_host, array_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            double scalar = 2.0;           doubleArrayScalarSubtractKernel<<<gridDim, blockDim>>>(d_in_device, d_out_device, array_size, scalar);           double *d_out_result = (double *)malloc(array_size * sizeof(double));     cudaMemcpy(d_out_result, d_out_device, array_size * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", d_out_result[i]);     }     printf(\"\\n\");           free(d_in_host);     free(d_out_result);     cudaFree(d_in_device);     cudaFree(d_out_device);      return 0; }   "
    },
    {
        "id": "216",
        "c_code": "#include <stdio.h>   void doubleArrayElementwiseSquare_cpu(double *d_in, double *d_out, int length);  int main() {          int length = 5;     double d_in[] = {1.0, 2.0, 3.0, 4.0, 5.0};     double d_out[5];           doubleArrayElementwiseSquare_cpu(d_in, d_out, length);           printf(\"Resultant array after elementwise square:\\n\");     for (int i = 0; i < length; i++) {         printf(\"%f \", d_out[i]);     }      return 0; }   void doubleArrayElementwiseSquare_cpu(double *d_in, double *d_out, int length) {     for (int idx = 0; idx < length; idx++) {         d_out[idx] = d_in[idx] * d_in[idx];     } }   ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void doubleArrayElementwiseSquareKernel(double *d_in, double *d_out, int length) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = pow(d_in[tid], 2);     } }  int main() {          const int array_size = 100;           double *d_in_device, *d_out_device;     cudaMalloc((void**)&d_in_device, array_size * sizeof(double));     cudaMalloc((void**)&d_out_device, array_size * sizeof(double));           double *d_in_host = (double *)malloc(array_size * sizeof(double));     for (int i = 0; i < array_size; ++i) {         d_in_host[i] = i + 1.0;      }           cudaMemcpy(d_in_device, d_in_host, array_size * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            doubleArrayElementwiseSquareKernel<<<gridDim, blockDim>>>(d_in_device, d_out_device, array_size);           double *d_out_result = (double *)malloc(array_size * sizeof(double));     cudaMemcpy(d_out_result, d_out_device, array_size * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", d_out_result[i]);     }     printf(\"\\n\");           free(d_in_host);     free(d_out_result);     cudaFree(d_in_device);     cudaFree(d_out_device);      return 0; }   "
    },
    {
        "id": "217",
        "c_code": "#include <stdio.h>   void sumArraysOnHostx(int *A, int *B, int *C, const int N);  int main() {          const int N = 5;     int A[] = {1, 2, 3, 4, 5};     int B[] = {5, 4, 3, 2, 1};     int C[5];           sumArraysOnHostx(A, B, C, N);           printf(\"Resultant array after sumArraysOnHostx:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%d \", C[i]);     }      return 0; }   void sumArraysOnHostx(int *A, int *B, int *C, const int N) {     for (int idx = 0; idx < N; idx++) {         C[idx] = A[idx] + B[idx];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void sum_array_overlap(int *a, int *b, int *c, int N) {     int gid = blockIdx.x * blockDim.x + threadIdx.x;     if (gid < N) {         c[gid] = a[gid] + b[gid];     } }  int main() {          const int array_size = 100;           int *a_device, *b_device, *c_device;     cudaMalloc((void**)&a_device, array_size * sizeof(int));     cudaMalloc((void**)&b_device, array_size * sizeof(int));     cudaMalloc((void**)&c_device, array_size * sizeof(int));           int *a_host = (int *)malloc(array_size * sizeof(int));     int *b_host = (int *)malloc(array_size * sizeof(int));     for (int i = 0; i < array_size; ++i) {         a_host[i] = i + 1;          b_host[i] = (i + 1) * 2;      }           cudaMemcpy(a_device, a_host, array_size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(b_device, b_host, array_size * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            sum_array_overlap<<<gridDim, blockDim>>>(a_device, b_device, c_device, array_size);           int *c_result = (int *)malloc(array_size * sizeof(int));     cudaMemcpy(c_result, c_device, array_size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%d \", c_result[i]);     }     printf(\"\\n\");           free(a_host);     free(b_host);     free(c_result);     cudaFree(a_device);     cudaFree(b_device);     cudaFree(c_device);      return 0; }   "
    },
    {
        "id": "218",
        "c_code": "#include <stdio.h>   void k_vec_divide(float *vec1, float *vec2, int max_size);  int main() {          const int max_size = 5;     float vec1[] = {10.0, 20.0, 30.0, 40.0, 50.0};     float vec2[] = {2.0, 4.0, 5.0, 8.0, 10.0};           k_vec_divide(vec1, vec2, max_size);           printf(\"Resultant vector after elementwise division:\\n\");     for (int i = 0; i < max_size; i++) {         printf(\"%f \", vec1[i]);     }      return 0; }   void k_vec_divide(float *vec1, float *vec2, int max_size) {     for (int i = 0; i < max_size; i++) {         vec1[i] = vec1[i] / vec2[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void k_vec_divide(float *vec1, float *vec2, size_t max_size) {     for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < max_size; i += blockDim.x * gridDim.x) {         vec1[i] = vec1[i] / vec2[i];     } }  int main() {          const size_t array_size = 100;           float *vec1_device, *vec2_device;     cudaMalloc((void**)&vec1_device, array_size * sizeof(float));     cudaMalloc((void**)&vec2_device, array_size * sizeof(float));           float *vec1_host = (float *)malloc(array_size * sizeof(float));     float *vec2_host = (float *)malloc(array_size * sizeof(float));     for (size_t i = 0; i < array_size; ++i) {         vec1_host[i] = i + 1.0;          vec2_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(vec1_device, vec1_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(vec2_device, vec2_host, array_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            k_vec_divide<<<gridDim, blockDim>>>(vec1_device, vec2_device, array_size);           float *vec1_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(vec1_result, vec1_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (size_t i = 0; i < array_size; ++i) {         printf(\"%.2f \", vec1_result[i]);     }     printf(\"\\n\");           free(vec1_host);     free(vec2_host);     free(vec1_result);     cudaFree(vec1_device);     cudaFree(vec2_device);      return 0; }   "
    },
    {
        "id": "219",
        "c_code": "#include <stdio.h>   void saxpi_c(int n, float a, float *x, float *y);  int main() {          const int n = 5;     float a = 2.0;     float x[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float y[] = {5.0, 4.0, 3.0, 2.0, 1.0};           saxpi_c(n, a, x, y);           printf(\"Resultant vector after saxpi_c operation:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%f \", y[i]);     }      return 0; }   void saxpi_c(int n, float a, float *x, float *y) {     for (int i = 0; i < n; i++) {         y[i] = a * x[i] + y[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void saxpi_nBlock(int n, float a, float *x, float *y) {     int idx = threadIdx.x + (blockIdx.x * blockDim.x);     if (idx < n) {         y[idx] = a * x[idx] + y[idx];     } }  int main() {          const int array_size = 100;           float *x_device, *y_device;     cudaMalloc((void**)&x_device, array_size * sizeof(float));     cudaMalloc((void**)&y_device, array_size * sizeof(float));           float *x_host = (float *)malloc(array_size * sizeof(float));     float *y_host = (float *)malloc(array_size * sizeof(float));     for (int i = 0; i < array_size; ++i) {         x_host[i] = i + 1.0;          y_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(x_device, x_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(y_device, y_host, array_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            float a = 0.5;           saxpi_nBlock<<<gridDim, blockDim>>>(array_size, a, x_device, y_device);           float *y_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(y_result, y_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", y_result[i]);     }     printf(\"\\n\");           free(x_host);     free(y_host);     free(y_result);     cudaFree(x_device);     cudaFree(y_device);      return 0; }   "
    },
    {
        "id": "22",
        "c_code": "#include <stdio.h>  void saxpy_serial(const int dim, float a, float *x, float *y) {     for (int i = 0; i < dim; i++) {         y[i] += a * x[i];     } }  int main() {          int vectorSize = 5;     float vectorX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float vectorY[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float alpha = 2.0;      printf(\"\u5411\u91cf X\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorX[i]);     }      printf(\"\\n\u5411\u91cf Y\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorY[i]);     }           saxpy_serial(vectorSize, alpha, vectorX, vectorY);      printf(\"\\nSAXPY \u540e\u7684\u5411\u91cf Y\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorY[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void saxpy_gpu(const int dim, float a, float* x, float* y) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < dim) {         y[i] = a * x[i] + y[i];     } }  int main() {          int arraySize = 1000;           float a = 2.0;     float* h_x = (float*)malloc(arraySize * sizeof(float));     float* h_y = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_x[i] = static_cast<float>(i);         h_y[i] = static_cast<float>(2 * i);     }           float* d_x;     float* d_y;     cudaMalloc((void**)&d_x, arraySize * sizeof(float));     cudaMalloc((void**)&d_y, arraySize * sizeof(float));           cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_y, h_y, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           saxpy_gpu<<<gridSize, blockSize>>>(arraySize, a, d_x, d_y);           cudaMemcpy(h_y, d_y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_y[i]);     }           free(h_x);     free(h_y);     cudaFree(d_x);     cudaFree(d_y);      return 0; } "
    },
    {
        "id": "220",
        "c_code": "#include <stdio.h>   void cpu_record(float *p, float *seis_kt, int *Gxz, int ng);  int main() {          const int ng = 5;     float p[] = {1.0, 2.0, 3.0, 4.0, 5.0};     int Gxz[] = {0, 2, 4, 1, 3};     float seis_kt[5];           cpu_record(p, seis_kt, Gxz, ng);           printf(\"Resultant array after cpu_record:\\n\");     for (int i = 0; i < ng; i++) {         printf(\"%f \", seis_kt[i]);     }      return 0; }   void cpu_record(float *p, float *seis_kt, int *Gxz, int ng) {     for (int id = 0; id < ng; id++) {         seis_kt[id] = p[Gxz[id]];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void cuda_record(float *p, float *seis_kt, int *Gxz, int ng) {     int id = threadIdx.x + blockDim.x * blockIdx.x;     if (id < ng) {         seis_kt[id] = p[Gxz[id]];     } }  int main() {          const int array_size = 100;           float *p_device, *seis_kt_device;     int *Gxz_device;      cudaMalloc((void**)&p_device, array_size * sizeof(float));     cudaMalloc((void**)&seis_kt_device, array_size * sizeof(float));     cudaMalloc((void**)&Gxz_device, array_size * sizeof(int));           float *p_host = (float *)malloc(array_size * sizeof(float));     float *seis_kt_host = (float *)malloc(array_size * sizeof(float));     int *Gxz_host = (int *)malloc(array_size * sizeof(int));      for (int i = 0; i < array_size; ++i) {         p_host[i] = i + 1.0;          seis_kt_host[i] = 0.0;          Gxz_host[i] = i % array_size;      }           cudaMemcpy(p_device, p_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(seis_kt_device, seis_kt_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(Gxz_device, Gxz_host, array_size * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            cuda_record<<<gridDim, blockDim>>>(p_device, seis_kt_device, Gxz_device, array_size);           float *seis_kt_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(seis_kt_result, seis_kt_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", seis_kt_result[i]);     }     printf(\"\\n\");           free(p_host);     free(seis_kt_host);     free(Gxz_host);     free(seis_kt_result);     cudaFree(p_device);     cudaFree(seis_kt_device);     cudaFree(Gxz_device);      return 0; }   "
    },
    {
        "id": "221",
        "c_code": "#include <stdio.h>   void vectorDiv(const float *A, const float *B, float *C, int numElements);  int main() {          const int numElements = 5;     float A[] = {10.0, 20.0, 30.0, 40.0, 50.0};     float B[] = {2.0, 4.0, 5.0, 8.0, 10.0};     float C[5];           vectorDiv(A, B, C, numElements);           printf(\"Resultant array after elementwise division:\\n\");     for (int i = 0; i < numElements; i++) {         printf(\"%f \", C[i]);     }      return 0; }   void vectorDiv(const float *A, const float *B, float *C, int numElements) {     for (int i = 0; i < numElements; i++) {         C[i] = A[i] / B[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void vectorDiv(const float *A, const float *B, float *C, int numElements) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < numElements) {         C[i] = A[i] / B[i];     } }  int main() {          const int array_size = 100;           float *A_device, *B_device, *C_device;      cudaMalloc((void**)&A_device, array_size * sizeof(float));     cudaMalloc((void**)&B_device, array_size * sizeof(float));     cudaMalloc((void**)&C_device, array_size * sizeof(float));           float *A_host = (float *)malloc(array_size * sizeof(float));     float *B_host = (float *)malloc(array_size * sizeof(float));     float *C_host = (float *)malloc(array_size * sizeof(float));      for (int i = 0; i < array_size; ++i) {         A_host[i] = i + 1.0;          B_host[i] = (i + 1.0) * 2.0;          C_host[i] = 0.0;      }           cudaMemcpy(A_device, A_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(B_device, B_host, array_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            vectorDiv<<<gridDim, blockDim>>>(A_device, B_device, C_device, array_size);           cudaMemcpy(C_host, C_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", C_host[i]);     }     printf(\"\\n\");           free(A_host);     free(B_host);     free(C_host);     cudaFree(A_device);     cudaFree(B_device);     cudaFree(C_device);      return 0; }   "
    },
    {
        "id": "222",
        "c_code": "#include <stdio.h>   void cpuSAXPY(int len, float a, float *x, float *y);  int main() {          const int len = 5;     float a = 2.0;     float x[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float y[] = {5.0, 4.0, 3.0, 2.0, 1.0};           cpuSAXPY(len, a, x, y);           printf(\"Resultant vector after cpuSAXPY operation:\\n\");     for (int i = 0; i < len; i++) {         printf(\"%f \", y[i]);     }      return 0; }   void cpuSAXPY(int len, float a, float *x, float *y) {     for (int i = 0; i < len; i++) {         y[i] = x[i] * a + y[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void kernelSAXPY(int len, float a, float *d_x, float *d_y) {     const int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < len) {         d_y[i] = d_x[i] * a + d_y[i];     } }  int main() {          const int array_size = 100;           float *d_x, *d_y;      cudaMalloc((void**)&d_x, array_size * sizeof(float));     cudaMalloc((void**)&d_y, array_size * sizeof(float));           float *h_x = (float *)malloc(array_size * sizeof(float));     float *h_y = (float *)malloc(array_size * sizeof(float));      for (int i = 0; i < array_size; ++i) {         h_x[i] = i + 1.0;          h_y[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(d_x, h_x, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_y, h_y, array_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            float a = 0.5;           kernelSAXPY<<<gridDim, blockDim>>>(array_size, a, d_x, d_y);           float *h_result = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(h_result, d_y, array_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", h_result[i]);     }     printf(\"\\n\");           free(h_x);     free(h_y);     free(h_result);     cudaFree(d_x);     cudaFree(d_y);      return 0; }   "
    },
    {
        "id": "223",
        "c_code": "#include <stdio.h>   void vectorAdd(const float *A, const float *B, float *C, int numElements);  int main() {          const int numElements = 5;     float A[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float B[] = {5.0, 4.0, 3.0, 2.0, 1.0};     float C[5];           vectorAdd(A, B, C, numElements);           printf(\"Resultant array after elementwise addition:\\n\");     for (int i = 0; i < numElements; i++) {         printf(\"%f \", C[i]);     }      return 0; }   void vectorAdd(const float *A, const float *B, float *C, int numElements) {     for (int i = 0; i < numElements; i++) {         C[i] = A[i] + B[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void vectorAdd(const float *A, const float *B, float *C, int numElements) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < numElements) {         C[i] = A[i] + B[i];     } }  int main() {          const int array_size = 100;           float *A_device, *B_device, *C_device;      cudaMalloc((void**)&A_device, array_size * sizeof(float));     cudaMalloc((void**)&B_device, array_size * sizeof(float));     cudaMalloc((void**)&C_device, array_size * sizeof(float));           float *A_host = (float *)malloc(array_size * sizeof(float));     float *B_host = (float *)malloc(array_size * sizeof(float));      for (int i = 0; i < array_size; ++i) {         A_host[i] = i + 1.0;          B_host[i] = (i + 1.0) * 2.0;      }           cudaMemcpy(A_device, A_host, array_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(B_device, B_host, array_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockDim(256);      dim3 gridDim((array_size + blockDim.x - 1) / blockDim.x);            vectorAdd<<<gridDim, blockDim>>>(A_device, B_device, C_device, array_size);           float *C_host = (float *)malloc(array_size * sizeof(float));     cudaMemcpy(C_host, C_device, array_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result after CUDA kernel execution:\\n\");     for (int i = 0; i < array_size; ++i) {         printf(\"%.2f \", C_host[i]);     }     printf(\"\\n\");           free(A_host);     free(B_host);     free(C_host);     cudaFree(A_device);     cudaFree(B_device);     cudaFree(C_device);      return 0; }   "
    },
    {
        "id": "224",
        "c_code": "#include <stdio.h>   void vectorAdd(double *a, double *b, double *c, int vector_size);  int main() {          const int vector_size = 5;     double a[] = {1.0, 2.0, 3.0, 4.0, 5.0};     double b[] = {5.0, 4.0, 3.0, 2.0, 1.0};     double c[5];           vectorAdd(a, b, c, vector_size);           printf(\"Resultant array after elementwise addition:\\n\");     for (int i = 0; i < vector_size; i++) {         printf(\"%f \", c[i]);     }      return 0; }   void vectorAdd(double *a, double *b, double *c, int vector_size) {     for (int idx = 0; idx < vector_size; idx++) {         c[idx] = a[idx] + b[idx];     } }   ",
        "cuda_code": "#include <iostream>   __global__ void vectorAdd(double* a, double* b, double* c, int vector_size) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < vector_size) {         c[tid] = a[tid] + b[tid];     } }  int main() {          int vector_size = 100;            double *h_a, *h_b, *h_c;     h_a = new double[vector_size];     h_b = new double[vector_size];     h_c = new double[vector_size];           for (int i = 0; i < vector_size; ++i) {         h_a[i] = i;         h_b[i] = i * 2;     }           double *d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, vector_size * sizeof(double));     cudaMalloc((void**)&d_b, vector_size * sizeof(double));     cudaMalloc((void**)&d_c, vector_size * sizeof(double));           cudaMemcpy(d_a, h_a, vector_size * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, vector_size * sizeof(double), cudaMemcpyHostToDevice);           int block_size = 256;     int grid_size = (vector_size + block_size - 1) / block_size;           vectorAdd<<<grid_size, block_size>>>(d_a, d_b, d_c, vector_size);           cudaMemcpy(h_c, d_c, vector_size * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < vector_size; ++i) {         std::cout << h_c[i] << \" \";     }     std::cout << std::endl;           delete[] h_a;     delete[] h_b;     delete[] h_c;     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   "
    },
    {
        "id": "225",
        "c_code": "#include <stdio.h>   void addIntValues(int *destination, int *value1, int *value2, unsigned int end);  int main() {          const unsigned int end = 5;     int value1[] = {1, 2, 3, 4, 5};     int value2[] = {5, 4, 3, 2, 1};     int destination[5];           addIntValues(destination, value1, value2, end);           printf(\"Resultant array after elementwise addition of integers:\\n\");     for (unsigned int i = 0; i < end; i++) {         printf(\"%d \", destination[i]);     }      return 0; }   void addIntValues(int *destination, int *value1, int *value2, unsigned int end) {     for (unsigned int i = 0; i < end; i++) {         destination[i] = value1[i] + value2[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void intAdd(int* c, const int* a, const int* b, const unsigned int d) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     if (i < d) {         c[i] = a[i] + b[i];     } }  int main() {          unsigned int vector_size = 100;            int *h_a, *h_b, *h_c;     h_a = (int*)malloc(vector_size * sizeof(int));     h_b = (int*)malloc(vector_size * sizeof(int));     h_c = (int*)malloc(vector_size * sizeof(int));           for (unsigned int i = 0; i < vector_size; ++i) {         h_a[i] = i;         h_b[i] = i * 2;     }           int *d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, vector_size * sizeof(int));     cudaMalloc((void**)&d_b, vector_size * sizeof(int));     cudaMalloc((void**)&d_c, vector_size * sizeof(int));           cudaMemcpy(d_a, h_a, vector_size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, vector_size * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     int grid_size = (vector_size + block_size - 1) / block_size;           intAdd<<<grid_size, block_size>>>(d_c, d_a, d_b, vector_size);           cudaMemcpy(h_c, d_c, vector_size * sizeof(int), cudaMemcpyDeviceToHost);           for (unsigned int i = 0; i < vector_size; ++i) {         printf(\"%d \", h_c[i]);     }     printf(\"\\n\");           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   "
    },
    {
        "id": "226",
        "c_code": "#include <stdio.h>   void histo_cpu(const unsigned int *const vals, unsigned int *const histo, int numVals);  int main() {          const int numVals = 10;     unsigned int vals[] = {1, 2, 3, 4, 5, 1, 2, 3, 4, 5};     unsigned int histo[6] = {0};           histo_cpu(vals, histo, numVals);           printf(\"Histogram result:\\n\");     for (int i = 0; i < 6; i++) {         printf(\"Value %d: %d occurrences\\n\", i, histo[i]);     }      return 0; }   void histo_cpu(const unsigned int *const vals, unsigned int *const histo, int numVals) {     for (int i = 0; i < numVals; i++) {         histo[vals[i]] = histo[vals[i]] + 1;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void histo_atomic(const unsigned int* const vals, unsigned int* const histo, int numVals) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     if (i >= numVals)         return;     atomicAdd(&histo[vals[i]], 1); }  int main() {          int numVals = 100;            unsigned int* h_vals;     unsigned int* h_histo;     h_vals = (unsigned int*)malloc(numVals * sizeof(unsigned int));     h_histo = (unsigned int*)malloc(numVals * sizeof(unsigned int));           for (int i = 0; i < numVals; ++i) {         h_vals[i] = i % numVals;      }           unsigned int* d_vals;     unsigned int* d_histo;     cudaMalloc((void**)&d_vals, numVals * sizeof(unsigned int));     cudaMalloc((void**)&d_histo, numVals * sizeof(unsigned int));           cudaMemcpy(d_vals, h_vals, numVals * sizeof(unsigned int), cudaMemcpyHostToDevice);           cudaMemset(d_histo, 0, numVals * sizeof(unsigned int));           int block_size = 256;     dim3 grid_size((numVals + block_size - 1) / block_size, 1);           histo_atomic<<<grid_size, block_size>>>(d_vals, d_histo, numVals);           cudaMemcpy(h_histo, d_histo, numVals * sizeof(unsigned int), cudaMemcpyDeviceToHost);           for (int i = 0; i < numVals; ++i) {         printf(\"%u \", h_histo[i]);     }     printf(\"\\n\");           free(h_vals);     free(h_histo);     cudaFree(d_vals);     cudaFree(d_histo);      return 0; } "
    },
    {
        "id": "227",
        "c_code": "#include <stdio.h>   void vadd(const float *a, const float *b, float *c, const unsigned int count);  int main() {          const unsigned int count = 5;     float a[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float b[] = {5.0, 4.0, 3.0, 2.0, 1.0};     float c[5];           vadd(a, b, c, count);           printf(\"Resultant array after elementwise addition:\\n\");     for (unsigned int i = 0; i < count; i++) {         printf(\"%f \", c[i]);     }      return 0; }   void vadd(const float *a, const float *b, float *c, const unsigned int count) {     for (unsigned int i = 0; i < count; i++) {         c[i] = a[i] + b[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void vadd(const float* a, const float* b, float* c, const unsigned int count) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < count) {         c[i] = a[i] + b[i];     } }  int main() {          unsigned int vector_size = 100;            float *h_a, *h_b, *h_c;     h_a = (float*)malloc(vector_size * sizeof(float));     h_b = (float*)malloc(vector_size * sizeof(float));     h_c = (float*)malloc(vector_size * sizeof(float));           for (unsigned int i = 0; i < vector_size; ++i) {         h_a[i] = i * 1.5f;          h_b[i] = i * 2.0f;      }           float *d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, vector_size * sizeof(float));     cudaMalloc((void**)&d_b, vector_size * sizeof(float));     cudaMalloc((void**)&d_c, vector_size * sizeof(float));           cudaMemcpy(d_a, h_a, vector_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, vector_size * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     int grid_size = (vector_size + block_size - 1) / block_size;           vadd<<<grid_size, block_size>>>(d_a, d_b, d_c, vector_size);           cudaMemcpy(h_c, d_c, vector_size * sizeof(float), cudaMemcpyDeviceToHost);           for (unsigned int i = 0; i < vector_size; ++i) {         printf(\"%f \", h_c[i]);     }     printf(\"\\n\");           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   "
    },
    {
        "id": "228",
        "c_code": "#include <stdio.h>   void subtractIntValues(int *destination, int *value1, int *value2, unsigned int end);  int main() {          const unsigned int end = 5;     int value1[] = {10, 8, 6, 4, 2};     int value2[] = {5, 4, 3, 2, 1};     int destination[5];           subtractIntValues(destination, value1, value2, end);           printf(\"Resultant array after elementwise subtraction of integers:\\n\");     for (unsigned int i = 0; i < end; i++) {         printf(\"%d \", destination[i]);     }      return 0; }   void subtractIntValues(int *destination, int *value1, int *value2, unsigned int end) {     for (unsigned int i = 0; i < end; i++) {         destination[i] = value1[i] - value2[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void intSubtract(int* c, const int* a, const int* b, const unsigned int d) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     if (i < d) {         c[i] = a[i] - b[i];     } }  int main() {          unsigned int vector_size = 100;            int *h_a, *h_b, *h_c;     h_a = (int*)malloc(vector_size * sizeof(int));     h_b = (int*)malloc(vector_size * sizeof(int));     h_c = (int*)malloc(vector_size * sizeof(int));           for (unsigned int i = 0; i < vector_size; ++i) {         h_a[i] = i * 2;          h_b[i] = i;          }           int *d_a, *d_b, *d_c;     cudaMalloc((void**)&d_a, vector_size * sizeof(int));     cudaMalloc((void**)&d_b, vector_size * sizeof(int));     cudaMalloc((void**)&d_c, vector_size * sizeof(int));           cudaMemcpy(d_a, h_a, vector_size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, vector_size * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     int grid_size = (vector_size + block_size - 1) / block_size;           intSubtract<<<grid_size, block_size>>>(d_c, d_a, d_b, vector_size);           cudaMemcpy(h_c, d_c, vector_size * sizeof(int), cudaMemcpyDeviceToHost);           for (unsigned int i = 0; i < vector_size; ++i) {         printf(\"%d \", h_c[i]);     }     printf(\"\\n\");           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   "
    },
    {
        "id": "229",
        "c_code": "#include <stdio.h>   void transferMBR3_cpu(double *xy_copy, long long *a_copy, int tasks);  int main() {          const int tasks = 5;     double xy_copy[] = {1.5, 2.5, 3.5, 4.5, 5.5};     long long a_copy[5];           transferMBR3_cpu(xy_copy, a_copy, tasks);           printf(\"Resultant array after transferMBR3_cpu:\\n\");     for (int i = 0; i < tasks; i++) {         printf(\"%lld \", a_copy[i]);     }      return 0; }   void transferMBR3_cpu(double *xy_copy, long long *a_copy, int tasks) {     for (int i = 0; i < tasks; i++) {         a_copy[i] = xy_copy[i] * 10000000;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void transferMBR3(double* xy_copy, long long* a_copy, int tasks) {     for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < tasks; i += blockDim.x * gridDim.x) {         a_copy[i] = static_cast<long long>(xy_copy[i] * 10000000);     } }  int main() {          int tasks = 100;            double* h_xy_copy;     long long* h_a_copy;     h_xy_copy = (double*)malloc(tasks * sizeof(double));     h_a_copy = (long long*)malloc(tasks * sizeof(long long));           for (int i = 0; i < tasks; ++i) {         h_xy_copy[i] = i * 1.5;      }           double* d_xy_copy;     long long* d_a_copy;     cudaMalloc((void**)&d_xy_copy, tasks * sizeof(double));     cudaMalloc((void**)&d_a_copy, tasks * sizeof(long long));           cudaMemcpy(d_xy_copy, h_xy_copy, tasks * sizeof(double), cudaMemcpyHostToDevice);           int block_size = 256;     int grid_size = (tasks + block_size - 1) / block_size;           transferMBR3<<<grid_size, block_size>>>(d_xy_copy, d_a_copy, tasks);           cudaMemcpy(h_a_copy, d_a_copy, tasks * sizeof(long long), cudaMemcpyDeviceToHost);           for (int i = 0; i < tasks; ++i) {         printf(\"%lld \", h_a_copy[i]);     }     printf(\"\\n\");           free(h_xy_copy);     free(h_a_copy);     cudaFree(d_xy_copy);     cudaFree(d_a_copy);      return 0; }   "
    },
    {
        "id": "23",
        "c_code": "#include <stdio.h>  void getCanBusData(int *canData, int size) {     for (int idx = 0; idx < size; idx++) {         canData[idx] += 1;     } }  int main() {          int dataSize = 8;     int canData[dataSize] = {10, 20, 30, 40, 50, 60, 70, 80};      printf(\"\u539f\u59cb CAN \u6570\u636e\uff1a\");     for (int i = 0; i < dataSize; i++) {         printf(\"%d \", canData[i]);     }           getCanBusData(canData, dataSize);      printf(\"\\n\u5904\u7406\u540e\u7684 CAN \u6570\u636e\uff1a\");     for (int i = 0; i < dataSize; i++) {         printf(\"%d \", canData[i]);     }      return 0; } #include <stdio.h>  void getCanBusData(int *canData, int size) {     for (int idx = 0; idx < size; idx++) {         canData[idx] += 1;     } }  int main() {          int dataSize = 8;     int canData[dataSize] = {10, 20, 30, 40, 50, 60, 70, 80};      printf(\"\u539f\u59cb CAN \u6570\u636e\uff1a\");     for (int i = 0; i < dataSize; i++) {         printf(\"%d \", canData[i]);     }           getCanBusData(canData, dataSize);      printf(\"\\n\u5904\u7406\u540e\u7684 CAN \u6570\u636e\uff1a\");     for (int i = 0; i < dataSize; i++) {         printf(\"%d \", canData[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void getCanBusData(int* canData, int size, int nthreads, int nblocks) {     int i;     int idx = blockIdx.x * blockDim.x + threadIdx.x;     for (i = idx; i < size; i += nthreads * nblocks) {         atomicAdd(&canData[i], 1);     } }  int main() {          int arraySize = 1000;           int* h_canData = (int*)malloc(arraySize * sizeof(int));           int* d_canData;     cudaMalloc((void**)&d_canData, arraySize * sizeof(int));           cudaMemcpy(d_canData, h_canData, arraySize * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           getCanBusData<<<gridSize, blockSize>>>(d_canData, arraySize, blockSize, gridSize);           cudaMemcpy(h_canData, d_canData, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_canData[i]);     }           free(h_canData);     cudaFree(d_canData);      return 0; } "
    },
    {
        "id": "230",
        "c_code": "#include <stdio.h>   void binarize_cpu(float *input, int n, float *binary);  int main() {          const int n = 5;     float input[] = {1.0, -2.0, 3.0, -4.0, 5.0};     float binary[5];           binarize_cpu(input, n, binary);           printf(\"Resultant array after binarization:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%f \", binary[i]);     }      return 0; }   void binarize_cpu(float *input, int n, float *binary) {     for (int i = 0; i < n; i++) {         binary[i] = (input[i] > 0) ? 1.0f : -1.0f;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void binarize_kernel(float* x, int n, float* binary) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i >= n)         return;     binary[i] = (x[i] >= 0) ? 1 : -1; }  int main() {          int n = 100;            float* h_x;     float* h_binary;     h_x = (float*)malloc(n * sizeof(float));     h_binary = (float*)malloc(n * sizeof(float));           for (int i = 0; i < n; ++i) {         h_x[i] = i - 50;      }           float* d_x;     float* d_binary;     cudaMalloc((void**)&d_x, n * sizeof(float));     cudaMalloc((void**)&d_binary, n * sizeof(float));           cudaMemcpy(d_x, h_x, n * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((n + block_size - 1) / block_size, 1);           binarize_kernel<<<grid_size, block_size>>>(d_x, n, d_binary);           cudaMemcpy(h_binary, d_binary, n * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < n; ++i) {         printf(\"%f \", h_binary[i]);     }     printf(\"\\n\");           free(h_x);     free(h_binary);     cudaFree(d_x);     cudaFree(d_binary);      return 0; }   "
    },
    {
        "id": "231",
        "c_code": "#include <stdio.h>   void add_vec_scalaire_cpu(int *vec, int *res, int a, long N);  int main() {          const long N = 5;     int vec[] = {1, 2, 3, 4, 5};     int res[5];     int scalar = 10;           add_vec_scalaire_cpu(vec, res, scalar, N);           printf(\"Resultant array after adding scalar to vector:\\n\");     for (long i = 0; i < N; i++) {         printf(\"%d \", res[i]);     }      return 0; }   void add_vec_scalaire_cpu(int *vec, int *res, int a, long N) {     for (long i = 0; i < N; i++) {         res[i] = vec[i] + a;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void add_vec_scalaire_gpu(int* vec, int* res, int a, long N) {     long i = (long)blockIdx.x * (long)blockDim.x + (long)threadIdx.x;     if (i < N) {         res[i] = vec[i] + a;     } }  int main() {          long N = 100;            int* h_vec;     int* h_res;     h_vec = (int*)malloc(N * sizeof(int));     h_res = (int*)malloc(N * sizeof(int));           for (long i = 0; i < N; ++i) {         h_vec[i] = i;      }           int* d_vec;     int* d_res;     cudaMalloc((void**)&d_vec, N * sizeof(int));     cudaMalloc((void**)&d_res, N * sizeof(int));           cudaMemcpy(d_vec, h_vec, N * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((N + block_size - 1) / block_size, 1);           add_vec_scalaire_gpu<<<grid_size, block_size>>>(d_vec, d_res, 5, N);            cudaMemcpy(h_res, d_res, N * sizeof(int), cudaMemcpyDeviceToHost);           for (long i = 0; i < N; ++i) {         printf(\"%d \", h_res[i]);     }     printf(\"\\n\");           free(h_vec);     free(h_res);     cudaFree(d_vec);     cudaFree(d_res);      return 0; }     "
    },
    {
        "id": "232",
        "c_code": "#include <stdio.h> #include <string.h>   void memcpy_kernel(int *dst, int *src, int n);  int main() {          const int n = 5;     int src[] = {1, 2, 3, 4, 5};     int dst[5];           memcpy_kernel(dst, src, n * sizeof(int));           printf(\"Resultant array after memcpy_kernel:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%d \", dst[i]);     }      return 0; }   void memcpy_kernel(int *dst, int *src, int n) {     memcpy(dst, src, n); }   ",
        "cuda_code": "#include <stdio.h>   __global__ void memcpy_kernel(int* dst, int* src, size_t n) {     int num = gridDim.x * blockDim.x;     int id = blockDim.x * blockIdx.x + threadIdx.x;     for (int i = id; i < n / sizeof(int); i += num) {         dst[i] = src[i];     } }  int main() {          size_t n = 100;            int* h_src;     int* h_dst;     h_src = (int*)malloc(n * sizeof(int));     h_dst = (int*)malloc(n * sizeof(int));           for (size_t i = 0; i < n; ++i) {         h_src[i] = i;      }           int* d_src;     int* d_dst;     cudaMalloc((void**)&d_src, n * sizeof(int));     cudaMalloc((void**)&d_dst, n * sizeof(int));           cudaMemcpy(d_src, h_src, n * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((n + block_size - 1) / block_size, 1);           memcpy_kernel<<<grid_size, block_size>>>(d_dst, d_src, n * sizeof(int));           cudaMemcpy(h_dst, d_dst, n * sizeof(int), cudaMemcpyDeviceToHost);           for (size_t i = 0; i < n; ++i) {         printf(\"%d \", h_dst[i]);     }     printf(\"\\n\");           free(h_src);     free(h_dst);     cudaFree(d_src);     cudaFree(d_dst);      return 0; }   "
    },
    {
        "id": "233",
        "c_code": "#include <stdio.h>   void add_cpu(int N, int offset, float *X, int INCX);  int main() {          const int N = 5;     int offset = 10;     float X[] = {-130.0, -129.0, -128.0, -127.0, -126.0};           add_cpu(N, offset, X, 1);           printf(\"Resultant array after add_cpu:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", X[i]);     }      return 0; }   void add_cpu(int N, int offset, float *X, int INCX) {     for (int i = 0; i < N; i++) {         X[i * INCX] += offset;         if (X[i * INCX] == -128.0f) {             X[i * INCX] = -127.0f;         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void add_kernel(int N, float ALPHA, float* X, int INCX) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N)         X[i * INCX] += ALPHA; }  int main() {          int N = 100;            float* h_X;     h_X = (float*)malloc(N * sizeof(float));           for (int i = 0; i < N; ++i) {         h_X[i] = i;      }           float* d_X;     cudaMalloc((void**)&d_X, N * sizeof(float));           cudaMemcpy(d_X, h_X, N * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((N + block_size - 1) / block_size, 1);           add_kernel<<<grid_size, block_size>>>(N, 2.0f, d_X, 1);            cudaMemcpy(h_X, d_X, N * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < N; ++i) {         printf(\"%f \", h_X[i]);     }     printf(\"\\n\");           free(h_X);     cudaFree(d_X);      return 0; }   "
    },
    {
        "id": "234",
        "c_code": " #include <stdio.h>   void doubleArraySign_cpu(double *d_in, double *d_out, int length);  int main() {          const int length = 5;     double d_in[] = {-2.5, 0.0, 1.5, -3.0, 2.0};     double d_out[5];           doubleArraySign_cpu(d_in, d_out, length);           printf(\"Resultant array after doubleArraySign_cpu:\\n\");     for (int i = 0; i < length; i++) {         printf(\"%f \", d_out[i]);     }      return 0; }   void doubleArraySign_cpu(double *d_in, double *d_out, int length) {     for (int idx = 0; idx < length; idx++) {         d_out[idx] = (0 < d_in[idx]) - (d_in[idx] < 0);     } }  ",
        "cuda_code": "#include <stdio.h>   __global__ void doubleArraySignKernel(double* d_in, double* d_out, int length) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = (0 < d_in[tid]) - (d_in[tid] < 0);     } }  int main() {          int length = 100;            double* h_d_in;     double* h_d_out;     h_d_in = (double*)malloc(length * sizeof(double));     h_d_out = (double*)malloc(length * sizeof(double));           for (int i = 0; i < length; ++i) {         h_d_in[i] = i - 50.0;      }           double* d_d_in;     double* d_d_out;     cudaMalloc((void**)&d_d_in, length * sizeof(double));     cudaMalloc((void**)&d_d_out, length * sizeof(double));           cudaMemcpy(d_d_in, h_d_in, length * sizeof(double), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((length + block_size - 1) / block_size, 1);           doubleArraySignKernel<<<grid_size, block_size>>>(d_d_in, d_d_out, length);           cudaMemcpy(h_d_out, d_d_out, length * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < length; ++i) {         printf(\"%f \", h_d_out[i]);     }     printf(\"\\n\");           free(h_d_in);     free(h_d_out);     cudaFree(d_d_in);     cudaFree(d_d_out);      return 0; }   "
    },
    {
        "id": "235",
        "c_code": "#include <stdio.h>   void find_max_cpu(int *data, int N);  int main() {          const int N = 5;     int data[] = {8, 3, 12, 5, 7};           find_max_cpu(data, N);           printf(\"Maximum value in the array: %d\\n\", data[0]);      return 0; }   void find_max_cpu(int *data, int N) {     int m = data[0];      for (int i = 0; i < N; i++) {         if (data[i] > m) {             m = data[i];         }     }      data[0] = m; }   ",
        "cuda_code": "#include <stdio.h>   __global__ void find_max_among_blocks(int* data, int blockSize, int nbBlocks) {     for (int i = 0; i < nbBlocks; ++i) {         if (data[0] < data[i * blockSize]) {             data[0] = data[i * blockSize];         }     } }  int main() {          int dataSize = 100;            int nbBlocks = 10;     int blockSize = dataSize / nbBlocks;           int* h_data;     h_data = (int*)malloc(dataSize * sizeof(int));           for (int i = 0; i < dataSize; ++i) {         h_data[i] = i;      }           int* d_data;     cudaMalloc((void**)&d_data, dataSize * sizeof(int));           cudaMemcpy(d_data, h_data, dataSize * sizeof(int), cudaMemcpyHostToDevice);           find_max_among_blocks<<<1, 1>>>(d_data, blockSize, nbBlocks);           cudaMemcpy(h_data, d_data, dataSize * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Maximum value among blocks: %d\\n\", h_data[0]);           free(h_data);     cudaFree(d_data);      return 0; }   "
    },
    {
        "id": "236",
        "c_code": "#include <stdio.h>   void setOffset_cpu(int *offset, int dims, int batchSize);  int main() {          const int dims = 3;     const int batchSize = 4;     int offset[5];            setOffset_cpu(offset, dims, batchSize);           printf(\"Resultant offset array:\\n\");     for (int i = 0; i <= batchSize; i++) {         printf(\"%d \", offset[i]);     }      return 0; }   void setOffset_cpu(int *offset, int dims, int batchSize) {     offset[0] = 0;      for (int i = 1; i <= batchSize; i++) {         offset[i] = i * dims;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void setOffset(int* offset, int dims, int batchSize) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid > 0) {         return;     }      offset[0] = 0;      for (int i = 1; i < batchSize + 1; i++) {         offset[i] = i * dims;     } }  int main() {          int batchSize = 5;     int dims = 3;           int* h_offset = (int*)malloc((batchSize + 1) * sizeof(int));           int* d_offset;     cudaMalloc((void**)&d_offset, (batchSize + 1) * sizeof(int));           setOffset<<<1, 1>>>(d_offset, dims, batchSize);           cudaMemcpy(h_offset, d_offset, (batchSize + 1) * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Offsets: \");     for (int i = 0; i <= batchSize; i++) {         printf(\"%d \", h_offset[i]);     }     printf(\"\\n\");           free(h_offset);     cudaFree(d_offset);      return 0; }   "
    },
    {
        "id": "237",
        "c_code": "#include <stdio.h>   void expandScoreFactors_cpu(const float *input, float *output, int dims, int clsNum);  int main() {          const int dims = 8;     const int clsNum = 2;     float input[] = {1.0, 2.0, 3.0, 4.0};     float output[8];            expandScoreFactors_cpu(input, output, dims, clsNum);           printf(\"Resultant expanded array:\\n\");     for (int i = 0; i < dims; i++) {         printf(\"%f \", output[i]);     }      return 0; }   void expandScoreFactors_cpu(const float *input, float *output, int dims, int clsNum) {     for (int tid = 0; tid < dims; tid++) {         int k = tid / clsNum;         output[tid] = input[k];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void expandScoreFactors(const float* input, float* output, int dims, int clsNum) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }      int k = tid / clsNum;     output[tid] = input[k]; }  int main() {          int dims = 15;     int clsNum = 3;           float* h_input = (float*)malloc(clsNum * sizeof(float));     float* h_output = (float*)malloc(dims * sizeof(float));           for (int i = 0; i < clsNum; ++i) {         h_input[i] = static_cast<float>(i + 1);       }           float* d_input;     float* d_output;     cudaMalloc((void**)&d_input, clsNum * sizeof(float));     cudaMalloc((void**)&d_output, dims * sizeof(float));           cudaMemcpy(d_input, h_input, clsNum * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((dims + block_size - 1) / block_size, 1);           expandScoreFactors<<<grid_size, block_size>>>(d_input, d_output, dims, clsNum);           cudaMemcpy(h_output, d_output, dims * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Expanded Output: \");     for (int i = 0; i < dims; ++i) {         printf(\"%f \", h_output[i]);     }     printf(\"\\n\");           free(h_input);     free(h_output);     cudaFree(d_input);     cudaFree(d_output);      return 0; }   "
    },
    {
        "id": "238",
        "c_code": "#include <stdio.h>   void kernelIsFirst_cpu(int *head, int *first_pts, int n);  int main() {          const int n = 5;     int head[] = {1, 0, 1, 0, 1};     int first_pts[5];           kernelIsFirst_cpu(head, first_pts, n);           printf(\"Resultant first_pts array:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%d \", first_pts[i]);     }      return 0; }   void kernelIsFirst_cpu(int *head, int *first_pts, int n) {     for (int i = 0; i < n; i++) {         if (head[i] == 1) {             first_pts[i] = i;         } else {             first_pts[i] = 0;         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void kernelIsFirst(int* head, int* first_pts, int n) {     int i = threadIdx.x + blockDim.x * blockIdx.x;     if (i < n) {         if (head[i] == 1)             first_pts[i] = i;         else             first_pts[i] = 0;     } }  int main() {          int n = 10;            int* h_head = (int*)malloc(n * sizeof(int));     int* h_first_pts = (int*)malloc(n * sizeof(int));           for (int i = 0; i < n; ++i) {         h_head[i] = (i % 2 == 0) ? 1 : 0;       }           int* d_head;     int* d_first_pts;     cudaMalloc((void**)&d_head, n * sizeof(int));     cudaMalloc((void**)&d_first_pts, n * sizeof(int));           cudaMemcpy(d_head, h_head, n * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((n + block_size - 1) / block_size, 1);           kernelIsFirst<<<grid_size, block_size>>>(d_head, d_first_pts, n);           cudaMemcpy(h_first_pts, d_first_pts, n * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"First Points: \");     for (int i = 0; i < n; ++i) {         printf(\"%d \", h_first_pts[i]);     }     printf(\"\\n\");           free(h_head);     free(h_first_pts);     cudaFree(d_head);     cudaFree(d_first_pts);      return 0; }   "
    },
    {
        "id": "239",
        "c_code": "#include <stdio.h>   void sumRowKernel_cpu(const int *d_in, int *d_out, int DIM);  int main() {          const int DIM = 4;     int d_in[] = {1, 2, 3, 4};     int d_out;           sumRowKernel_cpu(d_in, &d_out, DIM);           printf(\"Sum of elements in the row: %d\\n\", d_out);      return 0; }   void sumRowKernel_cpu(const int *d_in, int *d_out, int DIM) {     int sum = 0;      for (int i = 0; i < DIM; i++) {         sum += d_in[i];     }      *d_out = sum; }   ",
        "cuda_code": "#include <stdio.h>   __global__ void sumRowKernel(int* d_in, int* d_out, int DIM) {     for (int bid = blockIdx.x; bid < DIM; bid += gridDim.x) {         int sum = 0;         for (int tid = threadIdx.x; tid < DIM; tid += blockDim.x) {             sum += d_in[tid + bid * DIM];         }         atomicAdd(&d_out[bid], sum);     } }  int main() {          int DIM = 5;            int* h_in = (int*)malloc(DIM * DIM * sizeof(int));     int* h_out = (int*)malloc(DIM * sizeof(int));           for (int i = 0; i < DIM * DIM; ++i) {         h_in[i] = i + 1;      }           int* d_in;     int* d_out;     cudaMalloc((void**)&d_in, DIM * DIM * sizeof(int));     cudaMalloc((void**)&d_out, DIM * sizeof(int));           cudaMemcpy(d_in, h_in, DIM * DIM * sizeof(int), cudaMemcpyHostToDevice);           dim3 block_size(256);     dim3 grid_size((DIM + block_size.x - 1) / block_size.x);     sumRowKernel<<<grid_size, block_size>>>(d_in, d_out, DIM);           cudaMemcpy(h_out, d_out, DIM * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Sum of Rows: \");     for (int i = 0; i < DIM; ++i) {         printf(\"%d \", h_out[i]);     }     printf(\"\\n\");           free(h_in);     free(h_out);     cudaFree(d_in);     cudaFree(d_out);      return 0; }   "
    },
    {
        "id": "24",
        "c_code": "#include <stdio.h>  void sum_array_cpu(float *a, float *b, float *c, const int size) {     for (int i = 0; i < size; ++i) {         c[i] = a[i] + b[i];     } }  int main() {          int arraySize = 5;     float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           sum_array_cpu(arrayA, arrayB, resultArray, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff08\u548c\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void sum_array_1Dgrid_1Dblock(float* a, float* b, float* c, int nx) {     int gid = blockDim.x * blockIdx.x + threadIdx.x;     if (gid < nx) {         c[gid] = a[gid] + b[gid];     } }  int main() {          int arraySize = 1000;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_b = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);         h_b[i] = static_cast<float>(2 * i);     }           float* d_a;     float* d_b;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_b, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           sum_array_1Dgrid_1Dblock<<<gridSize, blockSize>>>(d_a, d_b, d_c, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "240",
        "c_code": "#include <stdio.h>   void addVectorsInto_cpu(float *result, const float *a, const float *b, int N);  int main() {          const int N = 5;     float a[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float b[] = {5.0, 4.0, 3.0, 2.0, 1.0};     float result[5];           addVectorsInto_cpu(result, a, b, N);           printf(\"Resultant vector after addition:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", result[i]);     }      return 0; }   void addVectorsInto_cpu(float *result, const float *a, const float *b, int N) {     for (int i = 0; i < N; i++) {         result[i] = a[i] + b[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void addVectorsInto(float* result, float* a, float* b, int N) {     int index = threadIdx.x + blockIdx.x * blockDim.x;     int stride = blockDim.x * gridDim.x;      for (int i = index; i < N; i += stride) {         result[i] = a[i] + b[i];     } }  int main() {          int N = 100;            float* h_result = (float*)malloc(N * sizeof(float));     float* h_a = (float*)malloc(N * sizeof(float));     float* h_b = (float*)malloc(N * sizeof(float));           for (int i = 0; i < N; ++i) {         h_a[i] = i + 1;          h_b[i] = 2 * (i + 1);     }           float* d_result;     float* d_a;     float* d_b;     cudaMalloc((void**)&d_result, N * sizeof(float));     cudaMalloc((void**)&d_a, N * sizeof(float));     cudaMalloc((void**)&d_b, N * sizeof(float));           cudaMemcpy(d_a, h_a, N * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, N * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((N + block_size - 1) / block_size, 1);           addVectorsInto<<<grid_size, block_size>>>(d_result, d_a, d_b, N);           cudaMemcpy(h_result, d_result, N * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < N; ++i) {         printf(\"%f \", h_result[i]);     }     printf(\"\\n\");           free(h_result);     free(h_a);     free(h_b);     cudaFree(d_result);     cudaFree(d_a);     cudaFree(d_b);      return 0; }   "
    },
    {
        "id": "241",
        "c_code": "#include <stdio.h>   void setIndexYolov3_cpu(int *input, int dims, int batchSize);  int main() {          const int dims = 3;     const int batchSize = 2;     int input[6];            setIndexYolov3_cpu(input, dims, batchSize);           printf(\"Resultant input array:\\n\");     for (int i = 0; i < batchSize; i++) {         for (int j = 0; j < dims; j++) {             printf(\"%d \", input[i * dims + j]);         }         printf(\"\\n\");     }      return 0; }   void setIndexYolov3_cpu(int *input, int dims, int batchSize) {     for (int tid = 0; tid < dims; tid++) {         for (int i = 0; i < batchSize; i++) {             input[i * dims + tid] = tid;         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void setIndexYolov3(int* input, int dims, int batchSize) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }      for (int i = 0; i < batchSize; i++) {         input[i * dims + tid] = tid;     } }  int main() {          int dims = 5;     int batchSize = 3;           int* h_input = (int*)malloc(batchSize * dims * sizeof(int));           int* d_input;     cudaMalloc((void**)&d_input, batchSize * dims * sizeof(int));           dim3 block_size(256);     dim3 grid_size((dims + block_size.x - 1) / block_size.x);      setIndexYolov3<<<grid_size, block_size>>>(d_input, dims, batchSize);           cudaMemcpy(h_input, d_input, batchSize * dims * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result:\\n\");     for (int i = 0; i < batchSize; ++i) {         for (int j = 0; j < dims; ++j) {             printf(\"%d \", h_input[i * dims + j]);         }         printf(\"\\n\");     }           free(h_input);     cudaFree(d_input);      return 0; }   "
    },
    {
        "id": "242",
        "c_code": "#include <stdio.h>   void shiftIndices(long *vec_out, const long by, const long imageSize, const long N);  int main() {          const long imageSize = 10;     const long N = 5;     const long by = 3;     long vec_out[5];           shiftIndices(vec_out, by, imageSize, N);           printf(\"Resultant vec_out array:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%ld \", vec_out[i]);     }      return 0; }   void shiftIndices(long *vec_out, const long by, const long imageSize, const long N) {     for (int idx = 0; idx < N; idx++) {         vec_out[idx] = (imageSize + ((idx - N / 2 + by) % imageSize)) % imageSize;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void shiftIndices(long* vec_out, const long by, const long imageSize, const long N) {     long idx = threadIdx.x + blockDim.x * blockIdx.x;     if (idx < N) {         vec_out[idx] = (imageSize + ((idx - N / 2 + by) % imageSize)) % imageSize;     } }  int main() {          long N = 10;     long imageSize = 8;     long shiftAmount = 3;           long* h_vec_out = (long*)malloc(N * sizeof(long));           long* d_vec_out;     cudaMalloc((void**)&d_vec_out, N * sizeof(long));           dim3 block_size(256);     dim3 grid_size((N + block_size.x - 1) / block_size.x);      shiftIndices<<<grid_size, block_size>>>(d_vec_out, shiftAmount, imageSize, N);           cudaMemcpy(h_vec_out, d_vec_out, N * sizeof(long), cudaMemcpyDeviceToHost);           printf(\"Result:\\n\");     for (long i = 0; i < N; ++i) {         printf(\"%ld \", h_vec_out[i]);     }     printf(\"\\n\");           free(h_vec_out);     cudaFree(d_vec_out);      return 0; }   "
    },
    {
        "id": "243",
        "c_code": "#include <stdio.h>   void doubleArrayVectorSubtract_cpu(double *d_in_a, double *d_in_b, double *d_out, int length);  int main() {          const int length = 5;     double d_in_a[] = {1.0, 2.0, 3.0, 4.0, 5.0};     double d_in_b[] = {5.0, 4.0, 3.0, 2.0, 1.0};     double d_out[5];           doubleArrayVectorSubtract_cpu(d_in_a, d_in_b, d_out, length);           printf(\"Resultant d_out array:\\n\");     for (int i = 0; i < length; i++) {         printf(\"%f \", d_out[i]);     }      return 0; }   void doubleArrayVectorSubtract_cpu(double *d_in_a, double *d_in_b, double *d_out, int length) {     for (int idx = 0; idx < length; idx++) {         d_out[idx] = d_in_a[idx] - d_in_b[idx];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void doubleArrayVectorSubtractKernel(double* d_in_a, double* d_in_b, double* d_out, int length) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid < length) {         d_out[tid] = d_in_a[tid] - d_in_b[tid];     } }  int main() {          int length = 10;            double* h_in_a = (double*)malloc(length * sizeof(double));     double* h_in_b = (double*)malloc(length * sizeof(double));     double* h_out = (double*)malloc(length * sizeof(double));           for (int i = 0; i < length; ++i) {         h_in_a[i] = static_cast<double>(i + 1);          h_in_b[i] = static_cast<double>(i);     }           double* d_in_a;     double* d_in_b;     double* d_out;     cudaMalloc((void**)&d_in_a, length * sizeof(double));     cudaMalloc((void**)&d_in_b, length * sizeof(double));     cudaMalloc((void**)&d_out, length * sizeof(double));           cudaMemcpy(d_in_a, h_in_a, length * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_in_b, h_in_b, length * sizeof(double), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((length + block_size - 1) / block_size, 1);           doubleArrayVectorSubtractKernel<<<grid_size, block_size>>>(d_in_a, d_in_b, d_out, length);           cudaMemcpy(h_out, d_out, length * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < length; ++i) {         printf(\"%f \", h_out[i]);     }     printf(\"\\n\");           free(h_in_a);     free(h_in_b);     free(h_out);     cudaFree(d_in_a);     cudaFree(d_in_b);     cudaFree(d_out);      return 0; }   "
    },
    {
        "id": "244",
        "c_code": "#include <stdio.h>   void doubleArrayVectorElementwiseMultiply_cpu(double *d_in_a, double *d_in_b, double *d_out, int length);  int main() {          const int length = 5;     double d_in_a[] = {1.0, 2.0, 3.0, 4.0, 5.0};     double d_in_b[] = {5.0, 4.0, 3.0, 2.0, 1.0};     double d_out[5];           doubleArrayVectorElementwiseMultiply_cpu(d_in_a, d_in_b, d_out, length);           printf(\"Resultant d_out array:\\n\");     for (int i = 0; i < length; i++) {         printf(\"%f \", d_out[i]);     }      return 0; }   void doubleArrayVectorElementwiseMultiply_cpu(double *d_in_a, double *d_in_b, double *d_out, int length) {     for (int idx = 0; idx < length; idx++) {         d_out[idx] = d_in_a[idx] * d_in_b[idx];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void doubleArrayVectorElementwiseMultiplyKernel(double* d_in_a, double* d_in_b, double* d_out, int length) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid < length) {         d_out[tid] = d_in_a[tid] * d_in_b[tid];     } }  int main() {          int length = 10;            double* h_in_a = (double*)malloc(length * sizeof(double));     double* h_in_b = (double*)malloc(length * sizeof(double));     double* h_out = (double*)malloc(length * sizeof(double));           for (int i = 0; i < length; ++i) {         h_in_a[i] = static_cast<double>(i + 1);          h_in_b[i] = static_cast<double>(i);     }           double* d_in_a;     double* d_in_b;     double* d_out;     cudaMalloc((void**)&d_in_a, length * sizeof(double));     cudaMalloc((void**)&d_in_b, length * sizeof(double));     cudaMalloc((void**)&d_out, length * sizeof(double));           cudaMemcpy(d_in_a, h_in_a, length * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_in_b, h_in_b, length * sizeof(double), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((length + block_size - 1) / block_size, 1);           doubleArrayVectorElementwiseMultiplyKernel<<<grid_size, block_size>>>(d_in_a, d_in_b, d_out, length);           cudaMemcpy(h_out, d_out, length * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < length; ++i) {         printf(\"%f \", h_out[i]);     }     printf(\"\\n\");           free(h_in_a);     free(h_in_b);     free(h_out);     cudaFree(d_in_a);     cudaFree(d_in_b);     cudaFree(d_out);      return 0; }   "
    },
    {
        "id": "245",
        "c_code": "#include <stdio.h>   void fill_idx(int N, int *device_input, int *device_output);  int main() {          const int N = 6;     int device_input[] = {1, 2, 4, 5, 7, 8};     int device_output[8] = {0};            fill_idx(N, device_input, device_output);           printf(\"Resultant device_output array:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%d \", device_output[i]);     }      return 0; }   void fill_idx(int N, int *device_input, int *device_output) {     int idx;     for (idx = 0; idx + 1 < N; idx++) {         if (device_input[idx] + 1 == device_input[idx + 1]) {             device_output[device_input[idx]] = idx;         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void fill_idx(int N, int* device_input, int* device_output) {     int idx = blockDim.x * blockIdx.x + threadIdx.x;     if (idx + 1 < N && device_input[idx] + 1 == device_input[idx + 1]) {         device_output[device_input[idx]] = idx;     } }  int main() {          int N = 10;            int* h_input = (int*)malloc(N * sizeof(int));     int* h_output = (int*)malloc(N * sizeof(int));           for (int i = 0; i < N; ++i) {         h_input[i] = i;      }           int* d_input;     int* d_output;     cudaMalloc((void**)&d_input, N * sizeof(int));     cudaMalloc((void**)&d_output, N * sizeof(int));           cudaMemcpy(d_input, h_input, N * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((N + block_size - 1) / block_size, 1);           fill_idx<<<grid_size, block_size>>>(N, d_input, d_output);           cudaMemcpy(h_output, d_output, N * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < N; ++i) {         printf(\"%d \", h_output[i]);     }     printf(\"\\n\");           free(h_input);     free(h_output);     cudaFree(d_input);     cudaFree(d_output);      return 0; }   "
    },
    {
        "id": "246",
        "c_code": "#include <stdio.h>   void cpuSearchPosShmem1EQ(int key, int *devKey, int *devPos, int size);  int main() {          const int size = 5;     int key = 3;     int devKey[] = {1, 2, 3, 4, 3};     int devPos[1] = {-1};            cpuSearchPosShmem1EQ(key, devKey, devPos, size);           printf(\"Position of key %d: %d\\n\", key, devPos[0]);      return 0; }   void cpuSearchPosShmem1EQ(int key, int *devKey, int *devPos, int size) {     for (int globalTx = 0; globalTx < size; globalTx++) {         if (devKey[globalTx] == key) {             devPos[0] = globalTx;         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void gpuSearchPosShmem1EQ(int key, int* devKey, int* devPos, int size) {     int globalTx = blockIdx.x * blockDim.x + threadIdx.x;     if (globalTx < size) {         if (devKey[globalTx] == key) {             devPos[0] = globalTx;         }     } }  int main() {          int size = 10;      int key = 5;              int* h_devKey = (int*)malloc(size * sizeof(int));     int* h_devPos = (int*)malloc(sizeof(int));           for (int i = 0; i < size; ++i) {         h_devKey[i] = i;      }           int* d_devKey;     int* d_devPos;     cudaMalloc((void**)&d_devKey, size * sizeof(int));     cudaMalloc((void**)&d_devPos, sizeof(int));           cudaMemcpy(d_devKey, h_devKey, size * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((size + block_size - 1) / block_size, 1);           gpuSearchPosShmem1EQ<<<grid_size, block_size>>>(key, d_devKey, d_devPos, size);           cudaMemcpy(h_devPos, d_devPos, sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Position of key %d: %d\\n\", key, h_devPos[0]);           free(h_devKey);     free(h_devPos);     cudaFree(d_devKey);     cudaFree(d_devPos);      return 0; }   "
    },
    {
        "id": "247",
        "c_code": "#include <stdio.h>   void mathKernel1(float *c, int size);  int main() {          const int size = 5;     float c[5];           mathKernel1(c, size);           printf(\"Resultant array:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%f \", c[i]);     }      return 0; }   void mathKernel1(float *c, int size) {     int tid;     float ia, ib;     ia = ib = 0.0f;      for (tid = 0; tid < size; tid++) {         if (tid % 2 == 0) {             ia = 100.0f;         } else {             ib = 200.0f;         }         c[tid] = ia + ib;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void mathKernel1(float* c) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     float ia, ib;     ia = ib = 0.0f;      if (tid % 2 == 0) {         ia = 100.0f;     } else {         ib = 200.0f;     }      c[tid] = ia + ib; }  int main() {          int size = 10;            float* h_c = (float*)malloc(size * sizeof(float));           float* d_c;     cudaMalloc((void**)&d_c, size * sizeof(float));           int block_size = 256;     dim3 grid_size((size + block_size - 1) / block_size, 1);           mathKernel1<<<grid_size, block_size>>>(d_c);           cudaMemcpy(h_c, d_c, size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < size; ++i) {         printf(\"%f \", h_c[i]);     }     printf(\"\\n\");           free(h_c);     cudaFree(d_c);      return 0; }   "
    },
    {
        "id": "248",
        "c_code": "#include <stdio.h>   void Reverse(int *d_in, int *d_out, int size);  int main() {          const int size = 5;     int d_in[] = {1, 2, 3, 4, 5};     int d_out[5];           Reverse(d_in, d_out, size);           printf(\"Reversed array:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", d_out[i]);     }      return 0; }   void Reverse(int *d_in, int *d_out, int size) {     for (int i = 0; i < size; i++) {         d_out[i] = d_in[size - 1 - i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void reverseArrayBlock(int* d_out, int* d_in) {     extern __shared__ int s_data[];      int i = blockIdx.x * blockDim.x + threadIdx.x;     int j = (gridDim.x - 1 - blockIdx.x) * blockDim.x + threadIdx.x;      s_data[blockDim.x - 1 - threadIdx.x] = d_in[i];      __syncthreads();      d_out[j] = s_data[threadIdx.x]; }  int main() {          int size = 10;            int* h_in = (int*)malloc(size * sizeof(int));     int* h_out = (int*)malloc(size * sizeof(int));           for (int i = 0; i < size; ++i) {         h_in[i] = i;      }           int* d_in;     int* d_out;     cudaMalloc((void**)&d_in, size * sizeof(int));     cudaMalloc((void**)&d_out, size * sizeof(int));           cudaMemcpy(d_in, h_in, size * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((size + block_size - 1) / block_size, 1);           reverseArrayBlock<<<grid_size, block_size, block_size * sizeof(int)>>>(d_out, d_in);           cudaMemcpy(h_out, d_out, size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Original Array: \");     for (int i = 0; i < size; ++i) {         printf(\"%d \", h_in[i]);     }     printf(\"\\n\");      printf(\"Reversed Array: \");     for (int i = 0; i < size; ++i) {         printf(\"%d \", h_out[i]);     }     printf(\"\\n\");           free(h_in);     free(h_out);     cudaFree(d_in);     cudaFree(d_out);      return 0; }   "
    },
    {
        "id": "249",
        "c_code": "#include <stdio.h>   void gaussianPass(int patchSize, int dataSize, float *gaussFilter, float *data);  int main() {          const int patchSize = 3;     const int dataSize = 9;     float gaussFilter[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9};     float data[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};           gaussianPass(patchSize, dataSize, gaussFilter, data);           printf(\"Resultant data array:\\n\");     for (int i = 0; i < dataSize; i++) {         printf(\"%f \", data[i]);     }      return 0; }   void gaussianPass(int patchSize, int dataSize, float *gaussFilter, float *data) {     for (int i = 0; i < dataSize; i++) {         data[i] = gaussFilter[i % (patchSize * patchSize)] * data[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void gaussianPass(int patchSize, int dataSize, float* gaussFilter, float* data) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = blockDim.x * gridDim.x;      for (int i = index; i < dataSize; i += stride) {         data[i] = gaussFilter[i % (patchSize * patchSize)] * data[i];     } }  int main() {          int dataSize = 1000;      int patchSize = 5;               float* h_gaussFilter = (float*)malloc(patchSize * patchSize * sizeof(float));     float* h_data = (float*)malloc(dataSize * sizeof(float));           for (int i = 0; i < patchSize * patchSize; ++i) {         h_gaussFilter[i] = static_cast<float>(i + 1);      }      for (int i = 0; i < dataSize; ++i) {         h_data[i] = static_cast<float>(i + 1);      }           float* d_gaussFilter;     float* d_data;     cudaMalloc((void**)&d_gaussFilter, patchSize * patchSize * sizeof(float));     cudaMalloc((void**)&d_data, dataSize * sizeof(float));           cudaMemcpy(d_gaussFilter, h_gaussFilter, patchSize * patchSize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_data, h_data, dataSize * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((dataSize + block_size - 1) / block_size, 1);           gaussianPass<<<grid_size, block_size>>>(patchSize, dataSize, d_gaussFilter, d_data);           cudaMemcpy(h_data, d_data, dataSize * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < dataSize; ++i) {         printf(\"%f \", h_data[i]);     }     printf(\"\\n\");           free(h_gaussFilter);     free(h_data);     cudaFree(d_gaussFilter);     cudaFree(d_data);      return 0; }   "
    },
    {
        "id": "25",
        "c_code": "#include <stdio.h>  void matColMeanDiv_cpu(double *buf, int m, int n, double *tmp) {     for (int i = 0; i < n; i++) {         buf[i] = tmp[i] / m;     } }  int main() {          int numRows = 3;     int numCols = 4;     double matrix[numRows][numCols] = {{1.0, 2.0, 3.0, 4.0},                                        {5.0, 6.0, 7.0, 8.0},                                        {9.0, 10.0, 11.0, 12.0}};     double resultArray[numCols];           double colMeanArray[numCols] = {0.0};     for (int i = 0; i < numRows; i++) {         for (int j = 0; j < numCols; j++) {             colMeanArray[j] += matrix[i][j];         }     }     for (int j = 0; j < numCols; j++) {         colMeanArray[j] /= numRows;     }      printf(\"\u539f\u59cb\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < numRows; i++) {         for (int j = 0; j < numCols; j++) {             printf(\"%.2f \", matrix[i][j]);         }         printf(\"\\n\");     }           matColMeanDiv_cpu(resultArray, numRows, numCols, colMeanArray);      printf(\"\\n\u6bcf\u5217\u5747\u503c\u9664\u6cd5\u540e\u7684\u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < numCols; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void matColMeanDiv(double* buf, int m, int n, double* tmp) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         buf[i] = tmp[i] / static_cast<double>(m);     } }  int main() {          int rows = 1000;     int cols = 10;           double* h_buf = (double*)malloc(cols * sizeof(double));     double* h_tmp = (double*)malloc(cols * sizeof(double));           for (int i = 0; i < cols; ++i) {         h_tmp[i] = static_cast<double>(i);     }           double* d_buf;     double* d_tmp;     cudaMalloc((void**)&d_buf, cols * sizeof(double));     cudaMalloc((void**)&d_tmp, cols * sizeof(double));           cudaMemcpy(d_tmp, h_tmp, cols * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (cols + blockSize - 1) / blockSize;           matColMeanDiv<<<gridSize, blockSize>>>(d_buf, rows, cols, d_tmp);           cudaMemcpy(h_buf, d_buf, cols * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_buf[i]);     }           free(h_buf);     free(h_tmp);     cudaFree(d_buf);     cudaFree(d_tmp);      return 0; } "
    },
    {
        "id": "250",
        "c_code": "#include <stdio.h>   void cpuAdd(int *a, int *b, int *c, int vectorSize);  int main() {          const int vectorSize = 5;     int a[] = {1, 2, 3, 4, 5};     int b[] = {5, 4, 3, 2, 1};     int c[5];           cpuAdd(a, b, c, vectorSize);           printf(\"Resultant array:\\n\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%d \", c[i]);     }      return 0; }   void cpuAdd(int *a, int *b, int *c, int vectorSize) {     #pragma omp parallel for     for (int i = 0; i < vectorSize; i++) {         c[i] = a[i] + b[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void addKernel(int* a, int* b, int* c, int vectorSize, int elements_per_thread) {     int start = (blockIdx.x * blockDim.x + threadIdx.x) * elements_per_thread;      for (int i = start; i - start < elements_per_thread && (i < vectorSize); i++) {         c[i] = a[i] + b[i];     } }  int main() {          int vectorSize = 1000;             int elements_per_thread = 10;            int* h_a = (int*)malloc(vectorSize * sizeof(int));     int* h_b = (int*)malloc(vectorSize * sizeof(int));     int* h_c = (int*)malloc(vectorSize * sizeof(int));           for (int i = 0; i < vectorSize; ++i) {         h_a[i] = i;          h_b[i] = i * 2;     }           int* d_a;     int* d_b;     int* d_c;     cudaMalloc((void**)&d_a, vectorSize * sizeof(int));     cudaMalloc((void**)&d_b, vectorSize * sizeof(int));     cudaMalloc((void**)&d_c, vectorSize * sizeof(int));           cudaMemcpy(d_a, h_a, vectorSize * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, vectorSize * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((vectorSize + block_size - 1) / block_size, 1);           addKernel<<<grid_size, block_size>>>(d_a, d_b, d_c, vectorSize, elements_per_thread);           cudaMemcpy(h_c, d_c, vectorSize * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < vectorSize; ++i) {         printf(\"%d \", h_c[i]);     }     printf(\"\\n\");           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   "
    },
    {
        "id": "251",
        "c_code": "#include <stdio.h> #include <math.h>   void clamp_cpu(int N, float *X, int INCX, float clamp_min, float clamp_max);  int main() {          const int N = 5;     float X[] = {1.0, 2.0, 3.0, 4.0, 5.0};     const int INCX = 1;     const float clamp_min = 2.0;     const float clamp_max = 4.0;           clamp_cpu(N, X, INCX, clamp_min, clamp_max);           printf(\"Resultant array:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", X[i]);     }      return 0; }   void clamp_cpu(int N, float *X, int INCX, float clamp_min, float clamp_max) {     for (int i = 0; i < N; ++i) {         X[i * INCX] = fmin(clamp_max, fmax(clamp_min, X[i * INCX]));     } }   ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void clamp_kernel(int N, float* X, int INCX, float clamp_min, float clamp_max) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;          if (i < N) {         X[i * INCX] = fminf(clamp_max, fmaxf(clamp_min, X[i * INCX]));     } }  int main() {          int N = 1000;            float* h_X = (float*)malloc(N * sizeof(float));           for (int i = 0; i < N; ++i) {         h_X[i] = static_cast<float>(i - 500);      }           float* d_X;     cudaMalloc((void**)&d_X, N * sizeof(float));           cudaMemcpy(d_X, h_X, N * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((N + block_size - 1) / block_size, 1);           float clamp_min = -100.0f;     float clamp_max = 100.0f;           clamp_kernel<<<grid_size, block_size>>>(N, d_X, 1, clamp_min, clamp_max);           cudaMemcpy(h_X, d_X, N * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < N; ++i) {         printf(\"%f \", h_X[i]);     }     printf(\"\\n\");           free(h_X);     cudaFree(d_X);      return 0; }   "
    },
    {
        "id": "252",
        "c_code": "#include <stdio.h> #include <omp.h>   double histogram_serial(const int *values, int *bins, const int nbins, const int n);  int main() {          const int n = 10;     int values[] = {1, 2, 3, 4, 5, 1, 2, 3, 4, 5};     const int nbins = 5;     int bins[5];           double time = histogram_serial(values, bins, nbins, n);           printf(\"Histogram bins:\\n\");     for (int i = 0; i < nbins; i++) {         printf(\"Bin %d: %d\\n\", i, bins[i]);     }           printf(\"Time taken: %f seconds\\n\", time);      return 0; }   double histogram_serial(const int *values, int *bins, const int nbins, const int n) {     double time = -omp_get_wtime();           for (int i = 0; i < nbins; ++i) {         bins[i] = 0;     }           for (int i = 0; i < n; ++i) {         bins[values[i]]++;     }      time += omp_get_wtime();     return time; }   ",
        "cuda_code": "#include <stdio.h>   __global__ void histogram(int* x, int* bins, int n) {     auto i = threadIdx.x + blockIdx.x * blockDim.x;      if (i < n) {         const auto c = x[i];         atomicAdd(&bins[c], 1);     } }  int main() {          int n = 1000;            int* h_x = (int*)malloc(n * sizeof(int));     int* h_bins = (int*)calloc(n, sizeof(int));            for (int i = 0; i < n; ++i) {         h_x[i] = i % 10;      }           int* d_x;     int* d_bins;     cudaMalloc((void**)&d_x, n * sizeof(int));     cudaMalloc((void**)&d_bins, n * sizeof(int));           cudaMemcpy(d_x, h_x, n * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_bins, h_bins, n * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((n + block_size - 1) / block_size, 1);           histogram<<<grid_size, block_size>>>(d_x, d_bins, n);           cudaMemcpy(h_bins, d_bins, n * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Histogram Result:\\n\");     for (int i = 0; i < n; ++i) {         printf(\"Bin %d: %d\\n\", i, h_bins[i]);     }           free(h_x);     free(h_bins);     cudaFree(d_x);     cudaFree(d_bins);      return 0; }   "
    },
    {
        "id": "253",
        "c_code": "#include <stdio.h>   void multMat_cpu(int n, int *arrForce_d, int *arrDistance_d, int *arrAnswer_d);  int main() {          const int n = 5;     int arrForce_d[] = {1, 2, 3, 4, 5};     int arrDistance_d[] = {2, 4, 6, 8, 10};     int arrAnswer_d[5];           multMat_cpu(n, arrForce_d, arrDistance_d, arrAnswer_d);           printf(\"Resultant array:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%d \", arrAnswer_d[i]);     }      return 0; }   void multMat_cpu(int n, int *arrForce_d, int *arrDistance_d, int *arrAnswer_d) {     for (int i = 0; i < n; i++) {         arrAnswer_d[i] = arrForce_d[i] * arrDistance_d[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void multMat(int n, int* arrForce_d, int* arrDistance_d, int* arrAnswer_d) {     int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i < n) {         arrAnswer_d[i] = arrForce_d[i] * arrDistance_d[i];     } }  int main() {          int n = 1000;            int* h_arrForce = (int*)malloc(n * sizeof(int));     int* h_arrDistance = (int*)malloc(n * sizeof(int));     int* h_arrAnswer = (int*)malloc(n * sizeof(int));           for (int i = 0; i < n; ++i) {         h_arrForce[i] = i;                    h_arrDistance[i] = i * 2;         }           int* d_arrForce;     int* d_arrDistance;     int* d_arrAnswer;     cudaMalloc((void**)&d_arrForce, n * sizeof(int));     cudaMalloc((void**)&d_arrDistance, n * sizeof(int));     cudaMalloc((void**)&d_arrAnswer, n * sizeof(int));           cudaMemcpy(d_arrForce, h_arrForce, n * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_arrDistance, h_arrDistance, n * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((n + block_size - 1) / block_size, 1);           multMat<<<grid_size, block_size>>>(n, d_arrForce, d_arrDistance, d_arrAnswer);           cudaMemcpy(h_arrAnswer, d_arrAnswer, n * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < n; ++i) {         printf(\"%d \", h_arrAnswer[i]);     }     printf(\"\\n\");           free(h_arrForce);     free(h_arrDistance);     free(h_arrAnswer);     cudaFree(d_arrForce);     cudaFree(d_arrDistance);     cudaFree(d_arrAnswer);      return 0; }   "
    },
    {
        "id": "254",
        "c_code": " #include <stdio.h>   void axpy_cpu(int N, float ALPHA, float *X, int INCX, float *Y, int INCY);  int main() {          const int N = 5;     const float ALPHA = 2.0;     float X[] = {1.0, 2.0, 3.0, 4.0, 5.0};     const int INCX = 1;     float Y[] = {2.0, 4.0, 6.0, 8.0, 10.0};     const int INCY = 1;           axpy_cpu(N, ALPHA, X, INCX, Y, INCY);           printf(\"Resultant array Y after axpy operation:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", Y[i]);     }      return 0; }   void axpy_cpu(int N, float ALPHA, float *X, int INCX, float *Y, int INCY) {     for (int i = 0; i < N; ++i) {         Y[i * INCY] += ALPHA * X[i * INCX];     } }  ",
        "cuda_code": "#include <stdio.h>   __global__ void axpy_kernel(int N, float ALPHA, float* X, int OFFX, int INCX, float* Y, int OFFY, int INCY) {     int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i < N) {         Y[OFFY + i * INCY] += ALPHA * X[OFFX + i * INCX];     } }  int main() {          int N = 1000;            float ALPHA = 2.0f;     float* h_X = (float*)malloc(N * sizeof(float));     float* h_Y = (float*)malloc(N * sizeof(float));           for (int i = 0; i < N; ++i) {         h_X[i] = i;          h_Y[i] = i * 2;     }           float* d_X;     float* d_Y;     cudaMalloc((void**)&d_X, N * sizeof(float));     cudaMalloc((void**)&d_Y, N * sizeof(float));           cudaMemcpy(d_X, h_X, N * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Y, h_Y, N * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((N + block_size - 1) / block_size, 1);           axpy_kernel<<<grid_size, block_size>>>(N, ALPHA, d_X, 0, 1, d_Y, 0, 1);           cudaMemcpy(h_Y, d_Y, N * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < N; ++i) {         printf(\"%f \", h_Y[i]);     }     printf(\"\\n\");           free(h_X);     free(h_Y);     cudaFree(d_X);     cudaFree(d_Y);      return 0; }   "
    },
    {
        "id": "255",
        "c_code": "#include <stdio.h>   void castImageTofloat(float *deviceOutputImageData, unsigned char *ucharImage,                        int imageWidth, int imageHeight, int channels, int pixelSize);  int main() {          const int imageWidth = 2;     const int imageHeight = 2;     const int channels = 3;     const int pixelSize = channels;      unsigned char ucharImage[] = {255, 128, 0, 200, 100, 50, 0, 0, 255, 128, 255, 0};           const int floatPixelSize = channels;      float deviceOutputImageData[floatPixelSize];           castImageTofloat(deviceOutputImageData, ucharImage, imageWidth, imageHeight, channels, pixelSize);           printf(\"Resultant array after casting to float:\\n\");     for (int i = 0; i < floatPixelSize; i++) {         printf(\"%f \", deviceOutputImageData[i]);     }      return 0; }   void castImageTofloat(float *deviceOutputImageData, unsigned char *ucharImage,                        int imageWidth, int imageHeight, int channels, int pixelSize) {     for (int w = 0; w < pixelSize; w++) {         deviceOutputImageData[w] = (float)(ucharImage[w] / 255.0);     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void castImageTofloat(float* deviceOutputImageData, unsigned char* ucharImage,                                   int imageWidth, int imageHeight, int channels, int pixelSize) {     int w = threadIdx.x + blockDim.x * blockIdx.x;      if (w < pixelSize) {         deviceOutputImageData[w] = static_cast<float>(ucharImage[w]) / 255.0f;     } }  int main() {          int imageWidth = 512;         int imageHeight = 512;        int channels = 3;             int pixelSize = channels * imageWidth * imageHeight;           float* h_deviceOutputImageData = (float*)malloc(pixelSize * sizeof(float));     unsigned char* h_ucharImage = (unsigned char*)malloc(pixelSize * sizeof(unsigned char));           for (int i = 0; i < pixelSize; ++i) {         h_ucharImage[i] = static_cast<unsigned char>(i % 256);       }           float* d_deviceOutputImageData;     unsigned char* d_ucharImage;     cudaMalloc((void**)&d_deviceOutputImageData, pixelSize * sizeof(float));     cudaMalloc((void**)&d_ucharImage, pixelSize * sizeof(unsigned char));           cudaMemcpy(d_ucharImage, h_ucharImage, pixelSize * sizeof(unsigned char), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((pixelSize + block_size - 1) / block_size, 1);           castImageTofloat<<<grid_size, block_size>>>(d_deviceOutputImageData, d_ucharImage,                                                imageWidth, imageHeight, channels, pixelSize);           cudaMemcpy(h_deviceOutputImageData, d_deviceOutputImageData, pixelSize * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < pixelSize; ++i) {         printf(\"%f \", h_deviceOutputImageData[i]);     }     printf(\"\\n\");           free(h_deviceOutputImageData);     free(h_ucharImage);     cudaFree(d_deviceOutputImageData);     cudaFree(d_ucharImage);      return 0; }   "
    },
    {
        "id": "256",
        "c_code": "#include <stdio.h>   void zero_centroid_vals_cpu(int k, double *Cx_sum, double *Cy_sum, int *Csize);  int main() {          const int k = 3;     double Cx_sum[k], Cy_sum[k];     int Csize[k];           zero_centroid_vals_cpu(k, Cx_sum, Cy_sum, Csize);           printf(\"Resultant arrays after zeroing centroid values:\\n\");     printf(\"Cx_sum: \");     for (int i = 0; i < k; i++) {         printf(\"%f \", Cx_sum[i]);     }     printf(\"\\nCy_sum: \");     for (int i = 0; i < k; i++) {         printf(\"%f \", Cy_sum[i]);     }     printf(\"\\nCsize: \");     for (int i = 0; i < k; i++) {         printf(\"%d \", Csize[i]);     }      return 0; }   void zero_centroid_vals_cpu(int k, double *Cx_sum, double *Cy_sum, int *Csize) {     for (int index = 0; index < k; index++) {         Cx_sum[index] = 0;         Cy_sum[index] = 0;         Csize[index] = 0;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void zero_centroid_vals(int k, double* Cx_sum, double* Cy_sum, int* Csize) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < k) {         Cx_sum[index] = 0.0;         Cy_sum[index] = 0.0;         Csize[index] = 0;     } }  int main() {          int k = 10;            double* h_Cx_sum = (double*)malloc(k * sizeof(double));     double* h_Cy_sum = (double*)malloc(k * sizeof(double));     int* h_Csize = (int*)malloc(k * sizeof(int));           double* d_Cx_sum;     double* d_Cy_sum;     int* d_Csize;     cudaMalloc((void**)&d_Cx_sum, k * sizeof(double));     cudaMalloc((void**)&d_Cy_sum, k * sizeof(double));     cudaMalloc((void**)&d_Csize, k * sizeof(int));           int block_size = 256;     dim3 grid_size((k + block_size - 1) / block_size, 1);           zero_centroid_vals<<<grid_size, block_size>>>(k, d_Cx_sum, d_Cy_sum, d_Csize);           cudaMemcpy(h_Cx_sum, d_Cx_sum, k * sizeof(double), cudaMemcpyDeviceToHost);     cudaMemcpy(h_Cy_sum, d_Cy_sum, k * sizeof(double), cudaMemcpyDeviceToHost);     cudaMemcpy(h_Csize, d_Csize, k * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result:\\n\");     for (int i = 0; i < k; ++i) {         printf(\"Centroid %d: Cx_sum=%f, Cy_sum=%f, Csize=%d\\n\", i, h_Cx_sum[i], h_Cy_sum[i], h_Csize[i]);     }           free(h_Cx_sum);     free(h_Cy_sum);     free(h_Csize);     cudaFree(d_Cx_sum);     cudaFree(d_Cy_sum);     cudaFree(d_Csize);      return 0; }   "
    },
    {
        "id": "257",
        "c_code": "#include <stdio.h>   void HammingDistanceCPU(int *c, const int *a, const int *b, long const int *size);  int main() {          const int size = 5;     int a[] = {1, 0, 1, 1, 0};     int b[] = {0, 1, 1, 1, 1};     int c = 0;           HammingDistanceCPU(&c, a, b, &size);           printf(\"Hamming distance: %d\\n\", c);      return 0; }   void HammingDistanceCPU(int *c, const int *a, const int *b, long const int *size) {     for (int i = 0; i < *size; i += 1) {         if (a[i] != b[i])             *c = *c + 1;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void HammingDistance(int* c, const int* a, const int* b, const long int* size) {     int i = threadIdx.x + blockDim.x * blockIdx.x;     int stride = blockDim.x * gridDim.x;      for (; i < *size; i += stride) {         if (a[i] != b[i]) {             atomicAdd(c, 1);         }     } }  int main() {          long int size = 1000;            int* h_a = (int*)malloc(size * sizeof(int));     int* h_b = (int*)malloc(size * sizeof(int));     int* h_c = (int*)malloc(sizeof(int));           for (int i = 0; i < size; ++i) {         h_a[i] = i % 2;          h_b[i] = (i + 1) % 2;      }      *h_c = 0;           int* d_a;     int* d_b;     int* d_c;     cudaMalloc((void**)&d_a, size * sizeof(int));     cudaMalloc((void**)&d_b, size * sizeof(int));     cudaMalloc((void**)&d_c, sizeof(int));           cudaMemcpy(d_a, h_a, size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_c, h_c, sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((size + block_size - 1) / block_size, 1);           HammingDistance<<<grid_size, block_size>>>(d_c, d_a, d_b, &size);           cudaMemcpy(h_c, d_c, sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Hamming Distance: %d\\n\", *h_c);           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   "
    },
    {
        "id": "258",
        "c_code": "#include <stdio.h>   void castImageToUchar(float *deviceInputImageData, unsigned char *ucharImage, int imageWidth, int imageHeight, int channels, int pixelSize);  int main() {          const int imageWidth = 2;     const int imageHeight = 2;     const int channels = 3;     const int pixelSize = channels;     float deviceInputImageData[pixelSize] = {0.1f, 0.5f, 0.9f, 0.3f, 0.7f, 1.0f};     unsigned char ucharImage[pixelSize];           castImageToUchar(deviceInputImageData, ucharImage, imageWidth, imageHeight, channels, pixelSize);           printf(\"Resultant ucharImage:\\n\");     for (int i = 0; i < pixelSize; ++i) {         printf(\"%d \", ucharImage[i]);     }      return 0; }   void castImageToUchar(float *deviceInputImageData, unsigned char *ucharImage, int imageWidth, int imageHeight, int channels, int pixelSize) {     int w;     for (w = 0; w < pixelSize; w++) {         ucharImage[w] = (unsigned char)(255 * deviceInputImageData[w]);     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void castImageToUchar(float* deviceInputImageData, unsigned char* ucharImage,                                   int imageWidth, int imageHeight, int channels, int pixelSize) {     int w = threadIdx.x + blockDim.x * blockIdx.x;      if (w < pixelSize) {         ucharImage[w] = static_cast<unsigned char>(255 * deviceInputImageData[w]);     } }  int main() {          int imageWidth = 512;         int imageHeight = 512;        int channels = 3;             int pixelSize = channels * imageWidth * imageHeight;           float* h_deviceInputImageData = (float*)malloc(pixelSize * sizeof(float));     unsigned char* h_ucharImage = (unsigned char*)malloc(pixelSize * sizeof(unsigned char));           for (int i = 0; i < pixelSize; ++i) {         h_deviceInputImageData[i] = static_cast<float>(i % 256) / 255.0f;       }           float* d_deviceInputImageData;     unsigned char* d_ucharImage;     cudaMalloc((void**)&d_deviceInputImageData, pixelSize * sizeof(float));     cudaMalloc((void**)&d_ucharImage, pixelSize * sizeof(unsigned char));           cudaMemcpy(d_deviceInputImageData, h_deviceInputImageData, pixelSize * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((pixelSize + block_size - 1) / block_size, 1);           castImageToUchar<<<grid_size, block_size>>>(d_deviceInputImageData, d_ucharImage,                                                  imageWidth, imageHeight, channels, pixelSize);           cudaMemcpy(h_ucharImage, d_ucharImage, pixelSize * sizeof(unsigned char), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < pixelSize; ++i) {         printf(\"%d \", h_ucharImage[i]);     }     printf(\"\\n\");           free(h_deviceInputImageData);     free(h_ucharImage);     cudaFree(d_deviceInputImageData);     cudaFree(d_ucharImage);      return 0; }   "
    },
    {
        "id": "259",
        "c_code": "#include <stdio.h>   void compareDoubleArrayToThreshold_cpu(double *d_in, int *d_out, int length, double threshold);  int main() {          const int length = 5;     double d_in[length] = {1.5, -2.0, 0.8, -0.3, 2.7};     int d_out[length];           double threshold = 1.0;     compareDoubleArrayToThreshold_cpu(d_in, d_out, length, threshold);           printf(\"Resultant d_out array:\\n\");     for (int i = 0; i < length; ++i) {         printf(\"%d \", d_out[i]);     }      return 0; }   void compareDoubleArrayToThreshold_cpu(double *d_in, int *d_out, int length, double threshold) {     for (int idx = 0; idx < length; idx++) {         double abs_value = (d_in[idx] > 0) ? d_in[idx] : -d_in[idx];         d_out[idx] = (abs_value < threshold) ? 1 : 0;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void compareDoubleArrayToThresholdKernel(double* d_in, int* d_out, int length, double threshold) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid < length) {         double abs_val = (d_in[tid] > 0) ? d_in[tid] : -d_in[tid];         d_out[tid] = (abs_val < threshold) ? 1 : 0;     } }  int main() {          int length = 100;            double* h_d_in = (double*)malloc(length * sizeof(double));     int* h_d_out = (int*)malloc(length * sizeof(int));           for (int i = 0; i < length; ++i) {         h_d_in[i] = (i % 3 == 0) ? 0.5 : -1.0;      }           double* d_d_in;     int* d_d_out;     cudaMalloc((void**)&d_d_in, length * sizeof(double));     cudaMalloc((void**)&d_d_out, length * sizeof(int));           cudaMemcpy(d_d_in, h_d_in, length * sizeof(double), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((length + block_size - 1) / block_size, 1);           double threshold = 1.0;            compareDoubleArrayToThresholdKernel<<<grid_size, block_size>>>(d_d_in, d_d_out, length, threshold);           cudaMemcpy(h_d_out, d_d_out, length * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result: \");     for (int i = 0; i < length; ++i) {         printf(\"%d \", h_d_out[i]);     }     printf(\"\\n\");           free(h_d_in);     free(h_d_out);     cudaFree(d_d_in);     cudaFree(d_d_out);      return 0; }   "
    },
    {
        "id": "26",
        "c_code": "#include <stdio.h>  void dmul_Scalar_matrix(double *a, double value, double *c, int N) {     for (int idx = 0; idx < N; idx++) {         c[idx] = a[idx] * value;     } }  int main() {          int arraySize = 6;     double arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};     double scalarValue = 2.0;     double resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }           dmul_Scalar_matrix(arrayA, scalarValue, resultArray, arraySize);      printf(\"\\n\u6807\u91cf\u4e58\u6cd5\u540e\u7684\u6570\u7ec4 C\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void dmul_Scalar_matrix(double* a, double value, double* c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] * value;     } }  int main() {          int arraySize = 1000;           double value = 2.0;           double* h_a = (double*)malloc(arraySize * sizeof(double));     double* h_c = (double*)malloc(arraySize * sizeof(double));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<double>(i);     }           double* d_a;     double* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(double));     cudaMalloc((void**)&d_c, arraySize * sizeof(double));           cudaMemcpy(d_a, h_a, arraySize * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           dmul_Scalar_matrix<<<gridSize, blockSize>>>(d_a, value, d_c, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_c);     cudaFree(d_a);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "260",
        "c_code": "#include <stdio.h>   void transpose(int A[][10000], int trans[][10000]);  int main() {          const int rows = 10000;     const int cols = 10000;     int A[rows][cols];     int trans[cols][rows];           for (int i = 0; i < rows; i++) {         for (int j = 0; j < cols; j++) {             A[i][j] = i * cols + j + 1;          }     }           transpose(A, trans);           printf(\"Original array A:\\n\");     for (int i = 0; i < 5; i++) {         for (int j = 0; j < 5; j++) {             printf(\"%d \", A[i][j]);         }         printf(\"\\n\");     }      printf(\"\\nTransposed array:\\n\");     for (int i = 0; i < 5; i++) {         for (int j = 0; j < 5; j++) {             printf(\"%d \", trans[i][j]);         }         printf(\"\\n\");     }      return 0; }   void transpose(int A[][10000], int trans[][10000]) {     for (int i = 0; i < 10000; i++) {         for (int j = 0; j < 10000; j++) {             trans[i][j] = A[j][i];         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void transpose(float* a, float* b, int width) {     int row = blockIdx.y * blockDim.y + threadIdx.y;     int col = blockIdx.x * blockDim.x + threadIdx.x;      if (row < width && col < width) {         b[col * width + row] = a[row * width + col];     } }  int main() {          int width = 4;            float* h_a = (float*)malloc(width * width * sizeof(float));     float* h_b = (float*)malloc(width * width * sizeof(float));           for (int i = 0; i < width * width; ++i) {         h_a[i] = static_cast<float>(i);      }           float* d_a;     float* d_b;     cudaMalloc((void**)&d_a, width * width * sizeof(float));     cudaMalloc((void**)&d_b, width * width * sizeof(float));           cudaMemcpy(d_a, h_a, width * width * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(16, 16);      dim3 grid_size((width + block_size.x - 1) / block_size.x, (width + block_size.y - 1) / block_size.y);           transpose<<<grid_size, block_size>>>(d_a, d_b, width);           cudaMemcpy(h_b, d_b, width * width * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Original Matrix:\\n\");     for (int i = 0; i < width; ++i) {         for (int j = 0; j < width; ++j) {             printf(\"%.2f\\t\", h_a[i * width + j]);         }         printf(\"\\n\");     }      printf(\"\\nTransposed Matrix:\\n\");     for (int i = 0; i < width; ++i) {         for (int j = 0; j < width; ++j) {             printf(\"%.2f\\t\", h_b[i * width + j]);         }         printf(\"\\n\");     }           free(h_a);     free(h_b);     cudaFree(d_a);     cudaFree(d_b);      return 0; }   "
    },
    {
        "id": "261",
        "c_code": "#include <stdio.h>   void ReLU_forward(float *in, int *mask, int datasize, int training);  int main() {          const int datasize = 5;     float in[5] = {-1.5, 2.0, -0.8, 0.3, 1.7};     int mask[5] = {0};             ReLU_forward(in, mask, datasize, 1);             printf(\"Output array after ReLU forward pass:\\n\");     for (int i = 0; i < datasize; ++i) {         printf(\"%f \", in[i]);     }      printf(\"\\nBinary mask (for training): \");     for (int i = 0; i < datasize; ++i) {         printf(\"%d \", mask[i]);     }      return 0; }   void ReLU_forward(float *in, int *mask, int datasize, int training) {     for (int i = 0; i < datasize; ++i) {         int keep = in[i] > 0;         if (training) {             mask[i] = keep;         }         if (!keep) {             in[i] = 0;         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void cuda_ReLU_forward_kernel(float* d_in_data, bool* d_mask, const long unsigned int datasize, bool training) {     uint i = blockIdx.x * blockDim.x + threadIdx.x;      if (i >= datasize)         return;      bool keep = d_in_data[i] > 0;      if (training)         d_mask[i] = keep;      if (!keep)         d_in_data[i] = 0; }  int main() {          long unsigned int datasize = 100;            float* h_d_in_data = (float*)malloc(datasize * sizeof(float));     bool* h_d_mask = (bool*)malloc(datasize * sizeof(bool));           for (int i = 0; i < datasize; ++i) {         h_d_in_data[i] = i - datasize / 2;      }           float* d_d_in_data;     bool* d_d_mask;     cudaMalloc((void**)&d_d_in_data, datasize * sizeof(float));     cudaMalloc((void**)&d_d_mask, datasize * sizeof(bool));           cudaMemcpy(d_d_in_data, h_d_in_data, datasize * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((datasize + block_size - 1) / block_size, 1);           bool training = true;            cuda_ReLU_forward_kernel<<<grid_size, block_size>>>(d_d_in_data, d_d_mask, datasize, training);           cudaMemcpy(h_d_in_data, d_d_in_data, datasize * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_d_mask, d_d_mask, datasize * sizeof(bool), cudaMemcpyDeviceToHost);           printf(\"Input Data:\\n\");     for (int i = 0; i < datasize; ++i) {         printf(\"%.2f \", h_d_in_data[i]);     }      printf(\"\\nMask (for training):\\n\");     for (int i = 0; i < datasize; ++i) {         printf(\"%d \", h_d_mask[i] ? 1 : 0);     }     printf(\"\\n\");           free(h_d_in_data);     free(h_d_mask);     cudaFree(d_d_in_data);     cudaFree(d_d_mask);      return 0; }   "
    },
    {
        "id": "262",
        "c_code": "#include <stdio.h>   void sum_backward(float *db, float *dout, int r, int c);  int main() {          const int r = 3;     const int c = 2;     float db[2] = {0.0, 0.0};     float dout[6] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};           sum_backward(db, dout, r, c);           printf(\"Gradients with respect to bias terms (db): \");     for (int i = 0; i < c; ++i) {         printf(\"%f \", db[i]);     }      return 0; }   void sum_backward(float *db, float *dout, int r, int c) {     for (int j = 0; j < c; ++j) {         for (int i = 0; i < r; ++i) {             db[j] += dout[i * c + j];         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void kernel_sum_backward(float* db, float* dout, int r, int c) {     unsigned int tid = blockDim.x * blockIdx.x + threadIdx.x;     int N = c;      while (tid < N) {         for (int i = 0; i < r; i++) {             db[tid] += dout[i * c + tid];         }         tid += gridDim.x * blockDim.x;     } }  int main() {          int r = 4;      int c = 5;            float* h_db = (float*)malloc(c * sizeof(float));     float* h_dout = (float*)malloc(r * c * sizeof(float));           for (int i = 0; i < c; ++i) {         h_db[i] = 0.0;      }      for (int i = 0; i < r * c; ++i) {         h_dout[i] = i + 1;      }           float* d_db;     float* d_dout;     cudaMalloc((void**)&d_db, c * sizeof(float));     cudaMalloc((void**)&d_dout, r * c * sizeof(float));           cudaMemcpy(d_db, h_db, c * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_dout, h_dout, r * c * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((c + block_size - 1) / block_size, 1);           kernel_sum_backward<<<grid_size, block_size>>>(d_db, d_dout, r, c);           cudaMemcpy(h_db, d_db, c * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Gradients with respect to input (db):\\n\");     for (int i = 0; i < c; ++i) {         printf(\"%.2f \", h_db[i]);     }     printf(\"\\n\");           free(h_db);     free(h_dout);     cudaFree(d_db);     cudaFree(d_dout);      return 0; }   "
    },
    {
        "id": "263",
        "c_code": "#include <stdio.h>   void clip_cpu(int N, float ALPHA, float *X, int INCX, float *Y, int INCY);  int main() {          const int N = 5;     const float ALPHA = 2.0;     float X[] = {1.0, 3.0, 2.0, -1.0, 4.0};     float Y[N];           clip_cpu(N, ALPHA, X, 1, Y, 1);           printf(\"Clipped array (Y): \");     for (int i = 0; i < N; ++i) {         printf(\"%f \", Y[i]);     }      return 0; }   void clip_cpu(int N, float ALPHA, float *X, int INCX, float *Y, int INCY) {     for (int i = 0; i < N; ++i) {         float val = X[i * INCX];         Y[i * INCY] = val > ALPHA ? val : 0;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void clip_kernel(int N, float ALPHA, float* X, int INCX, float* Y, int INCY) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i < N) {         float val = X[i * INCX];         Y[i * INCY] = (val > ALPHA) ? val : 0;     } }  int main() {          int N = 100;            float* h_X = (float*)malloc(N * sizeof(float));     float* h_Y = (float*)malloc(N * sizeof(float));           for (int i = 0; i < N; ++i) {         h_X[i] = i - N / 2.0;      }           float* d_X;     float* d_Y;     cudaMalloc((void**)&d_X, N * sizeof(float));     cudaMalloc((void**)&d_Y, N * sizeof(float));           cudaMemcpy(d_X, h_X, N * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((N + block_size - 1) / block_size, 1);           float ALPHA = 5.0;            clip_kernel<<<grid_size, block_size>>>(N, ALPHA, d_X, 1, d_Y, 1);           cudaMemcpy(h_Y, d_Y, N * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Input Array:\\n\");     for (int i = 0; i < N; ++i) {         printf(\"%.2f \", h_X[i]);     }      printf(\"\\nClipped Array (ALPHA=%.2f):\\n\", ALPHA);     for (int i = 0; i < N; ++i) {         printf(\"%.2f \", h_Y[i]);     }     printf(\"\\n\");           free(h_X);     free(h_Y);     cudaFree(d_X);     cudaFree(d_Y);      return 0; }   "
    },
    {
        "id": "264",
        "c_code": "#include <stdio.h>   void update_x(double *x, double *a, double *b, int n);  int main() {          const int n = 5;     double x[] = {1.0, 2.0, 3.0, 4.0, 5.0};     double a[] = {2.0, 4.0, 6.0, 8.0, 10.0};     double b[] = {1.0, 2.0, 3.0, 2.0, 1.0};           update_x(x, a, b, n);           printf(\"Updated array (x): \");     for (int i = 0; i < n; ++i) {         printf(\"%f \", x[i]);     }      return 0; }   void update_x(double *x, double *a, double *b, int n) {     for (int i = 0; i < n; ++i) {         x[i] = (2.0 / 3.0) * (a[i] / b[i]) + (1.0 / 3.0) * x[i];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void update_x(double* x, double* a, double* b, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = gridDim.x * blockDim.x;      for (int i = index; i < n; i += stride) {         x[i] = 2.0 / 3.0 * a[i] / b[i] + 1.0 / 3.0 * x[i];     } }  int main() {          int n = 100;            double* h_x = (double*)malloc(n * sizeof(double));     double* h_a = (double*)malloc(n * sizeof(double));     double* h_b = (double*)malloc(n * sizeof(double));           for (int i = 0; i < n; ++i) {         h_x[i] = i + 1.0;          h_a[i] = 2.0 * i + 1.0;          h_b[i] = i + 2.0;      }           double* d_x;     double* d_a;     double* d_b;     cudaMalloc((void**)&d_x, n * sizeof(double));     cudaMalloc((void**)&d_a, n * sizeof(double));     cudaMalloc((void**)&d_b, n * sizeof(double));           cudaMemcpy(d_x, h_x, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_a, h_a, n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, n * sizeof(double), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((n + block_size - 1) / block_size, 1);           update_x<<<grid_size, block_size>>>(d_x, d_a, d_b, n);           cudaMemcpy(h_x, d_x, n * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Initial x Array:\\n\");     for (int i = 0; i < n; ++i) {         printf(\"%.2f \", h_x[i]);     }      printf(\"\\n\");           free(h_x);     free(h_a);     free(h_b);     cudaFree(d_x);     cudaFree(d_a);     cudaFree(d_b);      return 0; }   "
    },
    {
        "id": "265",
        "c_code": "#include <stdio.h>  int seqTrans(float **h_in, float **h_out, int x_size, int y_size) ;  int main() {          int x_size = 3;     int y_size = 2;     float **h_in;       float **h_out;            seqTrans(h_in, h_out, x_size, y_size);           printf(\"Transposed Matrix:\\n\");     for (int y = 0; y < x_size; y++) {         for (int x = 0; x < y_size; x++) {             printf(\"%f \", h_out[y][x]);         }         printf(\"\\n\");     }            return 0; }  int seqTrans(float **h_in, float **h_out, int x_size, int y_size) {     for (int y = 0; y < y_size; y++) {         for (int x = 0; x < x_size; x++) {             h_out[x][y] = h_in[y][x];         }     }     return 1; }   ",
        "cuda_code": "#include <stdio.h>   __global__ void naiveParTrans(float* d_in, float* d_out, int x_size, int y_size) {     int gidx = blockIdx.x * blockDim.x + threadIdx.x;     int gidy = blockIdx.y * blockDim.y + threadIdx.y;      if (gidx < x_size && gidy < y_size) {         d_out[gidx * y_size + gidy] = d_in[gidy * x_size + gidx];     } }  int main() {          int x_size = 4;      int y_size = 3;            float* h_in = (float*)malloc(x_size * y_size * sizeof(float));     float* h_out = (float*)malloc(y_size * x_size * sizeof(float));           for (int i = 0; i < x_size * y_size; ++i) {         h_in[i] = i + 1.0;      }           float* d_in;     float* d_out;     cudaMalloc((void**)&d_in, x_size * y_size * sizeof(float));     cudaMalloc((void**)&d_out, y_size * x_size * sizeof(float));           cudaMemcpy(d_in, h_in, x_size * y_size * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(2, 2);      dim3 grid_size((x_size + block_size.x - 1) / block_size.x, (y_size + block_size.y - 1) / block_size.y);           naiveParTrans<<<grid_size, block_size>>>(d_in, d_out, x_size, y_size);           cudaMemcpy(h_out, d_out, y_size * x_size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Input Matrix:\\n\");     for (int i = 0; i < x_size * y_size; ++i) {         printf(\"%.2f \", h_in[i]);         if ((i + 1) % y_size == 0) {             printf(\"\\n\");         }     }      printf(\"\\nTransposed Matrix:\\n\");     for (int i = 0; i < y_size * x_size; ++i) {         printf(\"%.2f \", h_out[i]);         if ((i + 1) % x_size == 0) {             printf(\"\\n\");         }     }           free(h_in);     free(h_out);     cudaFree(d_in);     cudaFree(d_out);      return 0; }   "
    },
    {
        "id": "266",
        "c_code": "#include <stdio.h>   void l2_cpu(int n, float *pred, float *truth, float *delta, float *error)\uff1b  int main() {          int n = 3;     float pred[] = {1.0, 2.0, 3.0};     float truth[] = {2.0, 3.0, 5.0};     float delta[3];     float error[3];           l2_cpu(n, pred, truth, delta, error);           printf(\"Delta array: \");     for (int i = 0; i < n; ++i) {         printf(\"%f \", delta[i]);     }     printf(\"\\nError array: \");     for (int i = 0; i < n; ++i) {         printf(\"%f \", error[i]);     }      return 0; }  void l2_cpu(int n, float *pred, float *truth, float *delta, float *error) {     int i;     for (i = 0; i < n; ++i) {         float diff = truth[i] - pred[i];         error[i] = diff * diff;         delta[i] = diff;     } }   ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void l2_kernel(int n, float* pred, float* truth, float* delta, float* error) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i < n) {         float diff = truth[i] - pred[i];         error[i] = diff * diff;         delta[i] = diff;     } }  int main() {          int n = 100;            float* h_pred = (float*)malloc(n * sizeof(float));     float* h_truth = (float*)malloc(n * sizeof(float));     float* h_delta = (float*)malloc(n * sizeof(float));     float* h_error = (float*)malloc(n * sizeof(float));           for (int i = 0; i < n; ++i) {         h_pred[i] = i;          h_truth[i] = 2 * i;      }           float* d_pred;     float* d_truth;     float* d_delta;     float* d_error;     cudaMalloc((void**)&d_pred, n * sizeof(float));     cudaMalloc((void**)&d_truth, n * sizeof(float));     cudaMalloc((void**)&d_delta, n * sizeof(float));     cudaMalloc((void**)&d_error, n * sizeof(float));           cudaMemcpy(d_pred, h_pred, n * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_truth, h_truth, n * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((n + block_size - 1) / block_size, 1);           l2_kernel<<<grid_size, block_size>>>(n, d_pred, d_truth, d_delta, d_error);           cudaMemcpy(h_delta, d_delta, n * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_error, d_error, n * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Pred Array:\\n\");     for (int i = 0; i < n; ++i) {         printf(\"%.2f \", h_pred[i]);     }      printf(\"\\nTruth Array:\\n\");     for (int i = 0; i < n; ++i) {         printf(\"%.2f \", h_truth[i]);     }      printf(\"\\nDelta Array:\\n\");     for (int i = 0; i < n; ++i) {         printf(\"%.2f \", h_delta[i]);     }      printf(\"\\nError Array:\\n\");     for (int i = 0; i < n; ++i) {         printf(\"%.2f \", h_error[i]);     }     printf(\"\\n\");           free(h_pred);     free(h_truth);     free(h_delta);     free(h_error);     cudaFree(d_pred);     cudaFree(d_truth);     cudaFree(d_delta);     cudaFree(d_error);      return 0; }   "
    },
    {
        "id": "267",
        "c_code": "#include <stdio.h>   void flipKernel(float *array1, int width);  int main() {          int width = 4;     float array1[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};           flipKernel(array1, width);           printf(\"Flipped Array:\\n\");     for (int i = 0; i < width * width; i++) {         printf(\"%.1f \", array1[i]);     }     printf(\"\\n\");      return 0; }   void flipKernel(float *array1, int width) {     for (int current_index = 0; current_index < width * width / 2; current_index++) {         int replace = (width - 1 - current_index / width) * width + current_index % width;         float temp = array1[current_index];         array1[current_index] = array1[replace];         array1[replace] = temp;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void flipKernel(float* array1, int width) {     int current_index = blockIdx.x * blockDim.x + threadIdx.x;     int replace = (width - 1 - current_index / width) * width + current_index % width;      if (current_index < width * width / 2) {         float temp = array1[current_index];         array1[current_index] = array1[replace];         array1[replace] = temp;     } }  int main() {          int width = 4;            float* h_array1 = (float*)malloc(width * width * sizeof(float));           for (int i = 0; i < width * width; ++i) {         h_array1[i] = i + 1.0;      }           float* d_array1;     cudaMalloc((void**)&d_array1, width * width * sizeof(float));           cudaMemcpy(d_array1, h_array1, width * width * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((width * width + block_size - 1) / block_size, 1);           flipKernel<<<grid_size, block_size>>>(d_array1, width);           cudaMemcpy(h_array1, d_array1, width * width * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Original Array:\\n\");     for (int i = 0; i < width * width; ++i) {         printf(\"%.2f \", h_array1[i]);         if ((i + 1) % width == 0) {             printf(\"\\n\");         }     }           free(h_array1);     cudaFree(d_array1);      return 0; }   "
    },
    {
        "id": "268",
        "c_code": "#include <stdio.h>   void get_conf_inds(const float *mlvl_conf, const float conf_thr, int *conf_inds, int dims);  int main() {          int dims = 5;     float mlvl_conf[] = {0.8, 0.6, 0.9, 0.4, 0.7};     float conf_thr = 0.7;     int conf_inds[dims];           get_conf_inds(mlvl_conf, conf_thr, conf_inds, dims);           printf(\"Confidence Indices:\\n\");     for (int i = 0; i < dims; i++) {         printf(\"%d \", conf_inds[i]);     }     printf(\"\\n\");      return 0; }   void get_conf_inds(const float *mlvl_conf, const float conf_thr, int *conf_inds, int dims) {     for (int tid = 0; tid < dims; tid++) {         if (mlvl_conf[tid] >= conf_thr) {             conf_inds[tid] = 1;         } else {             conf_inds[tid] = -1;         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void get_conf_inds(const float* mlvl_conf, const float conf_thr, int* conf_inds, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid < dims) {         conf_inds[tid] = (mlvl_conf[tid] >= conf_thr) ? 1 : -1;     } }  int main() {          int dims = 10;            float* h_mlvl_conf = (float*)malloc(dims * sizeof(float));     int* h_conf_inds = (int*)malloc(dims * sizeof(int));           for (int i = 0; i < dims; ++i) {         h_mlvl_conf[i] = i * 0.1;      }           float* d_mlvl_conf;     int* d_conf_inds;     cudaMalloc((void**)&d_mlvl_conf, dims * sizeof(float));     cudaMalloc((void**)&d_conf_inds, dims * sizeof(int));           cudaMemcpy(d_mlvl_conf, h_mlvl_conf, dims * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((dims + block_size - 1) / block_size, 1);           float conf_thr = 0.5;            get_conf_inds<<<grid_size, block_size>>>(d_mlvl_conf, conf_thr, d_conf_inds, dims);           cudaMemcpy(h_conf_inds, d_conf_inds, dims * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"mlvl_conf Array:\\n\");     for (int i = 0; i < dims; ++i) {         printf(\"%.2f \", h_mlvl_conf[i]);     }      printf(\"\\nconf_inds Array:\\n\");     for (int i = 0; i < dims; ++i) {         printf(\"%d \", h_conf_inds[i]);     }     printf(\"\\n\");           free(h_mlvl_conf);     free(h_conf_inds);     cudaFree(d_mlvl_conf);     cudaFree(d_conf_inds);      return 0; }   "
    },
    {
        "id": "269",
        "c_code": "#include <stdio.h>   void cpuSearchPosShmem1(int key, int *gpu_key_arr, int *gpu_pos, int size);  int main() {          int size = 5;     int key = 7;     int gpu_key_arr[] = {3, 6, 8, 10, 12};     int gpu_pos;           cpuSearchPosShmem1(key, gpu_key_arr, &gpu_pos, size);           printf(\"Position of key %d: %d\\n\", key, gpu_pos);      return 0; }   void cpuSearchPosShmem1(int key, int *gpu_key_arr, int *gpu_pos, int size) {     for (int globalTx = 0; globalTx < size - 1; globalTx++) {         if (key >= gpu_key_arr[globalTx] && key < gpu_key_arr[globalTx + 1]) {             *gpu_pos = globalTx;             return;          }     }           if (key >= gpu_key_arr[size - 1]) {         *gpu_pos = size - 1;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void gpuSearchPosShmem1(int key, int* gpu_key_arr, int* gpu_pos, int size) {     int globalTx = blockIdx.x * blockDim.x + threadIdx.x;      if (globalTx < size - 1) {         if (key >= gpu_key_arr[globalTx] && key < gpu_key_arr[globalTx + 1]) {             *gpu_pos = globalTx;         }     } }  int main() {          int size = 10;            int* h_gpu_key_arr = (int*)malloc(size * sizeof(int));     int* h_gpu_pos = (int*)malloc(sizeof(int));           for (int i = 0; i < size; ++i) {         h_gpu_key_arr[i] = i * 10;      }           int* d_gpu_key_arr;     int* d_gpu_pos;     cudaMalloc((void**)&d_gpu_key_arr, size * sizeof(int));     cudaMalloc((void**)&d_gpu_pos, sizeof(int));           cudaMemcpy(d_gpu_key_arr, h_gpu_key_arr, size * sizeof(int), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((size + block_size - 1) / block_size, 1);           int key = 15;            gpuSearchPosShmem1<<<grid_size, block_size>>>(key, d_gpu_key_arr, d_gpu_pos, size);           cudaMemcpy(h_gpu_pos, d_gpu_pos, sizeof(int), cudaMemcpyDeviceToHost);           printf(\"gpu_key_arr Array:\\n\");     for (int i = 0; i < size; ++i) {         printf(\"%d \", h_gpu_key_arr[i]);     }      printf(\"\\nSearch Key: %d\\n\", key);     printf(\"Position: %d\\n\", *h_gpu_pos);           free(h_gpu_key_arr);     free(h_gpu_pos);     cudaFree(d_gpu_key_arr);     cudaFree(d_gpu_pos);      return 0; }   "
    },
    {
        "id": "27",
        "c_code": "#include <stdio.h>  void countRangesGlobal(int size, int *A, int *B) {     for (int i = 0; i < size; i++) {         int x = A[i] / 100;         B[x] += 1;     } }  int main() {          int arraySize = 8;     int inputArray[] = {50, 120, 250, 350, 420, 550, 670, 800};     int resultArray[9] = {0};       printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", inputArray[i]);     }           countRangesGlobal(arraySize, inputArray, resultArray);      printf(\"\\n\u7edf\u8ba1\u540e\u7684\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < 9; i++) {         printf(\"%d \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void countRangesGlobal(int size, int* A, int* B) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i >= size)         return;      int x = A[i] / 100;     atomicAdd(&B[x], 1); }  int main() {          int arraySize = 1000;           int* h_A = (int*)malloc(arraySize * sizeof(int));     int* h_B = (int*)malloc(arraySize * sizeof(int));           for (int i = 0; i < arraySize; ++i) {         h_A[i] = i;         h_B[i] = 0;     }           int* d_A;     int* d_B;     cudaMalloc((void**)&d_A, arraySize * sizeof(int));     cudaMalloc((void**)&d_B, arraySize * sizeof(int));           cudaMemcpy(d_A, h_A, arraySize * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_B, h_B, arraySize * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           countRangesGlobal<<<gridSize, blockSize>>>(arraySize, d_A, d_B);           cudaMemcpy(h_B, d_B, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_B[i]);     }           free(h_A);     free(h_B);     cudaFree(d_A);     cudaFree(d_B);      return 0; } "
    },
    {
        "id": "270",
        "c_code": "#include <stdio.h>   void histogram(int *hist_out, unsigned char *img_in, int img_size, int nbr_bin);  int main() {          int nbr_bin = 256;       int img_size = 10;     unsigned char img_in[] = {1, 2, 3, 4, 5, 1, 2, 3, 4, 5};     int hist_out[nbr_bin];           histogram(hist_out, img_in, img_size, nbr_bin);           printf(\"Histogram:\\n\");     for (int i = 0; i < nbr_bin; i++) {         printf(\"%d \", hist_out[i]);     }     printf(\"\\n\");      return 0; }   void histogram(int *hist_out, unsigned char *img_in, int img_size, int nbr_bin) {          for (int i = 0; i < nbr_bin; i++) {         hist_out[i] = 0;     }           for (int i = 0; i < img_size; i++) {         hist_out[img_in[i]]++;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void HistogramKernel(int* hist, unsigned char* img_in, int img_size) {     int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i < img_size) {         atomicAdd(&(hist[img_in[i]]), 1);     }     __syncthreads(); }  int main() {          int img_size = 100;            unsigned char* h_img_in = (unsigned char*)malloc(img_size * sizeof(unsigned char));     int* h_hist = (int*)malloc(256 * sizeof(int));           for (int i = 0; i < img_size; ++i) {         h_img_in[i] = i % 256;      }           unsigned char* d_img_in;     int* d_hist;     cudaMalloc((void**)&d_img_in, img_size * sizeof(unsigned char));     cudaMalloc((void**)&d_hist, 256 * sizeof(int));           cudaMemcpy(d_img_in, h_img_in, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemset(d_hist, 0, 256 * sizeof(int));           int block_size = 256;     dim3 grid_size((img_size + block_size - 1) / block_size, 1);           HistogramKernel<<<grid_size, block_size>>>(d_hist, d_img_in, img_size);           cudaMemcpy(h_hist, d_hist, 256 * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Image Array:\\n\");     for (int i = 0; i < img_size; ++i) {         printf(\"%d \", h_img_in[i]);     }      printf(\"\\nHistogram:\\n\");     for (int i = 0; i < 256; ++i) {         printf(\"Value %d: %d\\n\", i, h_hist[i]);     }           free(h_img_in);     free(h_hist);     cudaFree(d_img_in);     cudaFree(d_hist);      return 0; }   "
    },
    {
        "id": "271",
        "c_code": "#include <stdio.h>   void mean(float *A, float *means, int size_row, int size_col);  int main() {          int size_row = 3;     int size_col = 4;     float A[] = {1.0, 2.0, 3.0, 4.0,                  5.0, 6.0, 7.0, 8.0,                  9.0, 10.0, 11.0, 12.0};     float means[size_col];           mean(A, means, size_row, size_col);           printf(\"Means:\\n\");     for (int i = 0; i < size_col; i++) {         printf(\"%.2f \", means[i]);     }     printf(\"\\n\");      return 0; }   void mean(float *A, float *means, int size_row, int size_col) {     for (int idx = 0; idx < size_col; idx++) {         for (int i = 0; i < size_row; i++) {             means[idx] += A[idx * size_row + i];         }         means[idx] = means[idx] / size_row;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void mean(float* A, float* means, int size_row, int size_col) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;      if (idx < size_col) {         float sum = 0.0f;         for (int i = 0; i < size_row; ++i) {             sum += A[idx * size_row + i];         }         means[idx] = sum / size_row;     } }  int main() {          int size_row = 3;      int size_col = 4;            float* h_A = (float*)malloc(size_row * size_col * sizeof(float));     float* h_means = (float*)malloc(size_col * sizeof(float));           for (int i = 0; i < size_row * size_col; ++i) {         h_A[i] = i + 1;      }           float* d_A;     float* d_means;     cudaMalloc((void**)&d_A, size_row * size_col * sizeof(float));     cudaMalloc((void**)&d_means, size_col * sizeof(float));           cudaMemcpy(d_A, h_A, size_row * size_col * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     dim3 grid_size((size_col + block_size - 1) / block_size, 1);           mean<<<grid_size, block_size>>>(d_A, d_means, size_row, size_col);           cudaMemcpy(h_means, d_means, size_col * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Array A:\\n\");     for (int i = 0; i < size_row * size_col; ++i) {         printf(\"%.2f \", h_A[i]);     }      printf(\"\\nColumn Means:\\n\");     for (int i = 0; i < size_col; ++i) {         printf(\"Column %d: %.2f\\n\", i, h_means[i]);     }           free(h_A);     free(h_means);     cudaFree(d_A);     cudaFree(d_means);      return 0; }   "
    },
    {
        "id": "272",
        "c_code": "#include <stdio.h>   float reduceCPU(float *data, int size);  int main() {          int size = 5;     float data[] = {1.0, 2.0, 3.0, 4.0, 5.0};           float result = reduceCPU(data, size);           printf(\"Sum: %.2f\\n\", result);      return 0; }   float reduceCPU(float *data, int size) {     float sum = data[0];     float c = (float)0.0;      for (int i = 1; i < size; i++) {         float y = data[i] - c;         float t = sum + y;         c = (t - sum) - y;         sum = t;     }      return sum; }   ",
        "cuda_code": "#include <stdio.h>   __device__ float sumreduce(float in) {     extern __shared__ float sdata[];     unsigned int tid = threadIdx.x;      sdata[tid] = in;     __syncthreads();      for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {         if (tid < s) {             sdata[tid] += sdata[tid + s];         }         __syncthreads();     }      return sdata[0]; }   __global__ void reduceKernel(float* input, float* output, int size) {     extern __shared__ float sdata[];      unsigned int tid = threadIdx.x;     unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;           sdata[tid] = (i < size) ? input[i] : 0;     __syncthreads();           for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {         if (tid < s) {             sdata[tid] += sdata[tid + s];         }         __syncthreads();     }           if (tid == 0) {         output[blockIdx.x] = sdata[0];     } }  int main() {          int size = 1024;             float* h_input = (float*)malloc(size * sizeof(float));     float* h_output = (float*)malloc(size * sizeof(float));           for (int i = 0; i < size; ++i) {         h_input[i] = 1.0f;       }           float* d_input;     float* d_output;     cudaMalloc((void**)&d_input, size * sizeof(float));     cudaMalloc((void**)&d_output, size * sizeof(float));           cudaMemcpy(d_input, h_input, size * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     int grid_size = (size + block_size - 1) / block_size;           reduceKernel<<<grid_size, block_size, block_size * sizeof(float)>>>(d_input, d_output, size);           cudaMemcpy(h_output, d_output, grid_size * sizeof(float), cudaMemcpyDeviceToHost);           float final_result = 0.0f;     for (int i = 0; i < grid_size; ++i) {         final_result += h_output[i];     }           printf(\"Final Result: %.2f\\n\", final_result);           free(h_input);     free(h_output);     cudaFree(d_input);     cudaFree(d_output);      return 0; }   "
    },
    {
        "id": "273",
        "c_code": "#include <stdio.h> #include <math.h>   void pythagoras(unsigned char *a, unsigned char *b, unsigned char *c, int size);  int main() {          int size = 5;     unsigned char a[] = {3, 4, 5, 6, 7};     unsigned char b[] = {4, 5, 6, 7, 8};     unsigned char c[size];           pythagoras(a, b, c, size);           printf(\"Resultant C:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", c[i]);     }     printf(\"\\n\");      return 0; }   void pythagoras(unsigned char *a, unsigned char *b, unsigned char *c, int size) {     for (int idx = 0; idx < size; idx++) {         float af = (float)(a[idx]);         float bf = (float)(b[idx]);         c[idx] = (unsigned char)sqrtf(af * af + bf * bf);     } }   ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void pythagoras(unsigned char* a, unsigned char* b, unsigned char* c, int size) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;      if (idx < size) {         float af = static_cast<float>(a[idx]);         float bf = static_cast<float>(b[idx]);         c[idx] = static_cast<unsigned char>(sqrtf(af * af + bf * bf));     } }  int main() {          int size = 1024;             unsigned char* h_a = (unsigned char*)malloc(size * sizeof(unsigned char));     unsigned char* h_b = (unsigned char*)malloc(size * sizeof(unsigned char));     unsigned char* h_c = (unsigned char*)malloc(size * sizeof(unsigned char));           for (int i = 0; i < size; ++i) {         h_a[i] = 100;           h_b[i] = 150;       }           unsigned char* d_a;     unsigned char* d_b;     unsigned char* d_c;     cudaMalloc((void**)&d_a, size * sizeof(unsigned char));     cudaMalloc((void**)&d_b, size * sizeof(unsigned char));     cudaMalloc((void**)&d_c, size * sizeof(unsigned char));           cudaMemcpy(d_a, h_a, size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, size * sizeof(unsigned char), cudaMemcpyHostToDevice);           int block_size = 256;     int grid_size = (size + block_size - 1) / block_size;           pythagoras<<<grid_size, block_size>>>(d_a, d_b, d_c, size);           cudaMemcpy(h_c, d_c, size * sizeof(unsigned char), cudaMemcpyDeviceToHost);           printf(\"Results:\\n\");     for (int i = 0; i < size; ++i) {         printf(\"%u \", h_c[i]);     }     printf(\"\\n\");           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   "
    },
    {
        "id": "274",
        "c_code": "#include <stdio.h>   void avgpool_cpu(int n, float *input_im, float *output_im);  int main() {          int n = 3;     float input_im[] = {1.0, 2.0, 3.0,  9.0, 10.0, 11.0,  17.0, 18.0, 19.0};     float output_im[n];           avgpool_cpu(n, input_im, output_im);           printf(\"Output Image:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%.2f \", output_im[i]);     }     printf(\"\\n\");      return 0; }   void avgpool_cpu(int n, float *input_im, float *output_im) {     for (int class_index = 0; class_index < n; class_index++) {         float *tmp_input = input_im + 169 * class_index;         float tmp = 0.0f;          for (int i = 0; i < 169; i++) {             tmp += tmp_input[i];         }          output_im[class_index] = tmp / 169.0;     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void avgpool(int n, float* input_im, float* output_im) {     int class_index = blockIdx.x * blockDim.x + threadIdx.x;      if (class_index < n) {         input_im += 169 * class_index;         float tmp = 0.0f;          for (int i = 0; i < 169; i++) {             tmp += input_im[i];         }          output_im[class_index] = tmp / 169.0;     } }  int main() {          int num_classes = 10;             float* h_input_im = (float*)malloc(169 * num_classes * sizeof(float));     float* h_output_im = (float*)malloc(num_classes * sizeof(float));           for (int i = 0; i < 169 * num_classes; ++i) {         h_input_im[i] = static_cast<float>(i);       }           float* d_input_im;     float* d_output_im;     cudaMalloc((void**)&d_input_im, 169 * num_classes * sizeof(float));     cudaMalloc((void**)&d_output_im, num_classes * sizeof(float));           cudaMemcpy(d_input_im, h_input_im, 169 * num_classes * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     int grid_size = (num_classes + block_size - 1) / block_size;           avgpool<<<grid_size, block_size>>>(num_classes, d_input_im, d_output_im);           cudaMemcpy(h_output_im, d_output_im, num_classes * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Results:\\n\");     for (int i = 0; i < num_classes; ++i) {         printf(\"%f \", h_output_im[i]);     }     printf(\"\\n\");           free(h_input_im);     free(h_output_im);     cudaFree(d_input_im);     cudaFree(d_output_im);      return 0; }   "
    },
    {
        "id": "275",
        "c_code": "#include <stdio.h>   void weighted_sum_cpu(float *a, float *b, float *s, int n, float *c);  int main() {          int n = 5;     float a[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float b[] = {6.0, 7.0, 8.0, 9.0, 10.0};     float s[] = {0.2, 0.4, 0.6, 0.8, 1.0};     float c[n];           weighted_sum_cpu(a, b, s, n, c);           printf(\"Weighted Sum:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%.2f \", c[i]);     }     printf(\"\\n\");      return 0; }   void weighted_sum_cpu(float *a, float *b, float *s, int n, float *c) {     for (int i = 0; i < n; ++i) {         c[i] = s[i] * a[i] + (1 - s[i]) * (b ? b[i] : 0);     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void weighted_sum_kernel(int n, float* a, float* b, float* s, float* c) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i < n) {         c[i] = s[i] * a[i] + (1 - s[i]) * (b ? b[i] : 0);     } }  int main() {          int size = 1024;             float* h_a = (float*)malloc(size * sizeof(float));     float* h_b = (float*)malloc(size * sizeof(float));     float* h_s = (float*)malloc(size * sizeof(float));     float* h_c = (float*)malloc(size * sizeof(float));           for (int i = 0; i < size; ++i) {         h_a[i] = 1.0f;           h_b[i] = 2.0f;           h_s[i] = 0.5f;       }           float* d_a;     float* d_b;     float* d_s;     float* d_c;     cudaMalloc((void**)&d_a, size * sizeof(float));     cudaMalloc((void**)&d_b, size * sizeof(float));     cudaMalloc((void**)&d_s, size * sizeof(float));     cudaMalloc((void**)&d_c, size * sizeof(float));           cudaMemcpy(d_a, h_a, size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_s, h_s, size * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     int grid_size = (size + block_size - 1) / block_size;           weighted_sum_kernel<<<grid_size, block_size>>>(size, d_a, d_b, d_s, d_c);           cudaMemcpy(h_c, d_c, size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Results:\\n\");     for (int i = 0; i < size; ++i) {         printf(\"%f \", h_c[i]);     }     printf(\"\\n\");           free(h_a);     free(h_b);     free(h_s);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_s);     cudaFree(d_c);      return 0; }   "
    },
    {
        "id": "276",
        "c_code": "#include <stdio.h> #include <math.h>   void kernel(float *x, int n);  int main() {          int n = 5;     float x[n];           kernel(x, n);           printf(\"Resultant x:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%.4f \", x[i]);     }     printf(\"\\n\");      return 0; }   void kernel(float *x, int n) {     for (int i = 0; i < n; i++) {         double sum = 0;         for (int j = 0; j < 1000; j++) {             sum += sqrt(pow(3.14159, i)) / (float)j;         }         x[i] = sum;     } }   ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void kernel(float* x, int n) {     int tid = threadIdx.x + blockIdx.x * blockDim.x;      for (int i = tid; i < n; i += blockDim.x * gridDim.x) {         double sum = 0;          for (int j = 0; j < 1000; j++) {             sum += sqrt(pow(3.14159, i)) / float(j);         }          x[i] = sum;     } }  int main() {          int size = 1024;             float* h_x = (float*)malloc(size * sizeof(float));           float* d_x;     cudaMalloc((void**)&d_x, size * sizeof(float));           int block_size = 256;     int grid_size = (size + block_size - 1) / block_size;           kernel<<<grid_size, block_size>>>(d_x, size);           cudaMemcpy(h_x, d_x, size * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Results:\\n\");     for (int i = 0; i < size; ++i) {         printf(\"%f \", h_x[i]);     }     printf(\"\\n\");           free(h_x);     cudaFree(d_x);      return 0; }   "
    },
    {
        "id": "277",
        "c_code": "#include <stdio.h>   void MMDSelfComputeWithSum(float *x_average, int size_x, float *distance_matrix);  int main() {          int size_x = 4;     float x_average[] = {1.5, 2.0, 3.0, 4.5};     float distance_matrix[size_x * size_x];           MMDSelfComputeWithSum(x_average, size_x, distance_matrix);           printf(\"Distance Matrix:\\n\");     for (int i = 0; i < size_x; i++) {         for (int j = 0; j < size_x; j++) {             printf(\"%.2f \", distance_matrix[i * size_x + j]);         }         printf(\"\\n\");     }      return 0; }   void MMDSelfComputeWithSum(float *x_average, int size_x, float *distance_matrix) {     for (int i = 0; i < size_x; i++) {         for (int j = i; j < size_x; j++) {             distance_matrix[i * size_x + j] = x_average[i] * x_average[j];             distance_matrix[j * size_x + i] = distance_matrix[i * size_x + j];          }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void MMDSelfComputeWithSum(float* x_average, int size_x, float* distance_matrix) {     int block_id = blockIdx.x;     int thread_id = threadIdx.x;      for (int i = block_id; i < size_x; i += gridDim.x) {         for (int j = thread_id + i; j < size_x; j += blockDim.x) {             distance_matrix[i * size_x + j] = x_average[i] * x_average[j];         }     } }  int main() {          int size_x = 1024;             float* h_x_average = (float*)malloc(size_x * sizeof(float));     float* h_distance_matrix = (float*)malloc(size_x * size_x * sizeof(float));           for (int i = 0; i < size_x; ++i) {         h_x_average[i] = float(i);       }           float* d_x_average;     float* d_distance_matrix;     cudaMalloc((void**)&d_x_average, size_x * sizeof(float));     cudaMalloc((void**)&d_distance_matrix, size_x * size_x * sizeof(float));           cudaMemcpy(d_x_average, h_x_average, size_x * sizeof(float), cudaMemcpyHostToDevice);           int block_size = 256;     int grid_size = (size_x + block_size - 1) / block_size;           MMDSelfComputeWithSum<<<grid_size, block_size>>>(d_x_average, size_x, d_distance_matrix);           cudaMemcpy(h_distance_matrix, d_distance_matrix, size_x * size_x * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Results:\\n\");     for (int i = 0; i < size_x; ++i) {         for (int j = 0; j < size_x; ++j) {             printf(\"%f \", h_distance_matrix[i * size_x + j]);         }         printf(\"\\n\");     }           free(h_x_average);     free(h_distance_matrix);     cudaFree(d_x_average);     cudaFree(d_distance_matrix);      return 0; }   "
    },
    {
        "id": "278",
        "c_code": "#include <stdio.h>   void matVecRowSub_cpu(const double *mat, const double *vec, double *buf, int m, int n);  int main() {          int m = 3;     int n = 4;     double mat[] = {1.0, 2.0, 3.0, 4.0,                     5.0, 6.0, 7.0, 8.0,                     9.0, 10.0, 11.0, 12.0};     double vec[] = {2.0, 4.0, 6.0, 8.0};     double buf[m * n];           matVecRowSub_cpu(mat, vec, buf, m, n);           printf(\"Resultant Buffer:\\n\");     for (int i = 0; i < m; i++) {         for (int j = 0; j < n; j++) {             printf(\"%.2f \", buf[i * n + j]);         }         printf(\"\\n\");     }      return 0; }   void matVecRowSub_cpu(const double *mat, const double *vec, double *buf, int m, int n) {     for (int index = 0; index < m * n; index++) {         int i = index / n;         int j = index % n;         buf[i * n + j] = mat[i * n + j] - vec[j];     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void matVecRowSubKernel(const double* mat, const double* vec, double* buf, int m, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < m * n) {         int i = index / n;         int j = index % n;         buf[i * n + j] = mat[i * n + j] - vec[j];     } }  int main() {          int m = 4;             int n = 3;             double* h_mat = (double*)malloc(m * n * sizeof(double));     double* h_vec = (double*)malloc(n * sizeof(double));     double* h_buf = (double*)malloc(m * n * sizeof(double));           for (int i = 0; i < m * n; ++i) {         h_mat[i] = i;       }      for (int i = 0; i < n; ++i) {         h_vec[i] = i;       }           double* d_mat;     double* d_vec;     double* d_buf;     cudaMalloc((void**)&d_mat, m * n * sizeof(double));     cudaMalloc((void**)&d_vec, n * sizeof(double));     cudaMalloc((void**)&d_buf, m * n * sizeof(double));           cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec, h_vec, n * sizeof(double), cudaMemcpyHostToDevice);           int block_size = 256;     int grid_size = (m * n + block_size - 1) / block_size;           matVecRowSubKernel<<<grid_size, block_size>>>(d_mat, d_vec, d_buf, m, n);           cudaMemcpy(h_buf, d_buf, m * n * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Results:\\n\");     for (int i = 0; i < m; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"%f \", h_buf[i * n + j]);         }         printf(\"\\n\");     }           free(h_mat);     free(h_vec);     free(h_buf);     cudaFree(d_mat);     cudaFree(d_vec);     cudaFree(d_buf);      return 0; }   "
    },
    {
        "id": "279",
        "c_code": "#include <stdio.h>   void transKernel(float *array1, float *array2, int width);  int main() {          int width = 3;     float array1[] = {1.0, 2.0, 3.0,                       4.0, 5.0, 6.0,                       7.0, 8.0, 9.0};     float array2[width * width];           transKernel(array1, array2, width);           printf(\"Transposed Array:\\n\");     for (int x = 0; x < width; x++) {         for (int y = 0; y < width; y++) {             printf(\"%.2f \", array2[x * width + y]);         }         printf(\"\\n\");     }      return 0; }   void transKernel(float *array1, float *array2, int width) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < width; y++) {             int current_index = x * width + y;             int replace = y * width + x;             array2[replace] = array1[current_index];         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void transKernel(float* array1, float* array2, int width) {     int current_index =         (blockIdx.y * blockDim.y + threadIdx.y) * width +         (blockIdx.x * blockDim.x + threadIdx.x);     int replace =         (blockIdx.x * blockDim.x + threadIdx.x) * width +         blockIdx.y * blockDim.y + threadIdx.y;      if (current_index < width * width) {         array2[replace] = array1[current_index];     } }  int main() {          int width = 4;             float* h_array1 = (float*)malloc(width * width * sizeof(float));     float* h_array2 = (float*)malloc(width * width * sizeof(float));           for (int i = 0; i < width * width; ++i) {         h_array1[i] = i;       }           float* d_array1;     float* d_array2;     cudaMalloc((void**)&d_array1, width * width * sizeof(float));     cudaMalloc((void**)&d_array2, width * width * sizeof(float));           cudaMemcpy(d_array1, h_array1, width * width * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(2, 2);       dim3 grid_size((width + block_size.x - 1) / block_size.x, (width + block_size.y - 1) / block_size.y);           transKernel<<<grid_size, block_size>>>(d_array1, d_array2, width);           cudaMemcpy(h_array2, d_array2, width * width * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Results:\\n\");     for (int i = 0; i < width; ++i) {         for (int j = 0; j < width; ++j) {             printf(\"%f \", h_array2[i * width + j]);         }         printf(\"\\n\");     }           free(h_array1);     free(h_array2);     cudaFree(d_array1);     cudaFree(d_array2);      return 0; }   "
    },
    {
        "id": "28",
        "c_code": "#include <stdio.h>  void dsubtract_matrix(double *a, double *b, double *c, int N) {     for (int idx = 0; idx < N; idx++) {         c[idx] = a[idx] - b[idx];     } }  int main() {          int arraySize = 6;     double arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};     double arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5, 5.5};     double resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           dsubtract_matrix(arrayA, arrayB, resultArray, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff08\u5dee\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void dsubtract_matrix(double* a, double* b, double* c, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         c[idx] = a[idx] - b[idx];     } }  int main() {          int arraySize = 1000;           double* h_a = (double*)malloc(arraySize * sizeof(double));     double* h_b = (double*)malloc(arraySize * sizeof(double));     double* h_c = (double*)malloc(arraySize * sizeof(double));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<double>(i);         h_b[i] = static_cast<double>(2 * i);     }           double* d_a;     double* d_b;     double* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(double));     cudaMalloc((void**)&d_b, arraySize * sizeof(double));     cudaMalloc((void**)&d_c, arraySize * sizeof(double));           cudaMemcpy(d_a, h_a, arraySize * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           dsubtract_matrix<<<gridSize, blockSize>>>(d_a, d_b, d_c, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "280",
        "c_code": "#include <stdio.h>   void rowSumSquare_cpu(const double *mat, double *buf, int m, int n);  int main() {          int m = 3;     int n = 4;     double mat[] = {1.0, 2.0, 3.0, 4.0,                     5.0, 6.0, 7.0, 8.0,                     9.0, 10.0, 11.0, 12.0};     double buf[m];           rowSumSquare_cpu(mat, buf, m, n);           printf(\"Row Sum Squares:\\n\");     for (int i = 0; i < m; i++) {         printf(\"%.2f \", buf[i]);     }     printf(\"\\n\");      return 0; }   void rowSumSquare_cpu(const double *mat, double *buf, int m, int n) {     for (int i = 0; i < m; i++) {         double sum = 0.0;       ",
        "cuda_code": "#include <stdio.h>   __global__ void rowSumSquareKernel(const double* mat, double* buf, int m, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i < m) {         double sum = 0.0;          for (int j = 0; j < n; j++) {             double a = mat[i * n + j];             sum += a * a;         }          buf[i] = sum;     } }  int main() {          int m = 3;       int n = 4;             double* h_mat = (double*)malloc(m * n * sizeof(double));     double* h_buf = (double*)malloc(m * sizeof(double));           for (int i = 0; i < m * n; ++i) {         h_mat[i] = i;       }           double* d_mat;     double* d_buf;     cudaMalloc((void**)&d_mat, m * n * sizeof(double));     cudaMalloc((void**)&d_buf, m * sizeof(double));           cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);           dim3 block_size(2, 1);       dim3 grid_size((m + block_size.x - 1) / block_size.x, 1);           rowSumSquareKernel<<<grid_size, block_size>>>(d_mat, d_buf, m, n);           cudaMemcpy(h_buf, d_buf, m * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Results:\\n\");     for (int i = 0; i < m; ++i) {         printf(\"%f \", h_buf[i]);     }     printf(\"\\n\");           free(h_mat);     free(h_buf);     cudaFree(d_mat);     cudaFree(d_buf);      return 0; }   "
    },
    {
        "id": "281",
        "c_code": "#include <stdio.h>   void matrixTranspose_cpu(int *in_mat, int *out_mat, int dim_rows, int dim_cols);  int main() {          int dim_rows = 3;     int dim_cols = 4;     int in_mat[] = {1, 2, 3, 4,                     5, 6, 7, 8,                     9, 10, 11, 12};     int out_mat[dim_cols * dim_rows];           matrixTranspose_cpu(in_mat, out_mat, dim_rows, dim_cols);           printf(\"Transposed Matrix:\\n\");     for (int i = 0; i < dim_cols; i++) {         for (int j = 0; j < dim_rows; j++) {             printf(\"%d \", out_mat[i * dim_rows + j]);         }         printf(\"\\n\");     }      return 0; }   void matrixTranspose_cpu(int *in_mat, int *out_mat, int dim_rows, int dim_cols) {     for (int i = 0; i < dim_rows; ++i) {         for (int j = 0; j < dim_cols; ++j) {             unsigned int new_pos = j * dim_rows + i;             out_mat[new_pos] = in_mat[i * dim_cols + j];         }     } }   ",
        "cuda_code": "#include <stdio.h>   __global__ void matrixTranspose(int* in_mat, int* out_mat, int dim_rows, int dim_cols) {     int row = threadIdx.y + blockIdx.y * blockDim.y;     int col = threadIdx.x + blockIdx.x * blockDim.x;      if (row < dim_rows && col < dim_cols) {         unsigned int new_pos = col * dim_rows + row;         out_mat[new_pos] = in_mat[row * dim_cols + col];     } }  int main() {          int dim_rows = 3;       int dim_cols = 4;             int* h_in_mat = (int*)malloc(dim_rows * dim_cols * sizeof(int));     int* h_out_mat = (int*)malloc(dim_cols * dim_rows * sizeof(int));           for (int i = 0; i < dim_rows * dim_cols; ++i) {         h_in_mat[i] = i;       }           int* d_in_mat;     int* d_out_mat;     cudaMalloc((void**)&d_in_mat, dim_rows * dim_cols * sizeof(int));     cudaMalloc((void**)&d_out_mat, dim_cols * dim_rows * sizeof(int));           cudaMemcpy(d_in_mat, h_in_mat, dim_rows * dim_cols * sizeof(int), cudaMemcpyHostToDevice);           dim3 block_size(2, 2);       dim3 grid_size((dim_cols + block_size.x - 1) / block_size.x, (dim_rows + block_size.y - 1) / block_size.y);           matrixTranspose<<<grid_size, block_size>>>(d_in_mat, d_out_mat, dim_rows, dim_cols);           cudaMemcpy(h_out_mat, d_out_mat, dim_cols * dim_rows * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Original Matrix:\\n\");     for (int i = 0; i < dim_rows; ++i) {         for (int j = 0; j < dim_cols; ++j) {             printf(\"%d \", h_in_mat[i * dim_cols + j]);         }         printf(\"\\n\");     }      printf(\"\\nTransposed Matrix:\\n\");     for (int i = 0; i < dim_cols; ++i) {         for (int j = 0; j < dim_rows; ++j) {             printf(\"%d \", h_out_mat[i * dim_rows + j]);         }         printf(\"\\n\");     }           free(h_in_mat);     free(h_out_mat);     cudaFree(d_in_mat);     cudaFree(d_out_mat);      return 0; }   "
    },
    {
        "id": "282",
        "c_code": "#include <stdio.h>   void analysis(int D[], int L[], int R[], int N);  int main() {          int N = 5;     int D[] = {0, 1, 2, 3, 4};     int L[] = {0, 1, 2, 3, 4};     int R[] = {0, 1, 2, 3, 4};           analysis(D, L, R, N);           printf(\"Results:\\n\");     printf(\"D: \");     for (int i = 0; i < N; i++) {         printf(\"%d \", D[i]);     }     printf(\"\\n\");     printf(\"L: \");     for (int i = 0; i < N; i++) {         printf(\"%d \", L[i]);     }     printf(\"\\n\");     printf(\"R: \");     for (int i = 0; i < N; i++) {         printf(\"%d \", R[i]);     }     printf(\"\\n\");      return 0; }   void analysis(int D[], int L[], int R[], int N) {     int id;     for (id = 0; id < N; id++) {         int label = L[id];         int ref;         if (label == id) {             do {                 label = R[ref = label];             } while (ref ^ label);             R[id] = label;         }     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void analysis(int D[], int L[], int R[], int N) {     int id = blockIdx.x * blockDim.x + blockIdx.y * blockDim.x * gridDim.x + threadIdx.x;      if (id >= N)         return;      int label = L[id];     int ref;      if (label == id) {         do {             label = R[ref = label];         } while (ref ^ label);          R[id] = label;     } }  int main() {          int N = 100;             int* h_D = (int*)malloc(N * sizeof(int));     int* h_L = (int*)malloc(N * sizeof(int));     int* h_R = (int*)malloc(N * sizeof(int));           for (int i = 0; i < N; ++i) {         h_D[i] = i;         h_L[i] = i;         h_R[i] = i;     }           int* d_D;     int* d_L;     int* d_R;      cudaMalloc((void**)&d_D, N * sizeof(int));     cudaMalloc((void**)&d_L, N * sizeof(int));     cudaMalloc((void**)&d_R, N * sizeof(int));           cudaMemcpy(d_D, h_D, N * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_L, h_L, N * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_R, h_R, N * sizeof(int), cudaMemcpyHostToDevice);           dim3 block_size(256);       dim3 grid_size((N + block_size.x - 1) / block_size.x);           analysis<<<grid_size, block_size>>>(d_D, d_L, d_R, N);           cudaMemcpy(h_R, d_R, N * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result array (R):\\n\");     for (int i = 0; i < N; ++i) {         printf(\"%d \", h_R[i]);     }     printf(\"\\n\");           free(h_D);     free(h_L);     free(h_R);     cudaFree(d_D);     cudaFree(d_L);     cudaFree(d_R);      return 0; }   "
    },
    {
        "id": "283",
        "c_code": "#include <stdio.h>   void Transpose2d(float *array_transpose, float *array, const int r, const int c);  int main() {          int r = 3;     int c = 4;     float array[] = {1.0, 2.0, 3.0, 4.0,                      5.0, 6.0, 7.0, 8.0,                      9.0, 10.0, 11.0, 12.0};     float array_transpose[c * r];           Transpose2d(array_transpose, array, r, c);           printf(\"Original Array:\\n\");     for (int i = 0; i < r; i++) {         for (int j = 0; j < c; j++) {             printf(\"%.2f \", array[i * c + j]);         }         printf(\"\\n\");     }      printf(\"\\nTransposed Array:\\n\");     for (int i = 0; i < c; i++) {         for (int j = 0; j < r; j++) {             printf(\"%.2f \", array_transpose[i * r + j]);         }         printf(\"\\n\");     }      return 0; }   void Transpose2d(float *array_transpose, float *array, const int r, const int c) {     int i, j;     for (i = 0; i < r; i++) {         for (j = 0; j < c; j++) {             array_transpose[j * r + i] = array[i * c + j];         }     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void Kernel_Transpose2d(float* dev_transposeArray, float* dev_array, const int r, const int c) {     unsigned int i = blockDim.x * blockIdx.x + threadIdx.x;     unsigned int j = blockDim.y * blockIdx.y + threadIdx.y;      if (i >= r || j >= c)         return;      int idx_transposeArray, idx_array;     idx_array = i * c + j;     idx_transposeArray = j * r + i;     dev_transposeArray[idx_transposeArray] = dev_array[idx_array]; }  int main() {          const int r = 4;      const int c = 3;            float* h_dev_transposeArray = (float*)malloc(r * c * sizeof(float));     float* h_dev_array = (float*)malloc(r * c * sizeof(float));           for (int i = 0; i < r * c; ++i) {         h_dev_array[i] = i;     }           float* d_dev_transposeArray;     float* d_dev_array;      cudaMalloc((void**)&d_dev_transposeArray, r * c * sizeof(float));     cudaMalloc((void**)&d_dev_array, r * c * sizeof(float));           cudaMemcpy(d_dev_array, h_dev_array, r * c * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(16, 16);      dim3 grid_size((r + block_size.x - 1) / block_size.x, (c + block_size.y - 1) / block_size.y);           Kernel_Transpose2d<<<grid_size, block_size>>>(d_dev_transposeArray, d_dev_array, r, c);           cudaMemcpy(h_dev_transposeArray, d_dev_transposeArray, r * c * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Original Array:\\n\");     for (int i = 0; i < r; ++i) {         for (int j = 0; j < c; ++j) {             printf(\"%.2f\\t\", h_dev_array[i * c + j]);         }         printf(\"\\n\");     }      printf(\"\\nTransposed Array:\\n\");     for (int i = 0; i < c; ++i) {         for (int j = 0; j < r; ++j) {             printf(\"%.2f\\t\", h_dev_transposeArray[i * r + j]);         }         printf(\"\\n\");     }           free(h_dev_transposeArray);     free(h_dev_array);     cudaFree(d_dev_transposeArray);     cudaFree(d_dev_array);      return 0; }   "
    },
    {
        "id": "284",
        "c_code": "#include <stdio.h>   void getMeanImage_cpu(const double *images, double *meanImage, int imageNum, int pixelNum);  int main() {          int imageNum = 3;     int pixelNum = 4;     double images[] = {1.0, 2.0, 3.0, 4.0,                        5.0, 6.0, 7.0, 8.0,                        9.0, 10.0, 11.0, 12.0};     double meanImage[pixelNum];           getMeanImage_cpu(images, meanImage, imageNum, pixelNum);           printf(\"Mean Image:\\n\");     for (int col = 0; col < pixelNum; col++) {         printf(\"%.2f \", meanImage[col]);     }     printf(\"\\n\");      return 0; }   void getMeanImage_cpu(const double *images, double *meanImage, int imageNum, int pixelNum) {     for (int col = 0; col < pixelNum; col++) {         meanImage[col] = 0.0;         for (int row = 0; row < imageNum; ++row) {             meanImage[col] += images[row * pixelNum + col];         }         meanImage[col] /= imageNum;     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void getMeanImage(const double* images, double* meanImage, int imageNum, int pixelNum) {     int col = blockIdx.x * blockDim.x + threadIdx.x;      if (col >= pixelNum) {         return;     }      meanImage[col] = 0.0;      for (int row = 0; row < imageNum; ++row) {         meanImage[col] += images[row * pixelNum + col];     }      meanImage[col] /= imageNum; }  int main() {          const int imageNum = 100;      const int pixelNum = 64;             double* h_images = (double*)malloc(imageNum * pixelNum * sizeof(double));     double* h_meanImage = (double*)malloc(pixelNum * sizeof(double));           for (int i = 0; i < imageNum * pixelNum; ++i) {         h_images[i] = i;      }           double* d_images;     double* d_meanImage;      cudaMalloc((void**)&d_images, imageNum * pixelNum * sizeof(double));     cudaMalloc((void**)&d_meanImage, pixelNum * sizeof(double));           cudaMemcpy(d_images, h_images, imageNum * pixelNum * sizeof(double), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;      int blocksPerGrid = (pixelNum + threadsPerBlock - 1) / threadsPerBlock;           getMeanImage<<<blocksPerGrid, threadsPerBlock>>>(d_images, d_meanImage, imageNum, pixelNum);           cudaMemcpy(h_meanImage, d_meanImage, pixelNum * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Mean Image:\\n\");     for (int i = 0; i < pixelNum; ++i) {         printf(\"%.2f\\t\", h_meanImage[i]);     }     printf(\"\\n\");           free(h_images);     free(h_meanImage);     cudaFree(d_images);     cudaFree(d_meanImage);      return 0; }   "
    },
    {
        "id": "285",
        "c_code": "#include <stdio.h>   void Avg(float *array_avg, float *array, const int r, const int c);  int main() {          int r = 3;     int c = 4;     float array[] = {1.0, 2.0, 3.0, 4.0,                      5.0, 6.0, 7.0, 8.0,                      9.0, 10.0, 11.0, 12.0};     float array_avg[r];           Avg(array_avg, array, r, c);           printf(\"Average Array:\\n\");     for (int i = 0; i < r; i++) {         printf(\"%.2f \", array_avg[i]);     }     printf(\"\\n\");      return 0; }   void Avg(float *array_avg, float *array, const int r, const int c) {     float sum;     for (int i = 0; i < r; i++) {         sum = 0.0;         for (int j = 0; j < c; j++) {             sum += array[i * c + j];         }         array_avg[i] = sum / c;     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void Kernel_Avg(float* dev_arrayMax, float* dev_array, const int r, const int c) {     unsigned int tid = blockDim.x * blockIdx.x + threadIdx.x;     int N = r;     float sum;     int i;      while (tid < N) {         i = tid;         sum = 0.0;          for (int j = 0; j < c; j++) {             sum += dev_array[i * c + j];         }          dev_arrayMax[i] = sum / c;         tid += gridDim.x * blockDim.x;     } }  int main() {          const int r = 100;      const int c = 64;             float* h_array = (float*)malloc(r * c * sizeof(float));     float* h_arrayMax = (float*)malloc(r * sizeof(float));           for (int i = 0; i < r * c; ++i) {         h_array[i] = i;      }           float* d_array;     float* d_arrayMax;      cudaMalloc((void**)&d_array, r * c * sizeof(float));     cudaMalloc((void**)&d_arrayMax, r * sizeof(float));           cudaMemcpy(d_array, h_array, r * c * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;      int blocksPerGrid = (r + threadsPerBlock - 1) / threadsPerBlock;           Kernel_Avg<<<blocksPerGrid, threadsPerBlock>>>(d_arrayMax, d_array, r, c);           cudaMemcpy(h_arrayMax, d_arrayMax, r * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Average for each row:\\n\");     for (int i = 0; i < r; ++i) {         printf(\"%.2f\\t\", h_arrayMax[i]);     }     printf(\"\\n\");           free(h_array);     free(h_arrayMax);     cudaFree(d_array);     cudaFree(d_arrayMax);      return 0; }   "
    },
    {
        "id": "286",
        "c_code": "#include <stdio.h>   void smallCorrelation_cpu(float *L, float *innerSums, int innerSumsLength);  int main() {          int innerSumsLength = 5;     float innerSums[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float L[innerSumsLength];           smallCorrelation_cpu(L, innerSums, innerSumsLength);           printf(\"Correlation Array (L):\\n\");     for (int u = 0; u < innerSumsLength; u++) {         printf(\"%.2f \", L[u]);     }     printf(\"\\n\");      return 0; }   void smallCorrelation_cpu(float *L, float *innerSums, int innerSumsLength) {     for (int u = 0; u < innerSumsLength; u++) {         int realIdx = 2 * u;         int imagIdx = realIdx + 1;         L[u] = (innerSums[realIdx] * innerSums[realIdx]) + (innerSums[imagIdx] * innerSums[imagIdx]);     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void smallCorrelation(float* L, float* innerSums, int innerSumsLength) {     int u = (blockIdx.x * blockDim.x) + threadIdx.x;     if (u >= innerSumsLength)         return;      int realIdx = 2 * u;     int imagIdx = realIdx + 1;     L[u] = (innerSums[realIdx] * innerSums[realIdx]) + (innerSums[imagIdx] * innerSums[imagIdx]); }  int main() {          const int innerSumsLength = 100;            float* h_L = (float*)malloc(innerSumsLength * sizeof(float));     float* h_innerSums = (float*)malloc(2 * innerSumsLength * sizeof(float));            for (int i = 0; i < 2 * innerSumsLength; ++i) {         h_innerSums[i] = i;      }           float* d_L;     float* d_innerSums;      cudaMalloc((void**)&d_L, innerSumsLength * sizeof(float));     cudaMalloc((void**)&d_innerSums, 2 * innerSumsLength * sizeof(float));           cudaMemcpy(d_innerSums, h_innerSums, 2 * innerSumsLength * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;      int blocksPerGrid = (innerSumsLength + threadsPerBlock - 1) / threadsPerBlock;           smallCorrelation<<<blocksPerGrid, threadsPerBlock>>>(d_L, d_innerSums, innerSumsLength);           cudaMemcpy(h_L, d_L, innerSumsLength * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Resultant array:\\n\");     for (int i = 0; i < innerSumsLength; ++i) {         printf(\"%.2f\\t\", h_L[i]);     }     printf(\"\\n\");           free(h_L);     free(h_innerSums);     cudaFree(d_L);     cudaFree(d_innerSums);      return 0; }   "
    },
    {
        "id": "287",
        "c_code": "#include <stdio.h>   void cpuDecodeBitstream(unsigned short *encoded, unsigned short *decoded, int size);  int main() {          int size = 5;     unsigned short encoded[] = {1, 0, 0, 1, 1, 1, 1, 0, 1, 0};     unsigned short decoded[size];           cpuDecodeBitstream(encoded, decoded, size);           printf(\"Decoded Bitstream:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%hu \", decoded[i]);     }     printf(\"\\n\");      return 0; }   void cpuDecodeBitstream(unsigned short *encoded, unsigned short *decoded, int size) {     for (int i = 0; i < size; i++) {         int bit_index = (i * 2) + 2;         unsigned short curr_bit = encoded[bit_index];         decoded[bit_index] = !encoded[bit_index - 1] ^ curr_bit;         decoded[bit_index + 1] = curr_bit ^ encoded[bit_index + 1];     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void cudaDecodeBitstream(unsigned short* encoded, unsigned short* decoded, int size) {     int bit_index = (((blockIdx.x * blockDim.x) + threadIdx.x) * 2) + 2;     if (bit_index >= size)         return;      unsigned short curr_bit = encoded[bit_index];     decoded[bit_index] = !encoded[bit_index - 1] ^ curr_bit;     decoded[bit_index + 1] = curr_bit ^ encoded[bit_index + 1]; }  int main() {          const int size = 100;            unsigned short* h_encoded = (unsigned short*)malloc(size * sizeof(unsigned short));     unsigned short* h_decoded = (unsigned short*)malloc(size * sizeof(unsigned short));           for (int i = 0; i < size; ++i) {         h_encoded[i] = i;      }           unsigned short* d_encoded;     unsigned short* d_decoded;      cudaMalloc((void**)&d_encoded, size * sizeof(unsigned short));     cudaMalloc((void**)&d_decoded, size * sizeof(unsigned short));           cudaMemcpy(d_encoded, h_encoded, size * sizeof(unsigned short), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;      int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;           cudaDecodeBitstream<<<blocksPerGrid, threadsPerBlock>>>(d_encoded, d_decoded, size);           cudaMemcpy(h_decoded, d_decoded, size * sizeof(unsigned short), cudaMemcpyDeviceToHost);           printf(\"Decoded array:\\n\");     for (int i = 0; i < size; ++i) {         printf(\"%hu\\t\", h_decoded[i]);     }     printf(\"\\n\");           free(h_encoded);     free(h_decoded);     cudaFree(d_encoded);     cudaFree(d_decoded);      return 0; }   "
    },
    {
        "id": "288",
        "c_code": "#include <stdio.h>   void vectorMatrixMult(long int totalPixels, float *matrix, float *vector, float *out);  int main() {          long int totalPixels = 3;     float matrix[] = {1.0, 2.0, 3.0,                       4.0, 5.0, 6.0,                       7.0, 8.0, 9.0};     float vector[] = {2.0, 1.0, 3.0};     float out[totalPixels];           vectorMatrixMult(totalPixels, matrix, vector, out);           printf(\"Resultant Vector:\\n\");     for (long int i = 0; i < totalPixels; i++) {         printf(\"%.2f \", out[i]);     }     printf(\"\\n\");      return 0; }   void vectorMatrixMult(long int totalPixels, float *matrix, float *vector, float *out) {     for (long int i = 0; i < totalPixels; i++) {         float sum = 0.0;         for (long int j = 0; j < totalPixels; j++) {             sum += matrix[i * totalPixels + j] * vector[j];         }         out[i] = sum;     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void vectorMatrixMult(long int totalPixels, float* matrix, float* vector, float* out) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = blockDim.x * gridDim.x;      for (long int i = index; i < totalPixels; i += stride) {         float sum = 0.0;          for (long int j = 0; j < totalPixels; j++) {             sum += matrix[i * totalPixels + j] * vector[j];         }          out[i] = sum;     } }  int main() {          const long int totalPixels = 100;            float* h_matrix = (float*)malloc(totalPixels * totalPixels * sizeof(float));     float* h_vector = (float*)malloc(totalPixels * sizeof(float));     float* h_out = (float*)malloc(totalPixels * sizeof(float));           for (long int i = 0; i < totalPixels * totalPixels; ++i) {         h_matrix[i] = i;      }      for (long int i = 0; i < totalPixels; ++i) {         h_vector[i] = i;      }           float* d_matrix;     float* d_vector;     float* d_out;      cudaMalloc((void**)&d_matrix, totalPixels * totalPixels * sizeof(float));     cudaMalloc((void**)&d_vector, totalPixels * sizeof(float));     cudaMalloc((void**)&d_out, totalPixels * sizeof(float));           cudaMemcpy(d_matrix, h_matrix, totalPixels * totalPixels * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vector, h_vector, totalPixels * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;      int blocksPerGrid = (totalPixels + threadsPerBlock - 1) / threadsPerBlock;           vectorMatrixMult<<<blocksPerGrid, threadsPerBlock>>>(totalPixels, d_matrix, d_vector, d_out);           cudaMemcpy(h_out, d_out, totalPixels * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result array:\\n\");     for (long int i = 0; i < totalPixels; ++i) {         printf(\"%f\\t\", h_out[i]);     }     printf(\"\\n\");           free(h_matrix);     free(h_vector);     free(h_out);     cudaFree(d_matrix);     cudaFree(d_vector);     cudaFree(d_out);      return 0; }   "
    },
    {
        "id": "289",
        "c_code": "#include <stdio.h>   void roundOff(float *mat, int N, int M);  int main() {          int N = 3;     int M = 4;     float mat[] = {1.2, -2.5, 3.8,                    -4.1, 5.6, -6.9,                    7.4, -8.2, 9.0,                    -10.3, 11.7, -12.5};           roundOff(mat, N, M);           printf(\"Rounded Matrix:\\n\");     for (int i = 0; i < M; i++) {         for (int j = 0; j < N; j++) {             printf(\"%.0f \", mat[i * N + j]);         }         printf(\"\\n\");     }      return 0; }   void roundOff(float *mat, int N, int M) {     for (int i = 0; i < M; i++) {         for (int j = 0; j < N; j++) {             if (mat[i * N + j] >= 0)                 mat[i * N + j] = (int)(mat[i * N + j] + 0.5);             else                 mat[i * N + j] = (int)(mat[i * N + j] - 0.5);         }     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void roundOff(float* mat, int N) {     int i = threadIdx.x;     int j = blockIdx.x;      if (mat[i * N + j] >= 0)         mat[i * N + j] = (int)(mat[i * N + j] + 0.5);     else         mat[i * N + j] = (int)(mat[i * N + j] - 0.5); }  int main() {          const int N = 100;            float* h_mat = (float*)malloc(N * N * sizeof(float));           for (int i = 0; i < N * N; ++i) {         h_mat[i] = i;      }           float* d_mat;     cudaMalloc((void**)&d_mat, N * N * sizeof(float));           cudaMemcpy(d_mat, h_mat, N * N * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = N;     int blocksPerGrid = 1;           roundOff<<<blocksPerGrid, threadsPerBlock>>>(d_mat, N);           cudaMemcpy(h_mat, d_mat, N * N * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result matrix:\\n\");     for (int i = 0; i < N; ++i) {         for (int j = 0; j < N; ++j) {             printf(\"%.1f\\t\", h_mat[i * N + j]);         }         printf(\"\\n\");     }           free(h_mat);     cudaFree(d_mat);      return 0; }   "
    },
    {
        "id": "29",
        "c_code": "#include <stdio.h>  void add_arrays(int n, float *x, float *y, float *z) {     for (int i = 0; i < n; i++) {         z[i] = x[i] + y[i];     } }  int main() {          int arraySize = 5;     float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayY[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }      printf(\"\\n\u6570\u7ec4 Y\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayY[i]);     }           add_arrays(arraySize, arrayX, arrayY, resultArray);      printf(\"\\n\u6570\u7ec4 Z\uff08\u548c\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void add_arrays(int n, float* x, float* y, float* z) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i < n) {         z[i] = x[i] + y[i];     } }  int main() {          int arraySize = 1000;           float* h_x = (float*)malloc(arraySize * sizeof(float));     float* h_y = (float*)malloc(arraySize * sizeof(float));     float* h_z = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_x[i] = static_cast<float>(i);         h_y[i] = static_cast<float>(2 * i);     }           float* d_x;     float* d_y;     float* d_z;     cudaMalloc((void**)&d_x, arraySize * sizeof(float));     cudaMalloc((void**)&d_y, arraySize * sizeof(float));     cudaMalloc((void**)&d_z, arraySize * sizeof(float));           cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_y, h_y, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           add_arrays<<<gridSize, blockSize>>>(arraySize, d_x, d_y, d_z);           cudaMemcpy(h_z, d_z, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_z[i]);     }           free(h_x);     free(h_y);     free(h_z);     cudaFree(d_x);     cudaFree(d_y);     cudaFree(d_z);      return 0; } "
    },
    {
        "id": "290",
        "c_code": "#include <stdio.h>   void update_clusters_cpu(int n, int k, double *Cx, double *Cy, double *Cx_sum, double *Cy_sum, int *Csize);  int main() {          int n = 5;     int k = 3;     double Cx[k] = {1.0, 2.0, 3.0};     double Cy[k] = {4.0, 5.0, 6.0};     double Cx_sum[k] = {10.0, 20.0, 30.0};     double Cy_sum[k] = {40.0, 50.0, 60.0};     int Csize[k] = {2, 3, 0};            update_clusters_cpu(n, k, Cx, Cy, Cx_sum, Cy_sum, Csize);           printf(\"Updated Clusters:\\n\");     for (int index = 0; index < k; index++) {         printf(\"Cluster %d: Cx=%.2f, Cy=%.2f\\n\", index, Cx[index], Cy[index]);     }      return 0; }   void update_clusters_cpu(int n, int k, double *Cx, double *Cy, double *Cx_sum, double *Cy_sum, int *Csize) {     for (int index = 0; index < k; index++) {         if (Csize[index]) {             Cx[index] = Cx_sum[index] / Csize[index];             Cy[index] = Cy_sum[index] / Csize[index];         }     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void update_clusters(int n, int k, double* Cx, double* Cy, double* Cx_sum, double* Cy_sum, int* Csize) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < k && Csize[index]) {         Cx[index] = Cx_sum[index] / Csize[index];         Cy[index] = Cy_sum[index] / Csize[index];     } }  int main() {          const int k = 10;      const int n = 1000;            double* h_Cx = (double*)malloc(k * sizeof(double));     double* h_Cy = (double*)malloc(k * sizeof(double));     double* h_Cx_sum = (double*)malloc(k * sizeof(double));     double* h_Cy_sum = (double*)malloc(k * sizeof(double));     int* h_Csize = (int*)malloc(k * sizeof(int));           for (int i = 0; i < k; ++i) {         h_Cx[i] = i;          h_Cy[i] = i;         h_Cx_sum[i] = i;         h_Cy_sum[i] = i;         h_Csize[i] = i + 1;     }           double* d_Cx, * d_Cy, * d_Cx_sum, * d_Cy_sum;     int* d_Csize;     cudaMalloc((void**)&d_Cx, k * sizeof(double));     cudaMalloc((void**)&d_Cy, k * sizeof(double));     cudaMalloc((void**)&d_Cx_sum, k * sizeof(double));     cudaMalloc((void**)&d_Cy_sum, k * sizeof(double));     cudaMalloc((void**)&d_Csize, k * sizeof(int));           cudaMemcpy(d_Cx, h_Cx, k * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_Cy, h_Cy, k * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_Cx_sum, h_Cx_sum, k * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_Cy_sum, h_Cy_sum, k * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_Csize, h_Csize, k * sizeof(int), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (k + threadsPerBlock - 1) / threadsPerBlock;           update_clusters<<<blocksPerGrid, threadsPerBlock>>>(n, k, d_Cx, d_Cy, d_Cx_sum, d_Cy_sum, d_Csize);           cudaMemcpy(h_Cx, d_Cx, k * sizeof(double), cudaMemcpyDeviceToHost);     cudaMemcpy(h_Cy, d_Cy, k * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Updated cluster centers:\\n\");     for (int i = 0; i < k; ++i) {         printf(\"Cluster %d: Cx=%.2f, Cy=%.2f\\n\", i, h_Cx[i], h_Cy[i]);     }           free(h_Cx);     free(h_Cy);     free(h_Cx_sum);     free(h_Cy_sum);     free(h_Csize);     cudaFree(d_Cx);     cudaFree(d_Cy);     cudaFree(d_Cx_sum);     cudaFree(d_Cy_sum);     cudaFree(d_Csize);      return 0; }   "
    },
    {
        "id": "291",
        "c_code": "#include <stdio.h>   void Gather_cpu(const int *input, float *output, int input_size, const float *data, int count, int dim, int data_offset);  int main() {          int input_size = 3;     int input[] = {2, 0, 1};      float output[input_size * dim];     int count = 2;     int dim = 3;     int data_offset = 1;     float data[] = {1.1, 1.2, 1.3,                     2.1, 2.2, 2.3,                     3.1, 3.2, 3.3,                     4.1, 4.2, 4.3};           Gather_cpu(input, output, input_size, data, count, dim, data_offset);           printf(\"Gathered Data:\\n\");     for (int i = 0; i < input_size; i++) {         for (int j = 0; j < dim; j++) {             printf(\"%.2f \", output[i * dim + j]);         }         printf(\"\\n\");     }      return 0; }   void Gather_cpu(const int *input, float *output, int input_size, const float *data, int count, int dim, int data_offset) {     int index;     for (index = 0; index < input_size * dim; index++) {         const int input_id = input[index / dim];         const int pos = index % dim;         if (input_id < count + data_offset && input_id >= data_offset) {             output[index] = data[input_id * dim + pos];         }     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void GatherKernel(const int* input, float* output, int input_size, const float* data, int count, int dim, int data_offset) {     const int thread_index = blockIdx.x * blockDim.x + threadIdx.x;      if (thread_index < input_size * dim) {         const int input_id = input[thread_index / dim];         const int pos = thread_index % dim;          if (input_id < count + data_offset && input_id >= data_offset) {             output[thread_index] = data[input_id * dim + pos];         }     } }  int main() {          const int input_size = 1000;      const int count = 100;      const int dim = 3;      const int data_offset = 50;            int* h_input = (int*)malloc(input_size * sizeof(int));     float* h_output = (float*)malloc(input_size * dim * sizeof(float));     float* h_data = (float*)malloc((count + data_offset) * dim * sizeof(float));           for (int i = 0; i < input_size; ++i) {         h_input[i] = i % (count + data_offset);      }      for (int i = 0; i < (count + data_offset) * dim; ++i) {         h_data[i] = i;      }           int* d_input;     float* d_output, * d_data;     cudaMalloc((void**)&d_input, input_size * sizeof(int));     cudaMalloc((void**)&d_output, input_size * dim * sizeof(float));     cudaMalloc((void**)&d_data, (count + data_offset) * dim * sizeof(float));           cudaMemcpy(d_input, h_input, input_size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_data, h_data, (count + data_offset) * dim * sizeof(float), cudaMemcpyHostToDevice);           int threadsPerBlock = 256;     int blocksPerGrid = (input_size * dim + threadsPerBlock - 1) / threadsPerBlock;           GatherKernel<<<blocksPerGrid, threadsPerBlock>>>(d_input, d_output, input_size, d_data, count, dim, data_offset);           cudaMemcpy(h_output, d_output, input_size * dim * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Gathered data:\\n\");     for (int i = 0; i < input_size; ++i) {         printf(\"Input ID %d: \", h_input[i]);         for (int j = 0; j < dim; ++j) {             printf(\"%.2f \", h_output[i * dim + j]);         }         printf(\"\\n\");     }           free(h_input);     free(h_output);     free(h_data);     cudaFree(d_input);     cudaFree(d_output);     cudaFree(d_data);      return 0; }   "
    },
    {
        "id": "292",
        "c_code": "#include <stdio.h>   void histogrammPrimitive(unsigned int *histogramVector, unsigned char *grayImage, int rows, int columns);  int main() {          int rows = 3;     int columns = 3;     unsigned char grayImage[] = {1, 2, 3,                                  1, 2, 3,                                  1, 2, 3};     unsigned int histogramVector[256] = {0};           histogramPrimitive(histogramVector, grayImage, rows, columns);           printf(\"Histogram Vector:\\n\");     for (int i = 0; i < 256; i++) {         printf(\"%u \", histogramVector[i]);     }     printf(\"\\n\");      return 0; }   void histogramPrimitive(unsigned int *histogramVector, unsigned char *grayImage, int rows, int columns) {     int column;     int row;     for (column = 0; column < columns; column++) {         for (row = 0; row < rows; row++) {             int offset = (column) + (columns * row);             unsigned char grayValue = grayImage[offset];             histogramVector[grayValue]++;         }     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void histogrammPrimitive(unsigned int* histogrammVector, unsigned char* grayImage, int rows, int columns) {     int column = blockIdx.x * blockDim.x + threadIdx.x;     int row = blockIdx.y * blockDim.y + threadIdx.y;     int offset = (column) + (columns * row);      if ((column < columns) && (row < rows)) {         unsigned char grayValue = grayImage[offset];         atomicAdd(&(histogrammVector[grayValue]), 1);     } }  int main() {          const int rows = 512;      const int columns = 512;      const int histogramSize = 256;            unsigned char* h_grayImage = (unsigned char*)malloc(rows * columns * sizeof(unsigned char));     unsigned int* h_histogramVector = (unsigned int*)malloc(histogramSize * sizeof(unsigned int));           for (int i = 0; i < rows * columns; ++i) {         h_grayImage[i] = i % 256;      }           unsigned char* d_grayImage;     unsigned int* d_histogramVector;      cudaMalloc((void**)&d_grayImage, rows * columns * sizeof(unsigned char));     cudaMalloc((void**)&d_histogramVector, histogramSize * sizeof(unsigned int));           cudaMemcpy(d_grayImage, h_grayImage, rows * columns * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemset(d_histogramVector, 0, histogramSize * sizeof(unsigned int));           dim3 threadsPerBlock(16, 16);      dim3 blocksPerGrid((columns + threadsPerBlock.x - 1) / threadsPerBlock.x, (rows + threadsPerBlock.y - 1) / threadsPerBlock.y);           histogrammPrimitive<<<blocksPerGrid, threadsPerBlock>>>(d_histogramVector, d_grayImage, rows, columns);           cudaMemcpy(h_histogramVector, d_histogramVector, histogramSize * sizeof(unsigned int), cudaMemcpyDeviceToHost);           printf(\"Histogram:\\n\");     for (int i = 0; i < histogramSize; ++i) {         printf(\"Value %d: %u\\n\", i, h_histogramVector[i]);     }           free(h_grayImage);     free(h_histogramVector);     cudaFree(d_grayImage);     cudaFree(d_histogramVector);      return 0; }   "
    },
    {
        "id": "293",
        "c_code": "#include <stdio.h>   void sumAndScale_cpu(float *noiseVariance, float *diffMag2, int n);  int main() {          int n = 3;     float diffMag2[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};     float noiseVariance[n];           sumAndScale_cpu(noiseVariance, diffMag2, n);           printf(\"Noise Variance:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%.8f \", noiseVariance[i]);     }     printf(\"\\n\");      return 0; }   void sumAndScale_cpu(float *noiseVariance, float *diffMag2, int n) {     for (int i = 0; i < n; i++) {         int batchJump = i * 347;         float temp = 0;         for (int sumIndex = 0; sumIndex < 347; sumIndex++) {             temp += diffMag2[batchJump + sumIndex];         }         temp = 0.00161812 * temp;         noiseVariance[i] = temp;     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void sumAndScale(float* noiseVariance, float* diffMag2, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i >= n)         return;      int batchJump = i * 347;     float temp = 0;      for (int sumIndex = 0; sumIndex < 347; sumIndex++)         temp += diffMag2[batchJump + sumIndex];      temp = 0.00161812 * temp;     noiseVariance[i] = temp; }  int main() {          const int n = 1000;            float* h_diffMag2 = (float*)malloc(n * 347 * sizeof(float));     float* h_noiseVariance = (float*)malloc(n * sizeof(float));           for (int i = 0; i < n * 347; ++i) {         h_diffMag2[i] = static_cast<float>(i % 100);      }           float* d_diffMag2;     float* d_noiseVariance;      cudaMalloc((void**)&d_diffMag2, n * 347 * sizeof(float));     cudaMalloc((void**)&d_noiseVariance, n * sizeof(float));           cudaMemcpy(d_diffMag2, h_diffMag2, n * 347 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemset(d_noiseVariance, 0, n * sizeof(float));           dim3 threadsPerBlock(256);     dim3 blocksPerGrid((n + threadsPerBlock.x - 1) / threadsPerBlock.x);           sumAndScale<<<blocksPerGrid, threadsPerBlock>>>(d_noiseVariance, d_diffMag2, n);           cudaMemcpy(h_noiseVariance, d_noiseVariance, n * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Noise Variance:\\n\");     for (int i = 0; i < n; ++i) {         printf(\"Element %d: %f\\n\", i, h_noiseVariance[i]);     }           free(h_diffMag2);     free(h_noiseVariance);     cudaFree(d_diffMag2);     cudaFree(d_noiseVariance);      return 0; }   "
    },
    {
        "id": "294",
        "c_code": "#include <stdio.h>   void convertInstanceToLabel_Kernel_cpu(unsigned short *d_outputLabel, const unsigned char *d_inputInstance, const unsigned short *d_instanceToLabel, unsigned int width, unsigned int height);  int main() {          unsigned int width = 3;     unsigned int height = 3;     unsigned char d_inputInstance[] = {1, 2, 3,                                         1, 2, 3,                                         1, 2, 3};     unsigned short d_instanceToLabel[] = {10, 20, 30};     unsigned short d_outputLabel[width * height];           convertInstanceToLabel_Kernel_cpu(d_outputLabel, d_inputInstance, d_instanceToLabel, width, height);           printf(\"Converted Labels:\\n\");     for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             printf(\"%hu \", d_outputLabel[y * width + x]);         }         printf(\"\\n\");     }      return 0; }   void convertInstanceToLabel_Kernel_cpu(unsigned short *d_outputLabel, const unsigned char *d_inputInstance, const unsigned short *d_instanceToLabel, unsigned int width, unsigned int height) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < height; y++) {             d_outputLabel[y * width + x] = d_instanceToLabel[d_inputInstance[y * width + x]];         }     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void convertInstanceToLabel_Kernel(unsigned short* d_outputLabel, const unsigned char* d_inputInstance,                                               const unsigned short* d_instanceToLabel, unsigned int width,                                               unsigned int height) {     const unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;     const unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;      if (x < width && y < height) {         d_outputLabel[y * width + x] = d_instanceToLabel[d_inputInstance[y * width + x]];     } }  int main() {          const unsigned int width = 512;       const unsigned int height = 512;            unsigned char* h_inputInstance = (unsigned char*)malloc(width * height * sizeof(unsigned char));     unsigned short* h_instanceToLabel = (unsigned short*)malloc(256 * sizeof(unsigned short));      unsigned short* h_outputLabel = (unsigned short*)malloc(width * height * sizeof(unsigned short));           for (unsigned int i = 0; i < width * height; ++i) {         h_inputInstance[i] = static_cast<unsigned char>(i % 256);      }      for (int i = 0; i < 256; ++i) {         h_instanceToLabel[i] = static_cast<unsigned short>(i);      }           unsigned char* d_inputInstance;     unsigned short* d_instanceToLabel;     unsigned short* d_outputLabel;      cudaMalloc((void**)&d_inputInstance, width * height * sizeof(unsigned char));     cudaMalloc((void**)&d_instanceToLabel, 256 * sizeof(unsigned short));     cudaMalloc((void**)&d_outputLabel, width * height * sizeof(unsigned short));           cudaMemcpy(d_inputInstance, h_inputInstance, width * height * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_instanceToLabel, h_instanceToLabel, 256 * sizeof(unsigned short), cudaMemcpyHostToDevice);     cudaMemset(d_outputLabel, 0, width * height * sizeof(unsigned short));           dim3 threadsPerBlock(16, 16);     dim3 blocksPerGrid((width + threadsPerBlock.x - 1) / threadsPerBlock.x,                        (height + threadsPerBlock.y - 1) / threadsPerBlock.y);           convertInstanceToLabel_Kernel<<<blocksPerGrid, threadsPerBlock>>>(d_outputLabel, d_inputInstance, d_instanceToLabel,                                                                       width, height);           cudaMemcpy(h_outputLabel, d_outputLabel, width * height * sizeof(unsigned short), cudaMemcpyDeviceToHost);           printf(\"Output Label:\\n\");     for (unsigned int i = 0; i < width * height; ++i) {         printf(\"Element %u: %u\\n\", i, h_outputLabel[i]);     }           free(h_inputInstance);     free(h_instanceToLabel);     free(h_outputLabel);     cudaFree(d_inputInstance);     cudaFree(d_instanceToLabel);     cudaFree(d_outputLabel);      return 0; }   "
    },
    {
        "id": "295",
        "c_code": "#include <stdio.h>   void downsampleCpu(float *I, float *Q, unsigned int numDownsampledSamples, float *downsampled_I, float *downsampled_Q, unsigned int factor);  int main() {          unsigned int numDownsampledSamples = 3;     unsigned int factor = 2;     float I[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float Q[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6};     float downsampled_I[numDownsampledSamples];     float downsampled_Q[numDownsampledSamples];           downsampleCpu(I, Q, numDownsampledSamples, downsampled_I, downsampled_Q, factor);           printf(\"Downsampled Data:\\n\");     for (int i = 0; i < numDownsampledSamples; i++) {         printf(\"I=%.2f, Q=%.2f\\n\", downsampled_I[i], downsampled_Q[i]);     }      return 0; }   void downsampleCpu(float *I, float *Q, unsigned int numDownsampledSamples, float *downsampled_I, float *downsampled_Q, unsigned int factor) {     for (int sampleIndex = 0; sampleIndex < numDownsampledSamples; sampleIndex++) {         unsigned int absoluteIndex = sampleIndex * factor;         downsampled_I[sampleIndex] = I[absoluteIndex];         downsampled_Q[sampleIndex] = Q[absoluteIndex];     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void downsampleCuda(float* I, float* Q, unsigned int numDownsampledSamples,                                 float* downsampled_I, float* downsampled_Q, unsigned int factor) {     int sampleIndex = (blockIdx.x * blockDim.x) + threadIdx.x;      if (sampleIndex < numDownsampledSamples) {         unsigned int absoluteIndex = sampleIndex * factor;         downsampled_I[sampleIndex] = I[absoluteIndex];         downsampled_Q[sampleIndex] = Q[absoluteIndex];     } }  int main() {          const unsigned int numDownsampledSamples = 1024;      const unsigned int factor = 2;                              float* h_I = (float*)malloc(numDownsampledSamples * factor * sizeof(float));     float* h_Q = (float*)malloc(numDownsampledSamples * factor * sizeof(float));     float* h_downsampled_I = (float*)malloc(numDownsampledSamples * sizeof(float));     float* h_downsampled_Q = (float*)malloc(numDownsampledSamples * sizeof(float));           for (unsigned int i = 0; i < numDownsampledSamples * factor; ++i) {         h_I[i] = static_cast<float>(i);          h_Q[i] = static_cast<float>(i);      }           float *d_I, *d_Q, *d_downsampled_I, *d_downsampled_Q;      cudaMalloc((void**)&d_I, numDownsampledSamples * factor * sizeof(float));     cudaMalloc((void**)&d_Q, numDownsampledSamples * factor * sizeof(float));     cudaMalloc((void**)&d_downsampled_I, numDownsampledSamples * sizeof(float));     cudaMalloc((void**)&d_downsampled_Q, numDownsampledSamples * sizeof(float));           cudaMemcpy(d_I, h_I, numDownsampledSamples * factor * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Q, h_Q, numDownsampledSamples * factor * sizeof(float), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(256);     dim3 blocksPerGrid((numDownsampledSamples + threadsPerBlock.x - 1) / threadsPerBlock.x);           downsampleCuda<<<blocksPerGrid, threadsPerBlock>>>(d_I, d_Q, numDownsampledSamples,                                                         d_downsampled_I, d_downsampled_Q, factor);           cudaMemcpy(h_downsampled_I, d_downsampled_I, numDownsampledSamples * sizeof(float),                cudaMemcpyDeviceToHost);     cudaMemcpy(h_downsampled_Q, d_downsampled_Q, numDownsampledSamples * sizeof(float),                cudaMemcpyDeviceToHost);           printf(\"Downsampled I and Q:\\n\");     for (unsigned int i = 0; i < numDownsampledSamples; ++i) {         printf(\"Element %u: I=%f, Q=%f\\n\", i, h_downsampled_I[i], h_downsampled_Q[i]);     }           free(h_I);     free(h_Q);     free(h_downsampled_I);     free(h_downsampled_Q);     cudaFree(d_I);     cudaFree(d_Q);     cudaFree(d_downsampled_I);     cudaFree(d_downsampled_Q);      return 0; }   "
    },
    {
        "id": "296",
        "c_code": "#include <stdio.h> #include <math.h>   void logistic_x_ent_cpu(int n, float *pred, float *truth, float *delta, float *error);  int main() {          int n = 3;     float pred[] = {0.2, 0.8, 0.6};     float truth[] = {0.0, 1.0, 1.0};     float delta[n];     float error[n];           logistic_x_ent_cpu(n, pred, truth, delta, error);           printf(\"Error:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%.4f \", error[i]);     }     printf(\"\\n\");      printf(\"Delta:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%.4f \", delta[i]);     }     printf(\"\\n\");      return 0; }   void logistic_x_ent_cpu(int n, float *pred, float *truth, float *delta, float *error) {     for (int i = 0; i < n; ++i) {         float t = truth[i];         float p = pred[i];         error[i] = -t * log(p) - (1 - t) * log(1 - p);         delta[i] = t - p;     } }   ",
        "cuda_code": "#include <stdio.h> #include <cmath>   #include <cuda_runtime.h>   __global__ void logistic_x_ent_kernel(int n, float* pred, float* truth, float* delta, float* error) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i < n) {         float t = truth[i];         float p = pred[i];         error[i] = -t * log(p + 0.0000001f) - (1 - t) * log(1 - p + 0.0000001f);         delta[i] = t - p;     } }  int main() {          const int n = 1024;            float* h_pred = (float*)malloc(n * sizeof(float));     float* h_truth = (float*)malloc(n * sizeof(float));     float* h_delta = (float*)malloc(n * sizeof(float));     float* h_error = (float*)malloc(n * sizeof(float));           for (int i = 0; i < n; ++i) {         h_pred[i] = 0.7f;           h_truth[i] = 0.5f;      }           float *d_pred, *d_truth, *d_delta, *d_error;      cudaMalloc((void**)&d_pred, n * sizeof(float));     cudaMalloc((void**)&d_truth, n * sizeof(float));     cudaMalloc((void**)&d_delta, n * sizeof(float));     cudaMalloc((void**)&d_error, n * sizeof(float));           cudaMemcpy(d_pred, h_pred, n * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_truth, h_truth, n * sizeof(float), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(256);     dim3 blocksPerGrid((n + threadsPerBlock.x - 1) / threadsPerBlock.x);           logistic_x_ent_kernel<<<blocksPerGrid, threadsPerBlock>>>(n, d_pred, d_truth, d_delta, d_error);           cudaMemcpy(h_delta, d_delta, n * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_error, d_error, n * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Delta and Error:\\n\");     for (int i = 0; i < n; ++i) {         printf(\"Element %d: Delta=%f, Error=%f\\n\", i, h_delta[i], h_error[i]);     }           free(h_pred);     free(h_truth);     free(h_delta);     free(h_error);     cudaFree(d_pred);     cudaFree(d_truth);     cudaFree(d_delta);     cudaFree(d_error);      return 0; }   "
    },
    {
        "id": "297",
        "c_code": "#include <stdio.h>   void Argmax(int *argMax, float **array, const int r, const int c);  int main() {          int r = 3;     int c = 4;     float data[3][4] = {{1.2, 2.3, 0.5, 1.8},                         {0.9, 2.0, 1.5, 3.2},                         {2.1, 1.4, 3.0, 0.8}};     float *array[r];     for (int i = 0; i < r; i++) {         array[i] = data[i];     }     int argMax[r];           Argmax(argMax, array, r, c);           printf(\"Argmax Indices:\\n\");     for (int i = 0; i < r; i++) {         printf(\"%d \", argMax[i]);     }     printf(\"\\n\");      return 0; }   void Argmax(int *argMax, float **array, const int r, const int c) {     int idx;     float temp;     for (int i = 0; i < r; i++) {         idx = 0;         temp = 0.0;         for (int j = 0; j < c; j++) {             if (array[i][j] > temp) {                 temp = array[i][j];                 idx = j;             }         }         argMax[i] = idx;     } }   ",
        "cuda_code": "#include <stdio.h>   #include <cuda_runtime.h>   __global__ void Kernel_Argmax(int* dev_argMax, float* dev_array, const int r, const int c) {     unsigned int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i >= r) return;      int idx;     float temp = 0.0;      for (int j = 0; j < c; j++) {         if (dev_array[i * c + j] > temp) {             temp = dev_array[i * c + j];             idx = j;         }     }      dev_argMax[i] = idx; }  int main() {          const int r = 4;      const int c = 5;            float* h_array = (float*)malloc(r * c * sizeof(float));     int* h_argMax = (int*)malloc(r * sizeof(int));           for (int i = 0; i < r * c; ++i) {         h_array[i] = static_cast<float>(i % 10);      }           float* d_array;     int* d_argMax;      cudaMalloc((void**)&d_array, r * c * sizeof(float));     cudaMalloc((void**)&d_argMax, r * sizeof(int));           cudaMemcpy(d_array, h_array, r * c * sizeof(float), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(256);     dim3 blocksPerGrid((r + threadsPerBlock.x - 1) / threadsPerBlock.x);           Kernel_Argmax<<<blocksPerGrid, threadsPerBlock>>>(d_argMax, d_array, r, c);           cudaMemcpy(h_argMax, d_argMax, r * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Argmax Result:\\n\");     for (int i = 0; i < r; ++i) {         printf(\"Row %d: Argmax=%d\\n\", i, h_argMax[i]);     }           free(h_array);     free(h_argMax);     cudaFree(d_array);     cudaFree(d_argMax);      return 0; }   "
    },
    {
        "id": "298",
        "c_code": "#include <stdio.h> #include <math.h>   float CEE(float *x, int *t, int r, int c);  int main() {          int r = 2;     int c = 3;     float x[] = {0.2, 0.8, 0.6, 0.4, 0.5, 0.9};     int t[] = {0, 1, 1, 0, 1, 0};           float result = CEE(x, t, r, c);           printf(\"Cross-Entropy Error: %.4f\\n\", result);      return 0; }   float CEE(float *x, int *t, int r, int c) {     float temp = 0;     for (int i = 0; i < r; i++) {         for (int j = 0; j < c; j++) {             if (t[i * c + j] == 1) {                 temp += log(x[i * c + j] + 1e-7);                 continue;             }         }     }     temp /= -r;     return temp; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h> #include <math.h>   __global__ void kernel_CEE(float *x, int *t, float *loss, int r, int c) {     int i = blockDim.x * blockIdx.x + threadIdx.x;     int N = r;     float temp;      while (i < N) {         for (int j = 0; j < c; j++) {             if (t[i * c + j] == 1) {                 temp = logf(x[i * c + j] + 1e-7);                 atomicAdd(loss, temp);                 continue;             }         }          i += gridDim.x * blockDim.x;     } }  int main() {          const int r = 100;       const int c = 10;              float *h_x = (float *)malloc(r * c * sizeof(float));     int *h_t = (int *)malloc(r * c * sizeof(int));     float *h_loss = (float *)malloc(sizeof(float));           for (int i = 0; i < r * c; i++) {         h_x[i] = (float)rand() / RAND_MAX;         h_t[i] = rand() % 2;       }           float *d_x;     int *d_t;     float *d_loss;     cudaMalloc((void **)&d_x, r * c * sizeof(float));     cudaMalloc((void **)&d_t, r * c * sizeof(int));     cudaMalloc((void **)&d_loss, sizeof(float));           cudaMemcpy(d_x, h_x, r * c * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_t, h_t, r * c * sizeof(int), cudaMemcpyHostToDevice);     cudaMemset(d_loss, 0, sizeof(float));             dim3 blockSize(256);       dim3 gridSize((r + blockSize.x - 1) / blockSize.x);           kernel_CEE<<<gridSize, blockSize>>>(d_x, d_t, d_loss, r, c);           cudaMemcpy(h_loss, d_loss, sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Cross-Entropy Loss: %f\\n\", *h_loss);           free(h_x);     free(h_t);     free(h_loss);     cudaFree(d_x);     cudaFree(d_t);     cudaFree(d_loss);      return 0; } "
    },
    {
        "id": "299",
        "c_code": "#include <stdio.h>   void check_results_kernel(unsigned int *g_results0, unsigned int *g_results1, int n);  int main() {          int n = 5;     unsigned int g_results0[] = {1, 2, 3, 4, 5};     unsigned int g_results1[] = {1, 2, 8, 4, 5};             check_results_kernel(g_results0, g_results1, n);      return 0; }   void check_results_kernel(unsigned int *g_results0, unsigned int *g_results1, int n) {     unsigned int gidx;     unsigned int result0;     unsigned int result1;     for (gidx = 0; gidx < n; gidx++) {         result0 = g_results0[gidx];         result1 = g_results1[gidx];         if (result0 != result1) {             printf(\"%u != %u for %u\\n\", result0, result1, gidx);         }     } }   ",
        "cuda_code": "#include <stdio.h>  __global__ void check_results_kernel(uint* g_results0, uint* g_results1, int n) {     uint idx = threadIdx.x;     uint gidx = blockDim.x * blockIdx.x + idx;     uint result0, result1;      if (gidx < n) {         result0 = g_results0[gidx];         result1 = g_results1[gidx];          if (result0 != result1) {             printf(\"%d != %d for thread %d\\n\", result0, result1, gidx);         }     } }  int main() {          const int n = 1000;             uint* h_results0 = (uint*)malloc(n * sizeof(uint));     uint* h_results1 = (uint*)malloc(n * sizeof(uint));           for (int i = 0; i < n; ++i) {         h_results0[i] = i;         h_results1[i] = i * 2;       }           uint* d_results0;     uint* d_results1;      cudaMalloc((void**)&d_results0, n * sizeof(uint));     cudaMalloc((void**)&d_results1, n * sizeof(uint));           cudaMemcpy(d_results0, h_results0, n * sizeof(uint), cudaMemcpyHostToDevice);     cudaMemcpy(d_results1, h_results1, n * sizeof(uint), cudaMemcpyHostToDevice);           dim3 threadsPerBlock(256);     dim3 blocksPerGrid((n + threadsPerBlock.x - 1) / threadsPerBlock.x   "
    },
    {
        "id": "3",
        "c_code": "#include <stdio.h>  void square(int *array, int arrayCount) {     for (int idx = 0; idx < arrayCount; idx++) {         array[idx] *= array[idx];     } }  int main() {          int array[] = {2, 4, 6, 8, 10};     int numElements = sizeof(array) / sizeof(array[0]);      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }           square(array, numElements);      printf(\"\\n\u5e73\u65b9\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void square(int* array, int arrayCount) {     int idx = threadIdx.x + blockIdx.x * blockDim.x;     if (idx < arrayCount) {         array[idx] *= array[idx];     } }  int main() {          int arrayCount = 1000;           int* h_array = (int*)malloc(arrayCount * sizeof(int));           for (int i = 0; i < arrayCount; ++i) {         h_array[i] = i;     }           int* d_array;     cudaMalloc((void**)&d_array, arrayCount * sizeof(int));           cudaMemcpy(d_array, h_array, arrayCount * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arrayCount + blockSize - 1) / blockSize;           square<<<gridSize, blockSize>>>(d_array, arrayCount);           cudaMemcpy(h_array, d_array, arrayCount * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_array[i]);     }           free(h_array);     cudaFree(d_array);      return 0; } "
    },
    {
        "id": "30",
        "c_code": "#include <stdio.h>  void sum_arrays_cpu(int *a, int *b, int *c, int size) {     for (int i = 0; i < size; i++) {         c[i] = a[i] + b[i];     } }  int main() {          int arraySize = 5;     int arrayA[] = {1, 2, 3, 4, 5};     int arrayB[] = {10, 20, 30, 40, 50};     int resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", arrayB[i]);     }           sum_arrays_cpu(arrayA, arrayB, resultArray, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff08\u548c\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void sum_arrays_gpu(int* a, int* b, int* c, int size) {     int index = blockDim.x * blockIdx.x + threadIdx.x;     if (index < size) {         c[index] = a[index] + b[index];     } }  int main() {          int arraySize = 1000;           int* h_a = (int*)malloc(arraySize * sizeof(int));     int* h_b = (int*)malloc(arraySize * sizeof(int));     int* h_c = (int*)malloc(arraySize * sizeof(int));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = i;         h_b[i] = 2 * i;     }           int* d_a;     int* d_b;     int* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(int));     cudaMalloc((void**)&d_b, arraySize * sizeof(int));     cudaMalloc((void**)&d_c, arraySize * sizeof(int));           cudaMemcpy(d_a, h_a, arraySize * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           sum_arrays_gpu<<<gridSize, blockSize>>>(d_a, d_b, d_c, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "300",
        "c_code": "#include <stdio.h>   void matrixMulOnHost(float *M, float *N, float *P, int width);  int main() {          int width = 3;     float M[] = {1.0, 2.0, 3.0,                  4.0, 5.0, 6.0,                  7.0, 8.0, 9.0};     float N[] = {9.0, 8.0, 7.0,                  6.0, 5.0, 4.0,                  3.0, 2.0, 1.0};     float P[width * width];           matrixMulOnHost(M, N, P, width);           printf(\"Result Matrix:\\n\");     for (int i = 0; i < width; i++) {         for (int j = 0; j < width; j++) {             printf(\"%.2f \", P[i * width + j]);         }         printf(\"\\n\");     }      return 0; }   void matrixMulOnHost(float *M, float *N, float *P, int width) {     for (int i = 0; i < width; ++i) {         for (int j = 0; j < width; ++j) {             double sum = 0;             for (int k = 0; k < width; ++k) {                 double a = M[i * width + k];                 double b = N[k * width + j];                 sum += a * b;             }             P[i * width + j] = sum;         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>   __global__ void MatrixMulKernel(float *Md, float *Nd, float *Pd, int width) {     int tx = threadIdx.x;     int ty = threadIdx.y;     float pvalue = 0;      for (int k = 0; k < width; ++k) {         float Mdelement = Md[ty * width + k];         float Ndelement = Nd[ty * width + k];         pvalue += Mdelement * Ndelement;     }      Pd[ty * width + tx] = pvalue; }  int main() {          const int width = 4;             float *h_Md = (float *)malloc(width * width * sizeof(float));     float *h_Nd = (float *)malloc(width * width * sizeof(float));     float *h_Pd = (float *)malloc(width * width * sizeof(float));           for (int i = 0; i < width * width; i++) {         h_Md[i] = (float)rand() / RAND_MAX;         h_Nd[i] = (float)rand() / RAND_MAX;     }           float *d_Md, *d_Nd, *d_Pd;     cudaMalloc((void **)&d_Md, width * width * sizeof(float));     cudaMalloc((void **)&d_Nd, width * width * sizeof(float));     cudaMalloc((void **)&d_Pd, width * width * sizeof(float));           cudaMemcpy(d_Md, h_Md, width * width * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Nd, h_Nd, width * width * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(width, width);     dim3 gridSize(1, 1);           MatrixMulKernel<<<gridSize, blockSize>>>(d_Md, d_Nd, d_Pd, width);           cudaMemcpy(h_Pd, d_Pd, width * width * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result Matrix:\\n\");     for (int i = 0; i < width; i++) {         for (int j = 0; j < width; j++) {             printf(\"%f \", h_Pd[i * width + j]);         }         printf(\"\\n\");     }           free(h_Md);     free(h_Nd);     free(h_Pd);     cudaFree(d_Md);     cudaFree(d_Nd);     cudaFree(d_Pd);      return 0; }   "
    },
    {
        "id": "301",
        "c_code": "#include <stdio.h> #include <math.h>   void normalize_cpu(float *x, float *mean, float *variance, int batch, int filters, int spatial);  int main() {          int batch = 2;     int filters = 3;     int spatial = 4;     float x[] = {1.0, 2.0, 3.0, 4.0,                  5.0, 6.0, 7.0, 8.0,                  9.0, 10.0, 11.0, 12.0,                  13.0, 14.0, 15.0, 16.0,                  17.0, 18.0, 19.0, 20.0,                  21.0, 22.0, 23.0, 24.0};     float mean[] = {2.0, 4.0, 6.0};     float variance[] = {1.0, 2.0, 3.0};           normalize_cpu(x, mean, variance, batch, filters, spatial);           printf(\"Normalized Data:\\n\");     for (int b = 0; b < batch; ++b) {         for (int f = 0; f < filters; ++f) {             for (int i = 0; i < spatial; ++i) {                 int index = b * filters * spatial + f * spatial + i;                 printf(\"%.4f \", x[index]);             }             printf(\"\\n\");         }     }      return 0; }   void normalize_cpu(float *x, float *mean, float *variance, int batch, int filters, int spatial) {     for (int b = 0; b < batch; ++b) {         for (int f = 0; f < filters; ++f) {             for (int i = 0; i < spatial; ++i) {                 int index = b * filters * spatial + f * spatial + i;                 x[index] = (x[index] - mean[f]) / (sqrt(variance[f]) + 0.000001f);             }         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>   __global__ void normalize_kernel(int N, float *x, float *mean, float *variance, int batch, int filters, int spatial) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     if (index < N) {         int f = (index / spatial) % filters;         x[index] = (x[index] - mean[f]) / sqrtf(variance[f] + 0.00001f);     } }  int main() {          const int N = 1024;       const int batch = 2;      const int filters = 3;      const int spatial = 4;            float *h_x = (float *)malloc(N * sizeof(float));     float *h_mean = (float *)malloc(filters * sizeof(float));     float *h_variance = (float *)malloc(filters * sizeof(float));           for (int i = 0; i < N; i++) {         h_x[i] = (float)rand() / RAND_MAX;     }      for (int i = 0; i < filters; i++) {         h_mean[i] = (float)rand() / RAND_MAX;         h_variance[i] = (float)rand() / RAND_MAX;     }           float *d_x, *d_mean, *d_variance;     cudaMalloc((void **)&d_x, N * sizeof(float));     cudaMalloc((void **)&d_mean, filters * sizeof(float));     cudaMalloc((void **)&d_variance, filters * sizeof(float));           cudaMemcpy(d_x, h_x, N * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_mean, h_mean, filters * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_variance, h_variance, filters * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x);           normalize_kernel<<<gridSize, blockSize>>>(N, d_x, d_mean, d_variance, batch, filters, spatial);           cudaMemcpy(h_x, d_x, N * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Normalized data:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%f \", h_x[i]);     }     printf(\"\\n\");           free(h_x);     free(h_mean);     free(h_variance);     cudaFree(d_x);     cudaFree(d_mean);     cudaFree(d_variance);      return 0; } "
    },
    {
        "id": "302",
        "c_code": "#include <stdio.h>   void kernel(int *a, int *b, int *c);  int main() {          int size = 1024 * 1024;     int a[size], b[size], c[size];           for (int i = 0; i < size; i++) {         a[i] = i;         b[i] = size - i;     }           kernel(a, b, c);           printf(\"Result Array:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", c[i]);     }      return 0; }   void kernel(int *a, int *b, int *c) {     for (int idx = 0; idx < 1024 * 1024; idx++) {         int idx1 = (idx + 1) % 256;         int idx2 = (idx + 2) % 256;         float as = (a[idx] + a[idx1] + a[idx2]) / 3.0f;         float bs = (b[idx] + b[idx1] + b[idx2]) / 3.0f;         c[idx] = (as + bs) / 2;     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>   __global__ void kernel(int *a, int *b, int *c) {     int idx = threadIdx.x + blockIdx.x * blockDim.x;      if (idx < (1024 * 1024)) {         int idx1 = (idx + 1) % 256;         int idx2 = (idx + 2) % 256;          float as = (a[idx] + a[idx1] + a[idx2]) / 3.0f;         float bs = (b[idx] + b[idx1] + b[idx2]) / 3.0f;          c[idx] = (as + bs) / 2;     } }  int main() {          const int size = 1024 * 1024;           int *h_a = (int *)malloc(size * sizeof(int));     int *h_b = (int *)malloc(size * sizeof(int));     int *h_c = (int *)malloc(size * sizeof(int));           for (int i = 0; i < size; i++) {         h_a[i] = rand() % 256;         h_b[i] = rand() % 256;     }           int *d_a, *d_b, *d_c;     cudaMalloc((void **)&d_a, size * sizeof(int));     cudaMalloc((void **)&d_b, size * sizeof(int));     cudaMalloc((void **)&d_c, size * sizeof(int));           cudaMemcpy(d_a, h_a, size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, size * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((size + blockSize.x - 1) / blockSize.x);           kernel<<<gridSize, blockSize>>>(d_a, d_b, d_c);           cudaMemcpy(h_c, d_c, size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Results printed here:\\n\");           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   "
    },
    {
        "id": "303",
        "c_code": "#include <stdio.h>   void kernel(int *a, int *b, int *c, int size);  int main() {          int size = 1024 * 1024;     int a[size], b[size], c[size];           for (int i = 0; i < size; i++) {         a[i] = i;         b[i] = size - i;     }           kernel(a, b, c, size);           printf(\"Result Array:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", c[i]);     }      return 0; }   void kernel(int *a, int *b, int *c, int size) {     for (int idx = 0; idx < size; idx++) {         int idx1 = (idx + 1) % size;         int idx2 = (idx + 2) % size;         float as = (a[idx] + a[idx1] + a[idx2]) / 3.0f;         float bs = (b[idx] + b[idx1] + b[idx2]) / 3.0f;         c[idx] = (as + bs) / 2;     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>   __global__ void kernel(int *a, int *b, int *c) {     int idx = threadIdx.x + blockIdx.x * blockDim.x;      if (idx < 1024 * 1024) {         int idx1 = (idx + 1) % 256;         int idx2 = (idx + 2) % 256;         float as = (a[idx] + a[idx1] + a[idx2]) / 3.0f;         float bs = (b[idx] + b[idx1] + b[idx2]) / 3.0f;         c[idx] = (as + bs) / 2;     } }  int main() {          const int size = 1024 * 1024;           int *h_a = (int *)malloc(size * sizeof(int));     int *h_b = (int *)malloc(size * sizeof(int));     int *h_c = (int *)malloc(size * sizeof(int));           for (int i = 0; i < size; i++) {         h_a[i] = rand() % 256;         h_b[i] = rand() % 256;     }           int *d_a, *d_b, *d_c;     cudaMalloc((void **)&d_a, size * sizeof(int));     cudaMalloc((void **)&d_b, size * sizeof(int));     cudaMalloc((void **)&d_c, size * sizeof(int));           cudaMemcpy(d_a, h_a, size * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, size * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((size + blockSize.x - 1) / blockSize.x);           kernel<<<gridSize, blockSize>>>(d_a, d_b, d_c);           cudaMemcpy(h_c, d_c, size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Results printed here:\\n\");           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; }   "
    },
    {
        "id": "304",
        "c_code": "#include <stdio.h>   void inter_cpu(int NX, float *X, int NY, float *Y, int B, float *OUT);  int main() {          int NX = 3;     int NY = 2;     int B = 4;     float X[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0};     float Y[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8};     float OUT[NX + NY];           inter_cpu(NX, X, NY, Y, B, OUT);           printf(\"Interleaved Array:\\n\");     for (int i = 0; i < NX + NY; i++) {         printf(\"%.2f \", OUT[i]);     }      return 0; }   void inter_cpu(int NX, float *X, int NY, float *Y, int B, float *OUT) {     int i, j;     int index = 0;     for (j = 0; j < B; ++j) {         for (i = 0; i < NX; ++i) {             OUT[index++] = X[j * NX + i];         }         for (i = 0; i < NY; ++i) {             OUT[index++] = Y[j * NY + i];         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>   __global__ void inter_kernel(int NX, float *X, int NY, float *Y, int B, float *OUT) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i < (NX + NY) * B) {         int b = i / (NX + NY);         int j = i % (NX + NY);          if (j < NX) {             OUT[i] = X[b * NX + j];         } else {             OUT[i] = Y[b * NY + j - NX];         }     } }  int main() {          const int NX = 128;     const int NY = 64;     const int B = 256;           float *h_X = (float *)malloc(NX * B * sizeof(float));     float *h_Y = (float *)malloc(NY * B * sizeof(float));     float *h_OUT = (float *)malloc((NX + NY) * B * sizeof(float));           for (int i = 0; i < NX * B; ++i) {         h_X[i] = static_cast<float>(i);     }      for (int i = 0; i < NY * B; ++i) {         h_Y[i] = static_cast<float>(i + NX * B);     }           float *d_X, *d_Y, *d_OUT;     cudaMalloc((void **)&d_X, NX * B * sizeof(float));     cudaMalloc((void **)&d_Y, NY * B * sizeof(float));     cudaMalloc((void **)&d_OUT, (NX + NY) * B * sizeof(float));           cudaMemcpy(d_X, h_X, NX * B * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Y, h_Y, NY * B * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((B * (NX + NY) + blockSize.x - 1) / blockSize.x);           inter_kernel<<<gridSize, blockSize>>>(NX, d_X, NY, d_Y, B, d_OUT);           cudaMemcpy(h_OUT, d_OUT, (NX + NY) * B * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Results printed here:\\n\");           free(h_X);     free(h_Y);     free(h_OUT);     cudaFree(d_X);     cudaFree(d_Y);     cudaFree(d_OUT);      return 0; }   "
    },
    {
        "id": "305",
        "c_code": "#include <stdio.h>   void manage_adj_matrix(float **graph, int n);  int main() {          int n = 3;     float **graph = (float **)malloc(n * sizeof(float *));     for (int i = 0; i < n; ++i) {         graph[i] = (float *)malloc(n * sizeof(float));         for (int j = 0; j < n; ++j) {             graph[i][j] = i + j + 1.0;          }     }           manage_adj_matrix(graph, n);           printf(\"Modified Adjacency Matrix:\\n\");     for (int i = 0; i < n; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"%.2f \", graph[i][j]);         }         printf(\"\\n\");     }           for (int i = 0; i < n; ++i) {         free(graph[i]);     }     free(graph);      return 0; }   void manage_adj_matrix(float **graph, int n) {     for (int j = 0; j < n; ++j) {         float sum = 0.0;         for (int i = 0; i < n; ++i) {             sum += graph[i][j];         }         for (int i = 0; i < n; ++i) {             if (sum != 0.0) {                 graph[i][j] /= sum;             } else {                 graph[i][j] = 1.0 / (float)n;             }         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>  __global__ void manage_adj_matrix(float *gpu_graph, int n) {     int id = blockIdx.x * blockDim.x + threadIdx.x;     if (id < n) {         float sum = 0.0;          for (int i = 0; i < n; ++i) {             sum += gpu_graph[i * n + id];         }          for (int i = 0; i < n; ++i) {             if (sum != 0.0) {                 gpu_graph[i * n + id] /= sum;             } else {                 gpu_graph[i * n + id] = (1.0 / (float)n);             }         }     } }  int main() {          const int n = 256;           float *h_gpu_graph = (float *)malloc(n * n * sizeof(float));           for (int i = 0; i < n * n; ++i) {         h_gpu_graph[i] = static_cast<float>(i % 10);     }           float *d_gpu_graph;     cudaMalloc((void **)&d_gpu_graph, n * n * sizeof(float));           cudaMemcpy(d_gpu_graph, h_gpu_graph, n * n * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((n + blockSize.x - 1) / blockSize.x);           manage_adj_matrix<<<gridSize, blockSize>>>(d_gpu_graph, n);           cudaMemcpy(h_gpu_graph, d_gpu_graph, n * n * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Results printed here:\\n\");           free(h_gpu_graph);     cudaFree(d_gpu_graph);      return 0; }   "
    },
    {
        "id": "306",
        "c_code": "#include <stdio.h>   void fa_cpu(const float *q, const float *h, int nq, float *a, float *fa);  int main() {          int nq = 4;     float q[] = {1.0, 2.0, 3.0, 4.0};     float h[] = {0.5, 1.0, 1.5, 2.0};     float a[nq - 1], fa[nq - 1];           fa_cpu(q, h, nq, a, fa);           printf(\"Acceleration (a) Array:\\n\");     for (int i = 0; i < nq - 1; ++i) {         printf(\"%.2f \", a[i]);     }      printf(\"\\n\\n\");      printf(\"Result (fa) Array:\\n\");     for (int i = 0; i < nq - 1; ++i) {         printf(\"%.2f \", fa[i]);     }      return 0; }   void fa_cpu(const float *q, const float *h, int nq, float *a, float *fa) {     for (int iq = 0; iq < (nq - 1); iq++) {         float dq = q[iq + 1] - q[iq];         a[iq] = (h[iq + 1] * q[iq + 1] - h[iq] * q[iq]) / dq;         fa[iq] = q[iq] * (a[iq] - h[iq]) + 1.0;     } }   ",
        "cuda_code": " #include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>  __global__ void faKernel(const float *__restrict__ q, const float *__restrict__ h, int nq, float *__restrict__ a, float *__restrict__ fa) {     int iq = blockIdx.x * blockDim.x + threadIdx.x;     if (iq < (nq - 1)) {         float dq = q[1] - q[0];         a[iq] = (h[iq + 1] * q[iq + 1] - h[iq] * q[iq]) / dq;         fa[iq] = q[iq] * (a[iq] - h[iq]) + 1.0f;     } }  int main() {          const int nq = 256;           float *h_q = (float *)malloc(nq * sizeof(float));     float *h_h = (float *)malloc(nq * sizeof(float));     float *h_a = (float *)malloc((nq - 1) * sizeof(float));     float *h_fa = (float *)malloc((nq - 1) * sizeof(float));           for (int i = 0; i < nq; ++i) {         h_q[i] = static_cast<float>(i);         h_h[i] = static_cast<float>(i * 2);     }           float *d_q, *d_h, *d_a, *d_fa;     cudaMalloc((void **)&d_q, nq * sizeof(float));     cudaMalloc((void **)&d_h, nq * sizeof(float));     cudaMalloc((void **)&d_a, (nq - 1) * sizeof(float));     cudaMalloc((void **)&d_fa, (nq - 1) * sizeof(float));           cudaMemcpy(d_q, h_q, nq * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_h, h_h, nq * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((nq + blockSize.x - 1) / blockSize.x);           faKernel<<<gridSize, blockSize>>>(d_q, d_h, nq, d_a, d_fa);           cudaMemcpy(h_a, d_a, (nq - 1) * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_fa, d_fa, (nq - 1) * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Results printed here:\\n\");           free(h_q);     free(h_h);     free(h_a);     free(h_fa);     cudaFree(d_q);     cudaFree(d_h);     cudaFree(d_a);     cudaFree(d_fa);      return 0; }  "
    },
    {
        "id": "307",
        "c_code": "#include <stdio.h> #include <stdlib.h>   void matrixProduct(double *matrix_a, double *matrix_b, double *matrix_c, int width, int height, int from, int my_rank);  int main() {          int width = 3;     int height = 3;     int from = 0;     int my_rank = 0;          double *matrix_a = (double *)malloc(width * height * sizeof(double));     double *matrix_b = (double *)malloc(width * height * sizeof(double));     double *matrix_c = (double *)malloc(width * height * sizeof(double));           for (int i = 0; i < width * height; i++) {         matrix_a[i] = i + 1.0;          matrix_b[i] = i + 1.0;      }           matrixProduct(matrix_a, matrix_b, matrix_c, width, height, from, my_rank);           printf(\"Result Matrix:\\n\");     for (int i = 0; i < width; i++) {         for (int j = 0; j < height; j++) {             printf(\"%.2f \", matrix_c[i * width + j]);         }         printf(\"\\n\");     }           free(matrix_a);     free(matrix_b);     free(matrix_c);      return 0; }   void matrixProduct(double *matrix_a, double *matrix_b, double *matrix_c, int width, int height, int from, int my_rank) {     int row, col;      for (row = 0; row < width; row++) {         for (col = 0; col < height; col++) {             matrix_c[row * width + col] = 0;              for (int k = 0; k < width; k++) {                 matrix_c[row * width + col] += matrix_a[((row + from) * width) + k] * matrix_b[k * width + col];             }         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>  __global__ void matrixProduct(double *matrix_a, double *matrix_b, double *matrix_c, int width, int from, int my_rank) {     int row = threadIdx.y + blockDim.y * blockIdx.y;     int col = threadIdx.x + blockDim.x * blockIdx.x;     matrix_c[row * width + col] = 0;     for (int k = 0; k < width; k++) {         matrix_c[row * width + col] += matrix_a[((row + from) * width) + k] * matrix_b[k * width + col];     } }  int main() {          const int width = 256;       const int height = 256;      const int from = 0;          const int my_rank = 0;             double *h_matrix_a = (double *)malloc(width * height * sizeof(double));     double *h_matrix_b = (double *)malloc(width * width * sizeof(double));     double *h_matrix_c = (double *)malloc(width * height * sizeof(double));           for (int i = 0; i < width * height; ++i) {         h_matrix_a[i] = static_cast<double>(i);     }      for (int i = 0; i < width * width; ++i) {         h_matrix_b[i] = static_cast<double>(i);     }           double *d_matrix_a, *d_matrix_b, *d_matrix_c;     cudaMalloc((void **)&d_matrix_a, width * height * sizeof(double));     cudaMalloc((void **)&d_matrix_b, width * width * sizeof(double));     cudaMalloc((void **)&d_matrix_c, width * height * sizeof(double));           cudaMemcpy(d_matrix_a, h_matrix_a, width * height * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_matrix_b, h_matrix_b, width * width * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y);           matrixProduct<<<gridSize, blockSize>>>(d_matrix_a, d_matrix_b, d_matrix_c, width, from, my_rank);           cudaMemcpy(h_matrix_c, d_matrix_c, width * height * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Results printed here:\\n\");           free(h_matrix_a);     free(h_matrix_b);     free(h_matrix_c);     cudaFree(d_matrix_a);     cudaFree(d_matrix_b);     cudaFree(d_matrix_c);      return 0; }   "
    },
    {
        "id": "308",
        "c_code": "#include <stdio.h> #include <stdlib.h>   void expandBoxes_cpu(const float *input, float *output, int dims, int clsNum);  int main() {          int dims = 12;     int clsNum = 3;     float *input = (float *)malloc(clsNum * 4 * sizeof(float));     float *output = (float *)malloc(dims * 4 * sizeof(float));           for (int i = 0; i < clsNum * 4; i++) {         input[i] = i + 1.0;      }           expandBoxes_cpu(input, output, dims, clsNum);           printf(\"Expanded Boxes Matrix:\\n\");     for (int i = 0; i < dims; i++) {         for (int j = 0; j < 4; j++) {             printf(\"%.2f \", output[i * 4 + j]);         }         printf(\"\\n\");     }           free(input);     free(output);      return 0; }   void expandBoxes_cpu(const float *input, float *output, int dims, int clsNum) {     for (int tid = 0; tid < dims; tid++) {         int k = tid / clsNum;         output[tid * 4 + 0] = input[k * 4 + 0];         output[tid * 4 + 1] = input[k * 4 + 1];         output[tid * 4 + 2] = input[k * 4 + 2];         output[tid * 4 + 3] = input[k * 4 + 3];     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>  __global__ void expandBoxes(const float *input, float *output, int dims, int clsNum) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }      int k = tid / clsNum;     output[tid * 4 + 0] = input[k * 4 + 0];     output[tid * 4 + 1] = input[k * 4 + 1];     output[tid * 4 + 2] = input[k * 4 + 2];     output[tid * 4 + 3] = input[k * 4 + 3]; }  int main() {          const int dims = 256;        const int clsNum = 4;              float *h_input = (float *)malloc(dims * clsNum * sizeof(float));     float *h_output = (float *)malloc(dims * 4 * sizeof(float));           for (int i = 0; i < dims * clsNum; ++i) {         h_input[i] = static_cast<float>(i);     }           float *d_input, *d_output;     cudaMalloc((void **)&d_input, dims * clsNum * sizeof(float));     cudaMalloc((void **)&d_output, dims * 4 * sizeof(float));           cudaMemcpy(d_input, h_input, dims * clsNum * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((dims + blockSize.x - 1) / blockSize.x);           expandBoxes<<<gridSize, blockSize>>>(d_input, d_output, dims, clsNum);           cudaMemcpy(h_output, d_output, dims * 4 * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Results printed here:\\n\");           free(h_input);     free(h_output);     cudaFree(d_input);     cudaFree(d_output);      return 0; }   "
    },
    {
        "id": "309",
        "c_code": "#include <stdio.h> #include <stdlib.h>   void equalization(float *cdf, float *mincdf, unsigned char *ucharImage, int imageWidth, int imageHeight, int channels, int pixelSize);  int main() {          int imageWidth = 100;     int imageHeight = 100;     int channels = 3;     int pixelSize = imageWidth * imageHeight * channels;      float *cdf = (float *)malloc(256 * sizeof(float));     float *mincdf = (float *)malloc(1 * sizeof(float));     unsigned char *ucharImage = (unsigned char *)malloc(pixelSize * sizeof(unsigned char));           for (int i = 0; i < 256; i++) {         cdf[i] = i / 255.0;      }      for (int i = 0; i < 1; i++) {         mincdf[i] = 0.1;      }      for (int i = 0; i < pixelSize; i++) {         ucharImage[i] = i % 256;      }           equalization(cdf, mincdf, ucharImage, imageWidth, imageHeight, channels, pixelSize);           printf(\"Equalized Image:\\n\");     for (int i = 0; i < pixelSize; i++) {         printf(\"%u \", ucharImage[i]);         if ((i + 1) % channels == 0) {             printf(\"\\n\");         }     }           free(cdf);     free(mincdf);     free(ucharImage);      return 0; }   void equalization(float *cdf, float *mincdf, unsigned char *ucharImage, int imageWidth, int imageHeight, int channels, int pixelSize) {     int idx;      for (idx = 0; idx < pixelSize; idx++) {         unsigned char val = ucharImage[idx];         float data = 255 * (cdf[val] - mincdf[0]) / (1 - mincdf[0]);          if (data < 0.0f) {             data = 0.0f;         } else if (data > 255.0f) {             data = 255.0f;         }          ucharImage[idx] = (unsigned char)data;     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>  __global__ void equalization(float *cdf, float *mincdf, unsigned char *ucharImage, int imageWidth, int imageHeight, int channels, int pixelSize) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;     if (idx < pixelSize) {         unsigned char val = ucharImage[idx];         float data = 255 * (cdf[val] - mincdf[0]) / (1 - mincdf[0]);         if (data < 0.0f)             data = 0.0f;         else if (data > 255.0f)             data = 255.0f;         ucharImage[idx] = (unsigned char)data;     } }  int main() {          const int imageWidth = 512;     const int imageHeight = 512;     const int channels = 3;      const int pixelSize = imageWidth * imageHeight * channels;           float *h_cdf = (float *)malloc(256 * sizeof(float));     float *h_mincdf = (float *)malloc(sizeof(float));     unsigned char *h_ucharImage = (unsigned char *)malloc(pixelSize * sizeof(unsigned char));           for (int i = 0; i < 256; ++i) {         h_cdf[i] = static_cast<float>(i);     }      *h_mincdf = 0.5f;       for (int i = 0; i < pixelSize; ++i) {         h_ucharImage[i] = static_cast<unsigned char>(i % 256);     }           float *d_cdf, *d_mincdf;     unsigned char *d_ucharImage;     cudaMalloc((void **)&d_cdf, 256 * sizeof(float));     cudaMalloc((void **)&d_mincdf, sizeof(float));     cudaMalloc((void **)&d_ucharImage, pixelSize * sizeof(unsigned char));           cudaMemcpy(d_cdf, h_cdf, 256 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_mincdf, h_mincdf, sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_ucharImage, h_ucharImage, pixelSize * sizeof(unsigned char), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((pixelSize + blockSize.x - 1) / blockSize.x);           equalization<<<gridSize, blockSize>>>(d_cdf, d_mincdf, d_ucharImage, imageWidth, imageHeight, channels, pixelSize);           cudaMemcpy(h_ucharImage, d_ucharImage, pixelSize * sizeof(unsigned char), cudaMemcpyDeviceToHost);           printf(\"Results printed here:\\n\");           free(h_cdf);     free(h_mincdf);     free(h_ucharImage);     cudaFree(d_cdf);     cudaFree(d_mincdf);     cudaFree(d_ucharImage);      return 0; }   "
    },
    {
        "id": "31",
        "c_code": "#include <stdio.h>  void iKernel_cpu(float *A, float *B, float *C, const int N) {     for (int i = 0; i < N; i++) {         C[i] = A[i] + B[i];     } }  int main() {          int arraySize = 6;     float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};     float arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5, 5.5};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           iKernel_cpu(arrayA, arrayB, resultArray, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void iKernel(float* A, float* B, float* C, const int N) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < N) {         C[i] = A[i] + B[i];     } }  int main() {          const int arraySize = 1000;           float* h_A = (float*)malloc(arraySize * sizeof(float));     float* h_B = (float*)malloc(arraySize * sizeof(float));     float* h_C = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_A[i] = static_cast<float>(i);         h_B[i] = static_cast<float>(2 * i);     }           float* d_A;     float* d_B;     float* d_C;     cudaMalloc((void**)&d_A, arraySize * sizeof(float));     cudaMalloc((void**)&d_B, arraySize * sizeof(float));     cudaMalloc((void**)&d_C, arraySize * sizeof(float));           cudaMemcpy(d_A, h_A, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_B, h_B, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           iKernel<<<gridSize, blockSize>>>(d_A, d_B, d_C, arraySize);           cudaMemcpy(h_C, d_C, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_C[i]);     }           free(h_A);     free(h_B);     free(h_C);     cudaFree(d_A);     cudaFree(d_B);     cudaFree(d_C);      return 0; } "
    },
    {
        "id": "310",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>   void smooth_l1_cpu(int n, float *pred, float *truth, float *delta, float *error);  int main() {          int n = 5;     float *pred = (float *)malloc(n * sizeof(float));     float *truth = (float *)malloc(n * sizeof(float));     float *delta = (float *)malloc(n * sizeof(float));     float *error = (float *)malloc(n * sizeof(float));           for (int i = 0; i < n; i++) {         pred[i] = i + 1.0;          truth[i] = i + 1.5;      }           smooth_l1_cpu(n, pred, truth, delta, error);           printf(\"Smooth L1 Error:\\n\");     for (int i = 0; i < n; i++) {         printf(\"%.2f \", error[i]);     }           free(pred);     free(truth);     free(delta);     free(error);      return 0; }   void smooth_l1_cpu(int n, float *pred, float *truth, float *delta, float *error) {     int i;      for (i = 0; i < n; ++i) {         float diff = truth[i] - pred[i];         float abs_val = fabs(diff);          if (abs_val < 1) {             error[i] = diff * diff;             delta[i] = diff;         } else {             error[i] = 2 * abs_val - 1;             delta[i] = (diff < 0) ? 1 : -1;         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>  __global__ void smooth_l1_kernel(int n, float *pred, float *truth, float *delta, float *error) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < n) {         float diff = truth[i] - pred[i];         float abs_val = fabsf(diff);         if (abs_val < 1) {             error[i] = diff * diff;             delta[i] = diff;         } else {             error[i] = 2 * abs_val - 1;             delta[i] = (diff > 0) ? 1 : -1;         }     } }  int main() {          const int n = 1024;           float *h_pred = (float *)malloc(n * sizeof(float));     float *h_truth = (float *)malloc(n * sizeof(float));     float *h_delta = (float *)malloc(n * sizeof(float));     float *h_error = (float *)malloc(n * sizeof(float));           for (int i = 0; i < n; ++i) {         h_pred[i] = static_cast<float>(i);         h_truth[i] = static_cast<float>(i * 2);     }           float *d_pred, *d_truth, *d_delta, *d_error;     cudaMalloc((void **)&d_pred, n * sizeof(float));     cudaMalloc((void **)&d_truth, n * sizeof(float));     cudaMalloc((void **)&d_delta, n * sizeof(float));     cudaMalloc((void **)&d_error, n * sizeof(float));           cudaMemcpy(d_pred, h_pred, n * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_truth, h_truth, n * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x);           smooth_l1_kernel<<<gridSize, blockSize>>>(n, d_pred, d_truth, d_delta, d_error);           cudaMemcpy(h_delta, d_delta, n * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_error, d_error, n * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Results printed here:\\n\");           free(h_pred);     free(h_truth);     free(h_delta);     free(h_error);     cudaFree(d_pred);     cudaFree(d_truth);     cudaFree(d_delta);     cudaFree(d_error);      return 0; }   "
    },
    {
        "id": "311",
        "c_code": "#include <stdio.h> #include <stdlib.h>   void multiply_matrices(float *A_Matrix, float *B_Matrix, float *ANS_Matrix, int N);  int main() {          int N = 3;      float *A_Matrix = (float *)malloc(N * N * sizeof(float));     float *B_Matrix = (float *)malloc(N * N * sizeof(float));     float *ANS_Matrix = (float *)malloc(N * N * sizeof(float));           for (int i = 0; i < N * N; i++) {         A_Matrix[i] = i + 1.0;          B_Matrix[i] = i + 2.0;      }           multiply_matrices(A_Matrix, B_Matrix, ANS_Matrix, N);           printf(\"Resultant Matrix:\\n\");     for (int i = 0; i < N; i++) {         for (int j = 0; j < N; j++) {             printf(\"%.2f \", ANS_Matrix[i * N + j]);         }         printf(\"\\n\");     }           free(A_Matrix);     free(B_Matrix);     free(ANS_Matrix);      return 0; }   void multiply_matrices(float *A_Matrix, float *B_Matrix, float *ANS_Matrix, int N) {     int i, j, k;     float sum, m, n;      for (i = 0; i < N; i++) {         for (j = 0; j < N; j++) {             sum = 0;             for (k = 0; k < N; k++) {                 m = *(A_Matrix + i * N + k);                 n = *(B_Matrix + k * N + j);                 sum += m * n;             }             *(ANS_Matrix + i * N + j) = sum;         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>   #define WIDTH 1024   __global__ void matrixMult(float *A, float *B, float *C, int width) {     int k = 0;     float sum = 0;     int col = blockDim.x * blockIdx.x + threadIdx.x;     int row = blockDim.y * blockIdx.y + threadIdx.y;      if (col < width && row < width) {         for (k = 0; k < width; k++) {             sum += A[row * width + k] * B[k * width + col];         }         C[row * width + col] = sum;     } }  int main() {          float *h_A, *h_B, *h_C;     h_A = (float *)malloc(WIDTH * WIDTH * sizeof(float));     h_B = (float *)malloc(WIDTH * WIDTH * sizeof(float));     h_C = (float *)malloc(WIDTH * WIDTH * sizeof(float));           for (int i = 0; i < WIDTH * WIDTH; ++i) {         h_A[i] = 1.0f;         h_B[i] = 2.0f;     }           float *d_A, *d_B, *d_C;     cudaMalloc((void **)&d_A, WIDTH * WIDTH * sizeof(float));     cudaMalloc((void **)&d_B, WIDTH * WIDTH * sizeof(float));     cudaMalloc((void **)&d_C, WIDTH * WIDTH * sizeof(float));           cudaMemcpy(d_A, h_A, WIDTH * WIDTH * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_B, h_B, WIDTH * WIDTH * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((WIDTH + blockSize.x - 1) / blockSize.x, (WIDTH + blockSize.y - 1) / blockSize.y);           matrixMult<<<gridSize, blockSize>>>(d_A, d_B, d_C, WIDTH);           cudaMemcpy(h_C, d_C, WIDTH * WIDTH * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Results printed here:\\n\");           free(h_A);     free(h_B);     free(h_C);     cudaFree(d_A);     cudaFree(d_B);     cudaFree(d_C);      return 0; }   "
    },
    {
        "id": "312",
        "c_code": "#include <stdio.h> #include <stdlib.h>   void SetToZero_kernel(float *d_vx, float *d_vy, float *d_vz, int w, int h, int l);  int main() {          int w = 3;      int h = 3;      int l = 3;            float *d_vx = (float *)malloc(w * h * l * sizeof(float));     float *d_vy = (float *)malloc(w * h * l * sizeof(float));     float *d_vz = (float *)malloc(w * h * l * sizeof(float));           SetToZero_kernel(d_vx, d_vy, d_vz, w, h, l);                      free(d_vx);     free(d_vy);     free(d_vz);      return 0; }   void SetToZero_kernel(float *d_vx, float *d_vy, float *d_vz, int w, int h, int l) {     unsigned int i, j;      for (i = 0; i < w; i++) {         for (j = 0; j < h; j++) {             unsigned int index = j * w + i;             for (int k = 0; k < l; ++k, index += w * h) {                 d_vx[index] = 0;                 d_vy[index] = 0;                 d_vz[index] = 0;             }         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>   #define WIDTH 1024 #define HEIGHT 1024 #define DEPTH 1024   __global__ void SetToZero_kernel(float *d_vx, float *d_vy, float *d_vz, int w, int h, int l) {     unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;     unsigned int j = blockIdx.y * blockDim.y + threadIdx.y;     unsigned int index = j * w + i;      if (i < w && j < h) {         for (int k = 0; k < l; ++k, index += w * h) {             d_vx[index] = 0;             d_vy[index] = 0;             d_vz[index] = 0;         }     } }  int main() {          float *d_vx, *d_vy, *d_vz;     cudaMalloc((void **)&d_vx, WIDTH * HEIGHT * DEPTH * sizeof(float));     cudaMalloc((void **)&d_vy, WIDTH * HEIGHT * DEPTH * sizeof(float));     cudaMalloc((void **)&d_vz, WIDTH * HEIGHT * DEPTH * sizeof(float));           dim3 blockSize(16, 16);       dim3 gridSize((WIDTH + blockSize.x - 1) / blockSize.x, (HEIGHT + blockSize.y - 1) / blockSize.y);           SetToZero_kernel<<<gridSize, blockSize>>>(d_vx, d_vy, d_vz, WIDTH, HEIGHT, DEPTH);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaFree(d_vx);     cudaFree(d_vy);     cudaFree(d_vz);      return 0; }   "
    },
    {
        "id": "313",
        "c_code": "#include <stdio.h> #include <stdlib.h>   void solveLower_cpu(const double *lower, const double *b, double *buf, int dim, int n);  int main() {          int dim = 3;      int n = 2;              double *lower = (double *)malloc(dim * dim * sizeof(double));     double *b = (double *)malloc(n * dim * sizeof(double));     double *buf = (double *)malloc(n * dim * sizeof(double));           for (int i = 0; i < dim * dim; i++) {         lower[i] = i + 1.0;      }      for (int i = 0; i < n * dim; i++) {         b[i] = i + 1.0;      }           solveLower_cpu(lower, b, buf, dim, n);                      free(lower);     free(b);     free(buf);      return 0; }   void solveLower_cpu(const double *lower, const double *b, double *buf, int dim, int n) {     for (int k = 0; k < n; k++) {         for (int i = 0; i < dim; i++) {             double val = b[k * dim + i];             for (int j = 0; j < i; j++) {                 val -= lower[i * dim + j] * buf[k * dim + j];             }             buf[k * dim + i] = val / lower[i * dim + i];         }     } }   ",
        "cuda_code": " #include <stdio.h> #include <cuda_runtime.h>  #define DIM 128 #define N 1024   __global__ void solveLowerKernel(const double *lower, const double *b, double *buf, int dim, int n) {     int k = blockIdx.x * blockDim.x + threadIdx.x;      if (k < n) {         for (int i = 0; i < dim; i++) {             double val = b[k * dim + i];             for (int j = 0; j < i; j++) {                 val -= lower[i * dim + j] * buf[k * dim + j];             }             buf[k * dim + i] = val / lower[i * dim + i];         }     } }  int main() {          double *d_lower, *d_b, *d_buf;      cudaMalloc((void **)&d_lower, DIM * DIM * sizeof(double));     cudaMalloc((void **)&d_b, N * DIM * sizeof(double));     cudaMalloc((void **)&d_buf, N * DIM * sizeof(double));           dim3 blockSize(256);       dim3 gridSize((N + blockSize.x - 1) / blockSize.x);           solveLowerKernel<<<gridSize, blockSize>>>(d_lower, d_b, d_buf, DIM, N);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaFree(d_lower);     cudaFree(d_b);     cudaFree(d_buf);      return 0; }  "
    },
    {
        "id": "314",
        "c_code": "#include <stdio.h> #include <stdlib.h>   void deinter_cpu(int NX, float *X, int NY, float *Y, int B, float *OUT);  int main() {          int NX = 3;      int NY = 2;      int B = 4;             float *X = (float *)malloc(B * NX * sizeof(float));     float *Y = (float *)malloc(B * NY * sizeof(float));     float *OUT = (float *)malloc((NX + NY) * B * sizeof(float));           for (int i = 0; i < B * NX; i++) {         X[i] = i + 1.0;      }      for (int i = 0; i < B * NY; i++) {         Y[i] = i + 1.0;      }           deinter_cpu(NX, X, NY, Y, B, OUT);                      free(X);     free(Y);     free(OUT);      return 0; }   void deinter_cpu(int NX, float *X, int NY, float *Y, int B, float *OUT) {     int i, j;     int index = 0;      for (j = 0; j < B; ++j) {         for (i = 0; i < NX; ++i) {             if (X) X[j * NX + i] += OUT[index];             ++index;         }          for (i = 0; i < NY; ++i) {             if (Y) Y[j * NY + i] += OUT[index];             ++index;         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  #define NX 128 #define NY 64 #define B 512   __global__ void deinter_kernel(int NX, float *X, int NY, float *Y, int B, float *OUT) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i < (NX + NY) * B) {         int b = i / (NX + NY);         int j = i % (NX + NY);          if (j < NX) {             if (X)                 X[b * NX + j] += OUT[i];         } else {             if (Y)                 Y[b * NY + j - NX] += OUT[i];         }     } }  int main() {          float *d_X, *d_Y, *d_OUT;      cudaMalloc((void **)&d_X, B * NX * sizeof(float));     cudaMalloc((void **)&d_Y, B * NY * sizeof(float));     cudaMalloc((void **)&d_OUT, B * (NX + NY) * sizeof(float));           dim3 blockSize(256);       dim3 gridSize((B * (NX + NY) + blockSize.x - 1) / blockSize.x);           deinter_kernel<<<gridSize, blockSize>>>(NX, d_X, NY, d_Y, B, d_OUT);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaFree(d_X);     cudaFree(d_Y);     cudaFree(d_OUT);      return 0; }   "
    },
    {
        "id": "315",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>   void binarize_input(float *input, int n, int size, float *binary);  int main() {          int n = 3;         int size = 5;            float *input = (float *)malloc(n * size * sizeof(float));     float *binary = (float *)malloc(n * size * sizeof(float));           for (int i = 0; i < n * size; i++) {         input[i] = i + 1.0;      }           binarize_input(input, n, size, binary);                      free(input);     free(binary);      return 0; }   void binarize_input(float *input, int n, int size, float *binary) {     int i, s;      for (s = 0; s < size; ++s) {         float mean = 0;          for (i = 0; i < n; ++i) {             mean += fabs(input[i * size + s]);         }          mean = mean / n;          for (i = 0; i < n; ++i) {             binary[i * size + s] = (input[i * size + s] > 0) ? mean : -mean;         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  #define N 512 #define Size 1024   __global__ void binarize_input_kernel(float *input, int n, int size, float *binary) {     int s = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (s >= size)         return;      int i = 0;     float mean = 0;      for (i = 0; i < n; ++i) {         mean += fabs(input[i * size + s]);     }      mean = mean / n;      for (i = 0; i < n; ++i) {         binary[i * size + s] = (input[i * size + s] > 0) ? mean : -mean;     } }  int main() {          float *d_input, *d_binary;      cudaMalloc((void **)&d_input, N * Size * sizeof(float));     cudaMalloc((void **)&d_binary, N * Size * sizeof(float));           dim3 blockSize(256);       dim3 gridSize((N * Size + blockSize.x - 1) / blockSize.x);           binarize_input_kernel<<<gridSize, blockSize>>>(d_input, N, Size, d_binary);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaFree(d_input);     cudaFree(d_binary);      return 0; }   "
    },
    {
        "id": "316",
        "c_code": "#include <stdio.h> #include <stdlib.h>   void matrixMultiply_cpu(float *A, float *B, float *C, int numARows, int numAColumns, int numBRows, int numBColumns);  int main() {          int numARows = 3;         int numAColumns = 2;      int numBRows = 2;         int numBColumns = 4;            float *A = (float *)malloc(numARows * numAColumns * sizeof(float));     float *B = (float *)malloc(numBRows * numBColumns * sizeof(float));     float *C = (float *)malloc(numARows * numBColumns * sizeof(float));           for (int i = 0; i < numARows * numAColumns; i++) {         A[i] = i + 1.0;      }      for (int i = 0; i < numBRows * numBColumns; i++) {         B[i] = i + 1.0;      }           matrixMultiply_cpu(A, B, C, numARows, numAColumns, numBRows, numBColumns);                      free(A);     free(B);     free(C);      return 0; }   void matrixMultiply_cpu(float *A, float *B, float *C, int numARows, int numAColumns, int numBRows, int numBColumns) {     int numCRows = numARows;     int numCColumns = numBColumns;      for (int row = 0; row < numCRows; row++) {         for (int col = 0; col < numCColumns; col++) {             float sum = 0;              for (int k = 0; k < numBRows; k++) {                 sum += A[row * numAColumns + k] * B[k * numBColumns + col];             }              C[row * numCColumns + col] = sum;         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  #define numARows 1024 #define numAColumns 1024 #define numBRows 1024 #define numBColumns 1024   __global__ void matrixMultiply(float *A, float *B, float *C, int numARows, int numAColumns, int numBRows, int numBColumns) {     int row = blockIdx.y * blockDim.y + threadIdx.y;     int col = blockIdx.x * blockDim.x + threadIdx.x;      int numCRows = numARows;     int numCColumns = numBColumns;      if (row < numCRows && col < numCColumns) {         float sum = 0;          for (int k = 0; k < numBRows; k++) {             sum += A[row * numAColumns + k] * B[k * numBColumns + col];         }          C[row * numCColumns + col] = sum;     } }  int main() {          float *d_A, *d_B, *d_C;      cudaMalloc((void **)&d_A, numARows * numAColumns * sizeof(float));     cudaMalloc((void **)&d_B, numBRows * numBColumns * sizeof(float));     cudaMalloc((void **)&d_C, numARows * numBColumns * sizeof(float));           dim3 blockSize(16, 16);       dim3 gridSize((numBColumns + blockSize.x - 1) / blockSize.x, (numARows + blockSize.y - 1) / blockSize.y);           matrixMultiply<<<gridSize, blockSize>>>(d_A, d_B, d_C, numARows, numAColumns, numBRows, numBColumns);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaFree(d_A);     cudaFree(d_B);     cudaFree(d_C);      return 0; }   "
    },
    {
        "id": "317",
        "c_code": "#include <stdio.h> #include <stdlib.h>   void backward_avgpool_layer(int batch, int c, int w, int h, float *delta);  int main() {          int batch = 2;      int c = 3;         int w = 4;         int h = 4;               float *delta = (float *)malloc(batch * c * w * h * sizeof(float));           for (int i = 0; i < batch * c * w * h; i++) {         delta[i] = i + 1.0;      }           backward_avgpool_layer(batch, c, w, h, delta);                      free(delta);      return 0; }   void backward_avgpool_layer(int batch, int c, int w, int h, float *delta) {     int b, i, k;      for (b = 0; b < batch; ++b) {         for (k = 0; k < c; ++k) {             int out_index = k + b * c;              for (i = 0; i < h * w; ++i) {                 int in_index = i + h * w * (k + b * c);                 delta[in_index] += delta[out_index] / (h * w);             }         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>   __global__ void backward_avgpool_layer_kernel(int n, int w, int h, int c, float *in_delta, float *out_delta) {     int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (id >= n)         return;      int k = id % c;     id /= c;     int b = id;     int i;     int out_index = (k + c * b);      for (i = 0; i < w * h; ++i) {         int in_index = i + h * w * (k + b * c);         in_delta[in_index] += out_delta[out_index] / (w * h);     } }  int main() {          int n = 1024;       int w = 28;         int h = 28;     int c = 3;           float *d_in_delta, *d_out_delta;      cudaMalloc((void **)&d_in_delta, n * w * h * c * sizeof(float));     cudaMalloc((void **)&d_out_delta, n * c * sizeof(float));           dim3 blockSize(256);       dim3 gridSize((n + blockSize.x - 1) / blockSize.x, 1);           backward_avgpool_layer_kernel<<<gridSize, blockSize>>>(n, w, h, c, d_in_delta, d_out_delta);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaFree(d_in_delta);     cudaFree(d_out_delta);      return 0; }   "
    },
    {
        "id": "318",
        "c_code": "#include <stdio.h> #include <stdlib.h>   void mean_cpu(float *x, int batch, int filters, int spatial, float *mean);  int main() {          int batch = 2;           int filters = 3;         int spatial = 4;               float *x = (float *)malloc(batch * filters * spatial * sizeof(float));     float *mean = (float *)malloc(filters * sizeof(float));           for (int i = 0; i < batch * filters * spatial; i++) {         x[i] = i + 1.0;      }           mean_cpu(x, batch, filters, spatial, mean);           printf(\"Mean: \");     for (int i = 0; i < filters; i++) {         printf(\"%f \", mean[i]);     }     printf(\"\\n\");           free(x);     free(mean);      return 0; }   void mean_cpu(float *x, int batch, int filters, int spatial, float *mean) {     float scale = 1.0 / (batch * spatial);     int i, j, k;      for (i = 0; i < filters; ++i) {         mean[i] = 0;          for (j = 0; j < batch; ++j) {             for (k = 0; k < spatial; ++k) {                 int index = j * filters * spatial + i * spatial + k;                 mean[i] += x[index];             }         }          mean[i] *= scale;     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void mean_kernel(float *x, int batch, int filters, int spatial, float *mean) {     float scale = 1.f / (batch * spatial);     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i >= filters)         return;      int j, k;     mean[i] = 0;      for (j = 0; j < batch; ++j) {         for (k = 0; k < spatial; ++k) {             int index = j * filters * spatial + i * spatial + k;             mean[i] += x[index];         }     }      mean[i] *= scale; }  int main() {          int batch = 64;           int filters = 128;        int spatial = 256;              float *d_x, *d_mean;     cudaMalloc((void **)&d_x, batch * filters * spatial * sizeof(float));     cudaMalloc((void **)&d_mean, filters * sizeof(float));           dim3 blockSize(256);       dim3 gridSize((filters + blockSize.x - 1) / blockSize.x, 1);           mean_kernel<<<gridSize, blockSize>>>(d_x, batch, filters, spatial, d_mean);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaFree(d_x);     cudaFree(d_mean);      return 0; }   "
    },
    {
        "id": "319",
        "c_code": "#include <stdio.h> #include <stdlib.h>   void boxesScale_cpu(const float *input, float *output, int dims, float scale0, float scale1, float scale2, float scale3);  int main() {          int dims = 2;                   float scale0 = 2.0;             float scale1 = 1.5;             float scale2 = 3.0;             float scale3 = 0.5;                   float *input = (float *)malloc(dims * 4 * sizeof(float));     float *output = (float *)malloc(dims * 4 * sizeof(float));           for (int i = 0; i < dims * 4; i++) {         input[i] = i + 1.0;          }           boxesScale_cpu(input, output, dims, scale0, scale1, scale2, scale3);           printf(\"Output: \");     for (int i = 0; i < dims * 4; i++) {         printf(\"%f \", output[i]);     }     printf(\"\\n\");           free(input);     free(output);      return 0; }   void boxesScale_cpu(const float *input, float *output, int dims, float scale0, float scale1, float scale2, float scale3) {     for (int tid = 0; tid < dims; tid++) {         output[tid * 4] = input[tid * 4] / scale0;         output[tid * 4 + 1] = input[tid * 4 + 1] / scale1;         output[tid * 4 + 2] = input[tid * 4 + 2] / scale2;         output[tid * 4 + 3] = input[tid * 4 + 3] / scale3;     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void boxesScale(const float *input, float *output, int dims, float scale0, float scale1, float scale2, float scale3) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }      output[tid * 4] = input[tid * 4] / scale0;     output[tid * 4 + 1] = input[tid * 4 + 1] / scale1;     output[tid * 4 + 2] = input[tid * 4 + 2] / scale2;     output[tid * 4 + 3] = input[tid * 4 + 3] / scale3; }  int main() {          int dims = 128;              float scale0 = 2.0f;         float scale1 = 1.5f;         float scale2 = 1.0f;         float scale3 = 0.5f;               float *d_input, *d_output;     cudaMalloc((void **)&d_input, dims * 4 * sizeof(float));     cudaMalloc((void **)&d_output, dims * 4 * sizeof(float));           dim3 blockSize(256);        dim3 gridSize((dims + blockSize.x - 1) / blockSize.x, 1);           boxesScale<<<gridSize, blockSize>>>(d_input, d_output, dims, scale0, scale1, scale2, scale3);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaFree(d_input);     cudaFree(d_output);      return 0; }   "
    },
    {
        "id": "32",
        "c_code": "#include <stdio.h>  void multiplyIntValues(int *destination, int *vector, int value, unsigned int end) {     for (unsigned int i = 0; i < end; i++) {         destination[i] = vector[i] * value;     } }  int main() {          unsigned int arraySize = 5;     int vector[] = {1, 2, 3, 4, 5};     int resultArray[arraySize];     int multiplier = 3;      printf(\"\u539f\u59cb\u5411\u91cf\uff1a\");     for (unsigned int i = 0; i < arraySize; i++) {         printf(\"%d \", vector[i]);     }           multiplyIntValues(resultArray, vector, multiplier, arraySize);      printf(\"\\n\u4e58\u6cd5\u540e\u7684\u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < arraySize; i++) {         printf(\"%d \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void intMultiply(int* result, const int* val1, const int val2, const unsigned int size) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     if (i < size) {         result[i] = val1[i] * val2;     } }  int main() {          const int arraySize = 1000;           int* h_result = (int*)malloc(arraySize * sizeof(int));     int* h_val1 = (int*)malloc(arraySize * sizeof(int));     const int h_val2 = 2;             for (int i = 0; i < arraySize; ++i) {         h_val1[i] = i;     }           int* d_result;     int* d_val1;     cudaMalloc((void**)&d_result, arraySize * sizeof(int));     cudaMalloc((void**)&d_val1, arraySize * sizeof(int));           cudaMemcpy(d_val1, h_val1, arraySize * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           intMultiply<<<gridSize, blockSize>>>(d_result, d_val1, h_val2, arraySize);           cudaMemcpy(h_result, d_result, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_result[i]);     }           free(h_result);     free(h_val1);     cudaFree(d_result);     cudaFree(d_val1);      return 0; } "
    },
    {
        "id": "320",
        "c_code": "#include <stdio.h>   void mat_mul_seq(int *m_A, int *m_B, int *m_C, int A_rows, int A_cols, int B_rows, int B_cols);  int main() {          int A_rows = 2, A_cols = 3;     int B_rows = 3, B_cols = 4;      int matrix_A[] = {1, 2, 3, 4, 5, 6};     int matrix_B[] = {7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18};           int matrix_C[A_rows * B_cols];           mat_mul_seq(matrix_A, matrix_B, matrix_C, A_rows, A_cols, B_rows, B_cols);           printf(\"Resulting Matrix C:\\n\");     for (int i = 0; i < A_rows; i++) {         for (int j = 0; j < B_cols; j++) {             printf(\"%d \", matrix_C[i * B_cols + j]);         }         printf(\"\\n\");     }      return 0; }   void mat_mul_seq(int *m_A, int *m_B, int *m_C, int A_rows, int A_cols, int B_rows, int B_cols) {     int sum;     for (int i = 0; i < A_rows; i++) {         for (int j = 0; j < B_cols; j++) {             sum = 0;             for (int k = 0; k < A_cols; k++) {                 sum += m_A[i * A_cols + k] * m_B[k * B_cols + j];             }             m_C[i * B_cols + j] = sum;         }     } }  ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void mat_mul_kernel(int *m_A, int *m_B, int *m_C, int A_rows, int A_cols, int B_rows, int B_cols) {     int sum = 0;     int row = threadIdx.y + blockIdx.y * blockDim.y;     int col = threadIdx.x + blockIdx.x * blockDim.x;      if (row < A_rows && col < B_cols) {         for (int i = 0; i < A_cols; i++) {             sum += m_A[row * A_cols + i] * m_B[i * B_cols + col];         }         m_C[row * B_cols + col] = sum;     } }  int main() {          int A_rows = 4;       int A_cols = 3;       int B_rows = 3;       int B_cols = 5;             int *h_A, *h_B, *h_C;     h_A = (int *)malloc(A_rows * A_cols * sizeof(int));     h_B = (int *)malloc(B_rows * B_cols * sizeof(int));     h_C = (int *)malloc(A_rows * B_cols * sizeof(int));           for (int i = 0; i < A_rows * A_cols; i++) {         h_A[i] = i + 1;     }      for (int i = 0; i < B_rows * B_cols; i++) {         h_B[i] = i + 1;     }           int *d_A, *d_B, *d_C;     cudaMalloc((void **)&d_A, A_rows * A_cols * sizeof(int));     cudaMalloc((void **)&d_B, B_rows * B_cols * sizeof(int));     cudaMalloc((void **)&d_C, A_rows * B_cols * sizeof(int));           cudaMemcpy(d_A, h_A, A_rows * A_cols * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_B, h_B, B_rows * B_cols * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);       dim3 gridSize((B_cols + blockSize.x - 1) / blockSize.x, (A_rows + blockSize.y - 1) / blockSize.y);           mat_mul_kernel<<<gridSize, blockSize>>>(d_A, d_B, d_C, A_rows, A_cols, B_rows, B_cols);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaMemcpy(h_C, d_C, A_rows * B_cols * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Result Matrix:\\n\");     for (int i = 0; i < A_rows; i++) {         for (int j = 0; j < B_cols; j++) {             printf(\"%d \", h_C[i * B_cols + j]);         }         printf(\"\\n\");     }           free(h_A);     free(h_B);     free(h_C);     cudaFree(d_A);     cudaFree(d_B);     cudaFree(d_C);      return 0; }   "
    },
    {
        "id": "321",
        "c_code": "#include <stdio.h>   void create_p_vect(float *node_info1, float *node_info2, float *p, int n_nodes_1, int n_nodes_2);  int main() {          int n_nodes_1 = 3;     int n_nodes_2 = 4;      float node_info1[] = {0.2, 0.6, 0.8};     float node_info2[] = {0.3, 0.7, 0.4, 0.9};           float p[n_nodes_1 * n_nodes_2];           create_p_vect(node_info1, node_info2, p, n_nodes_1, n_nodes_2);           printf(\"Resulting Array p:\\n\");     for (int i = 0; i < n_nodes_1; i++) {         for (int j = 0; j < n_nodes_2; j++) {             printf(\"%.2f \", p[i * n_nodes_2 + j]);         }         printf(\"\\n\");     }      return 0; }   void create_p_vect(float *node_info1, float *node_info2, float *p, int n_nodes_1, int n_nodes_2) {     int tx, ty;     float cutoff = 0.5;     for (tx = 0; tx < n_nodes_1; tx++) {         for (ty = 0; ty < n_nodes_2; ty++) {             int ind = tx * n_nodes_2 + ty;             if ((node_info1[tx] < cutoff) && (node_info2[ty] < cutoff))                 p[ind] = 0;             else                 p[ind] = node_info1[tx] * node_info2[ty];         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void create_p_vect(float *node_info1, float *node_info2, float *p, int n_nodes_1, int n_nodes_2) {     int tx = threadIdx.x + blockDim.x * blockIdx.x;     int ty = threadIdx.y + blockDim.y * blockIdx.y;     float cutoff = 0.5;      if ((tx < n_nodes_1) && (ty < n_nodes_2)) {         int ind = tx * n_nodes_2 + ty;          if ((node_info1[tx] < cutoff) && (node_info2[ty] < cutoff))             p[ind] = 0;         else             p[ind] = node_info1[tx] * node_info2[ty];     } }  int main() {          int n_nodes_1 = 4;       int n_nodes_2 = 3;             float *h_node_info1, *h_node_info2, *h_p;     h_node_info1 = (float *)malloc(n_nodes_1 * sizeof(float));     h_node_info2 = (float *)malloc(n_nodes_2 * sizeof(float));     h_p = (float *)malloc(n_nodes_1 * n_nodes_2 * sizeof(float));           for (int i = 0; i < n_nodes_1; i++) {         h_node_info1[i] = static_cast<float>(i + 1) / 10.0f;     }      for (int i = 0; i < n_nodes_2; i++) {         h_node_info2[i] = static_cast<float>(i + 1) / 10.0f;     }           float *d_node_info1, *d_node_info2, *d_p;     cudaMalloc((void **)&d_node_info1, n_nodes_1 * sizeof(float));     cudaMalloc((void **)&d_node_info2, n_nodes_2 * sizeof(float));     cudaMalloc((void **)&d_p, n_nodes_1 * n_nodes_2 * sizeof(float));           cudaMemcpy(d_node_info1, h_node_info1, n_nodes_1 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_node_info2, h_node_info2, n_nodes_2 * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);       dim3 gridSize((n_nodes_1 + blockSize.x - 1) / blockSize.x, (n_nodes_2 + blockSize.y - 1) / blockSize.y);           create_p_vect<<<gridSize, blockSize>>>(d_node_info1, d_node_info2, d_p, n_nodes_1, n_nodes_2);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaMemcpy(h_p, d_p, n_nodes_1 * n_nodes_2 * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Result Array:\\n\");     for (int i = 0; i < n_nodes_1; i++) {         for (int j = 0; j < n_nodes_2; j++) {             printf(\"%.2f \", h_p[i * n_nodes_2 + j]);         }         printf(\"\\n\");     }           free(h_node_info1);     free(h_node_info2);     free(h_p);     cudaFree(d_node_info1);     cudaFree(d_node_info2);     cudaFree(d_p);      return 0; }   "
    },
    {
        "id": "322",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void calcbidvalues(int n, int *src2tgt, float *adj, float *prices, unsigned short *complete, float *values, float *bids) {     for (int idx = 0; idx < n * n; idx++) {         int i = idx / n;         int j = idx - i * n;         bids[i * n + j] = -1;         if (src2tgt[i] != -1) {             continue;         }         complete[0] = 0;         values[i * n + j] = -adj[i * n + j] - prices[j];     } }  int main() {     int n = 5;      int *src2tgt = (int *)malloc(n * sizeof(int));     float *adj = (float *)malloc(n * n * sizeof(float));     float *prices = (float *)malloc(n * sizeof(float));     unsigned short *complete = (unsigned short *)malloc(sizeof(unsigned short));     float *values = (float *)malloc(n * n * sizeof(float));     float *bids = (float *)malloc(n * n * sizeof(float));                      calcbidvalues(n, src2tgt, adj, prices, complete, values, bids);                      free(src2tgt);     free(adj);     free(prices);     free(complete);     free(values);     free(bids);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void calcbidvalues(int n, int *src2tgt, float *adj, float *prices, bool *complete, float *values, float *bids) {     int INDEX = blockIdx.x * blockDim.x + threadIdx.x;     int stride = blockDim.x * gridDim.x;      for (int idx = INDEX; idx < n * n; idx += stride) {         int i = idx / n;         int j = idx - i * n;         bids[i * n + j] = -1;          if (src2tgt[i] != -1) {             continue;         }          complete[0] = false;         values[i * n + j] = -adj[i * n + j] - prices[j];     } }  int main() {          int n = 4;            int *h_src2tgt;     float *h_adj, *h_prices, *h_values, *h_bids;     bool *h_complete;      h_src2tgt = (int *)malloc(n * sizeof(int));     h_adj = (float *)malloc(n * n * sizeof(float));     h_prices = (float *)malloc(n * sizeof(float));     h_values = (float *)malloc(n * n * sizeof(float));     h_bids = (float *)malloc(n * n * sizeof(float));     h_complete = (bool *)malloc(sizeof(bool));           for (int i = 0; i < n; i++) {         h_src2tgt[i] = -1;          h_prices[i] = 0.5;            for (int j = 0; j < n; j++) {             h_adj[i * n + j] = static_cast<float>(i + j) / 10.0f;          }     }           int *d_src2tgt;     float *d_adj, *d_prices, *d_values, *d_bids;     bool *d_complete;      cudaMalloc((void **)&d_src2tgt, n * sizeof(int));     cudaMalloc((void **)&d_adj, n * n * sizeof(float));     cudaMalloc((void **)&d_prices, n * sizeof(float));     cudaMalloc((void **)&d_values, n * n * sizeof(float));     cudaMalloc((void **)&d_bids, n * n * sizeof(float));     cudaMalloc((void **)&d_complete, sizeof(bool));           cudaMemcpy(d_src2tgt, h_src2tgt, n * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_adj, h_adj, n * n * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_prices, h_prices, n * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((n * n + blockSize.x - 1) / blockSize.x, 1);           calcbidvalues<<<gridSize, blockSize>>>(n, d_src2tgt, d_adj, d_prices, d_complete, d_values, d_bids);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaMemcpy(h_values, d_values, n * n * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_bids, d_bids, n * n * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_complete, d_complete, sizeof(bool), cudaMemcpyDeviceToHost);           printf(\"Values Array:\\n\");     for (int i = 0; i < n; i++) {         for (int j = 0; j < n; j++) {             printf(\"%.2f \", h_values[i * n + j]);         }         printf(\"\\n\");     }      printf(\"Bids Array:\\n\");     for (int i = 0; i < n; i++) {         for (int j = 0; j < n; j++) {             printf(\"%.2f \", h_bids[i * n + j]);         }         printf(\"\\n\");     }      printf(\"Complete Flag: %s\\n\", *h_complete ? \"true\" : \"false\");           free(h_src2tgt);     free(h_adj);     free(h_prices);     free(h_values);     free(h_bids);     free(h_complete   "
    },
    {
        "id": "323",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void convolutionRowCPU(float *h_Dst, float *h_Src, float *h_Filter, int imageW, int imageH, int filterR) {     int x, y, k;     for (y = 0; y < imageH; y++) {         for (x = 0; x < imageW; x++) {             float sum = 0;             for (k = -filterR; k <= filterR; k++) {                 int d = x + k;                 if (d >= 0 && d < imageW) {                     sum += h_Src[y * imageW + d] * h_Filter[filterR - k];                 }             }             h_Dst[y * imageW + x] = sum;         }     } }  int main() {          int imageW = 5;     int imageH = 5;     int filterR = 1;           float *h_Src = (float *)malloc(imageW * imageH * sizeof(float));     float *h_Filter = (float *)malloc((2 * filterR + 1) * sizeof(float));     float *h_Dst = (float *)malloc(imageW * imageH * sizeof(float));           for (int i = 0; i < imageW * imageH; i++) {         h_Src[i] = rand() % 10;       }      for (int i = 0; i < 2 * filterR + 1; i++) {         h_Filter[i] = 0.1;       }           convolutionRowCPU(h_Dst, h_Src, h_Filter, imageW, imageH, filterR);           printf(\"Result:\\n\");     for (int i = 0; i < imageH; i++) {         for (int j = 0; j < imageW; j++) {             printf(\"%.2f\\t\", h_Dst[i * imageW + j]);         }         printf(\"\\n\");     }           free(h_Src);     free(h_Filter);     free(h_Dst);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void kernel_rows(const float *filter, const float *input, float *output, int imageW, int imageH, int filterR) {     int idx_x = threadIdx.x + blockDim.x * blockIdx.x;     int idx_y = threadIdx.y + blockDim.y * blockIdx.y;     int grid_width = gridDim.x * blockDim.x;     int idx = grid_width * idx_y + idx_x;     float sum = 0;      for (int k = -filterR; k <= filterR; k++) {         int d = idx_x + k;         if (d >= 0 && d < imageW) {             sum += input[idx_y * imageW + d] * filter[filterR - k];         }     }      output[idx] = sum; }  int main() {          int imageW = 128;       int imageH = 128;       int filterR = 3;              float *h_filter, *h_input, *h_output;     h_filter = (float *)malloc((2 * filterR + 1) * sizeof(float));     h_input = (float *)malloc(imageW * imageH * sizeof(float));     h_output = (float *)malloc(imageW * imageH * sizeof(float));           for (int i = 0; i < 2 * filterR + 1; i++) {         h_filter[i] = 1.0f / (2 * filterR + 1);      }      for (int i = 0; i < imageW * imageH; i++) {         h_input[i] = static_cast<float>(i % 255);      }           float *d_filter, *d_input, *d_output;     cudaMalloc((void **)&d_filter, (2 * filterR + 1) * sizeof(float));     cudaMalloc((void **)&d_input, imageW * imageH * sizeof(float));     cudaMalloc((void **)&d_output, imageW * imageH * sizeof(float));           cudaMemcpy(d_filter, h_filter, (2 * filterR + 1) * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_input, h_input, imageW * imageH * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((imageW + blockSize.x - 1) / blockSize.x, (imageH + blockSize.y - 1) / blockSize.y);           kernel_rows<<<gridSize, blockSize>>>(d_filter, d_input, d_output, imageW, imageH, filterR);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaMemcpy(h_output, d_output, imageW * imageH * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"Output Array:\\n\");     for (int i = 0; i < imageH; i++) {         for (int j = 0; j < imageW; j++) {             printf(\"%.2f \", h_output[i * imageW + j]);         }         printf(\"\\n\");     }           free(h_filter);     free(h_input);     free(h_output);     cudaFree(d_filter);     cudaFree(d_input);     cudaFree(d_output);      return 0; }   "
    },
    {
        "id": "324",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void castImageToGrayScale(unsigned char *ucharImage, unsigned char *grayImage, int imageWidth, int imageHeight, int channels) {     int w, h;     for (w = 0; w < imageWidth; w++) {         for (h = 0; h < imageHeight; h++) {             int idx = imageWidth * h + w;             unsigned char r = ucharImage[idx * channels];             unsigned char g = ucharImage[idx * channels + 1];             unsigned char b = ucharImage[idx * channels + 2];             grayImage[idx] = (unsigned char)(0.21f * r + 0.71f * g + 0.07f * b);         }     } }  int main() {          int imageWidth = 5;     int imageHeight = 5;     int channels = 3;            unsigned char *ucharImage = (unsigned char *)malloc(imageWidth * imageHeight * channels * sizeof(unsigned char));     unsigned char *grayImage = (unsigned char *)malloc(imageWidth * imageHeight * sizeof(unsigned char));           for (int i = 0; i < imageWidth * imageHeight * channels; i++) {         ucharImage[i] = rand() % 256;      }           castImageToGrayScale(ucharImage, grayImage, imageWidth, imageHeight, channels);           printf(\"Original Image:\\n\");     for (int i = 0; i < imageHeight; i++) {         for (int j = 0; j < imageWidth; j++) {             printf(\"(%3u, %3u, %3u)\\t\", ucharImage[(imageWidth * i + j) * channels], ucharImage[(imageWidth * i + j) * channels + 1], ucharImage[(imageWidth * i + j) * channels + 2]);         }         printf(\"\\n\");     }      printf(\"\\nGray Image:\\n\");     for (int i = 0; i < imageHeight; i++) {         for (int j = 0; j < imageWidth; j++) {             printf(\"%3u\\t\", grayImage[imageWidth * i + j]);         }         printf(\"\\n\");     }           free(ucharImage);     free(grayImage);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void castImageToGrayScale(unsigned char *ucharImage, unsigned char *grayImage, int imageWidth, int imageHeight, int channels) {     int w = threadIdx.x + blockDim.x * blockIdx.x;     int h = threadIdx.y + blockDim.y * blockIdx.y;     int idx = imageWidth * h + w;      if (w < imageWidth && h < imageHeight) {         unsigned char r = ucharImage[idx * channels];         unsigned char g = ucharImage[idx * channels + 1];         unsigned char b = ucharImage[idx * channels + 2];          grayImage[idx] = (unsigned char)(0.21f * r + 0.71f * g + 0.07f * b);     } }  int main() {          int imageWidth = 512;        int imageHeight = 512;       int channels = 3;                  unsigned char *h_ucharImage, *h_grayImage;     h_ucharImage = (unsigned char *)malloc(imageWidth * imageHeight * channels * sizeof(unsigned char));     h_grayImage = (unsigned char *)malloc(imageWidth * imageHeight * sizeof(unsigned char));           for (int i = 0; i < imageWidth * imageHeight * channels; i++) {         h_ucharImage[i] = (unsigned char)(i % 256);       }           unsigned char *d_ucharImage, *d_grayImage;     cudaMalloc((void **)&d_ucharImage, imageWidth * imageHeight * channels * sizeof(unsigned char));     cudaMalloc((void **)&d_grayImage, imageWidth * imageHeight * sizeof(unsigned char));           cudaMemcpy(d_ucharImage, h_ucharImage, imageWidth * imageHeight * channels * sizeof(unsigned char), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);       dim3 gridSize((imageWidth + blockSize.x - 1) / blockSize.x, (imageHeight + blockSize.y - 1) / blockSize.y);           castImageToGrayScale<<<gridSize, blockSize>>>(d_ucharImage, d_grayImage, imageWidth, imageHeight, channels);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaMemcpy(h_grayImage, d_grayImage, imageWidth * imageHeight * sizeof(unsigned char), cudaMemcpyDeviceToHost);           printf(\"Gray Image:\\n\");     for (int i = 0; i < imageHeight; i++) {         for (int j = 0; j < imageWidth; j++) {             printf(\"%u \", h_grayImage[i * imageWidth + j]);         }         printf(\"\\n\");     }           free(h_ucharImage);     free(h_grayImage);     cudaFree(d_ucharImage);     cudaFree(d_grayImage);      return 0; }   "
    },
    {
        "id": "325",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void CPU_array_rowKernel(double *input, double *output, int length) {     int xCuda, yCuda;     for (xCuda = 0; xCuda < length; xCuda++) {         for (yCuda = 0; yCuda < length; yCuda++) {             int idx = yCuda * length + xCuda;             if (xCuda == 0 || xCuda == length - 1) {                 output[idx] = 0;             } else {                 output[idx] = input[idx];                 output[idx] += xCuda == 0 ? 0 : input[idx - 1];                 output[idx] += xCuda == length - 1 ? 0 : input[idx + 1];             }         }     } }  int main() {          int length = 5;           double *input = (double *)malloc(length * length * sizeof(double));     double *output = (double *)malloc(length * length * sizeof(double));           for (int i = 0; i < length * length; i++) {         input[i] = rand() % 100;      }           CPU_array_rowKernel(input, output, length);           printf(\"Input Array:\\n\");     for (int i = 0; i < length; i++) {         for (int j = 0; j < length; j++) {             printf(\"%8.2f\\t\", input[length * i + j]);         }         printf(\"\\n\");     }      printf(\"\\nOutput Array:\\n\");     for (int i = 0; i < length; i++) {         for (int j = 0; j < length; j++) {             printf(\"%8.2f\\t\", output[length * i + j]);         }         printf(\"\\n\");     }           free(input);     free(output);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>   __global__ void GPU_array_rowKernel(double *input, double *output, int length) {     int xCuda = blockDim.x * blockIdx.x + threadIdx.x;     int yCuda = blockDim.y * blockIdx.y + threadIdx.y;     int idx = yCuda * length + xCuda;      if (xCuda >= length || yCuda >= length)         return;      if (xCuda == 0 || xCuda == length - 1) {         output[idx] = 0;         return;     }      output[idx] = input[idx];     output[idx] += xCuda == 0 ? 0 : input[idx - 1];     output[idx] += xCuda == length - 1 ? 0 : input[idx + 1]; }  int main() {          int length = 10;             double *h_input, *h_output;     h_input = (double *)malloc(length * length * sizeof(double));     h_output = (double *)malloc(length * length * sizeof(double));           for (int i = 0; i < length * length; i++) {         h_input[i] = i;       }           double *d_input, *d_output;     cudaMalloc((void **)&d_input, length * length * sizeof(double));     cudaMalloc((void **)&d_output, length * length * sizeof(double));           cudaMemcpy(d_input, h_input, length * length * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);       dim3 gridSize((length + blockSize.x - 1) / blockSize.x, (length + blockSize.y - 1) / blockSize.y);           GPU_array_rowKernel<<<gridSize, blockSize>>>(d_input, d_output, length);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }           cudaMemcpy(h_output, d_output, length * length * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Output Array:\\n\");     for (int i = 0; i < length; i++) {         for (int j = 0; j < length; j++) {             printf(\"%f \", h_output[i * length + j]);         }         printf(\"\\n\");     }           free(h_input);     free(h_output);     cudaFree(d_input);     cudaFree(d_output);      return 0; }   "
    },
    {
        "id": "326",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void waterElevationToDepth_cpu(const int nx_, const int ny_, float *h_ptr_, int h_pitch_, float *Bm_ptr_, int Bm_pitch_) {     for (int ti = 0; ti < nx_; ti++) {         for (int tj = 0; tj < ny_; tj++) {             float *h_row = (float *)((char *)h_ptr_ + h_pitch_ * tj);             float *Bm_row = (float *)((char *)Bm_ptr_ + Bm_pitch_ * tj);             h_row[ti] -= Bm_row[ti];         }     } }  int main() {          int nx = 5;      int ny = 5;            float *h_ptr = (float *)malloc(nx * ny * sizeof(float));     float *Bm_ptr = (float *)malloc(nx * ny * sizeof(float));           for (int i = 0; i < nx * ny; i++) {         h_ptr[i] = rand() % 100;          Bm_ptr[i] = rand() % 50;      }           waterElevationToDepth_cpu(nx, ny, h_ptr, nx, Bm_ptr, nx);           printf(\"h Array:\\n\");     for (int i = 0; i < nx; i++) {         for (int j = 0; j < ny; j++) {             printf(\"%8.2f\\t\", h_ptr[nx * i + j]);         }         printf(\"\\n\");     }      printf(\"\\nBm Array:\\n\");     for (int i = 0; i < nx; i++) {         for (int j = 0; j < ny; j++) {             printf(\"%8.2f\\t\", Bm_ptr[nx * i + j]);         }         printf(\"\\n\");     }           free(h_ptr);     free(Bm_ptr);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void waterElevationToDepth(const int nx_, const int ny_, float *h_ptr_, int h_pitch_, float *Bm_ptr_, int Bm_pitch_) {     int ti = blockIdx.x * blockDim.x + threadIdx.x;     int tj = blockIdx.y * blockDim.y + threadIdx.y;      if (ti < nx_ && tj < ny_) {         float *const h_row = (float *)((char *)h_ptr_ + h_pitch_ * tj);         float *const Bm_row = (float *)((char *)Bm_ptr_ + Bm_pitch_ * tj);         h_row[ti] -= Bm_row[ti];     } }  int main() {          const int nx = 256;       const int ny = 256;             float *h_host, *Bm_host;     size_t h_pitch, Bm_pitch;      cudaMallocPitch((void **)&h_host, &h_pitch, nx * sizeof(float), ny);     cudaMallocPitch((void **)&Bm_host, &Bm_pitch, nx * sizeof(float), ny);                      float *h_device, *Bm_device;     cudaMalloc((void **)&h_device, h_pitch * ny);     cudaMalloc((void **)&Bm_device, Bm_pitch * ny);           cudaMemcpy2D(h_device, h_pitch, h_host, h_pitch, nx * sizeof(float), ny, cudaMemcpyHostToDevice);     cudaMemcpy2D(Bm_device, Bm_pitch, Bm_host, Bm_pitch, nx * sizeof(float), ny, cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);       dim3 gridSize((nx + blockSize.x - 1) / blockSize.x, (ny + blockSize.y - 1) / blockSize.y);           waterElevationToDepth<<<gridSize, blockSize>>>(nx, ny, h_device, h_pitch / sizeof(float), Bm_device, Bm_pitch / sizeof(float));           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }                 cudaFree(h_device);     cudaFree(Bm_device);     cudaFreeHost(h_host);     cudaFreeHost(Bm_host);      return 0; }   "
    },
    {
        "id": "327",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>   float max(float a, float b) {     return a > b ? a : b; }  void softmax(float *x, int r, int c) {     float temp1, temp2;     for (int i = 0; i < r; i++) {         temp1 = 0.;         temp2 = 0.;         for (int j = 0; j < c; j++) {             temp1 = max(x[i * c + j], temp1);         }         for (int j = 0; j < c; j++) {             x[i * c + j] = expf(x[i * c + j] - temp1);             temp2 += x[i * c + j];         }         for (int j = 0; j < c; j++) {             x[i * c + j] /= temp2;         }     } }  int main() {          int r = 3;       int c = 4;             float *x = (float *)malloc(r * c * sizeof(float));           for (int i = 0; i < r * c; i++) {         x[i] = rand() % 100;       }           softmax(x, r, c);           printf(\"Softmax Result:\\n\");     for (int i = 0; i < r; i++) {         for (int j = 0; j < c; j++) {             printf(\"%8.4f\\t\", x[i * c + j]);         }         printf(\"\\n\");     }           free(x);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h> #include <math.h>  __global__ void kernel_softmax(float *x, int r, int c) {     unsigned int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i >= r)         return;      float temp1 = 0., temp2 = 0.;     for (int j = 0; j < c; j++)         temp1 = fmaxf(x[i * c + j], temp1);      for (int j = 0; j < c; j++) {         x[i * c + j] = expf(x[i * c + j] - temp1);         temp2 += x[i * c + j];     }      for (int j = 0; j < c; j++)         x[i * c + j] /= temp2; }  int main() {          const int r = 1000;       const int c = 10;               float *x_host = (float *)malloc(r * c * sizeof(float));                      float *x_device;     cudaMalloc((void **)&x_device, r * c * sizeof(float));           cudaMemcpy(x_device, x_host, r * c * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((r + blockSize.x - 1) / blockSize.x);           kernel_softmax<<<gridSize, blockSize>>>(x_device, r, c);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }                 cudaFree(x_device);     free(x_host);      return 0; }   "
    },
    {
        "id": "328",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>  void cuda_Adam_step_kernel(float *grad, float *data, float *m, float *v,                             short decay, float weight_decay,                             float beta1, float beta2,                             float eps, float step_size, int varsize) {     for (int i = 0; i < varsize; i++) {         float g = grad[i];         if (decay) g += weight_decay * data[i];         m[i] = beta1 * m[i] + (1.0 - beta1) * g;         v[i] = beta2 * v[i] + (1.0 - beta2) * g * g;         data[i] -= step_size * m[i] / (sqrt(v[i]) + eps);     } }  int main() {          int varsize = 10;             float *grad = (float *)malloc(varsize * sizeof(float));     float *data = (float *)malloc(varsize * sizeof(float));     float *m = (float *)malloc(varsize * sizeof(float));     float *v = (float *)malloc(varsize * sizeof(float));           for (int i = 0; i < varsize; i++) {         grad[i] = rand() % 100;           data[i] = rand() % 100;           m[i] = rand() % 100;             v[i] = rand() % 100;         }           short decay = 1;                 float weight_decay = 0.01;        float beta1 = 0.9;     float beta2 = 0.999;     float eps = 1e-8;     float step_size = 0.001;           cuda_Adam_step_kernel(grad, data, m, v, decay, weight_decay, beta1, beta2, eps, step_size, varsize);           printf(\"Updated Data:\\n\");     for (int i = 0; i < varsize; i++) {         printf(\"%8.4f\\t\", data[i]);     }     printf(\"\\n\");           free(grad);     free(data);     free(m);     free(v);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h> #include <math.h>  __global__ void cuda_Adam_step_kernel(float *grad, float *data, float *m, float *v, bool decay, float weight_decay, float beta1, float beta2, float eps, float step_size, int varsize) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i >= varsize)         return;      float g = grad[i];     if (decay)         g += weight_decay * data[i];      m[i] = beta1 * m[i] + (1.0 - beta1) * g;     v[i] = beta2 * v[i] + (1.0 - beta2) * g * g;     data[i] -= step_size * m[i] / (sqrtf(v[i]) + eps); }  int main() {          const int varsize = 1000;             float *grad_host = (float *)malloc(varsize * sizeof(float));     float *data_host = (float *)malloc(varsize * sizeof(float));     float *m_host = (float *)malloc(varsize * sizeof(float));     float *v_host = (float *)malloc(varsize * sizeof(float));                      float *grad_device, *data_device, *m_device, *v_device;     cudaMalloc((void **)&grad_device, varsize * sizeof(float));     cudaMalloc((void **)&data_device, varsize * sizeof(float));     cudaMalloc((void **)&m_device, varsize * sizeof(float));     cudaMalloc((void **)&v_device, varsize * sizeof(float));           cudaMemcpy(grad_device, grad_host, varsize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(data_device, data_host, varsize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(m_device, m_host, varsize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(v_device, v_host, varsize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((varsize + blockSize.x - 1) / blockSize.x);           cuda_Adam_step_kernel<<<gridSize, blockSize>>>(grad_device, data_device, m_device, v_device, true, 0.001, 0.9, 0.999, 1e-8, 0.001, varsize);           cudaDeviceSynchronize();           cudaError_t cudaErr = cudaGetLastError();     if (cudaErr != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));         return 1;     }                 cudaFree(grad_device);     cudaFree(data_device);     cudaFree(m_device);     cudaFree(v_device);     free(grad_host);     free(data_host);     free(m_host);     free(v_host);      return 0; }   "
    },
    {
        "id": "329",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <string.h>  void flatten(float *x, int size, int layers, int batch, int forward) {     float *swap = calloc(size * layers * batch, sizeof(float));     int i, c, b;     for (b = 0; b < batch; ++b) {         for (c = 0; c < layers; ++c) {             for (i = 0; i < size; ++i) {                 int i1 = b * layers * size + c * size + i;                 int i2 = b * layers * size + i * layers + c;                 if (forward)                     swap[i2] = x[i1];                 else                     swap[i1] = x[i2];             }         }     }     memcpy(x, swap, size * layers * batch * sizeof(float));     free(swap); }  int main() {          int size = 2;     int layers = 3;     int batch = 4;           float *array = (float *)malloc(size * layers * batch * sizeof(float));           for (int i = 0; i < size * layers * batch; ++i) {         array[i] = i + 1;     }           printf(\"Original Array:\\n\");     for (int b = 0; b < batch; ++b) {         for (int c = 0; c < layers; ++c) {             for (int i = 0; i < size; ++i) {                 printf(\"%8.2f \", array[b * layers * size + c * size + i]);             }             printf(\"\\n\");         }         printf(\"\\n\");     }           flatten(array, size, layers, batch, 1);           printf(\"\\nFlattened Array (Forward):\\n\");     for (int i = 0; i < size * layers * batch; ++i) {         printf(\"%8.2f \", array[i]);     }     printf(\"\\n\");           flatten(array, size, layers, batch, 0);           printf(\"\\nUnflattened Array (Backward):\\n\");     for (int b = 0; b < batch; ++b) {         for (int c = 0; c < layers; ++c) {             for (int i = 0; i < size; ++i) {                 printf(\"%8.2f \", array[b * layers * size + c * size + i]);             }             printf(\"\\n\");         }         printf(\"\\n\");     }           free(array);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void flatten_kernel(int N, float *x, int spatial, int layers, int batch, int forward, float *out) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i >= N)         return;      int in_s = i % spatial;     i = i / spatial;     int in_c = i % layers;     i = i / layers;     int b = i;      int i1 = b * layers * spatial + in_c * spatial + in_s;     int i2 = b * layers * spatial + in_s * layers + in_c;      if (forward)         out[i2] = x[i1];     else         out[i1] = x[i2]; }  int main() {          const int N = 1000;       const int spatial = 10;       const int layers = 5;       const int batch = 2;             float *x_host = (float *)malloc(N * sizeof(float));     float *out_host = (float *)malloc(N * sizeof(float));                      float *x_device, *out_device;     cudaMalloc((void **)&x_device, N * sizeof(float));     cudaMalloc((void **)&out_device, N * sizeof(float));           cudaMemcpy(x_device, x_host, N * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((N + blockSize.x - 1) / blockSize.x);           flatten_kernel<<<gridSize, blockSize>>>(N, x_device, spatial, layers, batch, 1, out_device);           cudaDeviceSynchronize();           cudaMemcpy(out_host, out_device, N * sizeof(float), cudaMemcpyDeviceToHost);                 cudaFree(x_device);     cudaFree(out_device);     free(x_host);     free(out_host);      return 0; }   "
    },
    {
        "id": "33",
        "c_code": "#include <stdio.h>  void doubleArrayScalarDivide_cpu(double *d_in, int *d_out, int length, double scalar) {     for (int idx = 0; idx < length; idx++) {         d_out[idx] = d_in[idx] / scalar;     } }  int main() {          int arraySize = 5;     double doubleArray[] = {10.0, 20.0, 30.0, 40.0, 50.0};     int resultArray[arraySize];     double scalar = 2.0;      printf(\"\u539f\u59cb\u53cc\u7cbe\u5ea6\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", doubleArray[i]);     }           doubleArrayScalarDivide_cpu(doubleArray, resultArray, arraySize, scalar);      printf(\"\\n\u9664\u6cd5\u540e\u7684\u6574\u6570\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void doubleArrayScalarDivideKernel(double* d_in, int* d_out, int length, double scalar) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = static_cast<int>(d_in[tid] / scalar);     } }  int main() {          const int arraySize = 1000;           double* h_d_in = (double*)malloc(arraySize * sizeof(double));     int* h_d_out = (int*)malloc(arraySize * sizeof(int));     const double scalar = 2.0;             for (int i = 0; i < arraySize; ++i) {         h_d_in[i] = static_cast<double>(i);     }           double* d_d_in;     int* d_d_out;     cudaMalloc((void**)&d_d_in, arraySize * sizeof(double));     cudaMalloc((void**)&d_d_out, arraySize * sizeof(int));           cudaMemcpy(d_d_in, h_d_in, arraySize * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           doubleArrayScalarDivideKernel<<<gridSize, blockSize>>>(d_d_in, d_d_out, arraySize, scalar);           cudaMemcpy(h_d_out, d_d_out, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_d_out[i]);     }           free(h_d_in);     free(h_d_out);     cudaFree(d_d_in);     cudaFree(d_d_out);      return 0; } "
    },
    {
        "id": "330",
        "c_code": "#include <stdio.h> #include <math.h>  void Softmax(float *x, const int r, const int c);  int main() {          const int rows = 3;     const int cols = 4;           float array[rows][cols] = {         {1.0, 2.0, 3.0, 4.0},         {5.0, 6.0, 7.0, 8.0},         {9.0, 10.0, 11.0, 12.0}     };           float flatArray[rows * cols];     for (int i = 0; i < rows; ++i) {         for (int j = 0; j < cols; ++j) {             flatArray[i * cols + j] = array[i][j];         }     }           Softmax(flatArray, rows, cols);           printf(\"Softmax Result:\\n\");     for (int i = 0; i < rows; ++i) {         for (int j = 0; j < cols; ++j) {             printf(\"%8.4f \", flatArray[i * cols + j]);         }         printf(\"\\n\");     }      return 0; }  void Softmax(float *x, const int r, const int c) {     float temp1, temp2;     for (int i = 0; i < r; i++) {         temp1 = 0.;         temp2 = 0.;         for (int j = 0; j < c; j++) {             temp1 = fmaxf(x[i * c + j], temp1);         }         for (int j = 0; j < c; j++) {             x[i * c + j] = expf(x[i * c + j] - temp1);             temp2 += x[i * c + j];         }         for (int j = 0; j < c; j++) {             x[i * c + j] /= temp2;         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void Kernel_Softmax(float *dev_x, const int r, const int c) {     unsigned int i = blockDim.x * blockIdx.x + threadIdx.x;     if (i >= r)         return;      float temp1 = 0., temp2 = 0.;     for (int j = 0; j < c; j++)         temp1 = fmaxf(dev_x[i * c + j], temp1);      for (int j = 0; j < c; j++) {         dev_x[i * c + j] = expf(dev_x[i * c + j] - temp1);         temp2 += dev_x[i * c + j];     }      for (int j = 0; j < c; j++)         dev_x[i * c + j] /= temp2; }  int main() {          const int r = 100;       const int c = 10;              float *dev_x_host = (float *)malloc(r * c * sizeof(float));                      float *dev_x_device;     cudaMalloc((void **)&dev_x_device, r * c * sizeof(float));           cudaMemcpy(dev_x_device, dev_x_host, r * c * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((r + blockSize.x - 1) / blockSize.x);           Kernel_Softmax<<<gridSize, blockSize>>>(dev_x_device, r, c);           cudaDeviceSynchronize();           cudaMemcpy(dev_x_host, dev_x_device, r * c * sizeof(float), cudaMemcpyDeviceToHost);                 cudaFree(dev_x_device);     free(dev_x_host);      return 0; }   "
    },
    {
        "id": "331",
        "c_code": "#include <stdio.h>  void deInterleave_cpu2(float *d_X_out, float *d_Y_out, char *d_XY_in, int pitch_out, int pitch_in, int width, int height);  int main() {          int width = 3;     int height = 2;           char input[2][3 * 2 * sizeof(float)] = {         {1.0, 2.0, 3.0, 4.0, 5.0, 6.0},         {7.0, 8.0, 9.0, 10.0, 11.0, 12.0}     };           float output_X[2][3];     float output_Y[2][3];           deInterleave_cpu2((float *)output_X, (float *)output_Y, (char *)input, sizeof(float) * 3, sizeof(char) * 2 * 3 * sizeof(float), width, height);           printf(\"Output X:\\n\");     for (int y = 0; y < height; ++y) {         for (int x = 0; x < width; ++x) {             printf(\"%8.4f \", output_X[y][x]);         }         printf(\"\\n\");     }      printf(\"\\nOutput Y:\\n\");     for (int y = 0; y < height; ++y) {         for (int x = 0; x < width; ++x) {             printf(\"%8.4f \", output_Y[y][x]);         }         printf(\"\\n\");     }      return 0; }  void deInterleave_cpu2(float *d_X_out, float *d_Y_out, char *d_XY_in, int pitch_out, int pitch_in, int width, int height) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < height; y++) {             float *data = (float *)(d_XY_in + y * pitch_in) + 2 * x;             *((float *)((char *)d_X_out + y * pitch_out) + x) = data[0];             *((float *)((char *)d_Y_out + y * pitch_out) + x) = data[1];         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void deInterleave_kernel2(float *d_X_out, float *d_Y_out, char *d_XY_in, int pitch_out, int pitch_in, int width, int height) {     unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;     unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;      if ((x < width) & (y < height)) {         float *data = (float *)(d_XY_in + y * pitch_in) + 2 * x;         *((float *)((char *)d_X_out + y * pitch_out) + x) = data[0];         *((float *)((char *)d_Y_out + y * pitch_out) + x) = data[1];     } }  int main() {          const int width = 100;       const int height = 100;            float *d_X_out_host = (float *)malloc(width * height * sizeof(float));     float *d_Y_out_host = (float *)malloc(width * height * sizeof(float));     char *d_XY_in_host = (char *)malloc(2 * width * height * sizeof(float));                       float *d_X_out_device, *d_Y_out_device;     char *d_XY_in_device;      cudaMalloc((void **)&d_X_out_device, width * height * sizeof(float));     cudaMalloc((void **)&d_Y_out_device, width * height * sizeof(float));     cudaMalloc((void **)&d_XY_in_device, 2 * width * height * sizeof(float));           cudaMemcpy(d_X_out_device, d_X_out_host, width * height * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Y_out_device, d_Y_out_host, width * height * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_XY_in_device, d_XY_in_host, 2 * width * height * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y);           deInterleave_kernel2<<<gridSize, blockSize>>>(d_X_out_device, d_Y_out_device, d_XY_in_device, 2 * width, 2 * width, width, height);           cudaDeviceSynchronize();           cudaMemcpy(d_X_out_host, d_X_out_device, width * height * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(d_Y_out_host, d_Y_out_device, width * height * sizeof(float), cudaMemcpyDeviceToHost);                 cudaFree(d_X_out_device);     cudaFree(d_Y_out_device);     cudaFree(d_XY_in_device);     free(d_X_out_host);     free(d_Y_out_host);     free(d_XY_in_host);      return 0; }   "
    },
    {
        "id": "332",
        "c_code": "#include <stdio.h>  void cpu_laplace_filter(float *Img, float *laplace, float _dz, float _dx, int npml, int nnz, int nnx);  int main() {          int npml = 2;     int nnz = 5;     int nnx = 4;           float Img[20] = {         1.0, 2.0, 3.0, 4.0,         5.0, 6.0, 7.0, 8.0,         9.0, 10.0, 11.0, 12.0,         13.0, 14.0, 15.0, 16.0,         17.0, 18.0, 19.0, 20.0     };           float laplace_result[20];           cpu_laplace_filter(Img, laplace_result, 0.1, 0.2, npml, nnz, nnx);           printf(\"Input Img:\\n\");     for (int i = 0; i < nnz; ++i) {         for (int j = 0; j < nnx; ++j) {             printf(\"%8.4f \", Img[i + j * nnz]);         }         printf(\"\\n\");     }      printf(\"\\nOutput Laplace:\\n\");     for (int i = 0; i < nnz; ++i) {         for (int j = 0; j < nnx; ++j) {             printf(\"%8.4f \", laplace_result[i + j * nnz]);         }         printf(\"\\n\");     }      return 0; }  void cpu_laplace_filter(float *Img, float *laplace, float _dz, float _dx, int npml, int nnz, int nnx) {     for (int i1 = npml; i1 < nnz - npml; i1++) {         for (int i2 = npml; i2 < nnx - npml; i2++) {             int id = i1 + i2 * nnz;             float diff1 = 0.0f;             float diff2 = 0.0f;             diff1 = Img[id + 1] - 2.0 * Img[id] + Img[id - 1];             diff2 = Img[id + nnz] - 2.0 * Img[id] + Img[id - nnz];             laplace[id] = _dz * _dz * diff1 + _dx * _dx * diff2;         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void cuda_laplace_filter(float *Img, float *laplace, float _dz, float _dx, int npml, int nnz, int nnx) {     int i1 = threadIdx.x + blockDim.x * blockIdx.x;     int i2 = threadIdx.y + blockDim.y * blockIdx.y;     int id = i1 + i2 * nnz;     float diff1 = 0.0f;     float diff2 = 0.0f;      if (i1 >= npml && i1 < nnz - npml && i2 >= npml && i2 < nnx - npml) {         diff1 = Img[id + 1] - 2.0 * Img[id] + Img[id - 1];         diff2 = Img[id + nnz] - 2.0 * Img[id] + Img[id - nnz];     }      laplace[id] = _dz * _dz * diff1 + _dx * _dx * diff2; }  int main() {          const int nnz = 100;       const int nnx = 100;       const int npml = 5;              float *Img_host = (float *)malloc(nnz * nnx * sizeof(float));     float *laplace_host = (float *)malloc(nnz * nnx * sizeof(float));                      float *Img_device, *laplace_device;      cudaMalloc((void **)&Img_device, nnz * nnx * sizeof(float));     cudaMalloc((void **)&laplace_device, nnz * nnx * sizeof(float));           cudaMemcpy(Img_device, Img_host, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(16, 16);      dim3 gridSize((nnz + blockSize.x - 1) / blockSize.x, (nnx + blockSize.y - 1) / blockSize.y);           cuda_laplace_filter<<<gridSize, blockSize>>>(Img_device, laplace_device, 1.0, 1.0, npml, nnz, nnx);           cudaDeviceSynchronize();           cudaMemcpy(laplace_host, laplace_device, nnz * nnx * sizeof(float), cudaMemcpyDeviceToHost);                 cudaFree(Img_device);     cudaFree(laplace_device);     free(Img_host);     free(laplace_host);      return 0; }   "
    },
    {
        "id": "333",
        "c_code": "#include <stdio.h>  void distanceMatFinal(long int totalPixels, int availablePixels, int outPixelOffset, float *distMat);  int main() {          long int totalPixels = 4;     int availablePixels = 3;     int outPixelOffset = 1;           float distMat[12] = {         1.0, 2.0, 3.0, 4.0,         5.0, 6.0, 7.0, 8.0,         9.0, 10.0, 11.0, 12.0     };           distanceMatFinal(totalPixels, availablePixels, outPixelOffset, distMat);           printf(\"Output distMat:\\n\");     for (long int i = 0; i < availablePixels; ++i) {         for (long int j = 0; j < totalPixels; ++j) {             printf(\"%8.4f \", distMat[i * totalPixels + j]);         }         printf(\"\\n\");     }      return 0; }  void distanceMatFinal(long int totalPixels, int availablePixels, int outPixelOffset, float *distMat) {     for (long int i = 0; i < availablePixels; i++) {         float sum = 0.0;         float max = 0.0;                   for (long int j = 0; j < totalPixels; j++) {             float element = distMat[i * totalPixels + j];             if (element > max) max = element;             sum += element;         }                   sum += max;          for (long int j = 0; j < totalPixels; j++) {             if ((i + outPixelOffset) == j)                 distMat[i * totalPixels + j] = max / sum;             else                 distMat[i * totalPixels + j] /= sum;         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void distanceMatFinal(long int totalPixels, int availablePixels, int outPixelOffset, float *distMat) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     int stride = blockDim.x * gridDim.x;      for (long int i = index; i < availablePixels; i += stride) {         float sum = 0.0;         float max = 0.0;          for (long int j = 0; j < totalPixels; j++) {             float element = distMat[i * totalPixels + j];             if (element > max) max = element;             sum += element;         }          sum += max;          for (long int j = 0; j < totalPixels; j++) {             if ((i + outPixelOffset) == j)                 distMat[i * totalPixels + j] = max / sum;             else                 distMat[i * totalPixels + j] /= sum;         }     } }  int main() {          const long int totalPixels = 100;        const int availablePixels = 50;          const int outPixelOffset = 10;                 float *distMat_host = (float *)malloc(totalPixels * availablePixels * sizeof(float));                      float *distMat_device;     cudaMalloc((void **)&distMat_device, totalPixels * availablePixels * sizeof(float));           cudaMemcpy(distMat_device, distMat_host, totalPixels * availablePixels * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((availablePixels + blockSize.x - 1) / blockSize.x);           distanceMatFinal<<<gridSize, blockSize>>>(totalPixels, availablePixels, outPixelOffset, distMat_device);           cudaDeviceSynchronize();           cudaMemcpy(distMat_host, distMat_device, totalPixels * availablePixels * sizeof(float), cudaMemcpyDeviceToHost);                 cudaFree(distMat_device);     free(distMat_host);      return 0; }   "
    },
    {
        "id": "334",
        "c_code": "#include <stdio.h>  void permuteData2_cpu(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize);  int main() {          int num = 2;     int devideNum = 3;     int featureSize = 4;     int priorNum = 2;     int batchSize = 2;           float input[48] = {                  1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8,         2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8,         3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8,                  4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8,         5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8,         6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8,     };           float output[48];           permuteData2_cpu(input, output, num, devideNum, featureSize, priorNum, batchSize);           printf(\"Output data:\\n\");     for (int s = 0; s < batchSize; ++s) {         for (int i = 0; i < priorNum; ++i) {             for (int j = 0; j < devideNum; ++j) {                 for (int tid = 0; tid < num; ++tid) {                     printf(\"%8.4f \", output[s * num * priorNum * devideNum + tid * priorNum * devideNum + i * devideNum + j]);                 }             }         }         printf(\"\\n\");     }      return 0; }  void permuteData2_cpu(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize) {     for (int tid = 0; tid < num; tid++) {         int numPerbatch = num * devideNum * priorNum;         for (int s = 0; s < batchSize; s++) {             for (int i = 0; i < priorNum; i++) {                 for (int j = 0; j < devideNum; j++) {                     output[s * numPerbatch + tid * priorNum * devideNum + i * devideNum + j] =                         input[s * numPerbatch + (i * devideNum * featureSize) + (j * featureSize) + tid];                 }             }         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void permuteData2(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= num) {         return;     }      int numPerBatch = num * devideNum * priorNum;      for (int s = 0; s < batchSize; s++) {         for (int i = 0; i < priorNum; i++) {             for (int j = 0; j < devideNum; j++) {                 output[s * numPerBatch + tid * priorNum * devideNum + i * devideNum + j] =                     input[s * numPerBatch + (i * devideNum * featureSize) + (j * featureSize) + tid];             }         }     } }  int main() {          const int num = 100;               const int devideNum = 5;           const int featureSize = 10;        const int priorNum = 3;            const int batchSize = 2;                 float *input_host = (float *)malloc(num * devideNum * priorNum * featureSize * batchSize * sizeof(float));     float *output_host = (float *)malloc(num * devideNum * priorNum * batchSize * sizeof(float));                      float *input_device, *output_device;     cudaMalloc((void **)&input_device, num * devideNum * priorNum * featureSize * batchSize * sizeof(float));     cudaMalloc((void **)&output_device, num * devideNum * priorNum * batchSize * sizeof(float));           cudaMemcpy(input_device, input_host, num * devideNum * priorNum * featureSize * batchSize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((num + blockSize.x - 1) / blockSize.x);           permuteData2<<<gridSize, blockSize>>>(input_device, output_device, num, devideNum, featureSize, priorNum, batchSize);           cudaDeviceSynchronize();           cudaMemcpy(output_host, output_device, num * devideNum * priorNum * batchSize * sizeof(float), cudaMemcpyDeviceToHost);                 cudaFree(input_device);     cudaFree(output_device);     free(input_host);     free(output_host);      return 0; }   "
    },
    {
        "id": "335",
        "c_code": "#include <stdio.h>  void permuteDataTorch_cpu(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize);  int main() {          int num = 2;     int devideNum = 3;     int featureSize = 4;     int priorNum = 2;     int batchSize = 2;           float input[48] = {                  1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8,         2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8,         3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8,                  4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8,         5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8,         6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8,     };           float output[48];           permuteDataTorch_cpu(input, output, num, devideNum, featureSize, priorNum, batchSize);           printf(\"Output data:\\n\");     for (int s = 0; s < batchSize; ++s) {         for (int i = 0; i < priorNum; ++i) {             for (int j = 0; j < devideNum; ++j) {                 for (int tid = 0; tid < num; ++tid) {                     printf(\"%8.4f \", output[s * num * priorNum * devideNum + tid * priorNum * devideNum + i * devideNum + j]);                 }             }         }         printf(\"\\n\");     }      return 0; }  void permuteDataTorch_cpu(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize) {     for (int tid = 0; tid < num; tid++) {         int numPerbatch = num * devideNum * priorNum;         for (int s = 0; s < batchSize; s++) {             for (int i = 0; i < priorNum; i++) {                 for (int j = 0; j < devideNum; j++) {                     output[s * numPerbatch + tid * priorNum * devideNum + i * devideNum + j] =                         input[s * numPerbatch + (i * devideNum * featureSize) + (j * featureSize) + tid];                 }             }         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <cuda_runtime.h>  __global__ void permuteDataTorch(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= num) {         return;     }      int numPerBatch = num * devideNum * priorNum;      for (int s = 0; s < batchSize; s++) {         for (int i = 0; i < priorNum; i++) {             for (int j = 0; j < devideNum; j++) {                 output[s * numPerBatch + tid * priorNum * devideNum + i * devideNum + j] =                     input[s * numPerBatch + (i * devideNum * featureSize) + (j * featureSize) + tid];             }         }     } }  int main() {          const int num = 100;               const int devideNum = 5;           const int featureSize = 10;        const int priorNum = 3;            const int batchSize = 2;                 float *input_host = (float *)malloc(num * devideNum * priorNum * featureSize * batchSize * sizeof(float));     float *output_host = (float *)malloc(num * devideNum * priorNum * batchSize * sizeof(float));                      float *input_device, *output_device;     cudaMalloc((void **)&input_device, num * devideNum * priorNum * featureSize * batchSize * sizeof(float));     cudaMalloc((void **)&output_device, num * devideNum * priorNum * batchSize * sizeof(float));           cudaMemcpy(input_device, input_host, num * devideNum * priorNum * featureSize * batchSize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);       dim3 gridSize((num + blockSize.x - 1) / blockSize.x);           permuteDataTorch<<<gridSize, blockSize>>>(input_device, output_device, num, devideNum, featureSize, priorNum, batchSize);           cudaDeviceSynchronize();           cudaMemcpy(output_host, output_device, num * devideNum * priorNum * batchSize * sizeof(float), cudaMemcpyDeviceToHost);                 cudaFree(input_device);     cudaFree(output_device);     free(input_host);     free(output_host);      return 0; }   "
    },
    {
        "id": "336",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void conv1x1_cpu(int input_channels, int input_size, int n, float *input_im, float *filter_weight, float *filter_bias, float *output_im) {     for (int filter_index = 0; filter_index < n; filter_index++) {         filter_weight += filter_index * input_channels;         float bias = filter_bias[filter_index];         output_im += filter_index * input_size * input_size;          for (int i = 0; i < input_size; i++) {             for (int j = 0; j < input_size; j++) {                 float tmp = bias;                 for (int k = 0; k < input_channels; k++) {                     tmp += input_im[k * input_size * input_size + i * input_size + j] * filter_weight[k];                 }                 output_im[i * input_size + j] = (tmp > 0.0) ? tmp : 0.0;             }         }     } }  int main() {          int input_channels = 3;     int input_size = 4;     int n = 2;           float input_im[input_channels * input_size * input_size];     float filter_weight[input_channels * n];     float filter_bias[n];     float output_im[input_size * input_size * n];           for (int i = 0; i < input_channels * input_size * input_size; i++) {         input_im[i] = i + 1;       }      for (int i = 0; i < input_channels * n; i++) {         filter_weight[i] = 0.5;       }      for (int i = 0; i < n; i++) {         filter_bias[i] = 0.1;       }           conv1x1_cpu(input_channels, input_size, n, input_im, filter_weight, filter_bias, output_im);           printf(\"Output Image:\\n\");     for (int i = 0; i < n; i++) {         printf(\"Channel %d:\\n\", i + 1);         for (int j = 0; j < input_size; j++) {             for (int k = 0; k < input_size; k++) {                 printf(\"%f \", output_im[i * input_size * input_size + j * input_size + k]);             }             printf(\"\\n\");         }         printf(\"\\n\");     }      return 0; }   ",
        "cuda_code": " #include <iostream>   __global__ void conv1x1(int input_channels, int input_size, int n, float *input_im, float *filter_weight, float *filter_bias, float *output_im) {     int filter_index = blockIdx.x * blockDim.x + threadIdx.x;          if (filter_index < n) {         filter_weight += filter_index * input_channels;         float bias = filter_bias[filter_index];         output_im += filter_index * input_size * input_size;          for (int i = 0; i < input_size; i++) {             for (int j = 0; j < input_size; j++) {                 float tmp = bias;                  for (int k = 0; k < input_channels; k++) {                     tmp += input_im[k * input_size * input_size + i * input_size + j] * filter_weight[k];                 }                  output_im[i * input_size + j] = (tmp > 0.0) ? tmp : 0.0;             }         }     } }  int main() {          int input_channels = 3;     int input_size = 5;     int n = 64;       int total_elements = n * input_size * input_size;           float *d_input_im, *d_filter_weight, *d_filter_bias, *d_output_im;     cudaMalloc((void**)&d_input_im, input_channels * input_size * input_size * sizeof(float));     cudaMalloc((void**)&d_filter_weight, n * input_channels * sizeof(float));     cudaMalloc((void**)&d_filter_bias, n * sizeof(float));     cudaMalloc((void**)&d_output_im, total_elements * sizeof(float));           float *h_input_im = new float[input_channels * input_size * input_size];     float *h_filter_weight = new float[n * input_channels];     float *h_filter_bias = new float[n];     float *h_output_im = new float[total_elements];           cudaMemcpy(d_input_im, h_input_im, input_channels * input_size * input_size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_filter_weight, h_filter_weight, n * input_channels * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_filter_bias, h_filter_bias, n * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((n + blockSize.x - 1) / blockSize.x);           conv1x1<<<gridSize, blockSize>>>(input_channels, input_size, n, d_input_im, d_filter_weight, d_filter_bias, d_output_im);           cudaMemcpy(h_output_im, d_output_im, total_elements * sizeof(float), cudaMemcpyDeviceToHost);           delete[] h_input_im;     delete[] h_filter_weight;     delete[] h_filter_bias;     delete[] h_output_im;      cudaFree(d_input_im);     cudaFree(d_filter_weight);     cudaFree(d_filter_bias);     cudaFree(d_output_im);      return 0; }  "
    },
    {
        "id": "337",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>  void Softmax_seg(float *x, const int size_category, const int size_spatial_feature_map) {     int c = size_category;     int size = size_spatial_feature_map;     float temp1, temp2;      for (int i = 0; i < size; i++) {         temp1 = 0.;         temp2 = 0.;          for (int j = 0; j < c; j++) {             temp1 = fmaxf(x[j * size + i], temp1);         }          for (int j = 0; j < c; j++) {             x[j * size + i] = expf(x[j * size + i] - temp1);             temp2 += x[j * size + i];         }          for (int j = 0; j < c; j++) {             x[j * size + i] /= temp2;         }     } }  int main() {          int size_category = 3;     int size_spatial_feature_map = 4;     float input[] = {1.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0};     float output[size_category * size_spatial_feature_map];      printf(\"Input:\\n\");     for (int i = 0; i < size_category * size_spatial_feature_map; i++) {         printf(\"%.2f \", input[i]);     }     printf(\"\\n\");      Softmax_seg(input, size_category, size_spatial_feature_map);      printf(\"Output:\\n\");     for (int i = 0; i < size_category * size_spatial_feature_map; i++) {         printf(\"%.4f \", input[i]);     }     printf(\"\\n\");      return 0; }   ",
        "cuda_code": "#include <iostream> #include <cmath>   __global__ void Kernel_Softmax_seg(float *dev_x, const int c, const int size) {     unsigned int i = blockDim.x * blockIdx.x + threadIdx.x;     int N = size;      while (i < N) {         float temp = 0.0;                   for (int j = 0; j < c; j++) {             temp = fmaxf(dev_x[j * size + i], temp);         }                   for (int j = 0; j < c; j++) {             dev_x[j * size + i] = expf(dev_x[j * size + i] - temp);         }                   temp = 0.0;         for (int j = 0; j < c; j++) {             temp += dev_x[j * size + i];         }                   for (int j = 0; j < c; j++) {             dev_x[j * size + i] /= temp;         }          i += gridDim.x * blockDim.x;     } }  int main() {          int c = 5;       int size = 1000;       int total_elements = c * size;           float *d_dev_x;     cudaMalloc((void**)&d_dev_x, total_elements * sizeof(float));           float *h_dev_x = new float[total_elements];           cudaMemcpy(d_dev_x, h_dev_x, total_elements * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((size + blockSize.x - 1) / blockSize.x);           Kernel_Softmax_seg<<<gridSize, blockSize>>>(d_dev_x, c, size);           cudaMemcpy(h_dev_x, d_dev_x, total_elements * sizeof(float), cudaMemcpyDeviceToHost);           delete[] h_dev_x;     cudaFree(d_dev_x);      return 0; }   "
    },
    {
        "id": "338",
        "c_code": "#include <stdio.h>  void pad_input(float *f_in, float *f_out, int H, int W, int D, int pad) {     int col, row, dep;     int new_H = H + 2 * pad;     int new_W = W + 2 * pad;      for (col = 0; col < new_H; col++) {         for (row = 0; row < new_W; row++) {             for (dep = 0; dep < D; dep++) {                 int i = dep * new_H * new_W + col * new_W + row;                 int j = dep * H * W + (col - pad) * W + (row - pad);                  if ((col < pad || col > H + pad - 1) || (row < pad || row > W + pad - 1))                     f_out[i] = 0;                 else                     f_out[i] = f_in[j];             }         }     } }  int main() {          int H = 4;     int W = 4;     int D = 2;     int pad = 1;      float input[H * W * D];     float output[(H + 2 * pad) * (W + 2 * pad) * D];           for (int i = 0; i < H * W * D; i++) {         input[i] = i + 1;       }      printf(\"Input:\\n\");     for (int i = 0; i < H * W * D; i++) {         printf(\"%.2f \", input[i]);     }     printf(\"\\n\");           pad_input(input, output, H, W, D, pad);      printf(\"Output:\\n\");     for (int i = 0; i < (H + 2 * pad) * (W + 2 * pad) * D; i++) {         printf(\"%.2f \", output[i]);     }     printf(\"\\n\");      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE 16  __global__ void pad_input(float *f_in, float *f_out, int H, int W, int D, int pad) {     int col = blockIdx.x * blockDim.x + threadIdx.x;     int row = blockIdx.y * blockDim.y + threadIdx.y;     int dep = blockIdx.z * blockDim.z + threadIdx.z;      int new_H = H + 2 * pad;     int new_W = W + 2 * pad;      int i = dep * new_H * new_W + col * new_W + row;     int j = dep * H * W + (col - pad) * W + (row - pad);      if (col < new_H && row < new_W && dep < D) {         if ((col < pad || col > H + pad - 1) || (row < pad || row > W + pad - 1)) {             f_out[i] = 0;         } else {             f_out[i] = f_in[j];         }     } }  int main() {     const int H = 128;     const int W = 128;     const int D = 64;     const int pad = 2;      float *h_input, *h_output;     float *d_input, *d_output;      size_t input_size = H * W * D * sizeof(float);     size_t output_size = (H + 2 * pad) * (W + 2 * pad) * D * sizeof(float);           h_input = (float *)malloc(input_size);     h_output = (float *)malloc(output_size);           for (int i = 0; i < H * W * D; ++i) {         h_input[i] = (float)i;     }           cudaMalloc((void **)&d_input, input_size);     cudaMalloc((void **)&d_output, output_size);           cudaMemcpy(d_input, h_input, input_size, cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE);     dim3 grid_size((H + block_size.x - 1) / block_size.x, (W + block_size.y - 1) / block_size.y, (D + block_size.z - 1) / block_size.z);           pad_input<<<grid_size, block_size>>>(d_input, d_output, H, W, D, pad);           cudaMemcpy(h_output, d_output, output_size, cudaMemcpyDeviceToHost);           cudaFree(d_input);     cudaFree(d_output);     free(h_input);     free(h_output);      return 0; }   "
    },
    {
        "id": "339",
        "c_code": "#include <stdio.h>  void waterDepthToElevation_cpu(const int nx_, const int ny_, float *w_ptr_, int w_pitch_,                                float *h_ptr_, int h_pitch_, float *Bm_ptr_, int Bm_pitch_) {     for (int ti = 0; ti < nx_; ti++) {         for (int tj = 0; tj < ny_; tj++) {             float *h_row = (float *)((char *)h_ptr_ + h_pitch_ * tj);             float *Bm_row = (float *)((char *)Bm_ptr_ + Bm_pitch_ * tj);             float *w_row = (float *)((char *)w_ptr_ + w_pitch_ * tj);             w_row[ti] = h_row[ti] + Bm_row[ti];         }     } }  int main() {          int nx = 4;     int ny = 4;      float waterDepth[nx * ny];     float elevation[nx * ny];     float bedrockElevation[nx * ny];           for (int i = 0; i < nx * ny; i++) {         waterDepth[i] = i + 1;           bedrockElevation[i] = 2 * i + 1;       }      printf(\"Water Depth:\\n\");     for (int i = 0; i < nx * ny; i++) {         printf(\"%.2f \", waterDepth[i]);     }     printf(\"\\n\");      printf(\"Bedrock Elevation:\\n\");     for (int i = 0; i < nx * ny; i++) {         printf(\"%.2f \", bedrockElevation[i]);     }     printf(\"\\n\");           waterDepthToElevation_cpu(nx, ny, waterDepth, nx, elevation, nx, bedrockElevation, nx);      printf(\"Elevation:\\n\");     for (int i = 0; i < nx * ny; i++) {         printf(\"%.2f \", elevation[i]);     }     printf(\"\\n\");      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE 16  __global__ void waterDepthToElevation(const int nx_, const int ny_, float *w_ptr_, int w_pitch_, float *h_ptr_, int h_pitch_, float *Bm_ptr_, int Bm_pitch_) {     const int ti = blockIdx.x * blockDim.x + threadIdx.x;     const int tj = blockIdx.y * blockDim.y + threadIdx.y;      if (ti < nx_ && tj < ny_) {         float *const h_row = (float *)((char *)h_ptr_ + h_pitch_ * tj);         float *const Bm_row = (float *)((char *)Bm_ptr_ + Bm_pitch_ * tj);         float *const w_row = (float *)((char *)w_ptr_ + w_pitch_ * tj);          w_row[ti] = h_row[ti] + Bm_row[ti];     } }  int main() {     const int nx = 128;     const int ny = 64;      float *h_ptr, *Bm_ptr, *w_ptr;     int h_pitch, Bm_pitch, w_pitch;      size_t h_pitch_bytes = nx * sizeof(float);     size_t Bm_pitch_bytes = nx * sizeof(float);     size_t w_pitch_bytes = nx * sizeof(float);           h_ptr = (float *)malloc(ny * h_pitch_bytes);     Bm_ptr = (float *)malloc(ny * Bm_pitch_bytes);     w_ptr = (float *)malloc(ny * w_pitch_bytes);           for (int i = 0; i < nx * ny; ++i) {         h_ptr[i] = static_cast<float>(i);         Bm_ptr[i] = static_cast<float>(i * 2);     }           cudaMallocPitch((void **)&h_ptr, &h_pitch, nx * sizeof(float), ny);     cudaMallocPitch((void **)&Bm_ptr, &Bm_pitch, nx * sizeof(float), ny);     cudaMallocPitch((void **)&w_ptr, &w_pitch, nx * sizeof(float), ny);           cudaMemcpy2D(h_ptr, h_pitch, h_ptr, h_pitch_bytes, nx * sizeof(float), ny, cudaMemcpyHostToDevice);     cudaMemcpy2D(Bm_ptr, Bm_pitch, Bm_ptr, Bm_pitch_bytes, nx * sizeof(float), ny, cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE, BLOCK_SIZE);     dim3 grid_size((nx + block_size.x - 1) / block_size.x, (ny + block_size.y - 1) / block_size.y);           waterDepthToElevation<<<grid_size, block_size>>>(nx, ny, w_ptr, w_pitch / sizeof(float), h_ptr, h_pitch / sizeof(float), Bm_ptr, Bm_pitch / sizeof(float));           cudaMemcpy2D(w_ptr, w_pitch_bytes, w_ptr, w_pitch, nx * sizeof(float), ny, cudaMemcpyDeviceToHost);           cudaFree(h_ptr);     cudaFree(Bm_ptr);     cudaFree(w_ptr);     free(h_ptr);     free(Bm_ptr);     free(w_ptr);      return 0; }   "
    },
    {
        "id": "34",
        "c_code": "#include <stdio.h>  void add(const int x, const int y, const int WIDTH, int *c, const int *a, const int *b) {     int i = y * WIDTH + x;     c[i] = a[i] + b[i]; }  int main() {          const int WIDTH = 3;     const int HEIGHT = 2;     const int arraySize = WIDTH * HEIGHT;      int arrayA[arraySize] = {1, 2, 3, 4, 5, 6};     int arrayB[arraySize] = {7, 8, 9, 10, 11, 12};     int resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", arrayB[i]);     }           add(1, 1, WIDTH, resultArray, arrayA, arrayB);      printf(\"\\n\u6570\u7ec4 C\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>   #define N 16  __global__ void addKernel(int* c, const int* a, const int* b) {     int x = threadIdx.x;     int y = threadIdx.y;     int i = y * blockDim.x + x;     c[i] = a[i] + b[i]; }  int main() {          int a[N][N], b[N][N], c[N][N];           int* d_a;     int* d_b;     int* d_c;     cudaMalloc((void**)&d_a, N * N * sizeof(int));     cudaMalloc((void**)&d_b, N * N * sizeof(int));     cudaMalloc((void**)&d_c, N * N * sizeof(int));           for (int i = 0; i < N * N; ++i) {         a[i / N][i % N] = i;         b[i / N][i % N] = 2 * i;     }           cudaMemcpy(d_a, a, N * N * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, b, N * N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(N, N);     dim3 gridSize(1, 1);           addKernel<<<gridSize, blockSize>>>(d_c, d_a, d_b);           cudaMemcpy(c, d_c, N * N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < N; ++i) {         for (int j = 0; j < N; ++j) {             printf(\"%d \", c[i][j]);         }         printf(\"\\n\");     }           cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "340",
        "c_code": "#include <stdio.h>  void invalidateFlow_cpu(float *modFlowX, float *modFlowY, const float *constFlowX,                          const float *constFlowY, int width, int height, float cons_thres) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < height; y++) {             int ind = y * width + x;             float mFX = modFlowX[ind];             float mFY = modFlowY[ind];             float cFX = constFlowX[ind];             float cFY = constFlowY[ind];             float err = (mFX - cFX) * (mFX - cFX) + (mFY - cFY) * (mFY - cFY);             if (err > cons_thres) {                 mFX = 0;                 mFY = 0;             }             modFlowX[ind] = mFX;             modFlowY[ind] = mFY;         }     } }  int main() {          int width = 4;     int height = 4;      float modFlowX[width * height];     float modFlowY[width * height];     float constFlowX[width * height];     float constFlowY[width * height];           for (int i = 0; i < width * height; i++) {         modFlowX[i] = i + 1;           modFlowY[i] = 2 * i + 1;           constFlowX[i] = 3 * i + 1;           constFlowY[i] = 4 * i + 1;       }      printf(\"Modified Flow X:\\n\");     for (int i = 0; i < width * height; i++) {         printf(\"%.2f \", modFlowX[i]);     }     printf(\"\\n\");      printf(\"Modified Flow Y:\\n\");     for (int i = 0; i < width * height; i++) {         printf(\"%.2f \", modFlowY[i]);     }     printf(\"\\n\");      printf(\"Constant Flow X:\\n\");     for (int i = 0; i < width * height; i++) {         printf(\"%.2f \", constFlowX[i]);     }     printf(\"\\n\");      printf(\"Constant Flow Y:\\n\");     for (int i = 0; i < width * height; i++) {         printf(\"%.2f \", constFlowY[i]);     }     printf(\"\\n\");           invalidateFlow_cpu(modFlowX, modFlowY, constFlowX, constFlowY, width, height, 10.0);      printf(\"Invalidated Flow X:\\n\");     for (int i = 0; i < width * height; i++) {         printf(\"%.2f \", modFlowX[i]);     }     printf(\"\\n\");      printf(\"Invalidated Flow Y:\\n\");     for (int i = 0; i < width * height; i++) {         printf(\"%.2f \", modFlowY[i]);     }     printf(\"\\n\");      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE 16  __global__ void invalidateFlow_kernel(float *modFlowX, float *modFlowY, const float *constFlowX, const float *constFlowY, int width, int height, float cons_thres) {     const int x = blockIdx.x * blockDim.x + threadIdx.x;     const int y = blockIdx.y * blockDim.y + threadIdx.y;      if (x < width && y < height) {         int ind = y * width + x;         float mFX = modFlowX[ind];         float mFY = modFlowY[ind];         float cFX = constFlowX[ind];         float cFY = constFlowY[ind];          float err = (mFX - cFX) * (mFX - cFX) + (mFY - cFY) * (mFY - cFY);          if (err > cons_thres) {             mFX = 0;             mFY = 0;         }          modFlowX[ind] = mFX;         modFlowY[ind] = mFY;     } }  int main() {     const int width = 128;     const int height = 64;     const float cons_thres = 0.1;       float *modFlowX, *modFlowY, *constFlowX, *constFlowY;      size_t flow_size = width * height * sizeof(float);           modFlowX = (float *)malloc(flow_size);     modFlowY = (float *)malloc(flow_size);     constFlowX = (float *)malloc(flow_size);     constFlowY = (float *)malloc(flow_size);           for (int i = 0; i < width * height; ++i) {         modFlowX[i] = static_cast<float>(i);         modFlowY[i] = static_cast<float>(i * 2);         constFlowX[i] = static_cast<float>(i * 3);         constFlowY[i] = static_cast<float>(i * 4);     }           float *d_modFlowX, *d_modFlowY, *d_constFlowX, *d_constFlowY;     cudaMalloc((void **)&d_modFlowX, flow_size);     cudaMalloc((void **)&d_modFlowY, flow_size);     cudaMalloc((void **)&d_constFlowX, flow_size);     cudaMalloc((void **)&d_constFlowY, flow_size);           cudaMemcpy(d_modFlowX, modFlowX, flow_size, cudaMemcpyHostToDevice);     cudaMemcpy(d_modFlowY, modFlowY, flow_size, cudaMemcpyHostToDevice);     cudaMemcpy(d_constFlowX, constFlowX, flow_size, cudaMemcpyHostToDevice);     cudaMemcpy(d_constFlowY, constFlowY, flow_size, cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE, BLOCK_SIZE);     dim3 grid_size((width + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y);           invalidateFlow_kernel<<<grid_size, block_size>>>(d_modFlowX, d_modFlowY, d_constFlowX, d_constFlowY, width, height, cons_thres);           cudaMemcpy(modFlowX, d_modFlowX, flow_size, cudaMemcpyDeviceToHost);     cudaMemcpy(modFlowY, d_modFlowY, flow_size, cudaMemcpyDeviceToHost);           cudaFree(d_modFlowX);     cudaFree(d_modFlowY);     cudaFree(d_constFlowX);     cudaFree(d_constFlowY);     free(modFlowX);     free(modFlowY);     free(constFlowX);     free(constFlowY);      return 0; }   "
    },
    {
        "id": "341",
        "c_code": "#include <stdio.h>  void cpuRunComplexFilter(float *I, float *Q, int samplesLength, float *hr, float *hi,                           int filterLength, float *filtered_I, float *filtered_Q, int convLength) {     for (int sampleIndex = 0; sampleIndex < convLength; sampleIndex++) {         int index;         float sumI, sumQ;         sumI = 0;         sumQ = 0;         for (int j = sampleIndex - filterLength + 1; j <= sampleIndex; j++) {             index = sampleIndex - j;             if ((j < samplesLength) && (j >= 0)) {                 sumI += (I[j] * hr[index]) - (Q[j] * hi[index]);                 sumQ += (I[j] * hi[index]) + (Q[j] * hr[index]);             }         }         filtered_I[sampleIndex] = sumI;         filtered_Q[sampleIndex] = sumQ;     } }  int main() {          int samplesLength = 5;     int filterLength = 3;     int convLength = samplesLength + filterLength - 1;      float I[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float Q[] = {0.1, 0.2, 0.3, 0.4, 0.5};     float hr[] = {0.5, 0.3, 0.1};     float hi[] = {0.2, 0.4, 0.6};     float filtered_I[convLength];     float filtered_Q[convLength];      cpuRunComplexFilter(I, Q, samplesLength, hr, hi, filterLength, filtered_I, filtered_Q, convLength);      printf(\"Filtered I:\\n\");     for (int i = 0; i < convLength; i++) {         printf(\"%.2f \", filtered_I[i]);     }     printf(\"\\n\");      printf(\"Filtered Q:\\n\");     for (int i = 0; i < convLength; i++) {         printf(\"%.2f \", filtered_Q[i]);     }     printf(\"\\n\");      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE 256  __global__ void cudaRunComplexFilter(float *I, float *Q, int samplesLength, float *hr, float *hi, int filterLength, float *filtered_I, float *filtered_Q, int convLength) {     int sampleIndex = (blockIdx.x * blockDim.x) + threadIdx.x;      if (sampleIndex >= convLength)         return;      int index;     float sumI, sumQ;      sumI = 0;     sumQ = 0;      for (int j = sampleIndex - filterLength + 1; j <= sampleIndex; j++) {         index = sampleIndex - j;          if ((j < samplesLength) && (j >= 0)) {             sumI += (I[j] * hr[index]) - (Q[j] * hi[index]);             sumQ += (I[j] * hi[index]) + (Q[j] * hr[index]);         }     }      filtered_I[sampleIndex] = sumI;     filtered_Q[sampleIndex] = sumQ; }  int main() {     const int samplesLength = 1024;     const int filterLength = 64;     const int convLength = samplesLength - filterLength + 1;      float *I, *Q, *hr, *hi, *filtered_I, *filtered_Q;           I = (float *)malloc(samplesLength * sizeof(float));     Q = (float *)malloc(samplesLength * sizeof(float));     hr = (float *)malloc(filterLength * sizeof(float));     hi = (float *)malloc(filterLength * sizeof(float));     filtered_I = (float *)malloc(convLength * sizeof(float));     filtered_Q = (float *)malloc(convLength * sizeof(float));           for (int i = 0; i < samplesLength; ++i) {         I[i] = static_cast<float>(i);         Q[i] = static_cast<float>(i * 2);     }      for (int i = 0; i < filterLength; ++i) {         hr[i] = static_cast<float>(i);         hi[i] = static_cast<float>(i * 2);     }           float *d_I, *d_Q, *d_hr, *d_hi, *d_filtered_I, *d_filtered_Q;     cudaMalloc((void **)&d_I, samplesLength * sizeof(float));     cudaMalloc((void **)&d_Q, samplesLength * sizeof(float));     cudaMalloc((void **)&d_hr, filterLength * sizeof(float));     cudaMalloc((void **)&d_hi, filterLength * sizeof(float));     cudaMalloc((void **)&d_filtered_I, convLength * sizeof(float));     cudaMalloc((void **)&d_filtered_Q, convLength * sizeof(float));           cudaMemcpy(d_I, I, samplesLength * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Q, Q, samplesLength * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_hr, hr, filterLength * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_hi, hi, filterLength * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE);     dim3 grid_size((convLength + block_size.x - 1) / block_size.x);           cudaRunComplexFilter<<<grid_size, block_size>>>(d_I, d_Q, samplesLength, d_hr, d_hi, filterLength, d_filtered_I, d_filtered_Q, convLength);           cudaMemcpy(filtered_I, d_filtered_I, convLength * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(filtered_Q, d_filtered_Q, convLength * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_I);     cudaFree(d_Q);     cudaFree(d_hr);     cudaFree(d_hi);     cudaFree(d_filtered_I);     cudaFree(d_filtered_Q);     free(I);     free(Q);     free(hr);     free(hi);     free(filtered_I);     free(filtered_Q);      return 0; }   "
    },
    {
        "id": "342",
        "c_code": "#include <stdio.h>  void opL21_cpu(float *vec, float *vec1, long depth, long rows, long cols) {     for (int x = 0; x < cols; x++) {         for (int y = 0; y < rows; y++) {             for (int z = 0; z < depth; z++) {                 unsigned long long i = z * rows * cols + y * cols + x;                 unsigned long long j = z * rows * cols + x;                 unsigned long size2d = cols;                 unsigned long size3d = depth * rows * cols + rows * cols + cols;                 if (i + cols + 1 >= size3d || j + 1 >= size2d) {                     return;                 }                 vec[i + cols] = 0.25 * (vec1[i + 1] + vec1[i] + vec1[i + cols + 1] + vec1[i + cols]);                 vec[j] = (vec1[j] + vec1[j + 1]) / 4;             }         }     } }  int main() {          long depth = 3;     long rows = 4;     long cols = 5;      float vec1[depth * rows * cols];     float vec[depth * rows * cols];           for (long i = 0; i < depth * rows * cols; i++) {         vec1[i] = i + 1;     }      opL21_cpu(vec, vec1, depth, rows, cols);           printf(\"Output vec:\\n\");     for (long i = 0; i < depth * rows * cols; i++) {         printf(\"%.2f \", vec[i]);     }     printf(\"\\n\");      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE_X 16 #define BLOCK_SIZE_Y 16 #define BLOCK_SIZE_Z 4  __global__ void opL21(float *vec, float *vec1, long depth, long rows, long cols) {     unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;     unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;     unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;     unsigned long long i = z * rows * cols + y * cols + x;     unsigned long long j = z * rows * cols + x;     unsigned long size2d = cols;     unsigned long size3d = depth * rows * cols + rows * cols + cols;      if (x >= cols || y >= rows || z >= depth)         return;      if (i + cols + 1 >= size3d)         return;      vec[i + cols] = 0.25 * (vec1[i + 1] + vec1[i] + vec1[i + cols + 1] + vec1[i + cols]);      if (j + 1 >= size2d)         return;      vec[j] = (vec1[j] + vec1[j + 1]) / 4; }  int main() {     const long depth = 64;     const long rows = 128;     const long cols = 64;      float *vec, *vec1;      size_t size3d = depth * rows * cols * sizeof(float);     size_t size2d = rows * cols * sizeof(float);           vec = (float *)malloc(size3d);     vec1 = (float *)malloc(size3d);           for (long i = 0; i < depth * rows * cols; ++i) {         vec[i] = static_cast<float>(i);         vec1[i] = static_cast<float>(i * 2);     }           float *d_vec, *d_vec1;     cudaMalloc((void **)&d_vec, size3d);     cudaMalloc((void **)&d_vec1, size3d);           cudaMemcpy(d_vec, vec, size3d, cudaMemcpyHostToDevice);     cudaMemcpy(d_vec1, vec1, size3d, cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE_X, BLOCK_SIZE_Y, BLOCK_SIZE_Z);     dim3 grid_size((cols + block_size.x - 1) / block_size.x, (rows + block_size.y - 1) / block_size.y, (depth + block_size.z - 1) / block_size.z);           opL21<<<grid_size, block_size>>>(d_vec, d_vec1, depth, rows, cols);           cudaMemcpy(vec, d_vec, size3d, cudaMemcpyDeviceToHost);           cudaFree(d_vec);     cudaFree(d_vec1);     free(vec);     free(vec1);      return 0; }   "
    },
    {
        "id": "343",
        "c_code": "#include <stdio.h>  void reorg_cpu(float *x, int w, int h, int c, int batch, int stride, int forward, float *out) {     int b, i, j, k;     int out_c = c / (stride * stride);      for (b = 0; b < batch; ++b) {         for (k = 0; k < c; ++k) {             for (j = 0; j < h; ++j) {                 for (i = 0; i < w; ++i) {                     int in_index = i + w * (j + h * (k + c * b));                     int c2 = k % out_c;                     int offset = k / out_c;                     int w2 = i * stride + offset % stride;                     int h2 = j * stride + offset / stride;                     int out_index = w2 + w * stride * (h2 + h * stride * (c2 + out_c * b));                      if (forward)                         out[out_index] = x[in_index];                     else                         out[in_index] = x[out_index];                 }             }         }     } }  int main() {          int w = 4;     int h = 4;     int c = 3;     int batch = 2;     int stride = 2;      float x[w * h * c * batch];     float out[w * h * c * batch];           for (int i = 0; i < w * h * c * batch; i++) {         x[i] = i + 1;     }      reorg_cpu(x, w, h, c, batch, stride, 1, out);             printf(\"Output (Forward Pass):\\n\");     for (int i = 0; i < w * h * c * batch; i++) {         printf(\"%.2f \", out[i]);     }     printf(\"\\n\");      reorg_cpu(x, w, h, c, batch, stride, 0, out);             printf(\"Output (Backward Pass):\\n\");     for (int i = 0; i < w * h * c * batch; i++) {         printf(\"%.2f \", out[i]);     }     printf(\"\\n\");      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE 256  __global__ void reorg_kernel(int N, float *x, int w, int h, int c, int batch, int stride, int forward, float *out) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i >= N)         return;      int in_index = i;     int in_w = i % w;     i = i / w;     int in_h = i % h;     i = i / h;     int in_c = i % c;     i = i / c;     int b = i % batch;      int out_c = c / (stride * stride);     int c2 = in_c % out_c;     int offset = in_c / out_c;     int w2 = in_w * stride + offset % stride;     int h2 = in_h * stride + offset / stride;      int out_index = w2 + w * stride * (h2 + h * stride * (c2 + out_c * b));      if (forward)         out[out_index] = x[in_index];     else         out[in_index] = x[out_index]; }  int main() {     const int N = 1024;      const int w = 64;        const int h = 64;        const int c = 3;         const int batch = 4;      const int stride = 2;       float *x, *out;      size_t size = N * sizeof(float);           x = (float *)malloc(size);     out = (float *)malloc(size);           for (int i = 0; i < N; ++i) {         x[i] = static_cast<float>(i);     }           float *d_x, *d_out;     cudaMalloc((void **)&d_x, size);     cudaMalloc((void **)&d_out, size);           cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE);     dim3 grid_size((N + block_size.x - 1) / block_size.x);           reorg_kernel<<<grid_size, block_size>>>(N, d_x, w, h, c, batch, stride, 1, d_out);            cudaMemcpy(out, d_out, size, cudaMemcpyDeviceToHost);           cudaFree(d_x);     cudaFree(d_out);     free(x);     free(out);      return 0; }   "
    },
    {
        "id": "344",
        "c_code": "#include <stdio.h>  long int maxValExtractArray(float *normM_aux, long int *b_pos, long int b_pos_size) {     float max_val = -1;     long int pos = -1;      for (long int i = 0; i < b_pos_size; i++) {         if (normM_aux[b_pos[i]] > max_val) {             max_val = normM_aux[b_pos[i]];             pos = i;         }     }      return pos; }  int main() {          long int b_pos_size = 5;     float normM_aux[] = {1.2, 3.5, 2.8, 5.1, 4.2};     long int b_pos[] = {2, 0, 4, 1, 3};      long int result = maxValExtractArray(normM_aux, b_pos, b_pos_size);           printf(\"Position of maximum value: %ld\\n\", result);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE 1024  __global__ void maxValExtract(float *normM_c, float *normM1_c, long int image_size, float *d_projections, int *d_index, float a) {     __shared__ int pos[BLOCK_SIZE * 2];     __shared__ float val[BLOCK_SIZE * 2];      unsigned int tid = threadIdx.x;     unsigned int id = blockIdx.x * 2 * blockDim.x + threadIdx.x;      float faux, faux2;     faux = ((a - normM_c[id]) / a);     faux2 = ((a - normM_c[id + blockDim.x]) / a);      if (id < image_size && faux <= 1.0e-6) {         val[tid] = normM1_c[id];         pos[tid] = id;     } else {         val[tid] = -1;     }      if (id + blockDim.x < image_size && faux2 <= 1.0e-6) {         val[tid + blockDim.x] = normM1_c[id + blockDim.x];         pos[tid + blockDim.x] = id + blockDim.x;     } else {         val[tid + blockDim.x] = -1;     }      __syncthreads();      for (unsigned int s = blockDim.x; s > 0; s >>= 1) {         if (tid < s) {             if (val[tid] <= val[tid + s]) {                 val[tid] = val[tid + s];                 pos[tid] = pos[tid + s];             }         }          __syncthreads();     }      if (tid == 0) {         d_projections[blockIdx.x] = val[0];         d_index[blockIdx.x] = (int)pos[0];     }      __syncthreads(); }  int main() {     const long int image_size = 1024;      const float a = 1.0;       float *normM_c, *normM1_c, *d_projections;     int *d_index;      size_t size = image_size * sizeof(float);           normM_c = (float *)malloc(size * 2);      normM1_c = (float *)malloc(size);     d_projections = (float *)malloc((image_size / BLOCK_SIZE) * sizeof(float));     d_index = (int *)malloc((image_size / BLOCK_SIZE) * sizeof(int));           for (long int i = 0; i < size * 2; ++i) {         normM_c[i] = static_cast<float>(i);     }      for (long int i = 0; i < size; ++i) {         normM1_c[i] = static_cast<float>(i * 2);     }           float *d_normM_c, *d_normM1_c;     int *d_d_index;     cudaMalloc((void **)&d_normM_c, size * 2);     cudaMalloc((void **)&d_normM1_c, size);     cudaMalloc((void **)&d_d_index, (image_size / BLOCK_SIZE) * sizeof(int));           cudaMemcpy(d_normM_c, normM_c, size * 2, cudaMemcpyHostToDevice);     cudaMemcpy(d_normM1_c, normM1_c, size, cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE);     dim3 grid_size((image_size / BLOCK_SIZE + 1), 1);           maxValExtract<<<grid_size, block_size>>>(d_normM_c, d_normM1_c, image_size, d_projections, d_index, a);           cudaMemcpy(d_projections, d_projections, (image_size / BLOCK_SIZE) * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(d_index, d_d_index, (image_size / BLOCK_SIZE) * sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_normM_c);     cudaFree(d_normM1_c);     cudaFree(d_d_index);     free(normM_c);     free(normM1_c);     free(d_projections);     free(d_index);      return 0; }   "
    },
    {
        "id": "345",
        "c_code": "#include <stdio.h>  void returnResult_cpu(const float *box, const float *score, const int *label,                       float *box_out, float *score_out, int *label_out,                       float score_thr, const int dims) {     for (int tid = 0; tid < dims; tid++) {         if (score[tid] < score_thr) {             score_out[tid] = 0;             box_out[tid * 4 + 0] = -1;             box_out[tid * 4 + 1] = -1;             box_out[tid * 4 + 2] = -1;             box_out[tid * 4 + 3] = -1;             label_out[tid] = -1;         } else {             score_out[tid] = score[tid];             box_out[tid * 4 + 0] = box[tid * 4 + 0];             box_out[tid * 4 + 1] = box[tid * 4 + 1];             box_out[tid * 4 + 2] = box[tid * 4 + 2];             box_out[tid * 4 + 3] = box[tid * 4 + 3];             label_out[tid] = label[tid];         }     } }  int main() {          const int dims = 5;     float box[] = {1.0, 2.0, 3.0, 4.0, 5.0, 2.0, 3.0, 4.0, 5.0, 6.0,                    3.0, 4.0, 5.0, 6.0, 7.0, 4.0, 5.0, 6.0, 7.0, 8.0,                    5.0, 6.0, 7.0, 8.0, 9.0};     float score[] = {0.8, 0.6, 0.3, 0.9, 0.7};     int label[] = {1, 2, 3, 4, 5};     float box_out[dims * 4];     float score_out[dims];     int label_out[dims];      float score_thr = 0.5;      returnResult_cpu(box, score, label, box_out, score_out, label_out, score_thr, dims);           printf(\"Results after filtering:\\n\");     for (int i = 0; i < dims; i++) {         printf(\"Box: %.2f %.2f %.2f %.2f, Score: %.2f, Label: %d\\n\",                box_out[i * 4], box_out[i * 4 + 1], box_out[i * 4 + 2], box_out[i * 4 + 3],                score_out[i], label_out[i]);     }      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE 256  __global__ void returnResult(const float *box, const float *score, const int *label, float *box_out, float *score_out, int *label_out, float score_thr, const int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      if (score[tid] < score_thr) {         score_out[tid] = 0;         box_out[tid * 4 + 0] = -1;         box_out[tid * 4 + 1] = -1;         box_out[tid * 4 + 2] = -1;         box_out[tid * 4 + 3] = -1;         label_out[tid] = -1;     } else {         score_out[tid] = score[tid];         box_out[tid * 4 + 0] = box[tid * 4 + 0];         box_out[tid * 4 + 1] = box[tid * 4 + 1];         box_out[tid * 4 + 2] = box[tid * 4 + 2];         box_out[tid * 4 + 3] = box[tid * 4 + 3];         label_out[tid] = label[tid];     } }  int main() {     const int dims = 1024;      const float score_thr = 0.5;       float *box, *score_out, *box_out;     int *label, *label_out;      size_t size = dims * sizeof(float);           box = (float *)malloc(size * 4);     score_out = (float *)malloc(size);     box_out = (float *)malloc(size * 4);     label = (int *)malloc(size);     label_out = (int *)malloc(size);           for (int i = 0; i < dims * 4; ++i) {         box[i] = static_cast<float>(i);     }      for (int i = 0; i < dims; ++i) {         score_out[i] = static_cast<float>(i);         label[i] = i;     }           float *d_box, *d_score_out, *d_box_out;     int *d_label, *d_label_out;     cudaMalloc((void **)&d_box, size * 4);     cudaMalloc((void **)&d_score_out, size);     cudaMalloc((void **)&d_box_out, size * 4);     cudaMalloc((void **)&d_label, size);     cudaMalloc((void **)&d_label_out, size);           cudaMemcpy(d_box, box, size * 4, cudaMemcpyHostToDevice);     cudaMemcpy(d_score_out, score_out, size, cudaMemcpyHostToDevice);     cudaMemcpy(d_label, label, size, cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE);     dim3 grid_size((dims + block_size.x - 1) / block_size.x);           returnResult<<<grid_size, block_size>>>(d_box, d_score_out, d_label, d_box_out, d_score_out, d_label_out, score_thr, dims);           cudaMemcpy(score_out, d_score_out, size, cudaMemcpyDeviceToHost);     cudaMemcpy(box_out, d_box_out, size * 4, cudaMemcpyDeviceToHost);     cudaMemcpy(label_out, d_label_out, size, cudaMemcpyDeviceToHost);           cudaFree(d_box);     cudaFree(d_score_out);     cudaFree(d_box_out);     cudaFree(d_label);     cudaFree(d_label_out);     free(box);     free(score_out);     free(box_out);     free(label);     free(label_out);      return 0; }   "
    },
    {
        "id": "346",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void *RyT(float *R, float *T, float *P, float *Q, int start, int end) {     for (int i = start; i < end; i++) {         Q[0 + i * 3] = R[0 + 0 * 3] * P[0 + i * 3] + R[0 + 1 * 3] * P[1 + i * 3] +                        R[0 + 2 * 3] * P[2 + i * 3] + T[0];         Q[1 + i * 3] = R[1 + 0 * 3] * P[0 + i * 3] + R[1 + 1 * 3] * P[1 + i * 3] +                        R[1 + 2 * 3] * P[2 + i * 3] + T[1];         Q[2 + i * 3] = R[2 + 0 * 3] * P[0 + i * 3] + R[2 + 1 * 3] * P[1 + i * 3] +                        R[2 + 2 * 3] * P[2 + i * 3] + T[2];     }     return (void *)0; }  int main() {          int num_points = 3;     float R[9] = {1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0};     float T[3] = {1.0, 2.0, 3.0};     float P[9] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};     float Q[9];      RyT(R, T, P, Q, 0, num_points);           printf(\"Results after RyT function:\\n\");     for (int i = 0; i < num_points; i++) {         printf(\"Q[%d]: %.2f %.2f %.2f\\n\", i,                Q[0 + i * 3], Q[1 + i * 3], Q[2 + i * 3]);     }      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE 256  __global__ void RyT(float *R, float *T, float *P, float *Q, int num_points) {     int i = blockIdx.x * blockDim.x + threadIdx.x;      if (i < num_points) {         Q[0 + i * 3] = R[0 + 0 * 3] * P[0 + i * 3] + R[0 + 1 * 3] * P[1 + i * 3] + R[0 + 2 * 3] * P[2 + i * 3] + T[0];         Q[1 + i * 3] = R[1 + 0 * 3] * P[0 + i * 3] + R[1 + 1 * 3] * P[1 + i * 3] + R[1 + 2 * 3] * P[2 + i * 3] + T[1];         Q[2 + i * 3] = R[2 + 0 * 3] * P[0 + i * 3] + R[2 + 1 * 3] * P[1 + i * 3] + R[2 + 2 * 3] * P[2 + i * 3] + T[2];     } }  int main() {     const int num_points = 1024;       float *R, *T, *P, *Q;           R = (float *)malloc(9 * sizeof(float));     T = (float *)malloc(3 * sizeof(float));     P = (float *)malloc(3 * num_points * sizeof(float));     Q = (float *)malloc(3 * num_points * sizeof(float));           for (int i = 0; i < 9; ++i) {         R[i] = static_cast<float>(i);     }      for (int i = 0; i < 3; ++i) {         T[i] = static_cast<float>(i * 2);     }      for (int i = 0; i < 3 * num_points; ++i) {         P[i] = static_cast<float>(i * 3);     }           float *d_R, *d_T, *d_P, *d_Q;     cudaMalloc((void **)&d_R, 9 * sizeof(float));     cudaMalloc((void **)&d_T, 3 * sizeof(float));     cudaMalloc((void **)&d_P, 3 * num_points * sizeof(float));     cudaMalloc((void **)&d_Q, 3 * num_points * sizeof(float));           cudaMemcpy(d_R, R, 9 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_T, T, 3 * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_P, P, 3 * num_points * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE);     dim3 grid_size((num_points + block_size.x - 1) / block_size.x);           RyT<<<grid_size, block_size>>>(d_R, d_T, d_P, d_Q, num_points);           cudaMemcpy(Q, d_Q, 3 * num_points * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_R);     cudaFree(d_T);     cudaFree(d_P);     cudaFree(d_Q);     free(R);     free(T);     free(P);     free(Q);      return 0; }   "
    },
    {
        "id": "347",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>  void primal_descent(float *y1, float *y2, float *xbar, float sigma, int w, int h, int nc) {     for (int x = 0; x < w; x++) {         for (int y = 0; y < h; y++) {             int i;             float x1, x2, val, norm;             for (int z = 0; z < nc; z++) {                 i = x + w * y + w * h * z;                 val = xbar[i];                 x1 = (x + 1 < w) ? (xbar[(x + 1) + w * y + w * h * z] - val) : 0.f;                 x2 = (y + 1 < h) ? (xbar[x + w * (y + 1) + w * h * z] - val) : 0.f;                 x1 = y1[i] + sigma * x1;                 x2 = y2[i] + sigma * x2;                 norm = sqrtf(x1 * x1 + x2 * x2);                 y1[i] = x1 / fmax(1.f, norm);                 y2[i] = x2 / fmax(1.f, norm);             }         }     } }  int main() {          int w = 3;     int h = 3;     int nc = 2;     float sigma = 0.1;      float y1[w * h * nc];     float y2[w * h * nc];     float xbar[w * h * nc];           for (int i = 0; i < w * h * nc; i++) {         y1[i] = 1.0;         y2[i] = 2.0;         xbar[i] = 3.0;     }           primal_descent(y1, y2, xbar, sigma, w, h, nc);           printf(\"Results after primal_descent function:\\n\");     for (int i = 0; i < w * h * nc; i++) {         printf(\"y1[%d]: %.2f, y2[%d]: %.2f\\n\", i, y1[i], i, y2[i]);     }      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>  #define BLOCK_SIZE_X 16 #define BLOCK_SIZE_Y 16  __global__ void primal_descent(float *y1, float *y2, float *xbar, float sigma, int w, int h, int nc) {     int x = threadIdx.x + blockDim.x * blockIdx.x;     int y = threadIdx.y + blockDim.y * blockIdx.y;      if (x < w && y < h) {         int i;         float x1, x2, val, norm;          for (int z = 0; z < nc; z++) {             i = x + w * y + w * h * z;             val = xbar[i];              x1 = (x + 1 < w) ? (xbar[(x + 1) + w * y + w * h * z] - val) : 0.f;             x2 = (y + 1 < h) ? (xbar[x + w * (y + 1) + w * h * z] - val) : 0.f;              x1 = y1[i] + sigma * x1;             x2 = y2[i] + sigma * x2;              norm = sqrtf(x1 * x1 + x2 * x2);              y1[i] = x1 / fmax(1.f, norm);             y2[i] = x2 / fmax(1.f, norm);         }     } }  int main() {     const int w = 512;      const int h = 512;      const int nc = 3;        const float sigma = 0.01;       float *y1, *y2, *xbar;           y1 = (float *)malloc(w * h * nc * sizeof(float));     y2 = (float *)malloc(w * h * nc * sizeof(float));     xbar = (float *)malloc(w * h * nc * sizeof(float));           for (int i = 0; i < w * h * nc; ++i) {         y1[i] = static_cast<float>(i);         y2[i] = static_cast<float>(i * 2);         xbar[i] = static_cast<float>(i * 3);     }           float *d_y1, *d_y2, *d_xbar;     cudaMalloc((void **)&d_y1, w * h * nc * sizeof(float));     cudaMalloc((void **)&d_y2, w * h * nc * sizeof(float));     cudaMalloc((void **)&d_xbar, w * h * nc * sizeof(float));           cudaMemcpy(d_y1, y1, w * h * nc * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_y2, y2, w * h * nc * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_xbar, xbar, w * h * nc * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE_X, BLOCK_SIZE_Y);     dim3 grid_size((w + block_size.x - 1) / block_size.x, (h + block_size.y - 1) / block_size.y);           primal_descent<<<grid_size, block_size>>>(d_y1, d_y2, d_xbar, sigma, w, h, nc);           cudaMemcpy(y1, d_y1, w * h * nc * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(y2, d_y2, w * h * nc * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_y1);     cudaFree(d_y2);     cudaFree(d_xbar);     free(y1);     free(y2);     free(xbar);      return 0; }   "
    },
    {
        "id": "348",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>  void fractal_cpu(const int width, const int frames, unsigned char *const pic) {     for (int i = 0; i < width * width * frames; i++) {         const double Delta = 0.00304;         const double xMid = -0.055846456;         const double yMid = -0.668311119;          const int frame = i / (width * width);         double delta = Delta * pow(0.975, frame);          const int col = i % width;         const double xMin = xMid - delta;          const int row = (i / width) % width;         const double yMin = yMid - delta;          const double dw = 2.0 * delta / width;         const double cy = yMin + row * dw;         const double cx = xMin + col * dw;          double x = cx;         double y = cy;         double x2, y2;         int count = 256;          do {             x2 = x * x;             y2 = y * y;             y = 2.0 * x * y + cy;             x = x2 - y2 + cx;             count--;         } while ((count > 0) && ((x2 + y2) <= 5.0));          pic[frame * width * width + row * width + col] = (unsigned char)count;     } }  int main() {          int width = 512;     int frames = 3;     unsigned char *pic = (unsigned char *)malloc(width * width * frames * sizeof(unsigned char));           fractal_cpu(width, frames, pic);           printf(\"Results after fractal_cpu function:\\n\");     for (int i = 0; i < width * width * frames; i++) {         printf(\"%d \", pic[i]);     }      free(pic);     return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE 256  __global__ void fractal(const int width, const int frames, unsigned char *const pic) {     long i = threadIdx.x + blockIdx.x * (long)blockDim.x;      if (i >= width * width * frames) {         return;     }      const double Delta = 0.00304;     const double xMid = -0.055846456;     const double yMid = -0.668311119;      int frame = i / (width * width);     double delta = Delta * pow(0.975, frame);      int col = i % width;     double xMin = xMid - delta;     double yMin = yMid - delta;      double dw = 2.0 * delta / width;     int row = (i / width) % width;      double cy = yMin + row * dw;     double cx = xMin + col * dw;      double x = cx;     double y = cy;     double x2, y2;     int count = 256;      do {         x2 = x * x;         y2 = y * y;         y = 2.0 * x * y + cy;         x = x2 - y2 + cx;         count--;     } while ((count > 0) && ((x2 + y2) <= 5.0));      pic[frame * width * width + row * width + col] = (unsigned char)count; }  int main() {     const int width = 512;      const int frames = 30;       unsigned char *pic;           pic = (unsigned char *)malloc(width * width * frames * sizeof(unsigned char));           unsigned char *d_pic;     cudaMalloc((void **)&d_pic, width * width * frames * sizeof(unsigned char));           dim3 block_size(BLOCK_SIZE);     dim3 grid_size((width * width * frames + block_size.x - 1) / block_size.x);           fractal<<<grid_size, block_size>>>(width, frames, d_pic);           cudaMemcpy(pic, d_pic, width * width * frames * sizeof(unsigned char), cudaMemcpyDeviceToHost);           cudaFree(d_pic);     free(pic);      return 0; }   "
    },
    {
        "id": "349",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <omp.h>  #define ENDCOM  void Ring_cpu_kernel(float *A, float *BP, int *corrAB, float *M, int ring, int c, int h, int w) {     int ringSize = 2 * ring + 1;     int ringPatch = ringSize * ringSize;     int size = h * w;      #pragma omp parallel for ENDCOM     for (int y1 = 0; y1 < h; y1++) {         for (int x1 = 0; x1 < w; x1++) {             int id = y1 * w + x1;             int x2 = corrAB[2 * id + 0];             int y2 = corrAB[2 * id + 1];              for (int dx = -ring; dx <= ring; dx++) {                 for (int dy = -ring; dy <= ring; dy++) {                     int pIdx = (dy + ring) * ringSize + (dx + ring);                     int _x2 = x2 + dx, _y2 = y2 + dy;                      if (_x2 >= 0 && _x2 < w && _y2 >= 0 && _y2 < h) {                         for (int dc = 0; dc < c; dc++) {                             M[(dc * size + y1 * w) * ringPatch + pIdx * w + x1] = BP[dc * size + _y2 * w + _x2];                         }                     }                 }             }         }     }      return; }  int main() {          int ring = 1;     int c = 3;      int h = 4;      int w = 4;      int size = h * w;     int ringSize = 2 * ring + 1;     int ringPatch = ringSize * ringSize;      float *A = (float *)malloc(c * size * sizeof(float));     float *BP = (float *)malloc(c * size * sizeof(float));     int *corrAB = (int *)malloc(2 * size * sizeof(int));     float *M = (float *)malloc(c * size * ringPatch * sizeof(float));           for (int i = 0; i < c * size; i++) {         A[i] = (float)i;         BP[i] = (float)(i + c * size);     }      for (int i = 0; i < 2 * size; i++) {         corrAB[i] = i % size;     }           Ring_cpu_kernel(A, BP, corrAB, M, ring, c, h, w);           printf(\"Results after Ring_cpu_kernel function:\\n\");     for (int i = 0; i < c * size * ringPatch; i++) {         printf(\"%f \", M[i]);     }      free(A);     free(BP);     free(corrAB);     free(M);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE 256  __global__ void Ring_kernel(float *A, float *BP, int *corrAB, float *M, int ring, int c, int h, int w) {     int id1 = blockIdx.x * blockDim.x + threadIdx.x;     int size = h * w;     int ringSize = 2 * ring + 1;     int ringPatch = ringSize * ringSize;      if (id1 < size) {         int y1 = id1 / w, x1 = id1 % w;         int y2 = corrAB[2 * id1 + 1], x2 = corrAB[2 * id1 + 0];          for (int dx = -ring; dx <= ring; dx++)             for (int dy = -ring; dy <= ring; dy++) {                 int pIdx = (dy + ring) * ringSize + (dx + ring);                 int _x2 = x2 + dx, _y2 = y2 + dy;                  if (_x2 >= 0 && _x2 < w && _y2 >= 0 && _y2 < h) {                     for (int dc = 0; dc < c; dc++) {                         M[(dc * size + y1 * w) * ringPatch + pIdx * w + x1] = BP[dc * size + _y2 * w + _x2];                     }                 }             }     } }  int main() {     const int h = 512;      const int w = 512;      const int c = 3;        const int ring = 2;       float *A, *BP, *M;     int *corrAB;           A = (float *)malloc(h * w * sizeof(float));     BP = (float *)malloc(c * h * w * sizeof(float));     M = (float *)malloc(c * h * w * (2 * ring + 1) * (2 * ring + 1) * sizeof(float));     corrAB = (int *)malloc(2 * h * w * sizeof(int));           for (int i = 0; i < h * w; ++i) {         A[i] = static_cast<float>(i);         corrAB[2 * i] = i % w;         corrAB[2 * i + 1] = i / w;     }      for (int i = 0; i < c * h * w; ++i) {         BP[i] = static_cast<float>(i);     }           float *d_A, *d_BP, *d_M;     int *d_corrAB;     cudaMalloc((void **)&d_A, h * w * sizeof(float));     cudaMalloc((void **)&d_BP, c * h * w * sizeof(float));     cudaMalloc((void **)&d_M, c * h * w * (2 * ring + 1) * (2 * ring + 1) * sizeof(float));     cudaMalloc((void **)&d_corrAB, 2 * h * w * sizeof(int));           cudaMemcpy(d_A, A, h * w * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_BP, BP, c * h * w * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_corrAB, corrAB, 2 * h * w * sizeof(int), cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE);     dim3 grid_size((h * w + block_size.x - 1) / block_size.x);           Ring_kernel<<<grid_size, block_size>>>(d_A, d_BP, d_corrAB, d_M, ring, c, h, w);           cudaMemcpy(M, d_M, c * h * w * (2 * ring + 1) * (2 * ring + 1) * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_A);     cudaFree(d_BP);     cudaFree(d_M);     cudaFree(d_corrAB);     free(A);     free(BP);     free(M);     free(corrAB);      return 0; }   "
    },
    {
        "id": "35",
        "c_code": "#include <stdio.h>  void activate_array_leaky_cpu(float *x, int n) {     for (int index = 0; index < n; index++) {         float val = x[index];         x[index] = (val > 0) ? val : val / 10;     } }  int main() {          int arraySize = 5;     float inputArray[] = {2.0, -3.0, 4.0, -5.0, 6.0};      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           activate_array_leaky_cpu(inputArray, arraySize);      printf(\"\\n\u6fc0\u6d3b\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void activate_array_leaky_kernel(float* x, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     if (index < n) {         float val = x[index];         x[index] = (val > 0) ? val : val / 10;     } }  int main() {          const int arraySize = 1000;           float* h_x = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_x[i] = static_cast<float>(i - 500);       }           float* d_x;     cudaMalloc((void**)&d_x, arraySize * sizeof(float));           cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           activate_array_leaky_kernel<<<gridSize, blockSize>>>(d_x, arraySize);           cudaMemcpy(h_x, d_x, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_x[i]);     }           free(h_x);     cudaFree(d_x);      return 0; } "
    },
    {
        "id": "350",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <omp.h>  #define ENDCOM  void convolutionCPU(float *host_outputMatrix, float *host_inputMatrix, float *host_filter, int imageRows, int imageColumns, int filterSize) {     #pragma omp parallel for ENDCOM     for (int eachRowOfImage = 0; eachRowOfImage < (int)imageRows; ++eachRowOfImage) {         for (int eachColumnOfImage = 0; eachColumnOfImage < (int)imageColumns; ++eachColumnOfImage) {             float convolvedValue = 0.f;              for (int eachRowOfFilter = -filterSize / 2; eachRowOfFilter <= filterSize / 2; ++eachRowOfFilter) {                 for (int eachColumnOfFilter = -filterSize / 2; eachColumnOfFilter <= filterSize / 2; ++eachColumnOfFilter) {                     int imageRow = eachRowOfImage + eachRowOfFilter;                     int imageColumn = eachColumnOfImage + eachColumnOfFilter;                      float pixelValue = (imageRow >= 0 && imageRow < imageRows && imageColumn >= 0 && imageColumn < imageColumns)                         ? host_inputMatrix[imageRow * imageColumns + imageColumn]                         : 0.f;                      float filterValue = host_filter[(eachRowOfFilter + filterSize / 2) * filterSize + eachColumnOfFilter + filterSize / 2];                      convolvedValue += pixelValue * filterValue;                 }             }              host_outputMatrix[eachRowOfImage * imageColumns + eachColumnOfImage] = convolvedValue;         }     } }  int main() {          int imageRows = 4;     int imageColumns = 4;     int filterSize = 3;      float *host_outputMatrix = (float *)malloc(imageRows * imageColumns * sizeof(float));     float *host_inputMatrix = (float *)malloc(imageRows * imageColumns * sizeof(float));     float *host_filter = (float *)malloc(filterSize * filterSize * sizeof(float));           for (int i = 0; i < imageRows * imageColumns; i++) {         host_inputMatrix[i] = (float)i;     }      for (int i = 0; i < filterSize * filterSize; i++) {         host_filter[i] = 1.0f;     }           convolutionCPU(host_outputMatrix, host_inputMatrix, host_filter, imageRows, imageColumns, filterSize);           printf(\"Results after convolutionCPU function:\\n\");     for (int i = 0; i < imageRows * imageColumns; i++) {         printf(\"%f \", host_outputMatrix[i]);     }      free(host_outputMatrix);     free(host_inputMatrix);     free(host_filter);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE_X 16 #define BLOCK_SIZE_Y 16  __global__ void convolution_kernel_v1(float *device_outputMatrix, float *device_inputMatrix, float *device_filter, int imageRows, int imageColumns, int filterSize) {     int index_x = blockDim.x * blockIdx.x + threadIdx.x;     int index_y = blockDim.y * blockIdx.y + threadIdx.y;      float convolvedValue = 0.f;      for (int eachFilterRow = -filterSize / 2; eachFilterRow <= filterSize / 2; ++eachFilterRow) {         for (int eachFilterColumn = -filterSize / 2; eachFilterColumn <= filterSize / 2; ++eachFilterColumn) {             int imageRow = index_y + eachFilterRow;             int imageColumn = index_x + eachFilterColumn;              float pixelValue = (imageRow >= 0 && imageRow < imageRows && imageColumn >= 0 && imageColumn < imageColumns)                                    ? device_inputMatrix[imageRow * imageColumns + imageColumn]                                    : 0.f;              float filterValue = device_filter[(eachFilterRow + filterSize / 2) * filterSize + eachFilterColumn + filterSize / 2];              convolvedValue += pixelValue * filterValue;         }     }      device_outputMatrix[index_y * imageColumns + index_x] = convolvedValue; }  int main() {     const int imageRows = 512;         const int imageColumns = 512;      const int filterSize = 3;           float *device_outputMatrix, *device_inputMatrix, *device_filter;           float *host_outputMatrix = (float *)malloc(imageRows * imageColumns * sizeof(float));     float *host_inputMatrix = (float *)malloc(imageRows * imageColumns * sizeof(float));     float *host_filter = (float *)malloc(filterSize * filterSize * sizeof(float));           for (int i = 0; i < imageRows * imageColumns; ++i) {         host_inputMatrix[i] = static_cast<float>(i);     }      for (int i = 0; i < filterSize * filterSize; ++i) {         host_filter[i] = static_cast<float>(i);     }           cudaMalloc((void **)&device_outputMatrix, imageRows * imageColumns * sizeof(float));     cudaMalloc((void **)&device_inputMatrix, imageRows * imageColumns * sizeof(float));     cudaMalloc((void **)&device_filter, filterSize * filterSize * sizeof(float));           cudaMemcpy(device_inputMatrix, host_inputMatrix, imageRows * imageColumns * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(device_filter, host_filter, filterSize * filterSize * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE_X, BLOCK_SIZE_Y);     dim3 grid_size((imageColumns + block_size.x - 1) / block_size.x, (imageRows + block_size.y - 1) / block_size.y);           convolution_kernel_v1<<<grid_size, block_size>>>(device_outputMatrix, device_inputMatrix, device_filter, imageRows, imageColumns, filterSize);           cudaMemcpy(host_outputMatrix, device_outputMatrix, imageRows * imageColumns * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(device_outputMatrix);     cudaFree(device_inputMatrix);     cudaFree(device_filter);     free(host_outputMatrix);     free(host_inputMatrix);     free(host_filter);      return 0; }   "
    },
    {
        "id": "351",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void opLadj1_cpu(float *vec, float *vec1, float *vec2, float *vec3, long depth, long rows, long cols) {     for (int x = 0; x < cols; x++) {         for (int y = 0; y < rows; y++) {             for (int z = 0; z < depth; z++) {                 unsigned long long i = z * rows * cols + y * cols + x;                 unsigned long long j = z * rows * cols + x;                 unsigned long size2d = cols;                 unsigned long size3d = depth * rows * cols + rows * cols + cols;                  if (i + cols + 1 >= size3d)                     return;                  vec[i + cols] = vec1[i + cols] + 0.25 * (vec2[i + cols] + vec2[i] + vec2[i + cols + 1] + vec2[i + 1]) +                                 0.5 * (vec3[i + cols] + vec3[i + cols + 1]);                  if (j + 1 >= size2d)                     return;                  vec[j] = vec1[j] + (vec2[j] + vec2[j + 1]) / 4 + (vec3[j] + vec3[j + 1]) / 2;             }         }     } }  int main() {          long depth = 3;     long rows = 4;     long cols = 5;      float *vec = (float *)malloc(depth * rows * cols * sizeof(float));     float *vec1 = (float *)malloc(depth * rows * cols * sizeof(float));     float *vec2 = (float *)malloc(depth * rows * cols * sizeof(float));     float *vec3 = (float *)malloc(depth * rows * cols * sizeof(float));           for (int i = 0; i < depth * rows * cols; i++) {         vec[i] = (float)i;         vec1[i] = (float)i;         vec2[i] = (float)i;         vec3[i] = (float)i;     }           opLadj1_cpu(vec, vec1, vec2, vec3, depth, rows, cols);           printf(\"Results after opLadj1_cpu function:\\n\");     for (int i = 0; i < depth * rows * cols; i++) {         printf(\"%f \", vec[i]);     }      free(vec);     free(vec1);     free(vec2);     free(vec3);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE_X 16 #define BLOCK_SIZE_Y 16 #define BLOCK_SIZE_Z 4  __global__ void opLadj1(float *vec, float *vec1, float *vec2, float *vec3, long depth, long rows, long cols) {     unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;     unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;     unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;      unsigned long long i = z * rows * cols + y * cols + x;     unsigned long long j = z * rows * cols + x;      unsigned long size2d = cols;     unsigned long size3d = depth * rows * cols + rows * cols + cols;      if (x >= cols || y >= rows || z >= depth)         return;      if (i + cols + 1 >= size3d)         return;      vec[i + cols] = vec1[i + cols] + 0.25 * (vec2[i + cols] + vec2[i] + vec2[i + cols + 1] + vec2[i + 1]) + 0.5 * (vec3[i + cols] + vec3[i + cols + 1]);      if (j + 1 >= size2d)         return;      vec[j] = vec1[j] + (vec2[j] + vec2[j + 1]) / 4 + (vec3[j] + vec3[j + 1]) / 2; }  int main() {     const long depth = 32;        const long rows = 512;        const long cols = 512;         float *vec, *vec1, *vec2, *vec3;           vec = (float *)malloc(depth * rows * cols * sizeof(float));     vec1 = (float *)malloc(depth * rows * cols * sizeof(float));     vec2 = (float *)malloc(depth * rows * cols * sizeof(float));     vec3 = (float *)malloc(depth * rows * cols * sizeof(float));           for (int i = 0; i < depth * rows * cols; ++i) {         vec[i] = static_cast<float>(i);         vec1[i] = static_cast<float>(i);         vec2[i] = static_cast<float>(i);         vec3[i] = static_cast<float>(i);     }           float *d_vec, *d_vec1, *d_vec2, *d_vec3;     cudaMalloc((void **)&d_vec, depth * rows * cols * sizeof(float));     cudaMalloc((void **)&d_vec1, depth * rows * cols * sizeof(float));     cudaMalloc((void **)&d_vec2, depth * rows * cols * sizeof(float));     cudaMalloc((void **)&d_vec3, depth * rows * cols * sizeof(float));           cudaMemcpy(d_vec, vec, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec1, vec1, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec2, vec2, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec3, vec3, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE_X, BLOCK_SIZE_Y, BLOCK_SIZE_Z);     dim3 grid_size((cols + block_size.x - 1) / block_size.x, (rows + block_size.y - 1) / block_size.y, (depth + block_size.z - 1) / block_size.z);           opLadj1<<<grid_size, block_size>>>(d_vec, d_vec1, d_vec2, d_vec3, depth, rows, cols);           cudaMemcpy(vec, d_vec, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_vec);     cudaFree(d_vec1);     cudaFree(d_vec2);     cudaFree(d_vec3);     free(vec);     free(vec1);     free(vec2);     free(vec3);      return 0; }   "
    },
    {
        "id": "352",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void dual_ascent(float *xn, float *xbar, float *y1, float *y2, float *img, float tau, float lambda, float theta, int w, int h, int nc) {     for (int x = 0; x < w; x++) {         for (int y = 0; y < h; y++) {             int i;             float d1, d2, val;             for (int z = 0; z < nc; z++) {                 i = x + w * y + w * h * z;                 d1 = (x + 1 < w ? y1[i] : 0.f) - (x > 0 ? y1[(x - 1) + w * y + w * h * z] : 0.f);                 d2 = (y + 1 < h ? y2[i] : 0.f) - (y > 0 ? y2[x + w * (y - 1) + w * h * z] : 0.f);                 val = xn[i];                 xn[i] = ((val + tau * (d1 + d2)) + tau * lambda * img[i]) / (1.f + tau * lambda);                 xbar[i] = xn[i] + theta * (xn[i] - val);             }         }     } }  int main() {          int w = 3;     int h = 3;     int nc = 3;      float *xn = (float *)malloc(w * h * nc * sizeof(float));     float *xbar = (float *)malloc(w * h * nc * sizeof(float));     float *y1 = (float *)malloc(w * h * nc * sizeof(float));     float *y2 = (float *)malloc(w * h * nc * sizeof(float));     float *img = (float *)malloc(w * h * nc * sizeof(float));           for (int i = 0; i < w * h * nc; i++) {         xn[i] = (float)i;         xbar[i] = (float)i;         y1[i] = (float)i;         y2[i] = (float)i;         img[i] = (float)i;     }           float tau = 0.1;     float lambda = 0.01;     float theta = 0.05;     dual_ascent(xn, xbar, y1, y2, img, tau, lambda, theta, w, h, nc);           printf(\"Results after dual_ascent function:\\n\");     for (int i = 0; i < w * h * nc; i++) {         printf(\"%f \", xn[i]);     }      free(xn);     free(xbar);     free(y1);     free(y2);     free(img);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE_X 16 #define BLOCK_SIZE_Y 16  __global__ void dual_ascent(float *xn, float *xbar, float *y1, float *y2, float *img, float tau, float lambda, float theta, int w, int h, int nc) {     int x = threadIdx.x + blockDim.x * blockIdx.x;     int y = threadIdx.y + blockDim.y * blockIdx.y;      if (x < w && y < h) {         int i;         float d1, d2, val;          for (int z = 0; z < nc; z++) {             i = x + w * y + w * h * z;             d1 = (x + 1 < w ? y1[i] : 0.f) - (x > 0 ? y1[(x - 1) + w * y + w * h * z] : 0.f);             d2 = (y + 1 < h ? y2[i] : 0.f) - (y > 0 ? y2[x + w * (y - 1) + w * h * z] : 0.f);             val = xn[i];              xn[i] = ((val + tau * (d1 + d2)) + tau * lambda * img[i]) / (1.f + tau * lambda);             xbar[i] = xn[i] + theta * (xn[i] - val);         }     } }  int main() {     const int w = 512;         const int h = 512;         const int nc = 3;          const float tau = 0.1;      const float lambda = 0.5;      const float theta = 0.2;       float *xn, *xbar, *y1, *y2, *img;           xn = (float *)malloc(w * h * nc * sizeof(float));     xbar = (float *)malloc(w * h * nc * sizeof(float));     y1 = (float *)malloc(w * h * nc * sizeof(float));     y2 = (float *)malloc(w * h * nc * sizeof(float));     img = (float *)malloc(w * h * nc * sizeof(float));           for (int i = 0; i < w * h * nc; ++i) {         xn[i] = static_cast<float>(i);         xbar[i] = static_cast<float>(i);         y1[i] = static_cast<float>(i);         y2[i] = static_cast<float>(i);         img[i] = static_cast<float>(i);     }           float *d_xn, *d_xbar, *d_y1, *d_y2, *d_img;     cudaMalloc((void **)&d_xn, w * h * nc * sizeof(float));     cudaMalloc((void **)&d_xbar, w * h * nc * sizeof(float));     cudaMalloc((void **)&d_y1, w * h * nc * sizeof(float));     cudaMalloc((void **)&d_y2, w * h * nc * sizeof(float));     cudaMalloc((void **)&d_img, w * h * nc * sizeof(float));           cudaMemcpy(d_xn, xn, w * h * nc * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_xbar, xbar, w * h * nc * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_y1, y1, w * h * nc * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_y2, y2, w * h * nc * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_img, img, w * h * nc * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE_X, BLOCK_SIZE_Y);     dim3 grid_size((w + block_size.x - 1) / block_size.x, (h + block_size.y - 1) / block_size.y);           dual_ascent<<<grid_size, block_size>>>(d_xn, d_xbar, d_y1, d_y2, d_img, tau, lambda, theta, w, h, nc);           cudaMemcpy(xn, d_xn, w * h * nc * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_xn);     cudaFree(d_xbar);     cudaFree(d_y1);     cudaFree(d_y2);     cudaFree(d_img);     free(xn);     free(xbar);     free(y1);     free(y2);     free(img);      return 0; }   "
    },
    {
        "id": "353",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void convoluteCPU(float *dData, float *hData, int height, int width, float *mask, int masksize) {     for (int row = 0; row < height; row++) {         for (int col = 0; col < width; col++) {             int S = (masksize - 1) / 2;             float sum = 0;             int pixPos = row * width + col;             dData[pixPos] = 0.0;              for (int maskrow = -S; maskrow <= S; maskrow++) {                 for (int maskcol = -S; maskcol <= S; maskcol++) {                     int pixP = (row + maskrow) * width + (col + maskcol);                     int maskP = (maskrow + S) * masksize + (maskcol + S);                      if (pixP < height * width && pixP > 0 && maskP < masksize * masksize) {                         sum += mask[maskP] * hData[pixP];                     }                 }             }              dData[pixPos] = sum;              if (dData[pixPos] < 0) {                 dData[pixPos] = 0;             } else if (dData[pixPos] > 1) {                 dData[pixPos] = 1;             }         }     } }  int main() {          int height = 3;     int width = 3;     int masksize = 3;      float *dData = (float *)malloc(height * width * sizeof(float));     float *hData = (float *)malloc(height * width * sizeof(float));     float *mask = (float *)malloc(masksize * masksize * sizeof(float));           for (int i = 0; i < height * width; i++) {         hData[i] = (float)i;     }           for (int i = 0; i < masksize * masksize; i++) {         mask[i] = 0.1;     }           convoluteCPU(dData, hData, height, width, mask, masksize);           printf(\"Results after convoluteCPU function:\\n\");     for (int i = 0; i < height * width; i++) {         printf(\"%f \", dData[i]);     }      free(dData);     free(hData);     free(mask);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE_X 16 #define BLOCK_SIZE_Y 16  __global__ void convoluteGPU(float *dData, float *hData, int height, int width, float *mask, int masksize) {     int row = threadIdx.x + blockIdx.x * blockDim.x;     int col = threadIdx.y + blockIdx.y * blockDim.y;     int S = (masksize - 1) / 2;     float sum = 0;     int pixPos = row * width + col;      dData[pixPos] = 0.0;      if (row < height && col < width) {         for (int maskrow = -S; maskrow <= S; maskrow++) {             for (int maskcol = -S; maskcol <= S; maskcol++) {                 int pixP = (row + maskrow) * width + (col + maskcol);                 int maskP = (maskrow + S) * masksize + (maskcol + S);                  if (pixP < height * width && pixP > 0 && maskP < masksize * masksize) {                     sum += mask[maskP] * hData[pixP];                 }             }         }          dData[pixPos] = sum;          if (dData[pixPos] < 0) {             dData[pixPos] = 0;         } else if (dData[pixPos] > 1) {             dData[pixPos] = 1;         }     } }  int main() {     const int height = 512;        const int width = 512;         const int masksize = 3;         float *dData, *hData, *mask;           hData = (float *)malloc(height * width * sizeof(float));     dData = (float *)malloc(height * width * sizeof(float));     mask = (float *)malloc(masksize * masksize * sizeof(float));           for (int i = 0; i < height * width; ++i) {         hData[i] = static_cast<float>(i);     }           for (int i = 0; i < masksize * masksize; ++i) {         mask[i] = 1.0;     }           float *d_hData, *d_dData, *d_mask;     cudaMalloc((void **)&d_hData, height * width * sizeof(float));     cudaMalloc((void **)&d_dData, height * width * sizeof(float));     cudaMalloc((void **)&d_mask, masksize * masksize * sizeof(float));           cudaMemcpy(d_hData, hData, height * width * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_mask, mask, masksize * masksize * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE_X, BLOCK_SIZE_Y);     dim3 grid_size((width + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y);           convoluteGPU<<<grid_size, block_size>>>(d_dData, d_hData, height, width, d_mask, masksize);           cudaMemcpy(dData, d_dData, height * width * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_hData);     cudaFree(d_dData);     cudaFree(d_mask);     free(hData);     free(dData);     free(mask);      return 0; }   "
    },
    {
        "id": "354",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void opLadj2_cpu(float *vec, float *vec1, float *vec2, float *vec3, long depth, long rows, long cols) {     for (int x = 0; x < cols; x++) {         for (int y = 0; y < rows; y++) {             for (int z = 0; z < depth; z++) {                 unsigned long long i = z * rows * cols + y * cols + x;                 unsigned long long j = z * rows * cols + y * cols;                 unsigned long size2d = z * rows * cols + cols * rows;                 unsigned long size3d = depth * rows * cols + rows * cols + cols;                  if (i + cols + 1 >= size3d) return;                  vec[i + 1] = vec1[i + 1] + 0.25 * (vec2[i + 1] + vec2[i] + vec2[i + cols + 1] + vec2[i + cols]) + 0.5 * (vec3[i + 1] + vec3[i + cols + 1]);                  if (j + cols >= size2d) return;                  vec[j] = vec1[j] + (vec2[j] + vec2[j + cols]) / 4 + (vec3[j] + vec3[j + cols]) / 2;             }         }     } }  int main() {          int depth = 3;     int rows = 3;     int cols = 3;      float *vec = (float *)malloc(depth * rows * cols * sizeof(float));     float *vec1 = (float *)malloc(depth * rows * cols * sizeof(float));     float *vec2 = (float *)malloc(depth * rows * cols * sizeof(float));     float *vec3 = (float *)malloc(depth * rows * cols * sizeof(float));           for (int i = 0; i < depth * rows * cols; i++) {         vec1[i] = (float)i;         vec2[i] = (float)i * 2;         vec3[i] = (float)i * 3;     }           opLadj2_cpu(vec, vec1, vec2, vec3, depth, rows, cols);           printf(\"Results after opLadj2_cpu function:\\n\");     for (int i = 0; i < depth * rows * cols; i++) {         printf(\"%f \", vec[i]);     }      free(vec);     free(vec1);     free(vec2);     free(vec3);      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define BLOCK_SIZE_X 16 #define BLOCK_SIZE_Y 16 #define BLOCK_SIZE_Z 4  __global__ void opLadj2(float *vec, float *vec1, float *vec2, float *vec3, long depth, long rows, long cols) {     unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;     unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;     unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;     unsigned long long i = z * rows * cols + y * cols + x;     unsigned long long j = z * rows * cols + y * cols;     unsigned long size2d = z * rows * cols + cols * rows;     unsigned long size3d = depth * rows * cols + rows * cols + cols;      if (x >= cols || y >= rows || z >= depth) return;      if (i + cols + 1 >= size3d) return;      vec[i + 1] = vec1[i + 1] + 0.25 * (vec2[i + 1] + vec2[i] + vec2[i + cols + 1] + vec2[i + cols]) + 0.5 * (vec3[i + 1] + vec3[i + cols + 1]);      if (j + cols >= size2d) return;      vec[j] = vec1[j] + (vec2[j] + vec2[j + cols]) / 4 + (vec3[j] + vec3[j + cols]) / 2; }  int main() {     const long depth = 64;        const long rows = 512;        const long cols = 512;         float *vec, *vec1, *vec2, *vec3;           vec = (float *)malloc(depth * rows * cols * sizeof(float));     vec1 = (float *)malloc(depth * rows * cols * sizeof(float));     vec2 = (float *)malloc(depth * rows * cols * sizeof(float));     vec3 = (float *)malloc(depth * rows * cols * sizeof(float));           for (long i = 0; i < depth * rows * cols; ++i) {         vec[i] = static_cast<float>(i);         vec1[i] = static_cast<float>(i);         vec2[i] = static_cast<float>(i);         vec3[i] = static_cast<float>(i);     }           float *d_vec, *d_vec1, *d_vec2, *d_vec3;     cudaMalloc((void **)&d_vec, depth * rows * cols * sizeof(float));     cudaMalloc((void **)&d_vec1, depth * rows * cols * sizeof(float));     cudaMalloc((void **)&d_vec2, depth * rows * cols * sizeof(float));     cudaMalloc((void **)&d_vec3, depth * rows * cols * sizeof(float));           cudaMemcpy(d_vec, vec, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec1, vec1, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec2, vec2, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec3, vec3, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);           dim3 block_size(BLOCK_SIZE_X, BLOCK_SIZE_Y, BLOCK_SIZE_Z);     dim3 grid_size((cols + block_size.x - 1) / block_size.x, (rows + block_size.y - 1) / block_size.y, (depth + block_size.z - 1) / block_size.z);           opLadj2<<<grid_size, block_size>>>(d_vec, d_vec1, d_vec2, d_vec3, depth, rows, cols);           cudaMemcpy(vec, d_vec, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);           cudaFree(d_vec);     cudaFree(d_vec1);     cudaFree(d_vec2);     cudaFree(d_vec3);     free(vec);     free(vec1);     free(vec2);     free(vec3);      return 0; }   "
    },
    {
        "id": "355",
        "c_code": "#include <stdio.h> #include <stdlib.h> #include <math.h>  void CrossEntropyLoss_forward(float *logits_data, float *logits_grad, float *loss, int *truth, int training, int num_classes, int size, int grad_size) {     float total_loss = 0;     int count = 0;      for (int i = 0; i < size / num_classes; i++) {         if (truth[i] < 0) continue;          count++;         float *logit = &logits_data[i * num_classes];         float max_logit = -1e30, sum_exp = 0;          for (int j = 0; j < num_classes; j++)             max_logit = fmax(max_logit, logit[j]);          for (int j = 0; j < num_classes; j++) {             logit[j] -= max_logit;             sum_exp += expf(logit[j]);         }          total_loss += logf(sum_exp) - logit[truth[i]];          if (training) {             for (int j = 0; j < num_classes; j++) {                 float prob = expf(logit[j]) / sum_exp;                 logits_grad[i * num_classes + j] = prob;             }              logits_grad[i * num_classes + truth[i]] -= 1.0;         }     }      *loss = total_loss / count;      if (training) {         for (int i = 0; i < grad_size; i++)             logits_grad[i] /= count;     } }  int main() {          int num_classes = 3;     int size = 9;       int grad_size = num_classes * (size / num_classes);     int *truth = (int *)malloc(size / num_classes * sizeof(int));      float *logits_data = (float *)malloc(size * sizeof(float));     float *logits_grad = (float *)malloc(grad_size * sizeof(float));     float loss;           for (int i = 0; i < size / num_classes; i++) {         truth[i] = i % num_classes;     }      for (int i = 0; i < size; i++) {         logits_data[i] = i * 0.1;       }           CrossEntropyLoss_forward(logits_data, logits_grad, &loss, truth, 1, num_classes, size, grad_size);           printf(\"Loss: %f\\n\", loss);      printf(\"Gradient:\\n\");     for (int i = 0; i < grad_size; i++) {         printf(\"%f \", logits_grad[i]);     }      free(truth);     free(logits_data);     free(logits_grad);      return 0; }   ",
        "cuda_code": "#include <stdio.h>   __global__ void cuda_Cross_py_forward_A_kernel(float *logits_data, float *logits_grad, bool training, int num_classes, int *truth, int *count, float *thread_loss, int size) {     int i = blockIdx.x * blockDim.x + threadIdx.x;          if (i < size) {         if (truth[i] < 0) {             count[i] = 0;             return;         }          float *logit = &logits_data[i * num_classes];         float max_logit = -1e30, sum_exp = 0;          for (int j = 0; j < num_classes; j++)             max_logit = fmax(max_logit, logit[j]);          for (int j = 0; j < num_classes; j++) {             logit[j] -= max_logit;             sum_exp += expf(logit[j]);         }          if (training) {             for (int j = 0; j < num_classes; j++) {                 float prob = expf(logit[j]) / sum_exp;                 logits_grad[i * num_classes + j] = prob;             }             logits_grad[i * num_classes + truth[i]] -= 1.0;         }          count[i] = 1;         thread_loss[i] = logf(sum_exp) - logit[truth[i]];     } }   void launch_kernel(float *logits_data, float *logits_grad, bool training, int num_classes, int *truth, int *count, float *thread_loss, int size) {          dim3 gridSize(<<<YourGridSizeX>>>, <<<YourGridSizeY>>>);     dim3 blockSize(<<<YourBlockSizeX>>>, <<<YourBlockSizeY>>>;           cuda_Cross_py_forward_A_kernel<<<gridSize, blockSize>>>(logits_data, logits_grad, training, num_classes, truth, count, thread_loss, size);           cudaDeviceSynchronize();           cudaError_t error = cudaGetLastError();     if (error != cudaSuccess) {         fprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(error));     } }  int main() {          int size = 100;       float *logits_data, *logits_grad, *thread_loss;     int *truth, *count;           cudaMalloc((void **)&logits_data, size * sizeof(float));     cudaMalloc((void **)&logits_grad, size * sizeof(float));     cudaMalloc((void **)&truth, size * sizeof(int));     cudaMalloc((void **)&count, size * sizeof(int));     cudaMalloc((void **)&thread_loss, size * sizeof(float));                 launch_kernel(logits_data, logits_grad, true, 10, truth, count, thread_loss, size);           cudaFree(logits_data);     cudaFree(logits_grad);     cudaFree(truth);     cudaFree(count);     cudaFree(thread_loss);      return 0; }   "
    },
    {
        "id": "356",
        "c_code": "#include <stdio.h>  void insert_sort(int a[], int n) {     for (int i = 1; i < n; i++) {         int j = 0;         while ((a[j] < a[i]) && (j < i)) {             j++;         }         if (i != j) {             int temp = a[i];             for (int k = i; k > j; k--) {                 a[k] = a[k - 1];             }             a[j] = temp;         }     } }  int main() {          int n = 5;     int a[] = {5, 3, 1, 4, 2};           printf(\"Original array: \");     for (int i = 0; i < n; i++) {         printf(\"%d \", a[i]);     }     printf(\"\\n\");           insert_sort(a, n);           printf(\"Sorted array: \");     for (int i = 0; i < n; i++) {         printf(\"%d \", a[i]);     }     printf(\"\\n\");      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>   __global__ void cuInsertionSort(float *dist, long *ind, int width, int height, int k) {     int l, i, j;     float *p_dist;     long *p_ind;     float curr_dist, max_dist;     long curr_row, max_row;     unsigned int xIndex = blockIdx.x * blockDim.x + threadIdx.x;      if (xIndex < width) {         p_dist = dist + xIndex;         p_ind = ind + xIndex;         max_dist = p_dist[0];         p_ind[0] = 1;          for (l = 1; l < k; l++) {             curr_row = l * width;             curr_dist = p_dist[curr_row];              if (curr_dist < max_dist) {                 i = l - 1;                  for (int a = 0; a < l - 1; a++) {                     if (p_dist[a * width] > curr_dist) {                         i = a;                         break;                     }                 }                  for (j = l; j > i; j--) {                     p_dist[j * width] = p_dist[(j - 1) * width];                     p_ind[j * width] = p_ind[(j - 1) * width];                 }                  p_dist[i * width] = curr_dist;                 p_ind[i * width] = l + 1;             } else {                 p_ind[l * width] = l + 1;             }              max_dist = p_dist[curr_row];         }          max_row = (k - 1) * width;          for (l = k; l < height; l++) {             curr_dist = p_dist[l * width];              if (curr_dist < max_dist) {                 i = k - 1;                  for (int a = 0; a < k - 1; a++) {                     if (p_dist[a * width] > curr_dist) {                         i = a;                         break;                     }                 }                  for (j = k - 1; j > i; j--) {                     p_dist[j * width] = p_dist[(j - 1) * width];                     p_ind[j * width] = p_ind[(j - 1) * width];                 }                  p_dist[i * width] = curr_dist;                 p_ind[i * width] = l + 1;                 max_dist = p_dist[max_row];             }         }     } }   void launchKernel(float *dist, long *ind, int width, int height, int k) {     int blockSize = 256;     int numBlocks = (width + blockSize - 1) / blockSize;      cuInsertionSort<<<numBlocks, blockSize>>>(dist, ind, width, height, k);      cudaDeviceSynchronize();      cudaError_t cuda_err = cudaGetLastError();     if (cuda_err != cudaSuccess) {         fprintf(stderr, \"CUDA kernel launch error: %s\\n\", cudaGetErrorString(cuda_err));         exit(EXIT_FAILURE);     } }  int main() {     int width = 1024;     int height = 1024;     int k = 10;           float *hostDist = (float *)malloc(width * height * sizeof(float));     long *hostInd = (long *)malloc(width * height * sizeof(long));                 float *deviceDist;     long *deviceInd;      cudaMalloc((void **)&deviceDist, width * height * sizeof(float));     cudaMalloc((void **)&deviceInd, width * height * sizeof(long));           cudaMemcpy(deviceDist, hostDist, width * height * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(deviceInd, hostInd, width * height * sizeof(long), cudaMemcpyHostToDevice);           launchKernel(deviceDist, deviceInd, width, height, k);           cudaMemcpy(hostDist, deviceDist, width * height * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(hostInd, deviceInd, width * height * sizeof(long), cudaMemcpyDeviceToHost);           cudaFree(deviceDist);     cudaFree(deviceInd);           free(hostDist);     free(hostInd);      return 0; }   "
    },
    {
        "id": "357",
        "c_code": "#include <stdio.h>  void conv2_cpu(float *A, float *kernel, int inputSize, int depth, int kernelSize, int stride, int pad, float *B, int outputSize) {     for (int i = 0; i < outputSize; i++) {         for (int j = 0; j < outputSize; j++) {             int Ai = i * stride;             int Aj = j * stride;             int startk = (pad - Ai) < 0 ? 0 : pad - Ai;             int endk = kernelSize < (inputSize + pad - Ai) ? kernelSize : (inputSize + pad - Ai);             int startl = (pad - Aj) < 0 ? 0 : pad - Aj;             int endl = kernelSize < (inputSize + pad - Aj) ? kernelSize : (inputSize + pad - Aj);             float sum = 0;             for (int d = 0; d < depth; d++) {                 for (int k = startk; k < endk; k++) {                     for (int l = startl; l < endl; l++) {                         sum += A[d * inputSize * inputSize + (Ai + k - pad) * inputSize + Aj + l - pad] * kernel[d * kernelSize * kernelSize + k * kernelSize + l];                     }                 }                 B[d * outputSize * outputSize + i * outputSize + j] = sum;             }             B[i * outputSize + j] = sum;         }     } }  int main() {          int inputSize = 4;     int depth = 3;     int kernelSize = 3;     int stride = 1;     int pad = 1;     int outputSize = (inputSize - kernelSize + 2 * pad) / stride + 1;      float A[3 * 4 * 4];      float kernel[3 * 3 * 3];      float B[3 * 3 * 3];                  conv2_cpu(A, kernel, inputSize, depth, kernelSize, stride, pad, B, outputSize);           for (int d = 0; d < depth; d++) {         printf(\"Depth %d:\\n\", d);         for (int i = 0; i < outputSize; i++) {             for (int j = 0; j < outputSize; j++) {                 printf(\"%f \", B[d * outputSize * outputSize + i * outputSize + j]);             }             printf(\"\\n\");         }         printf(\"\\n\");     }      return 0; }   ",
        "cuda_code": "#include <stdio.h>  __global__ void conv2(float *A, float *kernel, int inputSize, int depth, int kernelSize, int stride, int pad, float *B, int outputSize) {     int i = threadIdx.x + blockDim.x * blockIdx.x;     int j = threadIdx.y + blockDim.y * blockIdx.y;      if (!(i < outputSize) || !(j < outputSize))         return;      int Ai = i * stride;     int Aj = j * stride;     int startk = (pad - Ai) < 0 ? 0 : pad - Ai;     int endk = kernelSize < (inputSize + pad - Ai) ? kernelSize : (inputSize + pad - Ai);     int startl = (pad - Aj) < 0 ? 0 : pad - Aj;     int endl = kernelSize < (inputSize + pad - Aj) ? kernelSize : (inputSize + pad - Aj);      for (int d = 0; d < depth; d++) {         float sum = 0;          for (int k = startk; k < endk; k++) {             for (int l = startl; l < endl; l++) {                 sum += A[d * inputSize * inputSize + (Ai + k - pad) * inputSize + Aj + l - pad] * kernel[d * kernelSize * kernelSize + k * kernelSize + l];             }         }          B[d * outputSize * outputSize + i * outputSize + j] = sum;     } }  int main() {          int inputSize = 5, depth = 3, kernelSize = 3, stride = 1, pad = 1, outputSize = (inputSize - kernelSize + 2 * pad) / stride + 1;     int A_size = depth * inputSize * inputSize;     int kernel_size = depth * kernelSize * kernelSize;     int B_size = depth * outputSize * outputSize;      float *d_A, *d_kernel, *d_B;           cudaMalloc((void **)&d_A, A_size * sizeof(float));     cudaMalloc((void **)&d_kernel, kernel_size * sizeof(float));     cudaMalloc((void **)&d_B, B_size * sizeof(float));                 dim3 gridSize(<<<YourGridSizeX>>>, <<<YourGridSizeY>>>, 1);     dim3 blockSize(<<<YourBlockSizeX>>>, <<<YourBlockSizeY>>>, 1);           conv2<<<gridSize, blockSize>>>(d_A, d_kernel, inputSize, depth, kernelSize, stride, pad, d_B, outputSize);           cudaDeviceSynchronize();           cudaFree(d_A);     cudaFree(d_kernel);     cudaFree(d_B);      return 0; }   "
    },
    {
        "id": "358",
        "c_code": "#include <stdio.h>  void get_positive_data_cpu(const float *all_box, const float *all_scores, const float *all_conf, const int *conf_inds, float *positive_box, float *positive_scores, float *positive_conf, int dims, int clsNum) {     for (int tid = 0; tid < dims; tid++) {         if (conf_inds[tid] != (-1)) {             positive_box[tid * 4 + 0] = all_box[tid * 4 + 0];             positive_box[tid * 4 + 1] = all_box[tid * 4 + 1];             positive_box[tid * 4 + 2] = all_box[tid * 4 + 2];             positive_box[tid * 4 + 3] = all_box[tid * 4 + 3];             for (int i = 0; i < clsNum; i++) {                 positive_scores[tid * clsNum + i] = all_scores[tid * clsNum + i];             }             positive_conf[tid] = all_conf[tid];         } else {             positive_box[tid * 4 + 0] = 0;             positive_box[tid * 4 + 1] = 0;             positive_box[tid * 4 + 2] = 0;             positive_box[tid * 4 + 3] = 0;             for (int i = 0; i < clsNum; i++) {                 positive_scores[tid * clsNum + i] = (-1);             }             positive_conf[tid] = (-1);         }     } }  int main() {          int dims = 5;     int clsNum = 3;      float all_box[5 * 4];      float all_scores[5 * clsNum];      float all_conf[5];     int conf_inds[5];      float positive_box[5 * 4];     float positive_scores[5 * clsNum];     float positive_conf[5];                 get_positive_data_cpu(all_box, all_scores, all_conf, conf_inds, positive_box, positive_scores, positive_conf, dims, clsNum);           for (int i = 0; i < dims; i++) {         printf(\"Example %d:\\n\", i);         printf(\"Positive Box: [%f, %f, %f, %f]\\n\", positive_box[i * 4 + 0], positive_box[i * 4 + 1], positive_box[i * 4 + 2], positive_box[i * 4 + 3]);         printf(\"Positive Scores: \");         for (int j = 0; j < clsNum; j++) {             printf(\"%f \", positive_scores[i * clsNum + j]);         }         printf(\"\\nPositive Confidence: %f\\n\", positive_conf[i]);         printf(\"\\n\");     }      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h>  #define THREADS_PER_BLOCK 256  __global__ void get_positive_data(const float *all_box, const float *all_scores, const float *all_conf,                                    const int *conf_inds, float *positive_box, float *positive_scores,                                    float *positive_conf, int dims, int clsNum) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;     if (tid >= dims) {         return;     }      if (conf_inds[tid] != (-1)) {         positive_box[tid * 4 + 0] = all_box[tid * 4 + 0];         positive_box[tid * 4 + 1] = all_box[tid * 4 + 1];         positive_box[tid * 4 + 2] = all_box[tid * 4 + 2];         positive_box[tid * 4 + 3] = all_box[tid * 4 + 3];          for (int i = 0; i < clsNum; i++) {             positive_scores[tid * clsNum + i] = all_scores[tid * clsNum + i];         }          positive_conf[tid] = all_conf[tid];     } else {         positive_box[tid * 4 + 0] = 0;         positive_box[tid * 4 + 1] = 0;         positive_box[tid * 4 + 2] = 0;         positive_box[tid * 4 + 3] = 0;          for (int i = 0; i < clsNum; i++) {             positive_scores[tid * clsNum + i] = (-1);         }          positive_conf[tid] = (-1);     } }  int main() {          int dims = 1000;     int clsNum = 5;           float *all_box_host = (float *)malloc(dims * 4 * sizeof(float));     float *all_scores_host = (float *)malloc(dims * clsNum * sizeof(float));     float *all_conf_host = (float *)malloc(dims * sizeof(float));     int *conf_inds_host = (int *)malloc(dims * sizeof(int));      float *positive_box_host = (float *)malloc(dims * 4 * sizeof(float));     float *positive_scores_host = (float *)malloc(dims * clsNum * sizeof(float));     float *positive_conf_host = (float *)malloc(dims * sizeof(float));                 float *all_box_device, *all_scores_device, *all_conf_device;     int *conf_inds_device;     float *positive_box_device, *positive_scores_device, *positive_conf_device;      cudaMalloc((void **)&all_box_device, dims * 4 * sizeof(float));     cudaMalloc((void **)&all_scores_device, dims * clsNum * sizeof(float));     cudaMalloc((void **)&all_conf_device, dims * sizeof(float));     cudaMalloc((void **)&conf_inds_device, dims * sizeof(int));      cudaMalloc((void **)&positive_box_device, dims * 4 * sizeof(float));     cudaMalloc((void **)&positive_scores_device, dims * clsNum * sizeof(float));     cudaMalloc((void **)&positive_conf_device, dims * sizeof(float));                 dim3 gridDim((dims + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, 1, 1);     dim3 blockDim(THREADS_PER_BLOCK, 1, 1);      get_positive_data<<<gridDim, blockDim>>>(all_box_device, all_scores_device, all_conf_device,                                              conf_inds_device, positive_box_device,                                              positive_scores_device, positive_conf_device, dims,                                              clsNum);                  free(all_box_host);     free(all_scores_host);     free(all_conf_host);     free(conf_inds_host);      free(positive_box_host);     free(positive_scores_host);     free(positive_conf_host);      cudaFree(all_box_device);     cudaFree(all_scores_device);     cudaFree(all_conf_device);     cudaFree(conf_inds_device);      cudaFree(positive_box_device);     cudaFree(positive_scores_device);     cudaFree(positive_conf_device);      return 0; }   "
    },
    {
        "id": "359",
        "c_code": "#include <stdio.h> #include <math.h>  void cpuChoiLee(float *xi, float *xq, float *sr, float *si, int N, float *L);  int main() {          int N = 10;     float xi[N], xq[N], sr[N], si[N], L[N];           for (int i = 0; i < N; ++i) {         xi[i] = i + 1;         xq[i] = i + 2;         sr[i] = i + 3;         si[i] = i + 4;     }           cpuChoiLee(xi, xq, sr, si, N, L);           printf(\"Results:\\n\");     for (int i = 0; i < N; ++i) {         printf(\"L[%d] = %f\\n\", i, L[i]);     }      return 0; }  void cpuChoiLee(float *xi, float *xq, float *sr, float *si, int N, float *L) {     for (int u = 0; u < N; u++) {         float uSum = 0;         float r_i, r_q, rconj_i, rconj_q;         float s_i, s_q, sconj_i, sconj_q;         float rsum_i, rsum_q, ssum_i, ssum_q;         float ksum_i, ksum_q;          for (int i = 0; i < N; i++) {             ksum_i = 0;             ksum_q = 0;              for (int k = 0; k < N - i; k++) {                 r_i = xi[u + k + i];                 r_q = xq[u + k + i];                 rconj_i = xi[u + k];                 rconj_q = xq[u + k] * (-1);                 s_i = sr[k];                 s_q = si[k];                 sconj_i = sr[k + i];                 sconj_q = si[k + i] * (-1);                 rsum_i = (r_i * rconj_i) - (r_q * rconj_q);                 rsum_q = (r_i * rconj_q) + (r_q * rconj_i);                 ssum_i = (s_i * sconj_i) - (s_q * sconj_q);                 ssum_q = (s_i * sconj_q) + (s_q * sconj_i);                 ksum_i += (rsum_i * ssum_i) - (rsum_q * ssum_q);                 ksum_q += (rsum_i * ssum_q) + (rsum_q * ssum_i);             }              uSum += sqrt((ksum_i * ksum_i) + (ksum_q * ksum_q));         }          L[u] = uSum;     } } ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <math.h> #include <cuda_runtime.h>  #define THREADS_PER_BLOCK 256  __global__ void cudaChoiLee(float *xi, float *xq, float *sr, float *si, int N, float *L) {     int u = (blockIdx.x * blockDim.x) + threadIdx.x;     if (u >= N)         return;      float uSum = 0;     float r_i, r_q, rconj_i, rconj_q;     float s_i, s_q, sconj_i, sconj_q;     float rsum_i, rsum_q, ssum_i, ssum_q;     float ksum_i, ksum_q;      for (int i = 0; i < N; i++) {         ksum_i = 0;         ksum_q = 0;          for (int k = 0; k < N - i; k++) {             r_i = xi[u + k + i];             r_q = xq[u + k + i];             rconj_i = xi[u + k];             rconj_q = xq[u + k] * (-1);              s_i = sr[k];             s_q = si[k];             sconj_i = sr[k + i];             sconj_q = si[k + i] * (-1);              rsum_i = (r_i * rconj_i) - (r_q * rconj_q);             rsum_q = (r_i * rconj_q) + (r_q * rconj_i);             ssum_i = (s_i * sconj_i) - (s_q * sconj_q);             ssum_q = (s_i * sconj_q) + (s_q * sconj_i);              ksum_i += (rsum_i * ssum_i) - (rsum_q * ssum_q);             ksum_q += (rsum_i * ssum_q) + (rsum_q * ssum_i);         }          uSum += sqrt((ksum_i * ksum_i) + (ksum_q * ksum_q));     }      L[u] = uSum; }  int main() {          int N = 1000;           float *xi_host = (float *)malloc(N * sizeof(float));     float *xq_host = (float *)malloc(N * sizeof(float));     float *sr_host = (float *)malloc(N * sizeof(float));     float *si_host = (float *)malloc(N * sizeof(float));     float *L_host = (float *)malloc(N * sizeof(float));                 float *xi_device, *xq_device, *sr_device, *si_device, *L_device;      cudaMalloc((void **)&xi_device, N * sizeof(float));     cudaMalloc((void **)&xq_device, N * sizeof(float));     cudaMalloc((void **)&sr_device, N * sizeof(float));     cudaMalloc((void **)&si_device, N * sizeof(float));     cudaMalloc((void **)&L_device, N * sizeof(float));                 dim3 gridDim((N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, 1, 1);     dim3 blockDim(THREADS_PER_BLOCK, 1, 1);      cudaChoiLee<<<gridDim, blockDim>>>(xi_device, xq_device, sr_device, si_device, N, L_device);                  free(xi_host);     free(xq_host);     free(sr_host);     free(si_host);     free(L_host);      cudaFree(xi_device);     cudaFree(xq_device);     cudaFree(sr_device);     cudaFree(si_device);     cudaFree(L_device);      return 0; }   "
    },
    {
        "id": "36",
        "c_code": "#include <stdio.h>  void logistic_cpu(unsigned int n, float a, float *x, float *z) {     for (unsigned int myId = 0; myId < n; myId++) {         z[myId] = a * x[myId] * (1 - x[myId]);     } }  int main() {          unsigned int arraySize = 5;     float inputArray[] = {0.2, 0.5, 0.7, 0.3, 0.8};     float resultArray[arraySize];     float a = 2.0;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           logistic_cpu(arraySize, a, inputArray, resultArray);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void logistic(unsigned int n, float a, float* x, float* z) {     unsigned int myId = blockDim.x * blockIdx.x + threadIdx.x;     if (myId < n) {         z[myId] = a * x[myId] * (1 - x[myId]);     } }  int main() {          const unsigned int arraySize = 1000;           float* h_x = (float*)malloc(arraySize * sizeof(float));     float* h_z = (float*)malloc(arraySize * sizeof(float));           for (unsigned int i = 0; i < arraySize; ++i) {         h_x[i] = static_cast<float>(i) / arraySize;       }           float* d_x;     float* d_z;     cudaMalloc((void**)&d_x, arraySize * sizeof(float));     cudaMalloc((void**)&d_z, arraySize * sizeof(float));           cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           logistic<<<gridSize, blockSize>>>(arraySize, 2.0f, d_x, d_z);           cudaMemcpy(h_z, d_z, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (unsigned int i = 0; i < 10; ++i) {         printf(\"%f \", h_z[i]);     }           free(h_x);     free(h_z);     cudaFree(d_x);     cudaFree(d_z);      return 0; } "
    },
    {
        "id": "360",
        "c_code": "#include <stdio.h> #include <math.h>   void calculateOuterSumsNew_cpu(float *innerSums, float *L, int uLength) {     for (int u = 0; u < uLength; u++) {         float real, imag, u_sum;         int realIdx = 2 * u;         int imagIdx = realIdx + 1;          real = innerSums[realIdx];         imag = innerSums[imagIdx];         u_sum = (real * real) + (imag * imag);          realIdx += 64;         imagIdx += 64;         real = innerSums[realIdx];         imag = innerSums[imagIdx];         u_sum += (real * real) + (imag * imag);          realIdx += 64;         imagIdx += 64;         real = innerSums[realIdx];         imag = innerSums[imagIdx];         u_sum += (real * real) + (imag * imag);          realIdx += 64;         imagIdx += 64;         real = innerSums[realIdx];         imag = innerSums[imagIdx];         u_sum += (real * real) + (imag * imag);          realIdx += 64;         imagIdx += 64;         real = innerSums[realIdx];         imag = innerSums[imagIdx];         u_sum += (real * real) + (imag * imag);          realIdx += 64;         imagIdx += 64;         real = innerSums[realIdx];         imag = innerSums[imagIdx];         u_sum += (real * real) + (imag * imag);          realIdx += 64;         imagIdx += 64;         real = innerSums[realIdx];         imag = innerSums[imagIdx];         u_sum += (real * real) + (imag * imag);          realIdx += 64;         imagIdx += 64;         real = innerSums[realIdx];         imag = innerSums[imagIdx];         u_sum += (real * real) + (imag * imag);          L[u] = u_sum;     } }   int main() {     const int uLength = 10;       float innerSums[uLength * 2];             for (int i = 0; i < uLength * 2; ++i) {         innerSums[i] = (float)i;     }      float L[uLength];           calculateOuterSumsNew_cpu(innerSums, L, uLength);           printf(\"Result: \");     for (int u = 0; u < uLength; ++u) {         printf(\"%f \", L[u]);     }     printf(\"\\n\");      return 0; }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>  #define THREADS_PER_BLOCK 256  __global__ void calculateOuterSumsNew(float *innerSums, float *L, int uLength) {     int u = blockDim.x * blockIdx.x + threadIdx.x;     if (u >= uLength)         return;      float real, imag, u_sum = 0.0f;      for (int i = 0; i < 8; i++) {         int realIdx = 2 * (u + i * 64);         int imagIdx = realIdx + 1;          real = innerSums[realIdx];         imag = innerSums[imagIdx];          u_sum += (real * real) + (imag * imag);     }      L[u] = u_sum; }  int main() {          int uLength = 1000;           float *innerSums_host = (float *)malloc(2 * uLength * sizeof(float));     float *L_host = (float *)malloc(uLength * sizeof(float));                 float *innerSums_device, *L_device;      cudaMalloc((void **)&innerSums_device, 2 * uLength * sizeof(float));     cudaMalloc((void **)&L_device, uLength * sizeof(float));                 dim3 gridDim((uLength + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, 1, 1);     dim3 blockDim(THREADS_PER_BLOCK, 1, 1);      calculateOuterSumsNew<<<gridDim, blockDim>>>(innerSums_device, L_device, uLength);                  free(innerSums_host);     free(L_host);      cudaFree(innerSums_device);     cudaFree(L_device);      return 0; }   "
    },
    {
        "id": "361",
        "c_code": " #include <stdio.h>  void nlf_right_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data);  int main() {          int n = 1;     int channel = 1;     int height = 3;     int width = 3;     int wsize = 5;      float filters[] = {              };      float top_data[n * height * width];             nlf_right_forward_cpu(n, filters, channel, height, width, wsize, top_data);           printf(\"Results:\\n\");     for (int i = 0; i < n; ++i) {         for (int j = 0; j < height; ++j) {             for (int k = 0; k < width; ++k) {                 printf(\"%f \", top_data[i * height * width + j * width + k]);             }             printf(\"\\n\");         }         printf(\"\\n\");     }      return 0; }  void nlf_right_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index * step;         int fbase = index / channel * wsize * step;          for (int col = 0; col < width; col++) {             for (int row = 0; row < height; row++) {                 float temp = 0;                 int r, c, shift;                  r = row;                 c = col;                 shift = 0 * step + row * width + col;                 temp += top_data[base + r * width + c] * filters[fbase + shift];                  r = row;                 c = col - 1;                 shift = 1 * step + row * width + col;                 if (c >= 0)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row - 1;                 c = col - 1;                 shift = 2 * step + row * width + col;                 if (c >= 0 && r >= 0)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row + 1;                 c = col - 1;                 shift = 3 * step + row * width + col;                 if (c >= 0 && r < height)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row - 1;                 c = col;                 shift = 4 * step + row * width + col;                 if (r >= 0)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  top_data[base + row * width + col] = temp;             }         }     } }  ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>  #define THREADS_PER_BLOCK 256  __global__ void nlf_right_forward(const int n, const float *filters, const int channel,                                    const int height, const int width, const int wsize,                                    float *top_data) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     if (index >= n) {         return;     }      int step = height * width;     int base = index * step;     int fbase = index / channel * wsize * step;      for (int col = 0; col < width; col++) {         for (int row = 0; row < height; row++) {             float temp = 0;             int r, c, shift;                           r = row;             c = col;             shift = 0 * step + row * width + col;             temp += top_data[base + r * width + c] * filters[fbase + shift];                           r = row;             c = col - 1;             shift = 1 * step + row * width + col;             if (c >= 0)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row - 1;             c = col - 1;             shift = 2 * step + row * width + col;             if (c >= 0 && r >= 0)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row + 1;             c = col - 1;             shift = 3 * step + row * width + col;             if (c >= 0 && r < height)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row - 1;             c = col;             shift = 4 * step + row * width + col;             if (r >= 0)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];              top_data[base + row * width + col] = temp;         }     } }  int main() {          int n = 1000;     int channel = 3;     int height = 32;     int width = 32;     int wsize = 5;           float *filters_host = (float *)malloc(n * channel * wsize * sizeof(float));     float *top_data_host = (float *)malloc(n * height * width * sizeof(float));                 float *filters_device, *top_data_device;      cudaMalloc((void **)&filters_device, n * channel * wsize * sizeof(float));     cudaMalloc((void **)&top_data_device, n * height * width * sizeof(float));                 dim3 gridDim((n + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, 1, 1);     dim3 blockDim(THREADS_PER_BLOCK, 1, 1);      nlf_right_forward<<<gridDim, blockDim>>>(n, filters_device, channel, height, width, wsize,                                              top_data_device);                  free(filters_host);     free(top_data_host);      cudaFree(filters_device);     cudaFree(top_data_device);      return 0; }   "
    },
    {
        "id": "362",
        "c_code": "#include <stdio.h>  void nlf_filter_right_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff);  int main() {          int n = 1;     int channel = 1;     int height = 3;     int width = 3;     int wsize = 5;      float bottom_data[n * channel * height * width];       float top_data[n * channel * height * width];          float temp_diff[n * channel * height * width];         float filters_diff[n * channel * wsize * height * width];             nlf_filter_right_backward_cpu(n, bottom_data, top_data, temp_diff, channel, height, width, wsize, filters_diff);           printf(\"Results:\\n\");     for (int i = 0; i < n; ++i) {         for (int j = 0; j < channel; ++j) {             for (int k = 0; k < wsize; ++k) {                 for (int m = 0; m < height; ++m) {                     for (int n = 0; n < width; ++n) {                         printf(\"%f \", filters_diff[i * channel * wsize * height * width + j * wsize * height * width + k * height * width + m * width + n]);                     }                     printf(\"\\n\");                 }                 printf(\"\\n\");             }         }     }      return 0; }  void nlf_filter_right_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index / step * step * channel + index % step;         int fbase = index / step * step * wsize + index % step;         int row = index % step / width;         int col = index % step % width;          for (int i = 0; i < channel; i++) {             filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col - 1 >= 0)                 filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base - 1 + i * step];             else                 filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col - 1 >= 0 && row - 1 >= 0)                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * top_data[base - width - 1 + i * step];             else                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col - 1 >= 0 && row + 1 < height)                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * top_data[base + width - 1 + i * step];             else                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row - 1 >= 0)                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base - width + i * step];             else                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>  #define THREADS_PER_BLOCK 256  __global__ void nlf_filter_right_backward(const int n, const float *bottom_data, const float *top_data,                                            const float *temp_diff, const int channel,                                            const int height, const int width, const int wsize,                                            float *filters_diff) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     if (index >= n) {         return;     }      int step = height * width;     int base = index / step * step * channel + index % step;     int fbase = index / step * step * wsize + index % step;     int row = index % step / width;     int col = index % step % width;      for (int i = 0; i < channel; i++) {         filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col - 1 >= 0)             filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base - 1 + i * step];         else             filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col - 1 >= 0 && row - 1 >= 0)             filters_diff[fbase + 2 * step] +=                 temp_diff[base + i * step] * top_data[base - width - 1 + i * step];         else             filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col - 1 >= 0 && row + 1 < height)             filters_diff[fbase + 3 * step] +=                 temp_diff[base + i * step] * top_data[base + width - 1 + i * step];         else             filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row - 1 >= 0)             filters_diff[fbase + 4 * step] +=                 temp_diff[base + i * step] * top_data[base - width + i * step];         else             filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];     } }  int main() {          int n = 1000;     int channel = 3;     int height = 32;     int width = 32;     int wsize = 5;           float *bottom_data_host = (float *)malloc(n * channel * height * width * sizeof(float));     float *top_data_host = (float *)malloc(n * channel * height * width * sizeof(float));     float *temp_diff_host = (float *)malloc(n * channel * height * width * sizeof(float));     float *filters_diff_host = (float *)malloc(n * channel * wsize * sizeof(float));                 float *bottom_data_device, *top_data_device, *temp_diff_device, *filters_diff_device;      cudaMalloc((void **)&bottom_data_device, n * channel * height * width * sizeof(float));     cudaMalloc((void **)&top_data_device, n * channel * height * width * sizeof(float));     cudaMalloc((void **)&temp_diff_device, n * channel * height * width * sizeof(float));     cudaMalloc((void **)&filters_diff_device, n * channel * wsize * sizeof(float));                 dim3 gridDim((n + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, 1, 1);     dim3 blockDim(THREADS_PER_BLOCK, 1, 1);      nlf_filter_right_backward<<<gridDim, blockDim>>>(n, bottom_data_device, top_data_device,                                                      temp_diff_device, channel, height, width,                                                      wsize, filters_diff_device);                  free(bottom_data_host);     free(top_data_host);     free(temp_diff_host);     free(filters_diff_host);      cudaFree(bottom_data_device);     cudaFree(top_data_device);     cudaFree(temp_diff_device);     cudaFree(filters_diff_device);      return 0; }   "
    },
    {
        "id": "363",
        "c_code": "#include <stdio.h>  void nlf_filter_up_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff);  int main() {          int n = 1;     int channel = 1;     int height = 3;     int width = 3;     int wsize = 5;      float bottom_data[n * channel * height * width];       float top_data[n * channel * height * width];          float temp_diff[n * channel * height * width];         float filters_diff[n * channel * wsize * height * width];             nlf_filter_up_backward_cpu(n, bottom_data, top_data, temp_diff, channel, height, width, wsize, filters_diff);           printf(\"Results:\\n\");     for (int i = 0; i < n; ++i) {         for (int j = 0; j < channel; ++j) {             for (int k = 0; k < wsize; ++k) {                 for (int m = 0; m < height; ++m) {                     for (int n = 0; n < width; ++n) {                         printf(\"%f \", filters_diff[i * channel * wsize * height * width + j * wsize * height * width + k * height * width + m * width + n]);                     }                     printf(\"\\n\");                 }                 printf(\"\\n\");             }         }     }      return 0; }  void nlf_filter_up_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index / step * step * channel + index % step;         int fbase = index / step * step * wsize + index % step;         int row = index % step / width;         int col = index % step % width;          for (int i = 0; i < channel; i++) {             filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row + 1 < height)                 filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base + width + i * step];             else                 filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row + 1 < height && col - 1 >= 0)                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * top_data[base + width - 1 + i * step];             else                 filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (row + 1 < height && col + 1 < width)                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * top_data[base + width + 1 + i * step];             else                 filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];              if (col + 1 < width)                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base + 1 + i * step];             else                 filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>  #define THREADS_PER_BLOCK 256  __global__ void nlf_filter_up_backward(const int n, const float *bottom_data, const float *top_data,                                         const float *temp_diff, const int channel,                                         const int height, const int width, const int wsize,                                         float *filters_diff) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     if (index >= n) {         return;     }      int step = height * width;     int base = index / step * step * channel + index % step;     int fbase = index / step * step * wsize + index % step;     int row = index % step / width;     int col = index % step % width;      for (int i = 0; i < channel; i++) {         filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row + 1 < height)             filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base + width + i * step];         else             filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row + 1 < height && col - 1 >= 0)             filters_diff[fbase + 2 * step] +=                 temp_diff[base + i * step] * top_data[base + width - 1 + i * step];         else             filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (row + 1 < height && col + 1 < width)             filters_diff[fbase + 3 * step] +=                 temp_diff[base + i * step] * top_data[base + width + 1 + i * step];         else             filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];          if (col + 1 < width)             filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base + 1 + i * step];         else             filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];     } }  int main() {          int n = 1000;     int channel = 3;     int height = 32;     int width = 32;     int wsize = 5;           float *bottom_data_host = (float *)malloc(n * channel * height * width * sizeof(float));     float *top_data_host = (float *)malloc(n * channel * height * width * sizeof(float));     float *temp_diff_host = (float *)malloc(n * channel * height * width * sizeof(float));     float *filters_diff_host = (float *)malloc(n * channel * wsize * sizeof(float));                 float *bottom_data_device, *top_data_device, *temp_diff_device, *filters_diff_device;      cudaMalloc((void **)&bottom_data_device, n * channel * height * width * sizeof(float));     cudaMalloc((void **)&top_data_device, n * channel * height * width * sizeof(float));     cudaMalloc((void **)&temp_diff_device, n * channel * height * width * sizeof(float));     cudaMalloc((void **)&filters_diff_device, n * channel * wsize * sizeof(float));                 dim3 gridDim((n + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, 1, 1);     dim3 blockDim(THREADS_PER_BLOCK, 1, 1);      nlf_filter_up_backward<<<gridDim, blockDim>>>(n, bottom_data_device, top_data_device,                                                    temp_diff_device, channel, height, width,                                                    wsize, filters_diff_device);                  free(bottom_data_host);     free(top_data_host);     free(temp_diff_host);     free(filters_diff_host);      cudaFree(bottom_data_device);     cudaFree(top_data_device);     cudaFree(temp_diff_device);     cudaFree(filters_diff_device);      return 0; }   "
    },
    {
        "id": "364",
        "c_code": "#include <stdio.h>  void nlf_left_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data);  int main() {          int n = 1;     int channel = 1;     int height = 3;     int width = 3;     int wsize = 5;      float filters[] = {              };      float top_data[n * height * width];             nlf_left_forward_cpu(n, filters, channel, height, width, wsize, top_data);           printf(\"Results:\\n\");     for (int i = 0; i < n; ++i) {         for (int j = 0; j < height; ++j) {             for (int k = 0; k < width; ++k) {                 printf(\"%f \", top_data[i * height * width + j * width + k]);             }             printf(\"\\n\");         }         printf(\"\\n\");     }      return 0; }  void nlf_left_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data) {     for (int index = 0; index < n; index++) {         int step = height * width;         int base = index * step;         int fbase = index / channel * wsize * step;          for (int col = width - 1; col >= 0; col--) {             for (int row = height - 1; row >= 0; row--) {                 float temp = 0;                 int r, c, shift;                  r = row;                 c = col;                 shift = 0 * step + row * width + col;                 temp += top_data[base + r * width + c] * filters[fbase + shift];                  r = row;                 c = col + 1;                 shift = 1 * step + row * width + col;                 if (c < width)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row - 1;                 c = col + 1;                 shift = 2 * step + row * width + col;                 if (c < width && r >= 0)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row + 1;                 c = col + 1;                 shift = 3 * step + row * width + col;                 if (c < width && r < height)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  r = row + 1;                 c = col;                 shift = 4 * step + row * width + col;                 if (r < height)                     temp += top_data[base + r * width + c] * filters[fbase + shift];                 else                     temp += top_data[base + row * width + col] * filters[fbase + shift];                  top_data[base + row * width + col] = temp;             }         }     } }   ",
        "cuda_code": "#include <stdio.h> #include <stdlib.h> #include <cuda_runtime.h>  #define THREADS_PER_BLOCK 256  __global__ void nlf_left_forward(const int n, const float *filters, const int channel,                                  const int height, const int width, const int wsize,                                  float *top_data) {     int index = blockIdx.x * blockDim.x + threadIdx.x;     if (index >= n) {         return;     }      int step = height * width;     int base = index * step;     int fbase = index / channel * wsize * step;      for (int col = width - 1; col >= 0; col--) {         for (int row = height - 1; row >= 0; row--) {             float temp = 0;             int r, c, shift;                           r = row;             c = col;             shift = 0 * step + row * width + col;             temp += top_data[base + r * width + c] * filters[fbase + shift];                           r = row;             c = col + 1;             shift = 1 * step + row * width + col;             if (c < width)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row - 1;             c = col + 1;             shift = 2 * step + row * width + col;             if (c < width && r >= 0)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row + 1;             c = col + 1;             shift = 3 * step + row * width + col;             if (c < width && r < height)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];                           r = row + 1;             c = col;             shift = 4 * step + row * width + col;             if (r < height)                 temp += top_data[base + r * width + c] * filters[fbase + shift];             else                 temp += top_data[base + row * width + col] * filters[fbase + shift];              top_data[base + row * width + col] = temp;         }     } }  int main() {          int n = 1000;     int channel = 3;     int height = 32;     int width = 32;     int wsize = 5;           float *filters_host = (float *)malloc(n * channel * wsize * sizeof(float));     float *top_data_host = (float *)malloc(n * height * width * sizeof(float));                 float *filters_device, *top_data_device;      cudaMalloc((void **)&filters_device, n * channel * wsize * sizeof(float));     cudaMalloc((void **)&top_data_device, n * height * width * sizeof(float));                 dim3 gridDim((n + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, 1, 1);     dim3 blockDim(THREADS_PER_BLOCK, 1, 1);      nlf_left_forward<<<gridDim, blockDim>>>(n, filters_device, channel, height, width,                                             wsize, top_data_device);                  free(filters_host);     free(top_data_host);      cudaFree(filters_device);     cudaFree(top_data_device);      return 0; }   "
    },
    {
        "id": "37",
        "c_code": "#include <stdio.h>  void add_kernel(float *inputleft, float *inputright, float *output, int count) {     for (int idx = 0; idx < count; idx++) {         output[idx] = inputleft[idx] + inputright[idx];     } }  int main() {          int arraySize = 4;     float inputLeft[] = {1.1, 2.2, 3.3, 4.4};     float inputRight[] = {0.5, 1.5, 2.5, 3.5};     float resultArray[arraySize];      printf(\"\u5de6\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputLeft[i]);     }      printf(\"\\n\u53f3\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputRight[i]);     }           add_kernel(inputLeft, inputRight, resultArray, arraySize);      printf(\"\\n\u8f93\u51fa\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void add_kernel(float* inputleft, float* inputright, float* output, int count) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;     if (idx < count) {         output[idx] = inputleft[idx] + inputright[idx];     } }  int main() {          const int arraySize = 1000;           float* h_inputleft = (float*)malloc(arraySize * sizeof(float));     float* h_inputright = (float*)malloc(arraySize * sizeof(float));     float* h_output = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_inputleft[i] = static_cast<float>(i);         h_inputright[i] = static_cast<float>(2 * i);     }           float* d_inputleft;     float* d_inputright;     float* d_output;     cudaMalloc((void**)&d_inputleft, arraySize * sizeof(float));     cudaMalloc((void**)&d_inputright, arraySize * sizeof(float));     cudaMalloc((void**)&d_output, arraySize * sizeof(float));           cudaMemcpy(d_inputleft, h_inputleft, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_inputright, h_inputright, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           add_kernel<<<gridSize, blockSize>>>(d_inputleft, d_inputright, d_output, arraySize);           cudaMemcpy(h_output, d_output, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_output[i]);     }           free(h_inputleft);     free(h_inputright);     free(h_output);     cudaFree(d_inputleft);     cudaFree(d_inputright);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "38",
        "c_code": "#include <stdio.h>  void mul_cpu(int N, float *X, int INCX, float *Y, int INCY) {     for (int i = 0; i < N; ++i) {         Y[i * INCY] *= X[i * INCX];     } }  int main() {          int arraySize = 5;     float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayY[] = {0.5, 1.5, 2.5, 3.5, 4.5};      printf(\"\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }      printf(\"\\n\u6570\u7ec4 Y\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayY[i]);     }           mul_cpu(arraySize, arrayX, 1, arrayY, 1);      printf(\"\\n\u6570\u7ec4 Y\uff08\u4e58\u6cd5\u540e\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayY[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void mul_kernel(int N, float* X, int INCX, float* Y, int INCY) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N) {         Y[i * INCY] *= X[i * INCX];     } }  int main() {          const int arraySize = 1000;           float* h_X = (float*)malloc(arraySize * sizeof(float));     float* h_Y = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_X[i] = static_cast<float>(i);         h_Y[i] = static_cast<float>(2 * i);     }           float* d_X;     float* d_Y;     cudaMalloc((void**)&d_X, arraySize * sizeof(float));     cudaMalloc((void**)&d_Y, arraySize * sizeof(float));           cudaMemcpy(d_X, h_X, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_Y, h_Y, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           mul_kernel<<<gridSize, blockSize>>>(arraySize, d_X, 1, d_Y, 1);           cudaMemcpy(h_Y, d_Y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_Y[i]);     }           free(h_X);     free(h_Y);     cudaFree(d_X);     cudaFree(d_Y);      return 0; } "
    },
    {
        "id": "39",
        "c_code": "#include <stdio.h>  void pathPlan(int *devSpeed, int *devSteer, int size) {     for (int tid = 0; tid < size; tid++) {         devSpeed[tid] += 1;         devSteer[tid] += 1;     } }  int main() {          int arraySize = 4;     int speedArray[] = {10, 20, 30, 40};     int steerArray[] = {1, 2, 3, 4};      printf(\"\u901f\u5ea6\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", speedArray[i]);     }      printf(\"\\n\u65b9\u5411\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", steerArray[i]);     }           pathPlan(speedArray, steerArray, arraySize);      printf(\"\\n\u8ba1\u5212\u540e\u7684\u901f\u5ea6\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", speedArray[i]);     }      printf(\"\\n\u8ba1\u5212\u540e\u7684\u65b9\u5411\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", steerArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void pathPlan(int* devSpeed, int* devSteer, int size) {     int tid = threadIdx.x + blockIdx.x * blockDim.x;     while (tid < size) {         devSpeed[tid] += 1;         devSteer[tid] += 1;         tid += blockDim.x * gridDim.x;     } }  int main() {          const int arraySize = 1000;           int* h_devSpeed = (int*)malloc(arraySize * sizeof(int));     int* h_devSteer = (int*)malloc(arraySize * sizeof(int));           for (int i = 0; i < arraySize; ++i) {         h_devSpeed[i] = i;         h_devSteer[i] = 2 * i;     }           int* d_devSpeed;     int* d_devSteer;     cudaMalloc((void**)&d_devSpeed, arraySize * sizeof(int));     cudaMalloc((void**)&d_devSteer, arraySize * sizeof(int));           cudaMemcpy(d_devSpeed, h_devSpeed, arraySize * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_devSteer, h_devSteer, arraySize * sizeof(int), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           pathPlan<<<gridSize, blockSize>>>(d_devSpeed, d_devSteer, arraySize);           cudaMemcpy(h_devSpeed, d_devSpeed, arraySize * sizeof(int), cudaMemcpyDeviceToHost);     cudaMemcpy(h_devSteer, d_devSteer, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"Speed: %d, Steer: %d\\n\", h_devSpeed[i], h_devSteer[i]);     }           free(h_devSpeed);     free(h_devSteer);     cudaFree(d_devSpeed);     cudaFree(d_devSteer);      return 0; } "
    },
    {
        "id": "4",
        "c_code": "#include <stdio.h>  void add(int n, float *x, float *y) {     for (int i = 0; i < n; i++) {         y[i] = x[i] + y[i];     } }  int main() {          int numElements = 5;     float x[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float y[] = {2.0, 4.0, 6.0, 8.0, 10.0};      printf(\"\u539f\u59cb\u6570\u7ec4 x\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", x[i]);     }      printf(\"\\n\u539f\u59cb\u6570\u7ec4 y\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", y[i]);     }           add(numElements, x, y);      printf(\"\\n\u76f8\u52a0\u540e\u7684\u6570\u7ec4 y\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", y[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void add(int n, float* x, float* y) {     int i = threadIdx.x;     if (i < n) {         y[i] = x[i] + y[i];     } }  int main() {          int arraySize = 1000;           float* h_x = (float*)malloc(arraySize * sizeof(float));     float* h_y = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_x[i] = static_cast<float>(i);         h_y[i] = static_cast<float>(2 * i);     }           float* d_x;     float* d_y;     cudaMalloc((void**)&d_x, arraySize * sizeof(float));     cudaMalloc((void**)&d_y, arraySize * sizeof(float));           cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_y, h_y, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           add<<<gridSize, blockSize>>>(arraySize, d_x, d_y);           cudaMemcpy(h_y, d_y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_y[i]);     }           free(h_x);     free(h_y);     cudaFree(d_x);     cudaFree(d_y);      return 0; } "
    },
    {
        "id": "40",
        "c_code": "#include <stdio.h>  void mult_add_into_cpu(int N, float *X, float *Y, float *Z) {     for (int i = 0; i < N; ++i) {         Z[i] += X[i] * Y[i];     } }  int main() {          int arraySize = 5;     float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float arrayY[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 X\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayX[i]);     }      printf(\"\\n\u6570\u7ec4 Y\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayY[i]);     }           mult_add_into_cpu(arraySize, arrayX, arrayY, resultArray);      printf(\"\\n\u6570\u7ec4 Z\uff08\u4e58\u6cd5\u5e76\u52a0\u6cd5\u540e\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void mult_add_into_kernel(int n, float* a, float* b, float* c) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < n) {         c[i] += a[i] * b[i];     } }  int main() {          const int arraySize = 1000;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_b = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);         h_b[i] = static_cast<float>(2 * i);         h_c[i] = static_cast<float>(3 * i);     }           float* d_a;     float* d_b;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_b, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_c, h_c, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           mult_add_into_kernel<<<gridSize, blockSize>>>(arraySize, d_a, d_b, d_c);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "41",
        "c_code": "#include <stdio.h>  void InitReduction(int *flags, int voxelCount, int *reduction, int reductionSize) {     for (int tid = 0; tid < reductionSize; tid++) {         reduction[tid] = (tid < voxelCount) ? flags[tid] : 0;     } }  int main() {          int voxelCount = 4;     int reductionSize = 6;     int flagsArray[] = {1, 0, 1, 0};     int reductionArray[reductionSize];      printf(\"\u6807\u5fd7\u6570\u7ec4\uff1a\");     for (int i = 0; i < voxelCount; i++) {         printf(\"%d \", flagsArray[i]);     }           InitReduction(flagsArray, voxelCount, reductionArray, reductionSize);      printf(\"\\n\u521d\u59cb\u5316\u7684\u7f29\u51cf\u6570\u7ec4\uff1a\");     for (int i = 0; i < reductionSize; i++) {         printf(\"%d \", reductionArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void InitReduction(bool* flags, int voxelCount, int* reduction, int reductionSize) {     int tid = threadIdx.x + blockIdx.x * blockDim.x;     if (tid < reductionSize) {         reduction[tid] = (tid < voxelCount) ? flags[tid] : 0;     } }  int main() {          const int voxelCount = 1000;     const int reductionSize = 1024;            bool* h_flags = (bool*)malloc(voxelCount * sizeof(bool));     int* h_reduction = (int*)malloc(reductionSize * sizeof(int));           for (int i = 0; i < voxelCount; ++i) {         h_flags[i] = i % 2 == 0;      }           bool* d_flags;     int* d_reduction;     cudaMalloc((void**)&d_flags, voxelCount * sizeof(bool));     cudaMalloc((void**)&d_reduction, reductionSize * sizeof(int));           cudaMemcpy(d_flags, h_flags, voxelCount * sizeof(bool), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((reductionSize + blockSize.x - 1) / blockSize.x, 1);           InitReduction<<<gridSize, blockSize>>>(d_flags, voxelCount, d_reduction, reductionSize);           cudaMemcpy(h_reduction, d_reduction, reductionSize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_reduction[i]);     }           free(h_flags);     free(h_reduction);     cudaFree(d_flags);     cudaFree(d_reduction);      return 0; } "
    },
    {
        "id": "42",
        "c_code": "#include <stdio.h>  void Function_update_sgd_cpu(float lr, float *parameter, float *gradient, int size) {     for (int i = 0; i < size; i++) {         parameter[i] -= lr * gradient[i];     } }  int main() {          int arraySize = 3;     float learningRate = 0.1;     float parameterArray[] = {1.0, 2.0, 3.0};     float gradientArray[] = {0.5, 1.0, 1.5};      printf(\"\u53c2\u6570\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", parameterArray[i]);     }      printf(\"\\n\u68af\u5ea6\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", gradientArray[i]);     }           Function_update_sgd_cpu(learningRate, parameterArray, gradientArray, arraySize);      printf(\"\\n\u66f4\u65b0\u540e\u7684\u53c2\u6570\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", parameterArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void Kernel_Function_update_sgd(float lr, float* dev_parameter, float* dev_gradient, int size) {     int tid = blockDim.x * blockIdx.x + threadIdx.x;     int N = size;     while (tid < N) {         dev_parameter[tid] -= lr * dev_gradient[tid];         tid += gridDim.x * blockDim.x;     } }  int main() {          const int arraySize = 1000;           float* h_dev_parameter = (float*)malloc(arraySize * sizeof(float));     float* h_dev_gradient = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_dev_parameter[i] = static_cast<float>(i);         h_dev_gradient[i] = static_cast<float>(2 * i);     }           float* d_dev_parameter;     float* d_dev_gradient;     cudaMalloc((void**)&d_dev_parameter, arraySize * sizeof(float));     cudaMalloc((void**)&d_dev_gradient, arraySize * sizeof(float));           cudaMemcpy(d_dev_parameter, h_dev_parameter, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_dev_gradient, h_dev_gradient, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           Kernel_Function_update_sgd<<<gridSize, blockSize>>>(0.01f, d_dev_parameter, d_dev_gradient, arraySize);           cudaMemcpy(h_dev_parameter, d_dev_parameter, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_dev_parameter[i]);     }           free(h_dev_parameter);     free(h_dev_gradient);     cudaFree(d_dev_parameter);     cudaFree(d_dev_gradient);      return 0; } "
    },
    {
        "id": "43",
        "c_code": "#include <stdio.h>  void operacionCPU(float *u, float *lu, float u_m, float u_d, int n) {     int idx = 0;     while (idx < n) {         lu[idx] = (u[idx] - u_m) / u_d;         idx += 1;     } }  int main() {          int arraySize = 4;     float uArray[] = {2.0, 3.0, 4.0, 5.0};     float luArray[arraySize];     float u_m = 3.0;     float u_d = 2.0;      printf(\"\u6570\u7ec4 u\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", uArray[i]);     }           operacionCPU(uArray, luArray, u_m, u_d, arraySize);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4 lu\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", luArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void operacionKernelGPU(float* u, float* lu, float u_m, float u_d, int n) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;     if (idx < n) {         lu[idx] = (u[idx] - u_m) / u_d;     } }  int main() {          const int arraySize = 1000;           float* h_u = (float*)malloc(arraySize * sizeof(float));     float* h_lu = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_u[i] = static_cast<float>(i);     }           float* d_u;     float* d_lu;     cudaMalloc((void**)&d_u, arraySize * sizeof(float));     cudaMalloc((void**)&d_lu, arraySize * sizeof(float));           cudaMemcpy(d_u, h_u, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           operacionKernelGPU<<<gridSize, blockSize>>>(d_u, d_lu, 5.0f, 2.0f, arraySize);           cudaMemcpy(h_lu, d_lu, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_lu[i]);     }           free(h_u);     free(h_lu);     cudaFree(d_u);     cudaFree(d_lu);      return 0; } "
    },
    {
        "id": "44",
        "c_code": "#include <stdio.h>  void host_add(float *c, float *a, float *b, int n) {     for (int k = 0; k < n; k++) {         c[k] = a[k] + b[k];     } }  int main() {          int arraySize = 4;     float arrayA[] = {1.0, 2.0, 3.0, 4.0};     float arrayB[] = {5.0, 6.0, 7.0, 8.0};     float resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           host_add(resultArray, arrayA, arrayB, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff08\u76f8\u52a0\u540e\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void gpu_add(float* c, float* a, float* b, int n) {     int j = blockIdx.x * blockDim.x + threadIdx.x;     int m = gridDim.x * blockDim.x;     for (int k = j; k < n; k += m) {         c[k] = a[k] + b[k];     } }  int main() {          const int arraySize = 1000;           float* h_a = (float*)malloc(arraySize * sizeof(float));     float* h_b = (float*)malloc(arraySize * sizeof(float));     float* h_c = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_a[i] = static_cast<float>(i);         h_b[i] = static_cast<float>(2 * i);     }           float* d_a;     float* d_b;     float* d_c;     cudaMalloc((void**)&d_a, arraySize * sizeof(float));     cudaMalloc((void**)&d_b, arraySize * sizeof(float));     cudaMalloc((void**)&d_c, arraySize * sizeof(float));           cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           gpu_add<<<gridSize, blockSize>>>(d_c, d_a, d_b, arraySize);           cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_c[i]);     }           free(h_a);     free(h_b);     free(h_c);     cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "45",
        "c_code": "#include <stdio.h> #include <math.h>  void squareSerial(float *d_in, float *d_out, int N) {     for (unsigned int i = 0; i < N; ++i) {         d_out[i] = pow(d_in[i] / (d_in[i] - 2.3), 3);     } }  int main() {          int arraySize = 3;     float inputArray[] = {1.0, 3.0, 5.0};     float outputArray[arraySize];      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           squareSerial(inputArray, outputArray, arraySize);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h> #include <cmath>  __global__ void squareKernel(float* d_in, float* d_out, int N) {     const unsigned int lid = threadIdx.x;     const unsigned int gid = blockIdx.x * blockDim.x + lid;     if (gid < N) {         d_out[gid] = pow(d_in[gid] / (d_in[gid] - 2.3), 3);     } }  int main() {          const int arraySize = 1000;           float* h_d_in = (float*)malloc(arraySize * sizeof(float));     float* h_d_out = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_d_in[i] = static_cast<float>(i);     }           float* d_d_in;     float* d_d_out;     cudaMalloc((void**)&d_d_in, arraySize * sizeof(float));     cudaMalloc((void**)&d_d_out, arraySize * sizeof(float));           cudaMemcpy(d_d_in, h_d_in, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           squareKernel<<<gridSize, blockSize>>>(d_d_in, d_d_out, arraySize);           cudaMemcpy(h_d_out, d_d_out, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_d_out[i]);     }           free(h_d_in);     free(h_d_out);     cudaFree(d_d_in);     cudaFree(d_d_out);      return 0; } "
    },
    {
        "id": "46",
        "c_code": "#include <stdio.h>  void doubleArrayVectorAdd_cpu(double *d_in_a, double *d_in_b, double *d_out, int length) {     for (int idx = 0; idx < length; idx++) {         d_out[idx] = d_in_a[idx] + d_in_b[idx];     } }  int main() {          int arraySize = 3;     double arrayA[] = {1.5, 2.5, 3.5};     double arrayB[] = {0.5, 1.0, 1.5};     double resultArray[arraySize];      printf(\"\u6570\u7ec4 A\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayA[i]);     }      printf(\"\\n\u6570\u7ec4 B\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", arrayB[i]);     }           doubleArrayVectorAdd_cpu(arrayA, arrayB, resultArray, arraySize);      printf(\"\\n\u6570\u7ec4 C\uff08\u76f8\u52a0\u540e\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", resultArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void doubleArrayVectorAddKernel(double* d_in_a, double* d_in_b, double* d_out, int length) {     int tid = (blockIdx.x * blockDim.x) + threadIdx.x;     if (tid < length) {         d_out[tid] = d_in_a[tid] + d_in_b[tid];     } }  int main() {          const int arraySize = 1000;           double* h_d_in_a = (double*)malloc(arraySize * sizeof(double));     double* h_d_in_b = (double*)malloc(arraySize * sizeof(double));     double* h_d_out = (double*)malloc(arraySize * sizeof(double));           for (int i = 0; i < arraySize; ++i) {         h_d_in_a[i] = static_cast<double>(i);         h_d_in_b[i] = static_cast<double>(2 * i);     }           double* d_d_in_a;     double* d_d_in_b;     double* d_d_out;     cudaMalloc((void**)&d_d_in_a, arraySize * sizeof(double));     cudaMalloc((void**)&d_d_in_b, arraySize * sizeof(double));     cudaMalloc((void**)&d_d_out, arraySize * sizeof(double));           cudaMemcpy(d_d_in_a, h_d_in_a, arraySize * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_d_in_b, h_d_in_b, arraySize * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           doubleArrayVectorAddKernel<<<gridSize, blockSize>>>(d_d_in_a, d_d_in_b, d_d_out, arraySize);           cudaMemcpy(h_d_out, d_d_out, arraySize * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_d_out[i]);     }           free(h_d_in_a);     free(h_d_in_b);     free(h_d_out);     cudaFree(d_d_in_a);     cudaFree(d_d_in_b);     cudaFree(d_d_out);      return 0; } "
    },
    {
        "id": "47",
        "c_code": "#include <stdio.h>  void fill_matrix(double *const A, const int rows, const int cols) {     for (int row = 0; row < rows; row++) {         for (int col = 0; col < cols; col++) {             A[row * cols + col] = row;         }     } }  int main() {          int numRows = 3;     int numCols = 4;     double matrix[numRows * numCols];           fill_matrix(matrix, numRows, numCols);           printf(\"\u586b\u5145\u540e\u7684\u77e9\u9635\uff1a\\n\");     for (int row = 0; row < numRows; row++) {         for (int col = 0; col < numCols; col++) {             printf(\"%.2f \", matrix[row * numCols + col]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void fill_matrix(double* const A, const int rows, const int cols) {     const int row = blockIdx.y * blockDim.y + threadIdx.y;     const int col = blockIdx.x * blockDim.x + threadIdx.x;     if (row < rows && col < cols) {         A[row * cols + col] = static_cast<double>(row);     } }  int main() {          const int rows = 10;     const int cols = 5;           double* h_A = (double*)malloc(rows * cols * sizeof(double));           double* d_A;     cudaMalloc((void**)&d_A, rows * cols * sizeof(double));           dim3 blockSize(16, 16);     dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y);           fill_matrix<<<gridSize, blockSize>>>(d_A, rows, cols);           cudaMemcpy(h_A, d_A, rows * cols * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < std::min(10, rows); ++i) {         for (int j = 0; j < std::min(5, cols); ++j) {             printf(\"%f \", h_A[i * cols + j]);         }         printf(\"\\n\");     }           free(h_A);     cudaFree(d_A);      return 0; } "
    },
    {
        "id": "48",
        "c_code": "#include <stdio.h>  void evenoddincrement_cpu(float *g_data, int even_inc, int odd_inc, int size) {     for (int tx = 0; tx < size; tx++) {         if ((tx % 2) == 0) {             g_data[tx] += even_inc;         } else {             g_data[tx] += odd_inc;         }     } }  int main() {          int arraySize = 6;     float dataArray[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     int evenIncrement = 2;     int oddIncrement = 1;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", dataArray[i]);     }           evenoddincrement_cpu(dataArray, evenIncrement, oddIncrement, arraySize);      printf(\"\\n\u589e\u91cf\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", dataArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void evenoddincrement(float* g_data, int even_inc, int odd_inc) {     int tx = threadIdx.x + blockIdx.x * blockDim.x;     if ((tx % 2) == 0) {         g_data[tx] += even_inc;     } else {         g_data[tx] += odd_inc;     } }  int main() {          const int arraySize = 1000;           float* h_data = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_data[i] = static_cast<float>(i);     }           float* d_data;     cudaMalloc((void**)&d_data, arraySize * sizeof(float));           cudaMemcpy(d_data, h_data, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           evenoddincrement<<<gridSize, blockSize>>>(d_data, 2, 3);           cudaMemcpy(h_data, d_data, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_data[i]);     }           free(h_data);     cudaFree(d_data);      return 0; } "
    },
    {
        "id": "49",
        "c_code": "#include <stdio.h>  void copy_cpu(int N, float *X, int INCX, float *Y, int INCY) {     for (int i = 0; i < N; ++i) {         Y[i * INCY] = X[i * INCX];     } }  int main() {          int arraySize = 4;     float sourceArray[] = {1.1, 2.2, 3.3, 4.4};     float destinationArray[arraySize];     int INCX = 1;     int INCY = 2;      printf(\"\u6e90\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", sourceArray[i]);     }           copy_cpu(arraySize, sourceArray, INCX, destinationArray, INCY);      printf(\"\\n\u590d\u5236\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", destinationArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void copy_kernel(int N, float* X, int OFFX, int INCX, float* Y, int OFFY, int INCY) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N) {         Y[i * INCY + OFFY] = X[i * INCX + OFFX];     } }  int main() {          const int arraySize = 1000;           float* h_X = (float*)malloc(arraySize * sizeof(float));     float* h_Y = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_X[i] = static_cast<float>(i);     }           float* d_X;     float* d_Y;     cudaMalloc((void**)&d_X, arraySize * sizeof(float));     cudaMalloc((void**)&d_Y, arraySize * sizeof(float));           cudaMemcpy(d_X, h_X, arraySize * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);           copy_kernel<<<gridSize, blockSize>>>(arraySize, d_X, 0, 1, d_Y, 0, 1);           cudaMemcpy(h_Y, d_Y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_Y[i]);     }           free(h_X);     free(h_Y);     cudaFree(d_X);     cudaFree(d_Y);      return 0; } "
    },
    {
        "id": "5",
        "c_code": "#include <stdio.h>  void scale_host(float *array, float scale, int N) {     for (int idx = 0; idx < N; idx++) {         array[idx] *= scale;     } }  int main() {          int numElements = 5;     float array[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float scale_factor = 2.0;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", array[i]);     }           scale_host(array, scale_factor, numElements);      printf(\"\\n\u7f29\u653e\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void scale_dev(float* array, float scale, int N) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;     if (idx < N) {         array[idx] *= scale;     } }  int main() {          int arraySize = 1000;           float scale = 1.5f;           float* h_array = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_array[i] = static_cast<float>(i);     }           float* d_array;     cudaMalloc((void**)&d_array, arraySize * sizeof(float));           cudaMemcpy(d_array, h_array, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           scale_dev<<<gridSize, blockSize>>>(d_array, scale, arraySize);           cudaMemcpy(h_array, d_array, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_array[i]);     }           free(h_array);     cudaFree(d_array);      return 0; } "
    },
    {
        "id": "50",
        "c_code": "#include <stdio.h>  void clearLabel(float *prA, float *prB, unsigned int num_nodes, float base) {     for (unsigned int id = 0; id < num_nodes; id++) {         prA[id] = base + prA[id] * 0.85;         prB[id] = 0;     } }  int main() {          unsigned int numNodes = 5;     float prAArray[] = {0.1, 0.2, 0.3, 0.4, 0.5};     float prBArray[numNodes];     float baseValue = 0.05;      printf(\"prA \u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < numNodes; i++) {         printf(\"%.2f \", prAArray[i]);     }           clearLabel(prAArray, prBArray, numNodes, baseValue);      printf(\"\\n\u6e05\u96f6\u540e\u7684 prA \u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < numNodes; i++) {         printf(\"%.2f \", prAArray[i]);     }      printf(\"\\n\u6e05\u96f6\u540e\u7684 prB \u6570\u7ec4\uff1a\");     for (unsigned int i = 0; i < numNodes; i++) {         printf(\"%.2f \", prBArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void clearLabel(float* prA, float* prB, unsigned int num_nodes, float base) {     unsigned int id = blockDim.x * blockIdx.x + threadIdx.x;     if (id < num_nodes) {         prA[id] = base + prA[id] * 0.85;         prB[id] = 0;     } }  int main() {          const unsigned int num_nodes = 1000;           float* h_prA = (float*)malloc(num_nodes * sizeof(float));     float* h_prB = (float*)malloc(num_nodes * sizeof(float));           for (unsigned int i = 0; i < num_nodes; ++i) {         h_prA[i] = static_cast<float>(i);         h_prB[i] = static_cast<float>(2 * i);     }           float* d_prA;     float* d_prB;     cudaMalloc((void**)&d_prA, num_nodes * sizeof(float));     cudaMalloc((void**)&d_prB, num_nodes * sizeof(float));           cudaMemcpy(d_prA, h_prA, num_nodes * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_prB, h_prB, num_nodes * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((num_nodes + blockSize.x - 1) / blockSize.x, 1);           clearLabel<<<gridSize, blockSize>>>(d_prA, d_prB, num_nodes, 1.0);           cudaMemcpy(h_prA, d_prA, num_nodes * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_prB, d_prB, num_nodes * sizeof(float), cudaMemcpyDeviceToHost);           for (unsigned int i = 0; i < 10; ++i) {         printf(\"prA[%u]: %f, prB[%u]: %f\\n\", i, h_prA[i], i, h_prB[i]);     }           free(h_prA);     free(h_prB);     cudaFree(d_prA);     cudaFree(d_prB);      return 0; } "
    },
    {
        "id": "51",
        "c_code": "#include <stdio.h>  void delay_kernel_cpu(int *N_mobil, int *Tau, int dia) {     int N = N_mobil[0];     for (int id = 0; id < N; id++) {         if (Tau[id] > 0) {             Tau[id] = Tau[id] - 1;         }     } }  int main() {          int numElements = 5;     int N_mobilArray[] = {numElements};     int TauArray[] = {2, 0, 4, 1, 0};     int diaValue = 0;      printf(\"Tau \u6570\u7ec4\uff08\u521d\u59cb\uff09\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", TauArray[i]);     }           delay_kernel_cpu(N_mobilArray, TauArray, diaValue);      printf(\"\\n\u5ef6\u8fdf\u540e\u7684 Tau \u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", TauArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void delay_kernel(int* N_mobil, int* Tau, int dia) {     int N = N_mobil[0];     int id = blockIdx.x * blockDim.x + threadIdx.x;     if (id < N) {         if (Tau[id] > 0) {             Tau[id] = Tau[id] - 1;         }     } }  int main() {          const int N = 1000;           int* h_N_mobil = (int*)malloc(sizeof(int));     int* h_Tau = (int*)malloc(N * sizeof(int));           h_N_mobil[0] = N;     for (int i = 0; i < N; ++i) {         h_Tau[i] = static_cast<int>(i);     }           int* d_N_mobil;     int* d_Tau;     cudaMalloc((void**)&d_N_mobil, sizeof(int));     cudaMalloc((void**)&d_Tau, N * sizeof(int));           cudaMemcpy(d_N_mobil, h_N_mobil, sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_Tau, h_Tau, N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           delay_kernel<<<gridSize, blockSize>>>(d_N_mobil, d_Tau, 1);           cudaMemcpy(h_Tau, d_Tau, N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"Tau[%d]: %d\\n\", i, h_Tau[i]);     }           free(h_N_mobil);     free(h_Tau);     cudaFree(d_N_mobil);     cudaFree(d_Tau);      return 0; } "
    },
    {
        "id": "52",
        "c_code": "#include <stdio.h>  void resetHeap_cpu(int *heap, int *heapPtr, int numBlock) {     for (int index = 0; index < numBlock; index++) {         if (index == 0)             heapPtr[0] = numBlock - 1;         heap[index] = numBlock - index - 1;     } }  int main() {          int numBlocks = 4;     int heapArray[numBlocks];     int heapPtrArray[] = {0};      printf(\"\u521d\u59cb\u7684 heap \u6570\u7ec4\uff1a\");     for (int i = 0; i < numBlocks; i++) {         printf(\"%d \", heapArray[i]);     }      printf(\"\\n\u521d\u59cb\u7684 heapPtr \u6570\u7ec4\uff1a%d\", heapPtrArray[0]);           resetHeap_cpu(heapArray, heapPtrArray, numBlocks);      printf(\"\\n\u91cd\u7f6e\u540e\u7684 heap \u6570\u7ec4\uff1a\");     for (int i = 0; i < numBlocks; i++) {         printf(\"%d \", heapArray[i]);     }      printf(\"\\n\u91cd\u7f6e\u540e\u7684 heapPtr \u6570\u7ec4\uff1a%d\", heapPtrArray[0]);      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void delay_kernel(int* N_mobil, int* Tau, int dia) {     int N = N_mobil[0];     int id = blockIdx.x * blockDim.x + threadIdx.x;     if (id < N) {         if (Tau[id] > 0) {             Tau[id] = Tau[id] - 1;         }     } }  int main() {          const int N = 1000;           int* h_N_mobil = (int*)malloc(sizeof(int));     int* h_Tau = (int*)malloc(N * sizeof(int));           h_N_mobil[0] = N;     for (int i = 0; i < N; ++i) {         h_Tau[i] = static_cast<int>(i);     }           int* d_N_mobil;     int* d_Tau;     cudaMalloc((void**)&d_N_mobil, sizeof(int));     cudaMalloc((void**)&d_Tau, N * sizeof(int));           cudaMemcpy(d_N_mobil, h_N_mobil, sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_Tau, h_Tau, N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           delay_kernel<<<gridSize, blockSize>>>(d_N_mobil, d_Tau, 1);           cudaMemcpy(h_Tau, d_Tau, N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"Tau[%d]: %d\\n\", i, h_Tau[i]);     }           free(h_N_mobil);     free(h_Tau);     cudaFree(d_N_mobil);     cudaFree(d_Tau);      return 0; } "
    },
    {
        "id": "53",
        "c_code": "#include <stdio.h> #include <math.h>  void pow_cpu(int N, float ALPHA, float *X, int INCX, float *Y, int INCY) {     for (int i = 0; i < N; ++i) {         Y[i * INCY] = pow(X[i * INCX], ALPHA);     } }  int main() {          int arraySize = 4;     float inputArray[] = {2.0, 3.0, 4.0, 5.0};     float outputArray[arraySize];     float alphaValue = 3.0;      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           pow_cpu(arraySize, alphaValue, inputArray, 1, outputArray, 1);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h> #include <cmath>  __global__ void pow_kernel(int N, float ALPHA, float* X, int INCX, float* Y, int INCY) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;     if (i < N) {         Y[i * INCY] = pow(X[i * INCX], ALPHA);     } }  int main() {          const int N = 1000;           float* h_X = (float*)malloc(N * sizeof(float));     float* h_Y = (float*)malloc(N * sizeof(float));           for (int i = 0; i < N; ++i) {         h_X[i] = static_cast<float>(i);     }           float* d_X;     float* d_Y;     cudaMalloc((void**)&d_X, N * sizeof(float));     cudaMalloc((void**)&d_Y, N * sizeof(float));           cudaMemcpy(d_X, h_X, N * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           pow_kernel<<<gridSize, blockSize>>>(N, 2.0, d_X, 1, d_Y, 1);           cudaMemcpy(h_Y, d_Y, N * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"Y[%d]: %f\\n\", i, h_Y[i]);     }           free(h_X);     free(h_Y);     cudaFree(d_X);     cudaFree(d_Y);      return 0; } "
    },
    {
        "id": "54",
        "c_code": "#include <stdio.h> #include <math.h>  void kComputeActs(const float *d_nets, float *d_acts, int size) {     for (int un_idx = 0; un_idx < size; un_idx++) {         float tact = 1.0f / (1.0f + expf(-d_nets[un_idx]));         d_acts[un_idx] = tact;     } }  int main() {          int arraySize = 5;     float netsArray[] = {0.5, -1.0, 1.5, -2.0, 2.5};     float actsArray[arraySize];      printf(\"\u8f93\u5165\u6570\u7ec4\uff08nets\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", netsArray[i]);     }           kComputeActs(netsArray, actsArray, arraySize);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff08acts\uff09\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.4f \", actsArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h> #include <cmath>  __global__ void kComputeActs(const float* d_nets, float* d_acts) {     int un_idx = blockIdx.x * blockDim.x + threadIdx.x;     float tact = 1.0f / (1.0f + expf(-d_acts[un_idx]));     __syncthreads();     d_acts[un_idx] = tact; }  int main() {          const int N = 1000;           float* h_nets = (float*)malloc(N * sizeof(float));     float* h_acts = (float*)malloc(N * sizeof(float));           for (int i = 0; i < N; ++i) {         h_nets[i] = static_cast<float>(i);         h_acts[i] = static_cast<float>(i);     }           float* d_nets;     float* d_acts;     cudaMalloc((void**)&d_nets, N * sizeof(float));     cudaMalloc((void**)&d_acts, N * sizeof(float));           cudaMemcpy(d_nets, h_nets, N * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_acts, h_acts, N * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           kComputeActs<<<gridSize, blockSize>>>(d_nets, d_acts);           cudaMemcpy(h_acts, d_acts, N * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"acts[%d]: %f\\n\", i, h_acts[i]);     }           free(h_nets);     free(h_acts);     cudaFree(d_nets);     cudaFree(d_acts);      return 0; } "
    },
    {
        "id": "55",
        "c_code": "#include <stdio.h>  void transpositionCPU(int *vector, int *transposed, int size) {     for (int i = 0; i < size; i++) {         for (int j = 0; j < size; j++) {             transposed[i + j * size] = vector[j + i * size];         }     } }  int main() {          int matrixSize = 3;     int inputMatrix[] = {1, 2, 3, 4, 5, 6, 7, 8, 9};     int transposedMatrix[matrixSize * matrixSize];      printf(\"\u8f93\u5165\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < matrixSize; i++) {         for (int j = 0; j < matrixSize; j++) {             printf(\"%d \", inputMatrix[i * matrixSize + j]);         }         printf(\"\\n\");     }           transpositionCPU(inputMatrix, transposedMatrix, matrixSize);      printf(\"\\n\u8f6c\u7f6e\u540e\u7684\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < matrixSize; i++) {         for (int j = 0; j < matrixSize; j++) {             printf(\"%d \", transposedMatrix[i * matrixSize + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void transposeNaive(int* vector, int* transposed, int size) {     int column = threadIdx.x + blockDim.x * blockIdx.x;     int row = threadIdx.y + blockDim.y * blockIdx.y;      if (row < size && column < size) {         transposed[row + column * size] = vector[column + row * size];     } }  int main() {          const int size = 4;           int* h_vector = (int*)malloc(size * size * sizeof(int));     int* h_transposed = (int*)malloc(size * size * sizeof(int));           for (int i = 0; i < size * size; ++i) {         h_vector[i] = i;     }           int* d_vector;     int* d_transposed;     cudaMalloc((void**)&d_vector, size * size * sizeof(int));     cudaMalloc((void**)&d_transposed, size * size * sizeof(int));           cudaMemcpy(d_vector, h_vector, size * size * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(2, 2);       dim3 gridSize((size + blockSize.x - 1) / blockSize.x, (size + blockSize.y - 1) / blockSize.y);           transposeNaive<<<gridSize, blockSize>>>(d_vector, d_transposed, size);           cudaMemcpy(h_transposed, d_transposed, size * size * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Original Matrix:\\n\");     for (int i = 0; i < size; ++i) {         for (int j = 0; j < size; ++j) {             printf(\"%d\\t\", h_vector[j + i * size]);         }         printf(\"\\n\");     }           printf(\"\\nTransposed Matrix:\\n\");     for (int i = 0; i < size; ++i) {         for (int j = 0; j < size; ++j) {             printf(\"%d\\t\", h_transposed[j + i * size]);         }         printf(\"\\n\");     }           free(h_vector);     free(h_transposed);     cudaFree(d_vector);     cudaFree(d_transposed);      return 0; } "
    },
    {
        "id": "56",
        "c_code": "#include <stdio.h>  void compute_array_square(float *array, float *outArray, int size) {     for (int i = 0; i < size; i++) {         outArray[i] = array[i] * array[i];     } }  int main() {          int arraySize = 4;     float inputArray[] = {2.0, 3.0, 4.0, 5.0};     float outputArray[arraySize];      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", inputArray[i]);     }           compute_array_square(inputArray, outputArray, arraySize);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%.2f \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void compute_array_square(float* array, float* outArray, int size) {     int thread_index = threadIdx.x + blockIdx.x * blockDim.x;     int num_threads = blockDim.x * gridDim.x;      for (int i = 0; i < size; i += num_threads) {         int index = i + thread_index;          if (index < size) {             outArray[index] = array[index] * array[index];         }     } }  int main() {          const int size = 1000;           float* h_array = (float*)malloc(size * sizeof(float));     float* h_outArray = (float*)malloc(size * sizeof(float));           for (int i = 0; i < size; ++i) {         h_array[i] = static_cast<float>(i);     }           float* d_array;     float* d_outArray;     cudaMalloc((void**)&d_array, size * sizeof(float));     cudaMalloc((void**)&d_outArray, size * sizeof(float));           cudaMemcpy(d_array, h_array, size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((size + blockSize.x - 1) / blockSize.x, 1);           compute_array_square<<<gridSize, blockSize>>>(d_array, d_outArray, size);           cudaMemcpy(h_outArray, d_outArray, size * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"outArray[%d]: %f\\n\", i, h_outArray[i]);     }           free(h_array);     free(h_outArray);     cudaFree(d_array);     cudaFree(d_outArray);      return 0; } "
    },
    {
        "id": "57",
        "c_code": "#include <stdio.h>  void testInt1_cpu(const int *input, int dims) {     for (int tid = 0; tid < dims; tid++) {         int sum = 0;         for (int i = 0; i < 3000 * 4; i++) {             if (input[i] == 0) {                 sum++;             }         }     } }  int main() {          int arraySize = 3000 * 4;     int inputArray[arraySize];           for (int i = 0; i < arraySize; i++) {         inputArray[i] = 0;     }           testInt1_cpu(inputArray, arraySize);      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void testInt1(const int* input, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      int sum = 0;      for (int i = 0; i < 3000 * 4; i++) {         if (input[i] == 0) {             sum++;         }     } }  int main() {          const int dims = 3000 * 4;           int* h_input = (int*)malloc(dims * sizeof(int));           for (int i = 0; i < dims; ++i) {         h_input[i] = i % 2;      }           int* d_input;     cudaMalloc((void**)&d_input, dims * sizeof(int));           cudaMemcpy(d_input, h_input, dims * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((dims + blockSize.x - 1) / blockSize.x, 1);           testInt1<<<gridSize, blockSize>>>(d_input, dims);           cudaDeviceSynchronize();           free(h_input);     cudaFree(d_input);      return 0; } "
    },
    {
        "id": "58",
        "c_code": "#include <stdio.h>  void incKernel(int *g_out, int *g_in, int N, int inner_reps) {     for (int idx = 0; idx < N; idx++) {         for (int i = 0; i < inner_reps; ++i) {             g_out[idx] = g_in[idx] + 1;         }     } }  int main() {          int arraySize = 5;     int inputArray[] = {1, 2, 3, 4, 5};     int outputArray[arraySize];      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", inputArray[i]);     }           incKernel(outputArray, inputArray, arraySize, 3);      printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void incKernel(int* g_out, const int* g_in, int N, int inner_reps) {     int idx = blockIdx.x * blockDim.x + threadIdx.x;      if (idx < N) {         for (int i = 0; i < inner_reps; ++i) {             g_out[idx] = g_in[idx] + 1;         }     } }  int main() {          const int N = 1000;     const int inner_reps = 1000;           int* h_in = (int*)malloc(N * sizeof(int));     int* h_out = (int*)malloc(N * sizeof(int));           for (int i = 0; i < N; ++i) {         h_in[i] = i;     }           int* d_in;     int* d_out;     cudaMalloc((void**)&d_in, N * sizeof(int));     cudaMalloc((void**)&d_out, N * sizeof(int));           cudaMemcpy(d_in, h_in, N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           incKernel<<<gridSize, blockSize>>>(d_out, d_in, N, inner_reps);           cudaMemcpy(h_out, d_out, N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_out[%d]: %d\\n\", i, h_out[i]);     }           free(h_in);     free(h_out);     cudaFree(d_in);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "59",
        "c_code": "#include <stdio.h>  void forward_dropout_layer(int batch, int inputs, float *input, float probability, float *rand, float scale) {     for (int i = 0; i < batch * inputs; ++i) {         if (rand[i] < probability) {             input[i] = 0;         } else {             input[i] *= scale;         }     } }  int main() {          int batchSize = 2;     int inputSize = 3;     float inputArray[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};     float randArray[] = {0.2, 0.8, 0.4, 0.1, 0.9, 0.5};     float probability = 0.5;     float scale = 2.0;      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < batchSize * inputSize; i++) {         printf(\"%.2f \", inputArray[i]);     }           forward_dropout_layer(batchSize, inputSize, inputArray, probability, randArray, scale);      printf(\"\\n\u5904\u7406\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < batchSize * inputSize; i++) {         printf(\"%.2f \", inputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <curand_kernel.h> #include <stdio.h>  __global__ void forward_dropout_layer(float* input, int size, float* rand, float prob, float scale) {     int id = blockIdx.x * blockDim.x + threadIdx.x;      if (id < size) {         input[id] = (rand[id] < prob) ? 0 : input[id] * scale;     } }  int main() {          const int size = 1000;           float* h_input = (float*)malloc(size * sizeof(float));     float* h_rand = (float*)malloc(size * sizeof(float));           for (int i = 0; i < size; ++i) {         h_input[i] = static_cast<float>(i);         h_rand[i] = static_cast<float>(i) / size;      }           float* d_input;     float* d_rand;     cudaMalloc((void**)&d_input, size * sizeof(float));     cudaMalloc((void**)&d_rand, size * sizeof(float));           cudaMemcpy(d_input, h_input, size * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_rand, h_rand, size * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((size + blockSize.x - 1) / blockSize.x, 1);           forward_dropout_layer<<<gridSize, blockSize>>>(d_input, size, d_rand, 0.5f, 2.0f);           cudaMemcpy(h_input, d_input, size * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_input[%d]: %f\\n\", i, h_input[i]);     }           free(h_input);     free(h_rand);     cudaFree(d_input);     cudaFree(d_rand);      return 0; } "
    },
    {
        "id": "6",
        "c_code": "#include <stdio.h>  void allAddInplace_cpu(double *arr, double alpha, int n) {     for (int i = 0; i < n; i++) {         arr[i] += alpha;     } }  int main() {          int numElements = 5;     double array[] = {1.1, 2.2, 3.3, 4.4, 5.5};     double alpha = 10.0;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", array[i]);     }           allAddInplace_cpu(array, alpha, numElements);      printf(\"\\n\u6240\u6709\u5143\u7d20\u52a0\u4e0a\u5e38\u6570\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%.2f \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void allAddInplaceKernel(double* arr, double alpha, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     if (i < n) {         arr[i] += alpha;     } }  int main() {          int arraySize = 1000;           double alpha = 5.0;           double* h_arr = (double*)malloc(arraySize * sizeof(double));           for (int i = 0; i < arraySize; ++i) {         h_arr[i] = static_cast<double>(i);     }           double* d_arr;     cudaMalloc((void**)&d_arr, arraySize * sizeof(double));           cudaMemcpy(d_arr, h_arr, arraySize * sizeof(double), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           allAddInplaceKernel<<<gridSize, blockSize>>>(d_arr, alpha, arraySize);           cudaMemcpy(h_arr, d_arr, arraySize * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_arr[i]);     }           free(h_arr);     cudaFree(d_arr);      return 0; } "
    },
    {
        "id": "60",
        "c_code": "#include <stdio.h>  void boundaryCorrectIndexes_cpu(int *d_in, int *d_out, int length, int N) {     for (int idx = 0; idx < length; idx++) {         if (d_in[idx] > N) {             d_out[idx] = N;         } else {             d_out[idx] = d_in[idx];         }     } }  int main() {          int arraySize = 5;     int inputArray[] = {2, 8, 5, 12, 6};     int outputArray[arraySize];     int boundaryValue = 10;      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", inputArray[i]);     }           boundaryCorrectIndexes_cpu(inputArray, outputArray, arraySize, boundaryValue);      printf(\"\\n\u5904\u7406\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void boundaryCorrectIndexesKernel(int* d_in, int* d_out, int length, int N) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid < length) {         if (d_in[tid] > N) {             d_out[tid] = N;         } else {             d_out[tid] = d_in[tid];         }     } }  int main() {          const int length = 1000;     const int N = 500;           int* h_in = (int*)malloc(length * sizeof(int));     int* h_out = (int*)malloc(length * sizeof(int));           for (int i = 0; i < length; ++i) {         h_in[i] = i * 2;      }           int* d_in;     int* d_out;     cudaMalloc((void**)&d_in, length * sizeof(int));     cudaMalloc((void**)&d_out, length * sizeof(int));           cudaMemcpy(d_in, h_in, length * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((length + blockSize.x - 1) / blockSize.x, 1);           boundaryCorrectIndexesKernel<<<gridSize, blockSize>>>(d_in, d_out, length, N);           cudaMemcpy(h_out, d_out, length * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_out[%d]: %d\\n\", i, h_out[i]);     }           free(h_in);     free(h_out);     cudaFree(d_in);     cudaFree(d_out);      return 0; } "
    },
    {
        "id": "61",
        "c_code": "#include <stdio.h>  void upsweep_scan(int twod, int N, int *output) {     int twod1 = twod * 2;     int idx;     for (idx = 0; idx + twod1 - 1 < N; idx += twod1) {         output[idx + twod1 - 1] += output[idx + twod - 1];     } }  int main() {          int arraySize = 8;     int outputArray[] = {1, 2, 3, 4, 5, 6, 7, 8};     int twodValue = 1;      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", outputArray[i]);     }           upsweep_scan(twodValue, arraySize, outputArray);      printf(\"\\n\u5904\u7406\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < arraySize; i++) {         printf(\"%d \", outputArray[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void upsweep_scan(int twod, int N, int* output) {     int twod1 = twod * 2;     int idx = (blockIdx.x * blockDim.x + threadIdx.x) * twod1;      if (idx + twod1 - 1 < N) {         output[idx + twod1 - 1] += output[idx + twod - 1];     } }  int main() {          const int N = 1000;     const int twod = 32;             int* h_output = (int*)malloc(N * sizeof(int));           for (int i = 0; i < N; ++i) {         h_output[i] = i * 2;       }           int* d_output;     cudaMalloc((void**)&d_output, N * sizeof(int));           cudaMemcpy(d_output, h_output, N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           upsweep_scan<<<gridSize, blockSize>>>(twod, N, d_output);           cudaMemcpy(h_output, d_output, N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_output[%d]: %d\\n\", i, h_output[i]);     }           free(h_output);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "62",
        "c_code": "#include <stdio.h>  void Blend_CPU(unsigned char *aImg1, unsigned char *aImg2, unsigned char *aRS, int width, int height) {     for (int i = 0; i < width * height; ++i) {         aRS[i] = (unsigned char)(0.5 * aImg1[i] + 0.5 * aImg2[i]);     } }  int main() {          int width = 2;     int height = 2;     unsigned char img1[] = {100, 150, 200, 255};     unsigned char img2[] = {50, 75, 100, 255};     unsigned char result[width * height];      printf(\"\u8f93\u5165\u56fe\u50cf1\uff1a\");     for (int i = 0; i < width * height; i++) {         printf(\"%d \", img1[i]);     }      printf(\"\\n\u8f93\u5165\u56fe\u50cf2\uff1a\");     for (int i = 0; i < width * height; i++) {         printf(\"%d \", img2[i]);     }           Blend_CPU(img1, img2, result, width, height);      printf(\"\\n\u6df7\u5408\u540e\u7684\u56fe\u50cf\uff1a\");     for (int i = 0; i < width * height; i++) {         printf(\"%d \", result[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void Blending_Kernel(unsigned char* aR1, unsigned char* aR2, unsigned char* aRS, int size) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < size) {         aRS[index] = 0.5 * aR1[index] + 0.5 * aR2[index];     } }  int main() {          const int size = 1000;           unsigned char* h_aR1 = (unsigned char*)malloc(size * sizeof(unsigned char));     unsigned char* h_aR2 = (unsigned char*)malloc(size * sizeof(unsigned char));     unsigned char* h_aRS = (unsigned char*)malloc(size * sizeof(unsigned char));           for (int i = 0; i < size; ++i) {         h_aR1[i] = static_cast<unsigned char>(i * 2);          h_aR2[i] = static_cast<unsigned char>(i * 3);      }           unsigned char* d_aR1;     unsigned char* d_aR2;     unsigned char* d_aRS;     cudaMalloc((void**)&d_aR1, size * sizeof(unsigned char));     cudaMalloc((void**)&d_aR2, size * sizeof(unsigned char));     cudaMalloc((void**)&d_aRS, size * sizeof(unsigned char));           cudaMemcpy(d_aR1, h_aR1, size * sizeof(unsigned char), cudaMemcpyHostToDevice);     cudaMemcpy(d_aR2, h_aR2, size * sizeof(unsigned char), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((size + blockSize.x - 1) / blockSize.x, 1);           Blending_Kernel<<<gridSize, blockSize>>>(d_aR1, d_aR2, d_aRS, size);           cudaMemcpy(h_aRS, d_aRS, size * sizeof(unsigned char), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_aRS[%d]: %u\\n\", i, h_aRS[i]);     }           free(h_aR1);     free(h_aR2);     free(h_aRS);     cudaFree(d_aR1);     cudaFree(d_aR2);     cudaFree(d_aRS);      return 0; } "
    },
    {
        "id": "63",
        "c_code": "#include <stdio.h>  void matVecRowSubInplace_cpu(double *mat, const double *vec, int m, int n) {     for (int index = 0; index < m * n; index++) {         int i = index / n;         int j = index % n;         mat[i * n + j] -= vec[j];     } }  int main() {          int rows = 3;     int cols = 4;     double matrix[] = {1.0, 2.0, 3.0, 4.0,                        5.0, 6.0, 7.0, 8.0,                        9.0, 10.0, 11.0, 12.0};      double vector[] = {0.5, 1.0, 1.5, 2.0};      printf(\"\u8f93\u5165\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < rows; i++) {         for (int j = 0; j < cols; j++) {             printf(\"%.2f \", matrix[i * cols + j]);         }         printf(\"\\n\");     }           matVecRowSubInplace_cpu(matrix, vector, rows, cols);      printf(\"\\n\u51cf\u53bb\u5411\u91cf\u540e\u7684\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < rows; i++) {         for (int j = 0; j < cols; j++) {             printf(\"%.2f \", matrix[i * cols + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void matVecRowSubInplaceKernel(double* mat, const double* vec, int m, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < m * n) {         int i = index / n;         int j = index % n;         mat[i * n + j] -= vec[j];     } }  int main() {          const int m = 5;     const int n = 3;           double* h_mat = (double*)malloc(m * n * sizeof(double));     double* h_vec = (double*)malloc(n * sizeof(double));           for (int i = 0; i < m * n; ++i) {         h_mat[i] = static_cast<double>(i);      }      for (int i = 0; i < n; ++i) {         h_vec[i] = static_cast<double>(i * 2);      }           double* d_mat;     double* d_vec;     cudaMalloc((void**)&d_mat, m * n * sizeof(double));     cudaMalloc((void**)&d_vec, n * sizeof(double));           cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec, h_vec, n * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((m * n + blockSize.x - 1) / blockSize.x, 1);           matVecRowSubInplaceKernel<<<gridSize, blockSize>>>(d_mat, d_vec, m, n);           cudaMemcpy(h_mat, d_mat, m * n * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < m; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"h_mat[%d][%d]: %f\\n\", i, j, h_mat[i * n + j]);         }     }           free(h_mat);     free(h_vec);     cudaFree(d_mat);     cudaFree(d_vec);      return 0; } "
    },
    {
        "id": "64",
        "c_code": "#include <stdio.h>  void matVecColAddInplace_cpu(double *mat, const double *vec, int m, int n) {     for (int index = 0; index < m * n; index++) {         int i = index / n;         int j = index % n;         mat[i * n + j] += vec[i];     } }  int main() {          int rows = 3;     int cols = 4;     double matrix[] = {1.0, 2.0, 3.0, 4.0,                        5.0, 6.0, 7.0, 8.0,                        9.0, 10.0, 11.0, 12.0};      double vector[] = {0.5, 1.0, 1.5};      printf(\"\u8f93\u5165\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < rows; i++) {         for (int j = 0; j < cols; j++) {             printf(\"%.2f \", matrix[i * cols + j]);         }         printf(\"\\n\");     }           matVecColAddInplace_cpu(matrix, vector, rows, cols);      printf(\"\\n\u6bcf\u5217\u52a0\u4e0a\u5411\u91cf\u540e\u7684\u77e9\u9635\uff1a\\n\");     for (int i = 0; i < rows; i++) {         for (int j = 0; j < cols; j++) {             printf(\"%.2f \", matrix[i * cols + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void matVecColAddInplaceKernel(double* mat, const double* vec, int m, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < m * n) {         int i = index / n;         int j = index % n;         mat[i * n + j] += vec[i];     } }  int main() {          const int m = 5;     const int n = 3;           double* h_mat = (double*)malloc(m * n * sizeof(double));     double* h_vec = (double*)malloc(m * sizeof(double));           for (int i = 0; i < m * n; ++i) {         h_mat[i] = static_cast<double>(i);      }      for (int i = 0; i < m; ++i) {         h_vec[i] = static_cast<double>(i * 2);      }           double* d_mat;     double* d_vec;     cudaMalloc((void**)&d_mat, m * n * sizeof(double));     cudaMalloc((void**)&d_vec, m * sizeof(double));           cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_vec, h_vec, m * sizeof(double), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((m * n + blockSize.x - 1) / blockSize.x, 1);           matVecColAddInplaceKernel<<<gridSize, blockSize>>>(d_mat, d_vec, m, n);           cudaMemcpy(h_mat, d_mat, m * n * sizeof(double), cudaMemcpyDeviceToHost);           for (int i = 0; i < m; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"h_mat[%d][%d]: %f\\n\", i, j, h_mat[i * n + j]);         }     }           free(h_mat);     free(h_vec);     cudaFree(d_mat);     cudaFree(d_vec);      return 0; } "
    },
    {
        "id": "65",
        "c_code": "#include <stdio.h>  void MMDOuterProdComputeWithSum(float *x_average, int size_x, float *x_outer_prod) {     for (int i = 0; i < size_x; i++) {         x_outer_prod[i] = x_average[i] * x_average[i];     } }  int main() {          int size = 4;     float averageValues[] = {1.5, 2.0, 3.5, 4.0};     float outerProdResult[size];      printf(\"\u5e73\u5747\u503c\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", averageValues[i]);     }           MMDOuterProdComputeWithSum(averageValues, size, outerProdResult);      printf(\"\\n\u5916\u79ef\u7ed3\u679c\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", outerProdResult[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void MMDOuterProdComputeWithSum(float* x_average, int size_x, float* x_outer_prod) {     int block_id = blockIdx.x;     int thread_id = threadIdx.x;      for (int i = block_id * blockDim.x + thread_id; i < size_x; i += gridDim.x * blockDim.x) {         x_outer_prod[i] = x_average[i] * x_average[i];     } }  int main() {          const int size_x = 100;           float* h_x_average = (float*)malloc(size_x * sizeof(float));     float* h_x_outer_prod = (float*)malloc(size_x * sizeof(float));           for (int i = 0; i < size_x; ++i) {         h_x_average[i] = static_cast<float>(i);      }           float* d_x_average;     float* d_x_outer_prod;     cudaMalloc((void**)&d_x_average, size_x * sizeof(float));     cudaMalloc((void**)&d_x_outer_prod, size_x * sizeof(float));           cudaMemcpy(d_x_average, h_x_average, size_x * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((size_x + blockSize.x - 1) / blockSize.x, 1);           MMDOuterProdComputeWithSum<<<gridSize, blockSize>>>(d_x_average, size_x, d_x_outer_prod);           cudaMemcpy(h_x_outer_prod, d_x_outer_prod, size_x * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < size_x; ++i) {         printf(\"h_x_outer_prod[%d]: %f\\n\", i, h_x_outer_prod[i]);     }           free(h_x_average);     free(h_x_outer_prod);     cudaFree(d_x_average);     cudaFree(d_x_outer_prod);      return 0; } "
    },
    {
        "id": "66",
        "c_code": "#include <stdio.h>  void saxpy_cpu(float *vecY, float *vecX, float alpha, int n) {     for (int i = 0; i < n; i++) {         vecY[i] = alpha * vecX[i] + vecY[i];     } }  int main() {          int size = 5;     float vecY[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float vecX[] = {0.5, 1.0, 1.5, 2.0, 2.5};     float alpha = 2.0;      printf(\"\u8f93\u5165\u5411\u91cf vecY\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", vecY[i]);     }      printf(\"\\n\u8f93\u5165\u5411\u91cf vecX\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", vecX[i]);     }           saxpy_cpu(vecY, vecX, alpha, size);      printf(\"\\n\u6267\u884c saxpy \u540e\u7684\u5411\u91cf vecY\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", vecY[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void saxpy_gpu(float* vecY, float* vecX, float alpha, int n) {     int x, y, i;     x = blockIdx.x * blockDim.x + threadIdx.x;     y = blockIdx.y * blockDim.y + threadIdx.y;     i = y * 1024 + x;      if (i < n) {         vecY[i] = alpha * vecX[i] + vecY[i];     } }  int main() {          const int n = 1024 * 1024;           float* h_vecY = (float*)malloc(n * sizeof(float));     float* h_vecX = (float*)malloc(n * sizeof(float));           for (int i = 0; i < n; ++i) {         h_vecY[i] = static_cast<float>(i);          h_vecX[i] = static_cast<float>(i * 2);      }           float* d_vecY;     float* d_vecX;     cudaMalloc((void**)&d_vecY, n * sizeof(float));     cudaMalloc((void**)&d_vecX, n * sizeof(float));           cudaMemcpy(d_vecY, h_vecY, n * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_vecX, h_vecX, n * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(32, 32);      dim3 gridSize((n + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);           saxpy_gpu<<<gridSize, blockSize>>>(d_vecY, d_vecX, 2.0f, n);           cudaMemcpy(h_vecY, d_vecY, n * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_vecY[%d]: %f\\n\", i, h_vecY[i]);     }           free(h_vecY);     free(h_vecX);     cudaFree(d_vecY);     cudaFree(d_vecX);      return 0; } "
    },
    {
        "id": "67",
        "c_code": "#include <stdio.h>  void set_valid_mask_cpu(const float *score, float score_thr, int *valid_mask, int dims) {     for (int tid = 0; tid < dims; tid++) {         if (score[tid] > score_thr) {             valid_mask[tid] = 1;         } else {             valid_mask[tid] = 0;         }     } }  int main() {          int size = 6;     float scores[] = {0.8, 0.5, 0.9, 0.3, 0.7, 0.6};     float threshold = 0.6;     int validMask[size];      printf(\"\u8f93\u5165\u5206\u6570\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", scores[i]);     }           set_valid_mask_cpu(scores, threshold, validMask, size);      printf(\"\\n\u6709\u6548\u63a9\u7801\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%d \", validMask[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void set_valid_mask(const float* score, float score_thr, int* valid_mask, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid < dims) {         valid_mask[tid] = (score[tid] > score_thr) ? 1 : 0;     } }  int main() {          const int dims = 1024;           float* h_score = (float*)malloc(dims * sizeof(float));     int* h_valid_mask = (int*)malloc(dims * sizeof(int));           for (int i = 0; i < dims; ++i) {         h_score[i] = static_cast<float>(i);      }           float* d_score;     int* d_valid_mask;     cudaMalloc((void**)&d_score, dims * sizeof(float));     cudaMalloc((void**)&d_valid_mask, dims * sizeof(int));           cudaMemcpy(d_score, h_score, dims * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((dims + blockSize.x - 1) / blockSize.x, 1);           set_valid_mask<<<gridSize, blockSize>>>(d_score, 500.0f, d_valid_mask, dims);           cudaMemcpy(h_valid_mask, d_valid_mask, dims * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_valid_mask[%d]: %d\\n\", i, h_valid_mask[i]);     }           free(h_score);     free(h_valid_mask);     cudaFree(d_score);     cudaFree(d_valid_mask);      return 0; } "
    },
    {
        "id": "68",
        "c_code": "#include <stdio.h>  void copy_swap(float *f_in, float *f_target, const int L_x) {     for (int k_x = 0; k_x < L_x; k_x++) {         float tempval = 0.0f;         tempval = f_in[k_x];         f_in[k_x] = f_target[k_x];         f_target[k_x] = tempval;     } }  int main() {          int size = 5;     float array1[] = {1.0, 2.0, 3.0, 4.0, 5.0};     float array2[] = {10.0, 20.0, 30.0, 40.0, 50.0};      printf(\"\u6570\u7ec41\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", array1[i]);     }      printf(\"\\n\u6570\u7ec42\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", array2[i]);     }           copy_swap(array1, array2, size);      printf(\"\\n\u4ea4\u6362\u540e\u7684\u6570\u7ec41\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", array1[i]);     }      printf(\"\\n\u4ea4\u6362\u540e\u7684\u6570\u7ec42\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", array2[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void copy_swap(float* f_in, float* f_target, const int L_x) {     const int k_x = threadIdx.x + blockIdx.x * blockDim.x;      if (k_x < L_x) {         float tempval = f_in[k_x];         f_in[k_x] = f_target[k_x];         f_target[k_x] = tempval;     } }  int main() {          const int L_x = 1024;           float* h_f_in = (float*)malloc(L_x * sizeof(float));     float* h_f_target = (float*)malloc(L_x * sizeof(float));           for (int i = 0; i < L_x; ++i) {         h_f_in[i] = static_cast<float>(i);          h_f_target[i] = static_cast<float>(i * 2);      }           float* d_f_in;     float* d_f_target;     cudaMalloc((void**)&d_f_in, L_x * sizeof(float));     cudaMalloc((void**)&d_f_target, L_x * sizeof(float));           cudaMemcpy(d_f_in, h_f_in, L_x * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_f_target, h_f_target, L_x * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((L_x + blockSize.x - 1) / blockSize.x, 1);           copy_swap<<<gridSize, blockSize>>>(d_f_in, d_f_target, L_x);           cudaMemcpy(h_f_in, d_f_in, L_x * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_f_target, d_f_target, L_x * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_f_in[%d]: %f, h_f_target[%d]: %f\\n\", i, h_f_in[i], i, h_f_target[i]);     }           free(h_f_in);     free(h_f_target);     cudaFree(d_f_in);     cudaFree(d_f_target);      return 0; } "
    },
    {
        "id": "69",
        "c_code": "#include <stdio.h>  void sum_backward(float *db, float *dout, int r, int c) {     for (int j = 0; j < c; j++) {         for (int i = 0; i < r; i++) {             db[j] += dout[i * c + j];         }     } }  int main() {          int rows = 3;     int cols = 4;     float dout[] = {1.0, 2.0, 3.0, 4.0,                     5.0, 6.0, 7.0, 8.0,                     9.0, 10.0, 11.0, 12.0};     float db[cols];      printf(\"\u8f93\u5165 dout \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < rows; i++) {         for (int j = 0; j < cols; j++) {             printf(\"%.2f \", dout[i * cols + j]);         }         printf(\"\\n\");     }           for (int i = 0; i < cols; i++) {         db[i] = 0.0;     }           sum_backward(db, dout, rows, cols);      printf(\"\\n\u8ba1\u7b97\u540e\u7684 db \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < cols; i++) {         printf(\"%.2f \", db[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void Kernel_Sum_backward_opt2(float* db, float* sum, int r_sum, int c) {     unsigned int j = blockDim.x * blockIdx.x + threadIdx.x;      if (j >= c)         return;      float temp = 0;      for (int i = 0; i < r_sum; i++) {         temp += sum[i * c + j];     }      db[j] = temp; }  int main() {          const int r_sum = 100;       const int c = 50;                  float* h_db = (float*)malloc(c * sizeof(float));     float* h_sum = (float*)malloc(r_sum * c * sizeof(float));           for (int i = 0; i < r_sum * c; ++i) {         h_sum[i] = static_cast<float>(i);       }           float* d_db;     float* d_sum;     cudaMalloc((void**)&d_db, c * sizeof(float));     cudaMalloc((void**)&d_sum, r_sum * c * sizeof(float));           cudaMemcpy(d_sum, h_sum, r_sum * c * sizeof(float), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((c + blockSize.x - 1) / blockSize.x, 1);           Kernel_Sum_backward_opt2<<<gridSize, blockSize>>>(d_db, d_sum, r_sum, c);           cudaMemcpy(h_db, d_db, c * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"h_db[%d]: %f\\n\", i, h_db[i]);     }           free(h_db);     free(h_sum);     cudaFree(d_db);     cudaFree(d_sum);      return 0; } "
    },
    {
        "id": "7",
        "c_code": "#include <stdio.h>  void memsetCpuInt(int *data, int val, int N) {     for (int index = 0; index < N; index++) {         data[index] = val;     } }  int main() {          int numElements = 5;     int array[] = {1, 2, 3, 4, 5};     int value = 42;      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }           memsetCpuInt(array, value, numElements);      printf(\"\\n\u8bbe\u7f6e\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numElements; i++) {         printf(\"%d \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void memsetCudaInt(int* data, int val, int N) {     unsigned int index = blockDim.x * blockIdx.x + threadIdx.x;     if (index < N) {         data[index] = val;     } }  int main() {          int arraySize = 1000;           int initialValue = 42;           int* h_data = (int*)malloc(arraySize * sizeof(int));           int* d_data;     cudaMalloc((void**)&d_data, arraySize * sizeof(int));           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           memsetCudaInt<<<gridSize, blockSize>>>(d_data, initialValue, arraySize);           cudaMemcpy(h_data, d_data, arraySize * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_data[i]);     }           free(h_data);     cudaFree(d_data);      return 0; } "
    },
    {
        "id": "70",
        "c_code": "#include <stdio.h>  void is_repeat(int N, int *device_input, int *device_output) {     for (int idx = 0; idx < N; idx++) {         device_output[idx] = 0;         if (idx + 1 < N && device_input[idx] == device_input[idx + 1]) {             device_output[idx] = 1;         }     } }  int main() {          int size = 8;     int input[] = {1, 2, 2, 3, 4, 4, 4, 5};     int output[size];      printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%d \", input[i]);     }           is_repeat(size, input, output);      printf(\"\\n\u91cd\u590d\u4f4d\u7f6e\u6570\u7ec4\uff1a\");     for (int i = 0; i < size; i++) {         printf(\"%d \", output[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void is_repeat(int N, int* device_input, int* device_output) {     int idx = blockDim.x * blockIdx.x + threadIdx.x;      if (idx < N) {         device_output[idx] = 0;          if (idx + 1 < N && device_input[idx] == device_input[idx + 1])             device_output[idx] = 1;     } }  int main() {          const int N = 100;             int* h_device_input = (int*)malloc(N * sizeof(int));     int* h_device_output = (int*)malloc(N * sizeof(int));           for (int i = 0; i < N; ++i) {         h_device_input[i] = i % 10;       }           int* d_device_input;     int* d_device_output;     cudaMalloc((void**)&d_device_input, N * sizeof(int));     cudaMalloc((void**)&d_device_output, N * sizeof(int));           cudaMemcpy(d_device_input, h_device_input, N * sizeof(int), cudaMemcpyHostToDevice);           dim3 blockSize(256);     dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);           is_repeat<<<gridSize, blockSize>>>(N, d_device_input, d_device_output);           cudaMemcpy(h_device_output, d_device_output, N * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < N; ++i) {         printf(\"h_device_output[%d]: %d\\n\", i, h_device_output[i]);     }           free(h_device_input);     free(h_device_output);     cudaFree(d_device_input);     cudaFree(d_device_output);      return 0; } "
    },
    {
        "id": "71",
        "c_code": "#include <stdio.h>  void kmeans_average(int *means, int *counts, int BID, int DIM) {     for (int bid = 0; bid < BID; bid++) {         for (int tid = 0; tid < DIM; tid++) {             if (counts[bid] == 0) {                 means[bid * DIM + tid] = 0;             } else {                 means[bid * DIM + tid] /= counts[bid];             }         }     } }  int main() {          int BID = 3;     int DIM = 4;     int means[BID * DIM];     int counts[BID];           for (int i = 0; i < BID; i++) {         counts[i] = i + 1;           for (int j = 0; j < DIM; j++) {             means[i * DIM + j] = i * DIM + j + 1;           }     }      printf(\"\u8f93\u5165 means \u6570\u7ec4\u548c counts \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < BID; i++) {         for (int j = 0; j < DIM; j++) {             printf(\"%d \", means[i * DIM + j]);         }         printf(\" | Count: %d\\n\", counts[i]);     }           kmeans_average(means, counts, BID, DIM);      printf(\"\\n\u5e73\u5747\u5316\u540e\u7684 means \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < BID; i++) {         for (int j = 0; j < DIM; j++) {             printf(\"%d \", means[i * DIM + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void kmeans_average(int* means, int* counts) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (counts[index] == 0)         means[index] = 0;     else         means[index] /= counts[index]; }  int main() {     const int K = 10;       const int threadsPerBlock = 256;     const int blocksPerGrid = (K + threadsPerBlock - 1) / threadsPerBlock;           int* h_means = (int*)malloc(K * sizeof(int));     int* h_counts = (int*)malloc(K * sizeof(int));           for (int i = 0; i < K; ++i) {         h_means[i] = i * 10;         h_counts[i] = i + 1;     }           int* d_means;     int* d_counts;     cudaMalloc((void**)&d_means, K * sizeof(int));     cudaMalloc((void**)&d_counts, K * sizeof(int));           cudaMemcpy(d_means, h_means, K * sizeof(int), cudaMemcpyHostToDevice);     cudaMemcpy(d_counts, h_counts, K * sizeof(int), cudaMemcpyHostToDevice);           kmeans_average<<<blocksPerGrid, threadsPerBlock>>>(d_means, d_counts);           cudaMemcpy(h_means, d_means, K * sizeof(int), cudaMemcpyDeviceToHost);           printf(\"Means after averaging:\\n\");     for (int i = 0; i < K; ++i) {         printf(\"%d \", h_means[i]);     }           free(h_means);     free(h_counts);     cudaFree(d_means);     cudaFree(d_counts);      return 0; } "
    },
    {
        "id": "72",
        "c_code": "#include <stdio.h>  void matPerRowDivInplace_cpu(double *mat, const double *alphas, int m, int n) {     for (int index = 0; index < m * n; index++) {         int i = index / n;         int j = index % n;         mat[i * n + j] /= (alphas[i] + 10 * 3);     } }  int main() {          int m = 3;     int n = 4;     double mat[] = {1.0, 2.0, 3.0, 4.0,                     5.0, 6.0, 7.0, 8.0,                     9.0, 10.0, 11.0, 12.0};     double alphas[] = {2.0, 3.0, 4.0};      printf(\"\u8f93\u5165\u77e9\u9635 mat\uff1a\\n\");     for (int i = 0; i < m; i++) {         for (int j = 0; j < n; j++) {             printf(\"%.2f \", mat[i * n + j]);         }         printf(\"\\n\");     }      printf(\"\\n\u8f93\u5165 alphas \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < m; i++) {         printf(\"%.2f \", alphas[i]);     }           matPerRowDivInplace_cpu(mat, alphas, m, n);      printf(\"\\n\u6bcf\u884c\u9664\u4ee5 alphas \u540e\u7684\u77e9\u9635 mat\uff1a\\n\");     for (int i = 0; i < m; i++) {         for (int j = 0; j < n; j++) {             printf(\"%.2f \", mat[i * n + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void matPerRowDivInplaceKernel(double* mat, const double* alphas, int m, int n) {     int index = blockIdx.x * blockDim.x + threadIdx.x;      if (index < m * n) {         int i = index / n;         int j = index % n;         mat[i * n + j] /= (alphas[i] + 10 * 3);     } }  int main() {     const int m = 5;       const int n = 4;       const int threadsPerBlock = 256;     const int blocksPerGrid = (m * n + threadsPerBlock - 1) / threadsPerBlock;           double* h_mat = (double*)malloc(m * n * sizeof(double));     double* h_alphas = (double*)malloc(m * sizeof(double));           for (int i = 0; i < m * n; ++i) {         h_mat[i] = i + 1;     }      for (int i = 0; i < m; ++i) {         h_alphas[i] = i + 1;     }           double* d_mat;     double* d_alphas;     cudaMalloc((void**)&d_mat, m * n * sizeof(double));     cudaMalloc((void**)&d_alphas, m * sizeof(double));           cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);     cudaMemcpy(d_alphas, h_alphas, m * sizeof(double), cudaMemcpyHostToDevice);           matPerRowDivInplaceKernel<<<blocksPerGrid, threadsPerBlock>>>(d_mat, d_alphas, m, n);           cudaMemcpy(h_mat, d_mat, m * n * sizeof(double), cudaMemcpyDeviceToHost);           printf(\"Matrix after per row division:\\n\");     for (int i = 0; i < m; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"%f \", h_mat[i * n + j]);         }         printf(\"\\n\");     }           free(h_mat);     free(h_alphas);     cudaFree(d_mat);     cudaFree(d_alphas);      return 0; } "
    },
    {
        "id": "73",
        "c_code": "#include <stdio.h>   int max(int a, int b) {     return (a > b) ? a : b; }  void compute_new_means(float *mx, float *my, const float *sx, const float *sy, const int *c, int size) {     int cluster = 0;     const int count = max(1, c[cluster]);      for (cluster = 0; cluster < size; cluster++) {         mx[cluster] = sx[cluster] / count;         my[cluster] = sy[cluster] / count;     } }  int main() {          int size = 3;     float mx[] = {1.0, 2.0, 3.0};     float my[] = {4.0, 5.0, 6.0};     float sx[] = {7.0, 8.0, 9.0};     float sy[] = {10.0, 11.0, 12.0};     int c[] = {2, 0, 1};      printf(\"\u8f93\u5165 mx \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", mx[i]);     }      printf(\"\\n\u8f93\u5165 my \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", my[i]);     }      printf(\"\\n\u8f93\u5165 sx \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", sx[i]);     }      printf(\"\\n\u8f93\u5165 sy \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", sy[i]);     }      printf(\"\\n\u8f93\u5165 c \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", c[i]);     }           compute_new_means(mx, my, sx, sy, c, size);      printf(\"\\n\u8ba1\u7b97\u65b0\u5747\u503c\u540e\u7684 mx \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", mx[i]);     }      printf(\"\\n\u8ba1\u7b97\u65b0\u5747\u503c\u540e\u7684 my \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%.2f \", my[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void compute_new_means(float* mx, float* my, const float* sx, const float* sy, const int* c) {     const int cluster = threadIdx.x;      if (cluster < blockDim.x) {         const int count = max(1, c[cluster]);         mx[cluster] = sx[cluster] / count;         my[cluster] = sy[cluster] / count;     } }  int main() {     const int clusters = 5;       const int threadsPerBlock = clusters;     const int blocksPerGrid = 1;             float* h_mx = (float*)malloc(clusters * sizeof(float));     float* h_my = (float*)malloc(clusters * sizeof(float));     float* h_sx = (float*)malloc(clusters * sizeof(float));     float* h_sy = (float*)malloc(clusters * sizeof(float));     int* h_c = (int*)malloc(clusters * sizeof(int));           for (int i = 0; i < clusters; ++i) {         h_sx[i] = i + 1;         h_sy[i] = i + 1;         h_c[i] = i + 1;     }           float* d_mx;     float* d_my;     float* d_sx;     float* d_sy;     int* d_c;     cudaMalloc((void**)&d_mx, clusters * sizeof(float));     cudaMalloc((void**)&d_my, clusters * sizeof(float));     cudaMalloc((void**)&d_sx, clusters * sizeof(float));     cudaMalloc((void**)&d_sy, clusters * sizeof(float));     cudaMalloc((void**)&d_c, clusters * sizeof(int));           cudaMemcpy(d_mx, h_mx, clusters * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_my, h_my, clusters * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_sx, h_sx, clusters * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_sy, h_sy, clusters * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_c, h_c, clusters * sizeof(int), cudaMemcpyHostToDevice);           compute_new_means<<<blocksPerGrid, threadsPerBlock>>>(d_mx, d_my, d_sx, d_sy, d_c);           cudaMemcpy(h_mx, d_mx, clusters * sizeof(float), cudaMemcpyDeviceToHost);     cudaMemcpy(h_my, d_my, clusters * sizeof(float), cudaMemcpyDeviceToHost);           printf(\"New means:\\n\");     for (int i = 0; i < clusters; ++i) {         printf(\"(%f, %f)\\n\", h_mx[i], h_my[i]);     }           free(h_mx);     free(h_my);     free(h_sx);     free(h_sy);     free(h_c);     cudaFree(d_mx);     cudaFree(d_my);     cudaFree(d_sx);     cudaFree(d_sy);     cudaFree(d_c);      return 0; } "
    },
    {
        "id": "74",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void copy_array_d2d(double **src, double **dst, int m, int n) {     int i, j;     for (i = 1; i < m + 1; i++)         for (j = 1; j < n + 1; j++)             dst[i][j] = src[i][j]; }  int main() {          int m = 3;     int n = 4;           double **src = (double **)malloc((m + 2) * sizeof(double *));     for (int i = 0; i < m + 2; i++) {         src[i] = (double *)malloc((n + 2) * sizeof(double));         for (int j = 0; j < n + 2; j++) {             src[i][j] = i * (n + 2) + j;          }     }           double **dst = (double **)malloc((m + 2) * sizeof(double *));     for (int i = 0; i < m + 2; i++) {         dst[i] = (double *)malloc((n + 2) * sizeof(double));     }           copy_array_d2d(src, dst, m, n);           printf(\"\u6e90\u6570\u7ec4 src\uff1a\\n\");     for (int i = 0; i < m + 2; i++) {         for (int j = 0; j < n + 2; j++) {             printf(\"%.2f \", src[i][j]);         }         printf(\"\\n\");     }      printf(\"\\n\u76ee\u6807\u6570\u7ec4 dst\uff08\u590d\u5236\u540e\uff09\uff1a\\n\");     for (int i = 0; i < m + 2; i++) {         for (int j = 0; j < n + 2; j++) {             printf(\"%.2f \", dst[i][j]);         }         printf(\"\\n\");     }           for (int i = 0; i < m + 2; i++) {         free(src[i]);         free(dst[i]);     }     free(src);     free(dst);      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h> #include <stdio.h>  __global__ void copy_array_d2d(double** src, double** dst, int m, int n) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     int j = blockIdx.y * blockDim.y + threadIdx.y;      if (i < m && j < n) {         dst[i][j] = src[i][j];     } }  int main() {     const int m = 10;      const int n = 5;             double** h_src = new double*[m];     double** h_dst = new double*[m];     for (int i = 0; i < m; ++i) {         h_src[i] = new double[n];         h_dst[i] = new double[n];         for (int j = 0; j < n; ++j) {             h_src[i][j] = i * n + j;          }     }           double** d_src;     double** d_dst;     cudaMalloc((void**)&d_src, m * sizeof(double*));     cudaMalloc((void**)&d_dst, m * sizeof(double*));      for (int i = 0; i < m; ++i) {         cudaMalloc((void**)&d_src[i], n * sizeof(double));         cudaMalloc((void**)&d_dst[i], n * sizeof(double));         cudaMemcpy(d_src[i], h_src[i], n * sizeof(double), cudaMemcpyHostToDevice);     }           dim3 blockSize(16, 16);     dim3 gridSize((m + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);     copy_array_d2d<<<gridSize, blockSize>>>(d_src, d_dst, m, n);           for (int i = 0; i < m; ++i) {         cudaMemcpy(h_dst[i], d_dst[i], n * sizeof(double), cudaMemcpyDeviceToHost);     }           printf(\"Original array:\\n\");     for (int i = 0; i < m; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"%f \", h_src[i][j]);         }         printf(\"\\n\");     }      printf(\"\\nCopied array:\\n\");     for (int i = 0; i < m; ++i) {         for (int j = 0; j < n; ++j) {             printf(\"%f \", h_dst[i][j]);         }         printf(\"\\n\");     }           for (int i = 0; i < m; ++i) {         cudaFree(d_src[i]);         cudaFree(d_dst[i]);         delete[] h_src[i];         delete[] h_dst[i];     }      cudaFree(d_src);     cudaFree(d_dst);     delete[] h_src;     delete[] h_dst;      return 0; } "
    },
    {
        "id": "75",
        "c_code": "#include <stdio.h>  void InitCCL(int labelList[], int reference[], int width, int height) {     int x, y;     for (x = 0; x < width; x++) {         for (y = 0; y < height; y++) {             int id = x + y * width;             labelList[id] = reference[id] = id;         }     } }  int main() {          int width = 3;     int height = 3;           int *labelList = new int[width * height];     int *reference = new int[width * height];           InitCCL(labelList, reference, width, height);           printf(\"\u521d\u59cb\u5316\u540e\u7684 labelList \u6570\u7ec4\uff1a\\n\");     for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             int id = x + y * width;             printf(\"%d \", labelList[id]);         }         printf(\"\\n\");     }      printf(\"\\n\u521d\u59cb\u5316\u540e\u7684 reference \u6570\u7ec4\uff1a\\n\");     for (int y = 0; y < height; y++) {         for (int x = 0; x < width; x++) {             int id = x + y * width;             printf(\"%d \", reference[id]);         }         printf(\"\\n\");     }           delete[] labelList;     delete[] reference;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void InitCCL(int labelList[], int reference[], int width, int height) {     int x = blockIdx.x * blockDim.x + threadIdx.x;     int y = blockIdx.y * blockDim.y + threadIdx.y;      if (x >= width || y >= height) return;      int id = x + y * width;     labelList[id] = reference[id] = id; }  int main() {          int width = 512;     int height = 512;           dim3 gridSize((width + 15) / 16, (height + 15) / 16);     dim3 blockSize(16, 16);           int* h_labelList = (int*)malloc(width * height * sizeof(int));     int* h_reference = (int*)malloc(width * height * sizeof(int));           int* d_labelList, * d_reference;     cudaMalloc((void**)&d_labelList, width * height * sizeof(int));     cudaMalloc((void**)&d_reference, width * height * sizeof(int));           InitCCL<<<gridSize, blockSize>>>(d_labelList, d_reference, width, height);           cudaMemcpy(h_labelList, d_labelList, width * height * sizeof(int), cudaMemcpyDeviceToHost);     cudaMemcpy(h_reference, d_reference, width * height * sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_labelList);     cudaFree(d_reference);           free(h_labelList);     free(h_reference);      return 0; } "
    },
    {
        "id": "76",
        "c_code": "#include <stdio.h>  void cpu_set_sg(int *sxz, int sxbeg, int szbeg, int jsx, int jsz, int ns, int npml, int nnz) {     for (int id = 0; id < ns; id++) {         sxz[id] = nnz * (sxbeg + id * jsx + npml) + (szbeg + id * jsz + npml);     } }  int main() {          int ns = 3;        int *sxz = new int[ns];           cpu_set_sg(sxz, 1, 2, 3, 4, ns, 5, 6);           printf(\"\u521d\u59cb\u5316\u540e\u7684 sxz \u6570\u7ec4\uff1a\\n\");     for (int id = 0; id < ns; id++) {         printf(\"%d \", sxz[id]);     }           delete[] sxz;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void cuda_set_sg(int* sxz, int sxbeg, int szbeg, int jsx, int jsz, int ns, int npml, int nnz) {     int id = threadIdx.x + blockDim.x * blockIdx.x;      if (id < ns) {         sxz[id] = nnz * (sxbeg + id * jsx + npml) + (szbeg + id * jsz + npml);     } }  int main() {          int ns = 512;       int npml = 10;       int nnz = 100;       int sxbeg = 0;     int szbeg = 0;     int jsx = 1;     int jsz = 1;           int* h_sxz = (int*)malloc(ns * sizeof(int));           int* d_sxz;     cudaMalloc((void**)&d_sxz, ns * sizeof(int));           dim3 gridSize((ns + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           cuda_set_sg<<<gridSize, blockSize>>>(d_sxz, sxbeg, szbeg, jsx, jsz, ns, npml, nnz);           cudaMemcpy(h_sxz, d_sxz, ns * sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_sxz);           free(h_sxz);      return 0; } "
    },
    {
        "id": "77",
        "c_code": "#include <stdio.h>  void addMatrix(float *a, float *b, float *c, int N) {     int i, j, idx;     for (i = 0; i < N; i++) {         for (j = 0; j < N; j++) {             idx = i * N + j;             a[idx] = b[idx] + c[idx];         }     } }  int main() {          int N = 3;        float *a = new float[N * N];     float *b = new float[N * N];     float *c = new float[N * N];                 addMatrix(a, b, c, N);           printf(\"\u77e9\u9635\u76f8\u52a0\u540e\u7684\u7ed3\u679c\uff08a\u77e9\u9635\uff09\uff1a\\n\");     for (int i = 0; i < N; i++) {         for (int j = 0; j < N; j++) {             int idx = i * N + j;             printf(\"%.2f \", a[idx]);         }         printf(\"\\n\");     }           delete[] a;     delete[] b;     delete[] c;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void addMatrixGPU(float* a, float* b, float* c, int N) {     int j = threadIdx.x + blockIdx.x * blockDim.x;     int i = threadIdx.y + blockIdx.y * blockDim.y;      if ((i < N) && (j < N)) {         int idx = i * N + j;         a[idx] = b[idx] + c[idx];     } }  int main() {          int N = 512;           float* h_a = (float*)malloc(N * N * sizeof(float));     float* h_b = (float*)malloc(N * N * sizeof(float));     float* h_c = (float*)malloc(N * N * sizeof(float));                 float* d_a, * d_b, * d_c;     cudaMalloc((void**)&d_a, N * N * sizeof(float));     cudaMalloc((void**)&d_b, N * N * sizeof(float));     cudaMalloc((void**)&d_c, N * N * sizeof(float));                 dim3 gridSize((N + 15) / 16, (N + 15) / 16);     dim3 blockSize(16, 16);           addMatrixGPU<<<gridSize, blockSize>>>(d_a, d_b, d_c, N);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);           free(h_a);     free(h_b);     free(h_c);      return 0; } "
    },
    {
        "id": "78",
        "c_code": "#include <stdio.h>  void resizedClsScore_cpu(const float *score, const float *score_factors, float *output, int dims) {     for (int tid = 0; tid < dims; tid++) {         if (score[tid] == (-1)) {             output[tid] = -1;         } else {             output[tid] = score[tid] * score_factors[tid];         }     } }  int main() {          int dims = 5;        float *score = new float[dims];     float *score_factors = new float[dims];     float *output = new float[dims];                 resizedClsScore_cpu(score, score_factors, output, dims);           printf(\"\u5904\u7406\u540e\u7684 output \u6570\u7ec4\uff1a\\n\");     for (int tid = 0; tid < dims; tid++) {         printf(\"%.2f \", output[tid]);     }           delete[] score;     delete[] score_factors;     delete[] output;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void resizedClsScore(const float* score, const float* score_factors, float* output, int dims) {     int tid = blockIdx.x * blockDim.x + threadIdx.x;      if (tid >= dims) {         return;     }      if (score[tid] == (-1)) {         output[tid] = -1;     } else {         output[tid] = score[tid] * score_factors[tid];     } }  int main() {          int dims = 512;           float* h_score = (float*)malloc(dims * sizeof(float));     float* h_score_factors = (float*)malloc(dims * sizeof(float));     float* h_output = (float*)malloc(dims * sizeof(float));                 float* d_score, * d_score_factors, * d_output;     cudaMalloc((void**)&d_score, dims * sizeof(float));     cudaMalloc((void**)&d_score_factors, dims * sizeof(float));     cudaMalloc((void**)&d_output, dims * sizeof(float));                 dim3 gridSize((dims + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           resizedClsScore<<<gridSize, blockSize>>>(d_score, d_score_factors, d_output, dims);                 cudaFree(d_score);     cudaFree(d_score_factors);     cudaFree(d_output);           free(h_score);     free(h_score_factors);     free(h_output);      return 0; } "
    },
    {
        "id": "79",
        "c_code": "  #include <stdio.h> #include <math.h>  void l1_cpu(int n, float *pred, float *truth, float *delta, float *error) {     for (int i = 0; i < n; ++i) {         float diff = truth[i] - pred[i];         error[i] = fabs(diff);         delta[i] = diff > 0 ? 1 : -1;     } }  int main() {          int n = 5;        float *pred = new float[n];     float *truth = new float[n];     float *delta = new float[n];     float *error = new float[n];                 l1_cpu(n, pred, truth, delta, error);           printf(\"\u5904\u7406\u540e\u7684 delta \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < n; i++) {         printf(\"%.2f \", delta[i]);     }      printf(\"\\n\u5904\u7406\u540e\u7684 error \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < n; i++) {         printf(\"%.2f \", error[i]);     }           delete[] pred;     delete[] truth;     delete[] delta;     delete[] error;      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <cmath>   __global__ void l1_kernel(int n, float* pred, float* truth, float* delta, float* error) {     int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;      if (i < n) {         float diff = truth[i] - pred[i];         error[i] = fabs(diff);         delta[i] = (diff > 0) ? 1 : -1;     } }  int main() {          int n = 512;           float* h_pred = (float*)malloc(n * sizeof(float));     float* h_truth = (float*)malloc(n * sizeof(float));     float* h_delta = (float*)malloc(n * sizeof(float));     float* h_error = (float*)malloc(n * sizeof(float));                 float* d_pred, * d_truth, * d_delta, * d_error;     cudaMalloc((void**)&d_pred, n * sizeof(float));     cudaMalloc((void**)&d_truth, n * sizeof(float));     cudaMalloc((void**)&d_delta, n * sizeof(float));     cudaMalloc((void**)&d_error, n * sizeof(float));                 dim3 gridSize((n + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           l1_kernel<<<gridSize, blockSize>>>(n, d_pred, d_truth, d_delta, d_error);                 cudaFree(d_pred);     cudaFree(d_truth);     cudaFree(d_delta);     cudaFree(d_error);           free(h_pred);     free(h_truth);     free(h_delta);     free(h_error);      return 0; } "
    },
    {
        "id": "8",
        "c_code": "#include <stdio.h>  void initialArray0_cpu(int tasks, int *f3) {     for (int i = 0; i < tasks; i++) {         f3[i] = 0;     } }  int main() {          int numTasks = 8;     int array[numTasks];      printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");     for (int i = 0; i < numTasks; i++) {         printf(\"%d \", array[i]);     }           initialArray0_cpu(numTasks, array);      printf(\"\\n\u521d\u59cb\u5316\u540e\u7684\u6570\u7ec4\uff1a\");     for (int i = 0; i < numTasks; i++) {         printf(\"%d \", array[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void initialArray0(int tasks, int* f3) {     for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < tasks; i += blockDim.x * gridDim.x) {         f3[i] = 0;     } }  int main() {          int numTasks = 1000;           int* h_f3 = (int*)malloc(numTasks * sizeof(int));           int* d_f3;     cudaMalloc((void**)&d_f3, numTasks * sizeof(int));           int blockSize = 256;     int gridSize = (numTasks + blockSize - 1) / blockSize;           initialArray0<<<gridSize, blockSize>>>(numTasks, d_f3);           cudaMemcpy(h_f3, d_f3, numTasks * sizeof(int), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%d \", h_f3[i]);     }           free(h_f3);     cudaFree(d_f3);      return 0; } "
    },
    {
        "id": "80",
        "c_code": "#include <stdio.h>  void AddMatrixOnCPU(int *A, int *B, int *C, int nx, int ny) {     int i, j;     int cnt = 0;     for (j = 0; j < ny; j++) {         for (i = 0; i < nx; i++) {             C[cnt] = A[cnt] + B[cnt];             cnt++;         }     } }  int main() {          int nx = 3;        int ny = 3;        int size = nx * ny;     int *A = new int[size];     int *B = new int[size];     int *C = new int[size];                 AddMatrixOnCPU(A, B, C, nx, ny);           printf(\"\u5904\u7406\u540e\u7684 C \u77e9\u9635\uff1a\\n\");     for (int i = 0; i < size; i++) {         printf(\"%d \", C[i]);     }           delete[] A;     delete[] B;     delete[] C;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void AddMatrixOnGPU(float* A, float* B, float* C, int nx, int ny) {     int i = threadIdx.x + blockIdx.x * blockDim.x;     int j = threadIdx.y + blockIdx.y * blockDim.y;     int idx = i * nx + j;      if (i < nx && j < ny) {         C[idx] = A[idx] + B[idx];     } }  int main() {          int nx = 512;     int ny = 512;           float* h_A = (float*)malloc(nx * ny * sizeof(float));     float* h_B = (float*)malloc(nx * ny * sizeof(float));     float* h_C = (float*)malloc(nx * ny * sizeof(float));                 float* d_A, * d_B, * d_C;     cudaMalloc((void**)&d_A, nx * ny * sizeof(float));     cudaMalloc((void**)&d_B, nx * ny * sizeof(float));     cudaMalloc((void**)&d_C, nx * ny * sizeof(float));                 dim3 gridSize((nx + 15) / 16, (ny + 15) / 16);     dim3 blockSize(16, 16);           AddMatrixOnGPU<<<gridSize, blockSize>>>(d_A, d_B, d_C, nx, ny);                 cudaFree(d_A);     cudaFree(d_B);     cudaFree(d_C);           free(h_A);     free(h_B);     free(h_C);      return 0; } "
    },
    {
        "id": "81",
        "c_code": "#include <stdio.h>  void LreluForward(float *srcData, float *dstData, int data_size, float alpha) {     for (int i = 0; i < data_size; i++) {         dstData[i] = srcData[i] > 0 ? srcData[i] : srcData[i] * alpha;     } }  int main() {          int data_size = 5;        float alpha = 0.01;        float *srcData = new float[data_size];     float *dstData = new float[data_size];                 LreluForward(srcData, dstData, data_size, alpha);           printf(\"\u5904\u7406\u540e\u7684 dstData \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < data_size; i++) {         printf(\"%.2f \", dstData[i]);     }           delete[] srcData;     delete[] dstData;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void LreluForward(float* srcData, float* dstData, int data_size, float alpha) {     int thread_index = threadIdx.x + blockIdx.x * blockDim.x;     int num_threads = blockDim.x * gridDim.x;      for (int i = 0; i < data_size; i += num_threads) {         int index = i + thread_index;          if (index < data_size) {             dstData[index] = (srcData[index] > 0) ? srcData[index] : srcData[index] * alpha;         }     } }  int main() {          int data_size = 512;     float alpha = 0.01;            float* h_srcData = (float*)malloc(data_size * sizeof(float));     float* h_dstData = (float*)malloc(data_size * sizeof(float));                 float* d_srcData, * d_dstData;     cudaMalloc((void**)&d_srcData, data_size * sizeof(float));     cudaMalloc((void**)&d_dstData, data_size * sizeof(float));                 dim3 gridSize((data_size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           LreluForward<<<gridSize, blockSize>>>(d_srcData, d_dstData, data_size, alpha);                 cudaFree(d_srcData);     cudaFree(d_dstData);           free(h_srcData);     free(h_dstData);      return 0; } "
    },
    {
        "id": "82",
        "c_code": "#include <stdio.h>  void filterFFT_cpu(float *FFT, float *filter, int nxprj2, int nviews, float scale) {     for (int i = 0; i < nviews; i++) {         for (int j = 0; j < nxprj2; j++) {             FFT[i * nxprj2 + j] *= filter[i * nxprj2 + j] * scale;         }     } }  int main() {          int nxprj2 = 3;         int nviews = 2;         float scale = 0.5;      float *FFT = new float[nxprj2 * nviews];     float *filter = new float[nxprj2 * nviews];                 filterFFT_cpu(FFT, filter, nxprj2, nviews, scale);           printf(\"\u5904\u7406\u540e\u7684 FFT \u6570\u7ec4\uff1a\\n\");     for (int i = 0; i < nviews; i++) {         for (int j = 0; j < nxprj2; j++) {             printf(\"%.2f \", FFT[i * nxprj2 + j]);         }         printf(\"\\n\");     }           delete[] FFT;     delete[] filter;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void filterFFT(float* FFT, float* filter, int nxprj2, int nviews, float scale) {     int j = blockIdx.x * blockDim.x + threadIdx.x;     int i = blockIdx.y * blockDim.y + threadIdx.y;      if (i < nviews && j < nxprj2) {         FFT[i * nxprj2 + j] *= filter[i * nxprj2 + j] * scale;     } }  int main() {          int nxprj2 = 512;     int nviews = 512;     float scale = 0.5;            float* h_FFT = (float*)malloc(nxprj2 * nviews * sizeof(float));     float* h_filter = (float*)malloc(nxprj2 * nviews * sizeof(float));                 float* d_FFT, * d_filter;     cudaMalloc((void**)&d_FFT, nxprj2 * nviews * sizeof(float));     cudaMalloc((void**)&d_filter, nxprj2 * nviews * sizeof(float));                 dim3 gridSize((nxprj2 + 15) / 16, (nviews + 15) / 16);     dim3 blockSize(16, 16);           filterFFT<<<gridSize, blockSize>>>(d_FFT, d_filter, nxprj2, nviews, scale);                 cudaFree(d_FFT);     cudaFree(d_filter);           free(h_FFT);     free(h_filter);      return 0; } "
    },
    {
        "id": "83",
        "c_code": "#include <stdio.h>  void convertFloatToRGBA_cpu(char *out_image, const float *in_image, int width, int height) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < height; y++) {             int IND = (y * width + x) * 4;               float val = in_image[y * width + x];                           char temp = static_cast<char>(val * 255.0f);                           out_image[IND] = temp;                  out_image[IND + 1] = temp;              out_image[IND + 2] = temp;              out_image[IND + 3] = 255;           }     } }  int main() {          int width = 3;        int height = 2;       float *in_image = new float[width * height];       char *out_image = new char[width * height * 4];                  convertFloatToRGBA_cpu(out_image, in_image, width, height);           for (int i = 0; i < width * height * 4; i++) {         printf(\"%d \", out_image[i]);     }           delete[] in_image;     delete[] out_image;      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void convertFloatToRGBA_kernel(char* out_image, const float* in_image, int width, int height) {     const int x = blockIdx.x * blockDim.x + threadIdx.x;     const int y = blockIdx.y * blockDim.y + threadIdx.y;      if (x < width && y < height) {         int IND = y * width + x;         float val = in_image[IND];         char temp = 255;         out_image[IND] = temp;     } }  int main() {          int width = 512;     int height = 512;           char* h_out_image = (char*)malloc(width * height * sizeof(char));     float* h_in_image = (float*)malloc(width * height * sizeof(float));                 char* d_out_image;     float* d_in_image;     cudaMalloc((void**)&d_out_image, width * height * sizeof(char));     cudaMalloc((void**)&d_in_image, width * height * sizeof(float));                 dim3 gridSize((width + 15) / 16, (height + 15) / 16);     dim3 blockSize(16, 16);           convertFloatToRGBA_kernel<<<gridSize, blockSize>>>(d_out_image, d_in_image, width, height);                 cudaFree(d_out_image);     cudaFree(d_in_image);           free(h_out_image);     free(h_in_image);      return 0; } "
    },
    {
        "id": "84",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void convertEdgeMaskToFloatCpu(float *d_output, unsigned char *d_input, unsigned int width, unsigned int height) {     for (int x = 0; x < width; x++) {         for (int y = 0; y < height; y++) {             d_output[y * width + x] = fminf(d_input[y * width + x], d_input[width * height + y * width + x]);         }     } }  int main() {          unsigned int width = 5;     unsigned int height = 5;           unsigned char *d_input = (unsigned char *)malloc(width * height * 2 * sizeof(unsigned char));       float *d_output = (float *)malloc(width * height * sizeof(float));           for (int i = 0; i < width * height * 2; i++) {         d_input[i] = i % 256;       }           convertEdgeMaskToFloatCpu(d_output, d_input, width, height);           for (int i = 0; i < width * height; i++) {         printf(\"%f \", d_output[i]);     }           free(d_input);     free(d_output);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void convertEdgeMaskToFloatDevice(float* d_output, unsigned char* d_input, unsigned int width, unsigned int height) {     const int x = blockIdx.x * blockDim.x + threadIdx.x;     const int y = blockIdx.y * blockDim.y + threadIdx.y;      if (x >= width || y >= height) return;      d_output[y * width + x] = min(d_input[y * width + x], d_input[width * height + y * width + x]); }  int main() {          unsigned int width = 512;     unsigned int height = 512;           float* h_output = (float*)malloc(width * height * sizeof(float));     unsigned char* h_input = (unsigned char*)malloc(2 * width * height * sizeof(unsigned char));                 float* d_output;     unsigned char* d_input;     cudaMalloc((void**)&d_output, width * height * sizeof(float));     cudaMalloc((void**)&d_input, 2 * width * height * sizeof(unsigned char));                 dim3 gridSize((width + 15) / 16, (height + 15) / 16);     dim3 blockSize(16, 16);           convertEdgeMaskToFloatDevice<<<gridSize, blockSize>>>(d_output, d_input, width, height);                 cudaFree(d_output);     cudaFree(d_input);           free(h_output);     free(h_input);      return 0; } "
    },
    {
        "id": "85",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void gpu_matrix_transpose(int *mat_in, int *mat_out, unsigned int rows, unsigned int cols) {     unsigned int idx;     unsigned int idy;      for (idx = 0; idx < cols; idx++) {         for (idy = 0; idy < rows; idy++) {             unsigned int pos = idy * cols + idx;             unsigned int trans_pos = idx * rows + idy;             mat_out[trans_pos] = mat_in[pos];         }     } }  int main() {          unsigned int rows = 3;     unsigned int cols = 4;           int *mat_in = (int *)malloc(rows * cols * sizeof(int));     int *mat_out = (int *)malloc(rows * cols * sizeof(int));           for (unsigned int i = 0; i < rows * cols; i++) {         mat_in[i] = i;     }           gpu_matrix_transpose(mat_in, mat_out, rows, cols);           for (unsigned int i = 0; i < rows * cols; i++) {         printf(\"%d \", mat_out[i]);     }           free(mat_in);     free(mat_out);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gpu_matrix_transpose(int* mat_in, int* mat_out, unsigned int rows, unsigned int cols) {     unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;     unsigned int idy = blockIdx.y * blockDim.y + threadIdx.y;      if (idx < cols && idy < rows) {         unsigned int pos = idy * cols + idx;         unsigned int trans_pos = idx * rows + idy;         mat_out[trans_pos] = mat_in[pos];     } }  int main() {          unsigned int rows = 512;     unsigned int cols = 512;           int* h_mat_in = (int*)malloc(rows * cols * sizeof(int));     int* h_mat_out = (int*)malloc(rows * cols * sizeof(int));                 int* d_mat_in, * d_mat_out;     cudaMalloc((void**)&d_mat_in, rows * cols * sizeof(int));     cudaMalloc((void**)&d_mat_out, rows * cols * sizeof(int));                 dim3 gridSize((cols + 15) / 16, (rows + 15) / 16);     dim3 blockSize(16, 16);           gpu_matrix_transpose<<<gridSize, blockSize>>>(d_mat_in, d_mat_out, rows, cols);                 cudaFree(d_mat_in);     cudaFree(d_mat_out);           free(h_mat_in);     free(h_mat_out);      return 0; } "
    },
    {
        "id": "86",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void LreluBackward(float *srcDiff, float *dstDiff, float *srcData, int data_size, float alpha) {     for (int i = 0; i < data_size; i++) {         dstDiff[i] = (srcData[i] > 0) ? srcDiff[i] * 1.0 : srcDiff[i] * alpha;     } }  int main() {          int data_size = 5;           float *srcDiff = (float *)malloc(data_size * sizeof(float));     float *dstDiff = (float *)malloc(data_size * sizeof(float));     float *srcData = (float *)malloc(data_size * sizeof(float));           for (int i = 0; i < data_size; i++) {         srcDiff[i] = i;         srcData[i] = i - 2.0;     }           float alpha = 0.1;           LreluBackward(srcDiff, dstDiff, srcData, data_size, alpha);           printf(\"srcDiff: \");     for (int i = 0; i < data_size; i++) {         printf(\"%f \", srcDiff[i]);     }      printf(\"\\nsrcData: \");     for (int i = 0; i < data_size; i++) {         printf(\"%f \", srcData[i]);     }      printf(\"\\ndstDiff: \");     for (int i = 0; i < data_size; i++) {         printf(\"%f \", dstDiff[i]);     }           free(srcDiff);     free(dstDiff);     free(srcData);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void LreluBackward(float* srcDiff, float* dstDiff, float* srcData, int data_size, float alpha) {     int thread_index = threadIdx.x + blockIdx.x * blockDim.x;     int num_threads = blockDim.x * gridDim.x;      for (int i = 0; i < data_size; i += num_threads) {         int index = i + thread_index;          if (index < data_size) {             dstDiff[index] = srcDiff[index] * ((srcData[index] > 0) + (srcData[index] <= 0) * alpha);         }     } }  int main() {          int data_size = 512;     float alpha = 0.01;            float* h_srcDiff = (float*)malloc(data_size * sizeof(float));     float* h_dstDiff = (float*)malloc(data_size * sizeof(float));     float* h_srcData = (float*)malloc(data_size * sizeof(float));                 float* d_srcDiff, * d_dstDiff, * d_srcData;     cudaMalloc((void**)&d_srcDiff, data_size * sizeof(float));     cudaMalloc((void**)&d_dstDiff, data_size * sizeof(float));     cudaMalloc((void**)&d_srcData, data_size * sizeof(float));                 dim3 gridSize((data_size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           LreluBackward<<<gridSize, blockSize>>>(d_srcDiff, d_dstDiff, d_srcData, data_size, alpha);                 cudaFree(d_srcDiff);     cudaFree(d_dstDiff);     cudaFree(d_srcData);           free(h_srcDiff);     free(h_dstDiff);     free(h_srcData);      return 0; } "
    },
    {
        "id": "87",
        "c_code": "#include <stdio.h> #include <stdlib.h>  int cpuReduce(int *N, const int size) {     if (size == 1)         return N[0];      int stride = size / 2;      for (int i = 0; i < stride; i++)         N[i] += N[i + stride];      return cpuReduce(N, stride); }  int main() {          const int size = 8;           int *N = (int *)malloc(size * sizeof(int));           for (int i = 0; i < size; i++) {         N[i] = i + 1;     }           int result = cpuReduce(N, size);           printf(\"Reduced value: %d\\n\", result);           free(N);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void gpuReduceRecursive(int* I, int* O, unsigned int n) {     unsigned int tid = threadIdx.x;     unsigned int idx = threadIdx.x + blockIdx.x * blockDim.x;      if (idx >= n) return;      int* N = I + blockIdx.x * blockDim.x;      for (int stride = 1; stride < blockDim.x; stride *= 2) {         if ((tid % (2 * stride)) == 0)             N[tid] += N[tid + stride];          __syncthreads();     }      if (tid == 0)         O[blockIdx.x] = N[0]; }  int main() {          unsigned int n = 512;           int* h_I = (int*)malloc(n * sizeof(int));     int* h_O = (int*)malloc((n + 255) / 256 * sizeof(int));                 int* d_I, * d_O;     cudaMalloc((void**)&d_I, n * sizeof(int));     cudaMalloc((void**)&d_O, (n + 255) / 256 * sizeof(int));                 dim3 gridSize((n + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           gpuReduceRecursive<<<gridSize, blockSize>>>(d_I, d_O, n);                 cudaFree(d_I);     cudaFree(d_O);           free(h_I);     free(h_O);      return 0; } "
    },
    {
        "id": "88",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void devidecountInnerCPU(long Xsize, long Ysize, long Zsize, double *p, double *pn, int *pcountinner) {     for (int tid = 0; tid < Xsize * Ysize * Zsize; tid++) {         if (pcountinner[tid] > 1) {             p[tid] = pn[tid] / pcountinner[tid];             pn[tid] = 0;         }     } }  int main() {          long Xsize = 3;     long Ysize = 3;     long Zsize = 3;           double *p = (double *)malloc(Xsize * Ysize * Zsize * sizeof(double));     double *pn = (double *)malloc(Xsize * Ysize * Zsize * sizeof(double));     int *pcountinner = (int *)malloc(Xsize * Ysize * Zsize * sizeof(int));           for (int i = 0; i < Xsize * Ysize * Zsize; i++) {         p[i] = i + 1;         pn[i] = 2 * i;         pcountinner[i] = i % 3;       }           devidecountInnerCPU(Xsize, Ysize, Zsize, p, pn, pcountinner);           printf(\"p: \");     for (int i = 0; i < Xsize * Ysize * Zsize; i++) {         printf(\"%f \", p[i]);     }      printf(\"\\npn: \");     for (int i = 0; i < Xsize * Ysize * Zsize; i++) {         printf(\"%f \", pn[i]);     }           free(p);     free(pn);     free(pcountinner);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void devidecountInner(long Xsize, long Ysize, long Zsize, double* p, double* pn, int* pcountinner) {     long tid = threadIdx.x + blockDim.x * blockIdx.x;      while (tid < Xsize * Ysize * Zsize) {         if (pcountinner[tid] > 1) {             p[tid] = pn[tid] / pcountinner[tid];             pn[tid] = 0;         }          tid += blockDim.x * gridDim.x;     } }  int main() {          long Xsize = 512;     long Ysize = 512;     long Zsize = 512;           double* h_p = (double*)malloc(Xsize * Ysize * Zsize * sizeof(double));     double* h_pn = (double*)malloc(Xsize * Ysize * Zsize * sizeof(double));     int* h_pcountinner = (int*)malloc(Xsize * Ysize * Zsize * sizeof(int));                 double* d_p, * d_pn;     int* d_pcountinner;     cudaMalloc((void**)&d_p, Xsize * Ysize * Zsize * sizeof(double));     cudaMalloc((void**)&d_pn, Xsize * Ysize * Zsize * sizeof(double));     cudaMalloc((void**)&d_pcountinner, Xsize * Ysize * Zsize * sizeof(int));                 dim3 gridSize((Xsize * Ysize * Zsize + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           devidecountInner<<<gridSize, blockSize>>>(Xsize, Ysize, Zsize, d_p, d_pn, d_pcountinner);                 cudaFree(d_p);     cudaFree(d_pn);     cudaFree(d_pcountinner);           free(h_p);     free(h_pn);     free(h_pcountinner);      return 0; } "
    },
    {
        "id": "89",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void cpuConvertToBits(int *bit_decisions, unsigned short *bit_stream, int dec_size) {     for (int dec_index = 0; dec_index < dec_size; dec_index++) {         int bit_index = dec_index * 2;         int curr_decision = bit_decisions[dec_index];         bit_stream[bit_index] = ((curr_decision & 2) >> 1);         bit_stream[bit_index + 1] = (curr_decision & 1);     } }  int main() {          int dec_size = 5;           int *bit_decisions = (int *)malloc(dec_size * sizeof(int));     unsigned short *bit_stream = (unsigned short *)malloc(dec_size * 2 * sizeof(unsigned short));           for (int i = 0; i < dec_size; i++) {         bit_decisions[i] = i % 4;       }           cpuConvertToBits(bit_decisions, bit_stream, dec_size);           printf(\"bit_decisions: \");     for (int i = 0; i < dec_size; i++) {         printf(\"%d \", bit_decisions[i]);     }      printf(\"\\nbit_stream: \");     for (int i = 0; i < dec_size * 2; i++) {         printf(\"%hu \", bit_stream[i]);     }           free(bit_decisions);     free(bit_stream);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void cudaConvertToBits(int* bit_decisions, unsigned short* bit_stream, int dec_size) {     int dec_index = (blockIdx.x * blockDim.x) + threadIdx.x;     int bit_index = dec_index * 2;      if (dec_index >= dec_size)         return;      int curr_decision = bit_decisions[dec_index];     bit_stream[bit_index] = ((curr_decision & 2) >> 1);     bit_stream[bit_index + 1] = (curr_decision & 1); }  int main() {          int dec_size = 512;           int* h_bit_decisions = (int*)malloc(dec_size * sizeof(int));     unsigned short* h_bit_stream = (unsigned short*)malloc(dec_size * 2 * sizeof(unsigned short));                 int* d_bit_decisions;     unsigned short* d_bit_stream;     cudaMalloc((void**)&d_bit_decisions, dec_size * sizeof(int));     cudaMalloc((void**)&d_bit_stream, dec_size * 2 * sizeof(unsigned short));                 dim3 gridSize((dec_size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           cudaConvertToBits<<<gridSize, blockSize>>>(d_bit_decisions, d_bit_stream, dec_size);                 cudaFree(d_bit_decisions);     cudaFree(d_bit_stream);           free(h_bit_decisions);     free(h_bit_stream);      return 0; } "
    },
    {
        "id": "9",
        "c_code": "#include <stdio.h>  void add_vector_cpu(float *a, float *b, float *c, int size) {     for (int i = 0; i < size; ++i) {         c[i] = a[i] + b[i];     } }  int main() {          int vectorSize = 5;     float vectorA[] = {1.1, 2.2, 3.3, 4.4, 5.5};     float vectorB[] = {0.5, 1.5, 2.5, 3.5, 4.5};     float resultVector[vectorSize];      printf(\"\u5411\u91cf A\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorA[i]);     }      printf(\"\\n\u5411\u91cf B\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", vectorB[i]);     }           add_vector_cpu(vectorA, vectorB, resultVector, vectorSize);      printf(\"\\n\u76f8\u52a0\u540e\u7684\u5411\u91cf C\uff1a\");     for (int i = 0; i < vectorSize; i++) {         printf(\"%.2f \", resultVector[i]);     }      return 0; } ",
        "cuda_code": "#include <cuda_runtime.h> #include <device_launch_parameters.h>  __global__ void VectorAdd(float* arrayA, float* arrayB, float* output) {     int idx = threadIdx.x;     output[idx] = arrayA[idx] + arrayB[idx]; }  int main() {          int arraySize = 1000;           float* h_arrayA = (float*)malloc(arraySize * sizeof(float));     float* h_arrayB = (float*)malloc(arraySize * sizeof(float));     float* h_output = (float*)malloc(arraySize * sizeof(float));           for (int i = 0; i < arraySize; ++i) {         h_arrayA[i] = static_cast<float>(i);         h_arrayB[i] = static_cast<float>(2 * i);     }           float* d_arrayA;     float* d_arrayB;     float* d_output;     cudaMalloc((void**)&d_arrayA, arraySize * sizeof(float));     cudaMalloc((void**)&d_arrayB, arraySize * sizeof(float));     cudaMalloc((void**)&d_output, arraySize * sizeof(float));           cudaMemcpy(d_arrayA, h_arrayA, arraySize * sizeof(float), cudaMemcpyHostToDevice);     cudaMemcpy(d_arrayB, h_arrayB, arraySize * sizeof(float), cudaMemcpyHostToDevice);           int blockSize = 256;     int gridSize = (arraySize + blockSize - 1) / blockSize;           VectorAdd<<<gridSize, blockSize>>>(d_arrayA, d_arrayB, d_output);           cudaMemcpy(h_output, d_output, arraySize * sizeof(float), cudaMemcpyDeviceToHost);           for (int i = 0; i < 10; ++i) {         printf(\"%f \", h_output[i]);     }           free(h_arrayA);     free(h_arrayB);     free(h_output);     cudaFree(d_arrayA);     cudaFree(d_arrayB);     cudaFree(d_output);      return 0; } "
    },
    {
        "id": "90",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void copyAliasRow(int *devMat, int memWidth, int memHeight, int size) {     for (int devMatX = 0; devMatX < size; devMatX++) {         devMat[memWidth * 0 + devMatX] = devMat[memWidth * (memHeight - 2) + devMatX];         devMat[memWidth * (memHeight - 1) + devMatX] = devMat[memWidth * 1 + devMatX];     } }  int main() {          int memWidth = 4;     int memHeight = 4;     int size = memWidth;           int *devMat = (int *)malloc(memWidth * memHeight * sizeof(int));           for (int i = 0; i < memWidth * memHeight; i++) {         devMat[i] = i + 1;     }           copyAliasRow(devMat, memWidth, memHeight, size);           printf(\"devMat after copyAliasRow:\\n\");     for (int i = 0; i < memHeight; i++) {         for (int j = 0; j < memWidth; j++) {             printf(\"%d \", devMat[i * memWidth + j]);         }         printf(\"\\n\");     }           free(devMat);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void copyAliasRow(int* devMat, int memWidth, int memHeight) {     int devMatX = blockIdx.x * blockDim.x + threadIdx.x + 1;      devMat[memWidth * 0 + devMatX] = devMat[memWidth * (memHeight - 2) + devMatX];     devMat[memWidth * (memHeight - 1) + devMatX] = devMat[memWidth * 1 + devMatX]; }  int main() {          int memWidth = 512;     int memHeight = 512;           int* h_devMat = (int*)malloc(memWidth * memHeight * sizeof(int));                 int* d_devMat;     cudaMalloc((void**)&d_devMat, memWidth * memHeight * sizeof(int));                 dim3 gridSize((memWidth - 1 + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           copyAliasRow<<<gridSize, blockSize>>>(d_devMat, memWidth, memHeight);                 cudaFree(d_devMat);           free(h_devMat);      return 0; } "
    },
    {
        "id": "91",
        "c_code": "#include <stdio.h> #include <stdlib.h>  double *ObjFeatures_circularity(const int compCount, const int *areaRes, const double *perimeter) {     if (compCount > 0) {         double *circ = (double *)malloc(compCount * sizeof(double));         for (int i = 0; i < compCount; i++) {             circ[i] = (4.0 * 3.14159265359 * (double)areaRes[i]) / (perimeter[i] * perimeter[i]);         }         return circ;     }     return (double *)0; }  int main() {          const int compCount = 3;     int areaRes[] = {10, 15, 20};     double perimeter[] = {12.56, 18.85, 25.13};           double *circ = ObjFeatures_circularity(compCount, areaRes, perimeter);           printf(\"Circularity features:\\n\");     for (int i = 0; i < compCount; i++) {         printf(\"%f \", circ[i]);     }           free(circ);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void circularity(const int compCount, const int* areaRes, const float* perimeterRes, float* circ) {     int tid = blockDim.x * blockIdx.x + threadIdx.x;      if (tid < compCount) {         circ[tid] = (4.0 * 3.14159265359 * (float)areaRes[tid]) / (perimeterRes[tid] * perimeterRes[tid]);     } }  int main() {          int compCount = 512;           int* h_areaRes = (int*)malloc(compCount * sizeof(int));     float* h_perimeterRes = (float*)malloc(compCount * sizeof(float));     float* h_circ = (float*)malloc(compCount * sizeof(float));                 int* d_areaRes;     float* d_perimeterRes;     float* d_circ;     cudaMalloc((void**)&d_areaRes, compCount * sizeof(int));     cudaMalloc((void**)&d_perimeterRes, compCount * sizeof(float));     cudaMalloc((void**)&d_circ, compCount * sizeof(float));                 dim3 gridSize((compCount + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           circularity<<<gridSize, blockSize>>>(compCount, d_areaRes, d_perimeterRes, d_circ);                 cudaFree(d_areaRes);     cudaFree(d_perimeterRes);     cudaFree(d_circ);           free(h_areaRes);     free(h_perimeterRes);     free(h_circ);      return 0; } "
    },
    {
        "id": "92",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void devidecountCPU(long Xsize, long Ysize, long Zsize, double *pint, int *pcount) {     int n = Xsize * Ysize * 2 + (Ysize - 2) * Zsize * 2 + (Xsize - 2) * (Zsize - 2) * 2;          for (int tid = 0; tid < n * n; tid++) {         if (pcount[tid] > 1) {             pint[tid] /= pcount[tid];         }     } }  int main() {          long Xsize = 3;     long Ysize = 3;     long Zsize = 3;           double *pint = (double *)malloc(Xsize * Ysize * Zsize * 2 * sizeof(double));     int *pcount = (int *)malloc(Xsize * Ysize * Zsize * 2 * sizeof(int));           for (int i = 0; i < Xsize * Ysize * Zsize * 2; i++) {         pint[i] = i + 1;         pcount[i] = i % 3;       }           devidecountCPU(Xsize, Ysize, Zsize, pint, pcount);           printf(\"pint after devidecountCPU:\\n\");     for (int i = 0; i < Xsize * Ysize * Zsize * 2; i++) {         printf(\"%f \", pint[i]);     }           free(pint);     free(pcount);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void devidecount(long Xsize, long Ysize, long Zsize, double* pint, int* pcount) {     int n = Xsize * Ysize * 2 + (Ysize - 2) * Zsize * 2 + (Xsize - 2) * (Zsize - 2) * 2;     long tid = threadIdx.x + blockDim.x * blockIdx.x;      while (tid < n * n) {         if (pcount[tid] > 1) {             pint[tid] /= pcount[tid];         }          tid += blockDim.x * gridDim.x;     } }  int main() {          long Xsize = 512;     long Ysize = 512;     long Zsize = 512;           double* h_pint = (double*)malloc(Xsize * Ysize * Zsize * sizeof(double));     int* h_pcount = (int*)malloc(Xsize * Ysize * Zsize * sizeof(int));                 double* d_pint;     int* d_pcount;     cudaMalloc((void**)&d_pint, Xsize * Ysize * Zsize * sizeof(double));     cudaMalloc((void**)&d_pcount, Xsize * Ysize * Zsize * sizeof(int));                 dim3 gridSize((n + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           devidecount<<<gridSize, blockSize>>>(Xsize, Ysize, Zsize, d_pint, d_pcount);                 cudaFree(d_pint);     cudaFree(d_pcount);           free(h_pint);     free(h_pcount);      return 0; } "
    },
    {
        "id": "93",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void bubbleSort(int *p, const int size) {     for (int i = 0; i < size - 1; i++) {         for (int j = 0; j < size - i - 1; j++) {             if (p[j] > p[j + 1]) {                 int temp = p[j];                 p[j] = p[j + 1];                 p[j + 1] = temp;             }         }     } }  int main() {          const int size = 5;           int *p = (int *)malloc(size * sizeof(int));           p[0] = 5;     p[1] = 3;     p[2] = 1;     p[3] = 4;     p[4] = 2;           bubbleSort(p, size);           printf(\"Sorted array: \");     for (int i = 0; i < size; i++) {         printf(\"%d \", p[i]);     }           free(p);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void oddevenSort(int* d_in, int size, int oe_flag, int& d_ch_flag) {     int idx = threadIdx.x + blockIdx.x * blockDim.x;     int p = 2 * idx + oe_flag;      if (p + 1 < size) {         if (d_in[p] > d_in[p + 1]) {             int temp = d_in[p];             d_in[p] = d_in[p + 1];             d_in[p + 1] = temp;             d_ch_flag = 1;         }     } }  int main() {          int size = 512;           int* h_d_in = (int*)malloc(size * sizeof(int));                 int* d_d_in;     cudaMalloc((void**)&d_d_in, size * sizeof(int));                 int h_d_ch_flag = 0;           int* d_d_ch_flag;     cudaMalloc((void**)&d_d_ch_flag, sizeof(int));           cudaMemcpy(d_d_ch_flag, &h_d_ch_flag, sizeof(int), cudaMemcpyHostToDevice);           dim3 gridSize((size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           oddevenSort<<<gridSize, blockSize>>>(d_d_in, size, 0, *d_d_ch_flag);           cudaMemcpy(&h_d_ch_flag, d_d_ch_flag, sizeof(int), cudaMemcpyDeviceToHost);           cudaFree(d_d_in);     cudaFree(d_d_ch_flag);           free(h_d_in);      return 0; } "
    },
    {
        "id": "94",
        "c_code": "#include <stdio.h>  void matmul(int a[100][100], int b[100][100], int c[100][100]) {     for (int i = 0; i < 100; i++) {         for (int j = 0; j < 100; j++) {             c[i][j] = 0;             for (int k = 0; k < 100; k++) {                 c[i][j] += a[i][k] * b[k][j];             }         }     } }  int main() {          int a[100][100];     int b[100][100];     int c[100][100];           for (int i = 0; i < 100; i++) {         for (int j = 0; j < 100; j++) {             a[i][j] = i + j;             b[i][j] = i - j;         }     }           matmul(a, b, c);           printf(\"Resultant matrix c:\\n\");     for (int i = 0; i < 100; i++) {         for (int j = 0; j < 100; j++) {             printf(\"%d \", c[i][j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void matmul(float* a, float* b, float* c, int width) {     float result = 0;     int row = blockIdx.y * blockDim.y + threadIdx.y;     int col = blockIdx.x * blockDim.x + threadIdx.x;      for (int k = 0; k < width; k++) {         result += a[row * width + k] * b[k * width + col];     }      c[row * width + col] = result; }  int main() {          int width = 512;           float* h_a = (float*)malloc(width * width * sizeof(float));     float* h_b = (float*)malloc(width * width * sizeof(float));     float* h_c = (float*)malloc(width * width * sizeof(float));                 float* d_a, * d_b, * d_c;     cudaMalloc((void**)&d_a, width * width * sizeof(float));     cudaMalloc((void**)&d_b, width * width * sizeof(float));     cudaMalloc((void**)&d_c, width * width * sizeof(float));                 dim3 gridSize((width + 15) / 16, (width + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           matmul<<<gridSize, blockSize>>>(d_a, d_b, d_c, width);                 cudaFree(d_a);     cudaFree(d_b);     cudaFree(d_c);           free(h_a);     free(h_b);     free(h_c);      return 0; } "
    },
    {
        "id": "95",
        "c_code": "#include <stdio.h>  void cudaKernel_estimateSnr_cpu(const float *corrSum, const int *corrValidCount, const float *maxval, float *snrValue, const int size) {     for (int idx = 0; idx < size; idx++) {         float mean = (corrSum[idx] - maxval[idx] * maxval[idx]) / (corrValidCount[idx] - 1);         snrValue[idx] = maxval[idx] * maxval[idx] / mean;     } }  int main() {          const int size = 5;     float corrSum[] = {10.0, 20.0, 30.0, 40.0, 50.0};     int corrValidCount[] = {2, 3, 4, 5, 6};     float maxval[] = {2.0, 4.0, 6.0, 8.0, 10.0};     float snrValue[size];           cudaKernel_estimateSnr_cpu(corrSum, corrValidCount, maxval, snrValue, size);           printf(\"SNR Values:\\n\");     for (int i = 0; i < size; i++) {         printf(\"%f \", snrValue[i]);     }      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void cudaKernel_estimateSnr(const float* corrSum, const int* corrValidCount, const float* maxval, float* snrValue, const int size) {     int idx = threadIdx.x + blockDim.x * blockIdx.x;      if (idx >= size)         return;      float mean = (corrSum[idx] - maxval[idx] * maxval[idx]) / (corrValidCount[idx] - 1);     snrValue[idx] = maxval[idx] * maxval[idx] / mean; }  int main() {          int size = 512;           float* h_corrSum = (float*)malloc(size * sizeof(float));     int* h_corrValidCount = (int*)malloc(size * sizeof(int));     float* h_maxval = (float*)malloc(size * sizeof(float));     float* h_snrValue = (float*)malloc(size * sizeof(float));                 float* d_corrSum, * d_maxval, * d_snrValue;     int* d_corrValidCount;     cudaMalloc((void**)&d_corrSum, size * sizeof(float));     cudaMalloc((void**)&d_corrValidCount, size * sizeof(int));     cudaMalloc((void**)&d_maxval, size * sizeof(float));     cudaMalloc((void**)&d_snrValue, size * sizeof(float));                 dim3 gridSize((size + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           cudaKernel_estimateSnr<<<gridSize, blockSize>>>(d_corrSum, d_corrValidCount, d_maxval, d_snrValue, size);                 cudaFree(d_corrSum);     cudaFree(d_corrValidCount);     cudaFree(d_maxval);     cudaFree(d_snrValue);           free(h_corrSum);     free(h_corrValidCount);     free(h_maxval);     free(h_snrValue);      return 0; } "
    },
    {
        "id": "96",
        "c_code": "#include <stdio.h> #include <stdlib.h>  void cpu_sgemm(float *C, float *A, float *B, long size) {     for (long i = 0; i < size; i++) {         for (long k = 0; k < size; k++) {             for (long j = 0; j < size; j++) {                 C[i * size + j] += A[i * size + k] * B[k * size + j];             }         }     } }  int main() {          const long size = 3;           float *A = (float *)malloc(size * size * sizeof(float));     float *B = (float *)malloc(size * size * sizeof(float));     float *C = (float *)malloc(size * size * sizeof(float));           for (long i = 0; i < size * size; i++) {         A[i] = i + 1;         B[i] = i - 1;         C[i] = 0.0;     }           cpu_sgemm(C, A, B, size);           printf(\"Resultant matrix C:\\n\");     for (long i = 0; i < size; i++) {         for (long j = 0; j < size; j++) {             printf(\"%f \", C[i * size + j]);         }         printf(\"\\n\");     }           free(A);     free(B);     free(C);      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void naive_sgemm_kernel(float* C, float* A, float* B, long size) {     const long i = blockIdx.x * blockDim.x + threadIdx.x;     const long j = blockIdx.y * blockDim.y + threadIdx.y;      float val = 0.0;      if (i >= size || j >= size)         return;      for (long k = 0; k < size; k++) {         val += A[i * size + k] * B[k * size + j];     }      C[i * size + j] += val; }  int main() {          long size = 512;           float* h_C = (float*)malloc(size * size * sizeof(float));     float* h_A = (float*)malloc(size * size * sizeof(float));     float* h_B = (float*)malloc(size * size * sizeof(float));                 float* d_C, * d_A, * d_B;     cudaMalloc((void**)&d_C, size * size * sizeof(float));     cudaMalloc((void**)&d_A, size * size * sizeof(float));     cudaMalloc((void**)&d_B, size * size * sizeof(float));                 dim3 gridSize((size + 15) / 16, (size + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           naive_sgemm_kernel<<<gridSize, blockSize>>>(d_C, d_A, d_B, size);                 cudaFree(d_C);     cudaFree(d_A);     cudaFree(d_B);           free(h_C);     free(h_A);     free(h_B);      return 0; } "
    },
    {
        "id": "97",
        "c_code": "#include <stdio.h>  void kernelXor(unsigned int key, char *input_str_cuda, unsigned char *possible_plaintext_str_cuda, int input_length) {     int id;     char *keyCharPtr;      for (id = 0; id < input_length; id++) {         int keyIndex = id % 4;         keyCharPtr = ((char *)&key);         char keyChar = keyCharPtr[keyIndex];         possible_plaintext_str_cuda[id] = keyChar ^ input_str_cuda[id];     } }  int main() {          const int input_length = 10;     const unsigned int key = 12345;           char input_str[input_length];     unsigned char possible_plaintext_str[input_length];           for (int i = 0; i < input_length; i++) {         input_str[i] = 'A' + i;     }           kernelXor(key, input_str, possible_plaintext_str, input_length);           printf(\"Input String: %s\\n\", input_str);     printf(\"Possible Plaintext String after XOR: \");     for (int i = 0; i < input_length; i++) {         printf(\"%c \", possible_plaintext_str[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void kernelXor(unsigned int key, char* input_str_cuda, unsigned char* possible_plaintext_str_cuda, int input_length) {     int id = threadIdx.x + blockDim.x * blockIdx.x;      if (id >= input_length)         return;      int keyIndex = id % 4;     char* keyCharPtr = ((char*)&key);     char keyChar = keyCharPtr[keyIndex];      possible_plaintext_str_cuda[id] = keyChar ^ input_str_cuda[id]; }  int main() {          int input_length = 512;     unsigned int key = 0x12345678;            char* h_input_str = (char*)malloc(input_length * sizeof(char));     unsigned char* h_possible_plaintext_str = (unsigned char*)malloc(input_length * sizeof(unsigned char));                 char* d_input_str;     unsigned char* d_possible_plaintext_str;     cudaMalloc((void**)&d_input_str, input_length * sizeof(char));     cudaMalloc((void**)&d_possible_plaintext_str, input_length * sizeof(unsigned char));                 dim3 gridSize((input_length + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           kernelXor<<<gridSize, blockSize>>>(key, d_input_str, d_possible_plaintext_str, input_length);                 cudaFree(d_input_str);     cudaFree(d_possible_plaintext_str);           free(h_input_str);     free(h_possible_plaintext_str);      return 0; } "
    },
    {
        "id": "98",
        "c_code": "#include <stdio.h>  void envejecer_kernel_cpu(int *estado, int *edad, int *pupacion, int *N_mobil, int dia) {     int N = N_mobil[0];          for (int id = 0; id < N; id++) {         if (dia < 80 || dia > 320) {             if (edad[id] > pupacion[id]) {                 edad[id]++;             }         } else {             edad[id]++;         }     } }  int main() {          const int N = 5;     int estado[N] = {1, 1, 1, 0, 1};     int edad[N] = {75, 90, 100, 50, 60};     int pupacion[N] = {70, 80, 95, 45, 55};     int N_mobil[1] = {N};     int dia = 100;           envejecer_kernel_cpu(estado, edad, pupacion, N_mobil, dia);           printf(\"Edad after envejecer_kernel_cpu:\\n\");     for (int i = 0; i < N; i++) {         printf(\"%d \", edad[i]);     }     printf(\"\\n\");      return 0; } ",
        "cuda_code": "#include <stdio.h>   __global__ void envejecer_kernel(int* estado, int* edad, int* pupacion, int* N_mobil, int dia) {     int N = N_mobil[0];     int id = blockIdx.x * blockDim.x + threadIdx.x;      if (id < N) {         if (dia < 80 || dia > 320) {             if (edad[id] > pupacion[id])                 edad[id]++;         } else {             edad[id]++;         }     } }  int main() {          int N = 512;      int dia = 150;            int* h_estado = (int*)malloc(N * sizeof(int));     int* h_edad = (int*)malloc(N * sizeof(int));     int* h_pupacion = (int*)malloc(N * sizeof(int));     int* h_N_mobil = (int*)malloc(sizeof(int));                 int* d_estado, * d_edad, * d_pupacion, * d_N_mobil;     cudaMalloc((void**)&d_estado, N * sizeof(int));     cudaMalloc((void**)&d_edad, N * sizeof(int));     cudaMalloc((void**)&d_pupacion, N * sizeof(int));     cudaMalloc((void**)&d_N_mobil, sizeof(int));                 dim3 gridSize((N + 255) / 256, 1, 1);     dim3 blockSize(256, 1, 1);           envejecer_kernel<<<gridSize, blockSize>>>(d_estado, d_edad, d_pupacion, d_N_mobil, dia);                 cudaFree(d_estado);     cudaFree(d_edad);     cudaFree(d_pupacion);     cudaFree(d_N_mobil);           free(h_estado);     free(h_edad);     free(h_pupacion);     free(h_N_mobil);      return 0; } "
    },
    {
        "id": "99",
        "c_code": "#include <stdio.h> #include <math.h>  void globalCalculateKernel(float *c, float *a, float *b, int size) {     for (int i = 0; i < size; i++) {         for (int j = 0; j < size; j++) {             c[i * size + j] = sin(a[i * size + j]) * sin(a[i * size + j]) +                                cos(b[i * size + j]) * cos(b[i * size + j]) * cos(b[i * size + j]);         }     } }  int main() {          const int size = 3;     float a[size * size];     float b[size * size];     float c[size * size];           for (int i = 0; i < size * size; i++) {         a[i] = i + 1;         b[i] = i - 1;     }           globalCalculateKernel(c, a, b, size);           printf(\"Resultant matrix c:\\n\");     for (int i = 0; i < size; i++) {         for (int j = 0; j < size; j++) {             printf(\"%f \", c[i * size + j]);         }         printf(\"\\n\");     }      return 0; } ",
        "cuda_code": "#include <stdio.h> #include <math.h>   __global__ void globalCalculateKernel(float* c, float* a, float* b) {     int i = blockIdx.x * blockDim.x + threadIdx.x;     int j = blockIdx.y * blockDim.y + threadIdx.y;      c[i * j] = sin(a[i * j]) * sin(a[i * j]) + cos(b[i * j]) * cos(b[i * j]) * cos(b[i * j]); }  int main() {          int width = 512;            float* h_c = (float*)malloc(width * width * sizeof(float));     float* h_a = (float*)malloc(width * width * sizeof(float));     float* h_b = (float*)malloc(width * width * sizeof(float));                 float* d_c, * d_a, * d_b;     cudaMalloc((void**)&d_c, width * width * sizeof(float));     cudaMalloc((void**)&d_a, width * width * sizeof(float));     cudaMalloc((void**)&d_b, width * width * sizeof(float));                 dim3 gridSize((width + 15) / 16, (width + 15) / 16, 1);     dim3 blockSize(16, 16, 1);           globalCalculateKernel<<<gridSize, blockSize>>>(d_c, d_a, d_b);                 cudaFree(d_c);     cudaFree(d_a);     cudaFree(d_b);           free(h_c);     free(h_a);     free(h_b);      return 0; } "
    }
]