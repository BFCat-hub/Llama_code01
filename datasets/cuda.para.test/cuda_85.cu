#include <device_launch_parameters.h>
#include <stdio.h>

// CUDA kernel for matrix transpose
__global__ void gpu_matrix_transpose(int* mat_in, int* mat_out, unsigned int rows, unsigned int cols) {
    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;
    unsigned int idy = blockIdx.y * blockDim.y + threadIdx.y;

    if (idx < cols && idy < rows) {
        unsigned int pos = idy * cols + idx;
        unsigned int trans_pos = idx * rows + idy;
        mat_out[trans_pos] = mat_in[pos];
    }
}

int main() {
    // Set your desired matrix dimensions
    unsigned int rows = 512;
    unsigned int cols = 512;

    // Allocate memory on the host
    int* h_mat_in = (int*)malloc(rows * cols * sizeof(int));
    int* h_mat_out = (int*)malloc(rows * cols * sizeof(int));

    // Initialize or copy data to host memory

    // Allocate memory on the device
    int* d_mat_in, * d_mat_out;
    cudaMalloc((void**)&d_mat_in, rows * cols * sizeof(int));
    cudaMalloc((void**)&d_mat_out, rows * cols * sizeof(int));

    // Copy data to device memory

    // Calculate grid and block dimensions
    dim3 gridSize((cols + 15) / 16, (rows + 15) / 16);
    dim3 blockSize(16, 16);

    // Launch the CUDA kernel for matrix transpose
    gpu_matrix_transpose<<<gridSize, blockSize>>>(d_mat_in, d_mat_out, rows, cols);

    // Copy the result back to the host

    // Free device memory
    cudaFree(d_mat_in);
    cudaFree(d_mat_out);

    // Free host memory
    free(h_mat_in);
    free(h_mat_out);

    return 0;
}
