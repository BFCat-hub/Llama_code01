[
    {
        "id": "1",
        "c_code": "#include <stdio.h>\n\nvoid add_100(int numElements, int *data) {\n    for (int idx = 0; idx < numElements; idx++) {\n        data[idx] += 100;\n    }\n}\n\nint main() {\n    \n    int array[] = {1, 2, 3, 4, 5};\n    int numElements = sizeof(array) / sizeof(array[0]);\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%d \", array[i]);\n    }\n\n    \n    add_100(numElements, array);\n\n    printf(\"\\n\u4fee\u6539\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%d \", array[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void add_100(int numElements, int* data) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid < numElements) {\n        data[tid] += 100;\n    }\n}\n\nint main() {\n    \n    int numElements = 1000;\n\n    \n    int* h_data = (int*)malloc(numElements * sizeof(int));\n\n    \n    for (int i = 0; i < numElements; ++i) {\n        h_data[i] = i;\n    }\n\n    \n    int* d_data;\n    cudaMalloc((void**)&d_data, numElements * sizeof(int));\n\n    \n    cudaMemcpy(d_data, h_data, numElements * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (numElements + blockSize - 1) / blockSize;\n\n    \n    add_100<<<gridSize, blockSize>>>(numElements, d_data);\n\n    \n    cudaMemcpy(h_data, d_data, numElements * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < numElements; ++i) {\n        printf(\"%d \", h_data[i]);\n    }\n\n    \n    free(h_data);\n    cudaFree(d_data);\n\n    return 0;\n}\n"
    },
    {
        "id": "10",
        "c_code": "#include <stdio.h>\n\nvoid test_cpu(float *input, const int dims) {\n    for (int tid = 0; tid < dims; tid++) {\n        if (tid == 0) {\n            input[tid] = 0;\n        }\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float array[arraySize];\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", array[i]);\n    }\n\n    \n    test_cpu(array, arraySize);\n\n    printf(\"\\n\u6d4b\u8bd5\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", array[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void test(float* input, const int dims) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= dims) {\n        return;\n    }\n\n    if (tid == 0) {\n        input[tid] = 0;\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float* h_input = (float*)malloc(arraySize * sizeof(float));\n\n    \n    float* d_input;\n    cudaMalloc((void**)&d_input, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_input, h_input, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    test<<<gridSize, blockSize>>>(d_input, arraySize);\n\n    \n    cudaMemcpy(h_input, d_input, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_input[i]);\n    }\n\n    \n    free(h_input);\n    cudaFree(d_input);\n\n    return 0;\n}\n"
    },
    {
        "id": "100",
        "c_code": "#include <stdio.h>\n\nvoid cpu_matrix_mul(int *a, int *b, int *c, int N) {\n    for (int row = 0; row < N; row++) {\n        for (int col = 0; col < N; col++) {\n            int sum = 0;\n            for (int i = 0; i < N; i++) {\n                sum += a[row * N + i] * b[i * N + col];\n            }\n            c[row * N + col] = sum;\n        }\n    }\n}\n\nint main() {\n    \n    const int N = 3;\n    int a[N * N] = {1, 2, 3, 4, 5, 6, 7, 8, 9};\n    int b[N * N] = {9, 8, 7, 6, 5, 4, 3, 2, 1};\n    int c[N * N];\n\n    \n    cpu_matrix_mul(a, b, c, N);\n\n    \n    printf(\"Resultant matrix c:\\n\");\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            printf(\"%d \", c[i * N + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void gpu_matrix_mul(int* a, int* b, int* c, int N) {\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    int sum = 0;\n\n    if (col < N && row < N) {\n        for (int i = 0; i < N; i++) {\n            sum += a[row * N + i] * b[i * N + col];\n        }\n        c[row * N + col] = sum;\n    }\n}\n\nint main() {\n    \n    int N = 512; \n\n    \n    int* h_a = (int*)malloc(N * N * sizeof(int));\n    int* h_b = (int*)malloc(N * N * sizeof(int));\n    int* h_c = (int*)malloc(N * N * sizeof(int));\n\n    \n\n    \n    int* d_a, * d_b, * d_c;\n    cudaMalloc((void**)&d_a, N * N * sizeof(int));\n    cudaMalloc((void**)&d_b, N * N * sizeof(int));\n    cudaMalloc((void**)&d_c, N * N * sizeof(int));\n\n    \n\n    \n    dim3 gridSize((N + 15) / 16, (N + 15) / 16, 1);\n    dim3 blockSize(16, 16, 1);\n\n    \n    gpu_matrix_mul<<<gridSize, blockSize>>>(d_a, d_b, d_c, N);\n\n    \n\n    \n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    \n    free(h_a);\n    free(h_b);\n    free(h_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "101",
        "c_code": "#include <stdio.h>\n\nvoid grayscale(unsigned char *input, unsigned char *output, int size) {\n    unsigned char r, g, b;\n    \n    for (int i = 0; i < size; i++) {\n        r = input[3 * i];\n        g = input[3 * i + 1];\n        b = input[3 * i + 2];\n        output[i] = (unsigned char)(0.21 * (float)r + 0.71 * (float)g + 0.07 * (float)b);\n    }\n}\n\nint main() {\n    \n    const int size = 3;\n    unsigned char input[size * 3] = {255, 0, 0, 0, 255, 0, 0, 0, 255};\n    unsigned char output[size];\n\n    \n    grayscale(input, output, size);\n\n    \n    printf(\"Resultant grayscale values:\\n\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%d \", output[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void grayscale(unsigned char* input, unsigned char* output, int size) {\n    int i = threadIdx.x + blockDim.x * blockIdx.x;\n\n    if (i < size) {\n        unsigned char r, g, b;\n        r = input[3 * i];\n        g = input[3 * i + 1];\n        b = input[3 * i + 2];\n\n        output[i] = (unsigned char)(0.21 * (float)r + 0.71 * (float)g + 0.07 * (float)b);\n    }\n}\n\nint main() {\n    \n    int size = 512; \n\n    \n    unsigned char* h_input = (unsigned char*)malloc(3 * size * sizeof(unsigned char));\n    unsigned char* h_output = (unsigned char*)malloc(size * sizeof(unsigned char));\n\n    \n\n    \n    unsigned char* d_input, * d_output;\n    cudaMalloc((void**)&d_input, 3 * size * sizeof(unsigned char));\n    cudaMalloc((void**)&d_output, size * sizeof(unsigned char));\n\n    \n\n    \n    dim3 gridSize((size + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    grayscale<<<gridSize, blockSize>>>(d_input, d_output, size);\n\n    \n\n    \n    cudaFree(d_input);\n    cudaFree(d_output);\n\n    \n    free(h_input);\n    free(h_output);\n\n    return 0;\n}\n"
    },
    {
        "id": "102",
        "c_code": "#include <stdio.h>\n\nvoid subtractMean_cpu(double *images, const double *meanImage, int imageNum, int pixelNum) {\n    for (int col = 0; col < pixelNum; col++) {\n        for (int row = 0; row < imageNum; ++row) {\n            images[row * pixelNum + col] -= meanImage[col];\n            if (images[row * pixelNum + col] < 0.0) {\n                images[row * pixelNum + col] = 0.0;\n            }\n        }\n    }\n}\n\nint main() {\n    \n    const int imageNum = 2;\n    const int pixelNum = 3;\n    double images[imageNum * pixelNum] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    double meanImage[pixelNum] = {2.0, 3.0, 4.0};\n\n    \n    subtractMean_cpu(images, meanImage, imageNum, pixelNum);\n\n    \n    printf(\"Resultant images after subtracting mean:\\n\");\n    for (int i = 0; i < imageNum; i++) {\n        for (int j = 0; j < pixelNum; j++) {\n            printf(\"%f \", images[i * pixelNum + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void subtractMean(double* images, const double* meanImage, size_t imageNum, size_t pixelNum) {\n    size_t col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (col >= pixelNum) {\n        return;\n    }\n\n    for (size_t row = 0; row < imageNum; ++row) {\n        images[row * pixelNum + col] -= meanImage[col];\n\n        if (images[row * pixelNum + col] < 0.0) {\n            images[row * pixelNum + col] = 0.0;\n        }\n    }\n}\n\nint main() {\n    \n    size_t imageNum = 512;   \n    size_t pixelNum = 1024;  \n\n    \n    double* h_images = (double*)malloc(imageNum * pixelNum * sizeof(double));\n    double* h_meanImage = (double*)malloc(pixelNum * sizeof(double));\n\n    \n\n    \n    double* d_images, * d_meanImage;\n    cudaMalloc((void**)&d_images, imageNum * pixelNum * sizeof(double));\n    cudaMalloc((void**)&d_meanImage, pixelNum * sizeof(double));\n\n    \n\n    \n    dim3 gridSize((pixelNum + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    subtractMean<<<gridSize, blockSize>>>(d_images, d_meanImage, imageNum, pixelNum);\n\n    \n\n    \n    cudaFree(d_images);\n    cudaFree(d_meanImage);\n\n    \n    free(h_images);\n    free(h_meanImage);\n\n    return 0;\n}\n"
    },
    {
        "id": "103",
        "c_code": "#include <stdio.h>\n\nvoid kernelMaximum(float *maxhd, float *maxvd, int start, int size) {\n    int tx = start;\n    float max_hd = 1.175494351e-38F;\n    float max_vd = 1.175494351e-38F;\n\n    for (; tx < size; tx++) {\n        if (maxhd[tx] > max_hd)\n            max_hd = maxhd[tx];\n        if (maxvd[tx] > max_vd)\n            max_vd = maxvd[tx];\n    }\n}\n\nint main() {\n    \n    const int size = 5;\n    float maxhd[size] = {1.0, 2.0, 3.0, 4.0, 5.0};\n    float maxvd[size] = {5.0, 4.0, 3.0, 2.0, 1.0};\n\n    \n    kernelMaximum(maxhd, maxvd, 0, size);\n\n    \n    printf(\"Max_hd: %f\\n\", maxhd[0]);\n    printf(\"Max_vd: %f\\n\", maxvd[0]);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void kernelMaximum(float* maxhd, float* maxvd, int start, int size) {\n    int tx = start + threadIdx.x;\n\n    for (int i = size >> 1; i > 0; i >>= 1) {\n        __syncthreads();\n\n        if (tx < i) {\n            if (maxhd[tx] < maxhd[tx + i]) maxhd[tx] = maxhd[tx + i];\n            if (maxvd[tx] < maxvd[tx + i]) maxvd[tx] = maxvd[tx + i];\n        }\n    }\n}\n\nint main() {\n    \n    int start = 0;    \n    int size = 1024;  \n\n    \n    float* h_maxhd = (float*)malloc(size * sizeof(float));\n    float* h_maxvd = (float*)malloc(size * sizeof(float));\n\n    \n\n    \n    float* d_maxhd, * d_maxvd;\n    cudaMalloc((void**)&d_maxhd, size * sizeof(float));\n    cudaMalloc((void**)&d_maxvd, size * sizeof(float));\n\n    \n\n    \n    dim3 gridSize(1, 1, 1);\n    dim3 blockSize(size, 1, 1);\n\n    \n    kernelMaximum<<<gridSize, blockSize>>>(d_maxhd, d_maxvd, start, size);\n\n    \n\n    \n    cudaFree(d_maxhd);\n    cudaFree(d_maxvd);\n\n    \n    free(h_maxhd);\n    free(h_maxvd);\n\n    return 0;\n}\n"
    },
    {
        "id": "104",
        "c_code": "#include <stdio.h>\n\nvoid SparseMatmul_forward(float *a, float *b, float *c, int *indptr, int *indices, int p, int size) {\n    for (int i = 0; i < size - 1; i++) {\n        for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {\n            int j = indices[jj];\n            for (int k = 0; k < p; k++) {\n                c[i * p + k] += a[jj] * b[j * p + k];\n            }\n        }\n    }\n}\n\nint main() {\n    \n    const int size = 3;\n    const int p = 2;\n    float a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    float b[] = {2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0};\n    float c[size * p] = {0.0};\n\n    int indptr[] = {0, 2, 4};   \n    int indices[] = {1, 2, 0, 1};   \n\n    \n    SparseMatmul_forward(a, b, c, indptr, indices, p, size);\n\n    \n    printf(\"Resultant matrix c:\\n\");\n    for (int i = 0; i < size; i++) {\n        for (int j = 0; j < p; j++) {\n            printf(\"%f \", c[i * p + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void cuda_SparseMatmul_forward_kernel(float* a_in, float* b_in, float* c_in, int* indptr, int* indices, int p) {\n    int i = blockIdx.x;\n    int k = threadIdx.x;\n\n    for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {\n        int j = indices[jj];\n        c_in[i * p + k] += a_in[jj] * b_in[j * p + k];\n    }\n}\n\nint main() {\n    \n    int numRows = 512;  \n    int numCols = 256;  \n    int numNonZeros = 1024;  \n\n    \n    float* h_a_in = (float*)malloc(numNonZeros * sizeof(float));\n    float* h_b_in = (float*)malloc(numCols * p * sizeof(float));\n    float* h_c_in = (float*)malloc(numRows * p * sizeof(float));\n    int* h_indptr = (int*)malloc((numRows + 1) * sizeof(int));\n    int* h_indices = (int*)malloc(numNonZeros * sizeof(int));\n\n    \n\n    \n    float* d_a_in, * d_b_in, * d_c_in;\n    int* d_indptr, * d_indices;\n    cudaMalloc((void**)&d_a_in, numNonZeros * sizeof(float));\n    cudaMalloc((void**)&d_b_in, numCols * p * sizeof(float));\n    cudaMalloc((void**)&d_c_in, numRows * p * sizeof(float));\n    cudaMalloc((void**)&d_indptr, (numRows + 1) * sizeof(int));\n    cudaMalloc((void**)&d_indices, numNonZeros * sizeof(int));\n\n    \n\n    \n    dim3 gridSize(numRows, 1, 1);\n    dim3 blockSize(p, 1, 1);\n\n    \n    cuda_SparseMatmul_forward_kernel<<<gridSize, blockSize>>>(d_a_in, d_b_in, d_c_in, d_indptr, d_indices, p);\n\n    \n\n    \n    cudaFree(d_a_in);\n    cudaFree(d_b_in);\n    cudaFree(d_c_in);\n    cudaFree(d_indptr);\n    cudaFree(d_indices);\n\n    \n    free(h_a_in);\n    free(h_b_in);\n    free(h_c_in);\n    free(h_indptr);\n    free(h_indices);\n\n    return 0;\n}\n"
    },
    {
        "id": "105",
        "c_code": "#include <stdio.h>\n\nvoid vectorMatrixMult(long int totalPixels, int availablePixels, int outPixelOffset, float *matrix, float *vector, float *out) {\n    for (long int i = 0; i < availablePixels; i++) {\n        float sum = 0.0;\n        for (long int j = 0; j < totalPixels; j++) {\n            sum += matrix[i * totalPixels + j] * vector[j];\n        }\n        out[i + outPixelOffset] = sum;\n    }\n}\n\nint main() {\n    \n    const long int totalPixels = 4;\n    const int availablePixels = 2;\n    const int outPixelOffset = 1;\n    float matrix[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0};\n    float vector[] = {2.0, 1.0, 3.0, 4.0};\n    float out[availablePixels + outPixelOffset];\n\n    \n    vectorMatrixMult(totalPixels, availablePixels, outPixelOffset, matrix, vector, out);\n\n    \n    printf(\"Resultant vector out:\\n\");\n    for (int i = 0; i < availablePixels + outPixelOffset; i++) {\n        printf(\"%f \", out[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void vectorMatrixMult(long int totalPixels, int availablePixels, int outPixelOffset, float* matrix, float* vector, float* out) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n\n    for (long int i = index; i < availablePixels; i += stride) {\n        float sum = 0.0;\n\n        for (long int j = 0; j < totalPixels; j++) {\n            sum += matrix[i * totalPixels + j] * vector[j];\n        }\n\n        out[i + outPixelOffset] = sum;\n    }\n}\n\nint main() {\n    \n    long int totalPixels = 1024;      \n    int availablePixels = 512;        \n    int outPixelOffset = 256;         \n\n    \n    float* h_matrix = (float*)malloc(availablePixels * totalPixels * sizeof(float));\n    float* h_vector = (float*)malloc(totalPixels * sizeof(float));\n    float* h_out = (float*)malloc(availablePixels * sizeof(float));\n\n    \n\n    \n    float* d_matrix, * d_vector, * d_out;\n    cudaMalloc((void**)&d_matrix, availablePixels * totalPixels * sizeof(float));\n    cudaMalloc((void**)&d_vector, totalPixels * sizeof(float));\n    cudaMalloc((void**)&d_out, availablePixels * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((availablePixels + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    vectorMatrixMult<<<gridSize, blockSize>>>(totalPixels, availablePixels, outPixelOffset, d_matrix, d_vector, d_out);\n\n    \n\n    \n    cudaFree(d_matrix);\n    cudaFree(d_vector);\n    cudaFree(d_out);\n\n    \n    free(h_matrix);\n    free(h_vector);\n    free(h_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "106",
        "c_code": "#include <stdio.h>\n\nvoid convertKinectDisparityInPlace_cpu(float *d_disparity, int pitch, int width, int height, float depth_scale) {\n    for (int x = 0; x < width; x++) {\n        for (int y = 0; y < height; y++) {\n            float *d_in = (float *)((char *)d_disparity + y * pitch) + x;\n            *d_in = (*d_in == 0.0f) ? 1 : (-depth_scale / *d_in);\n        }\n    }\n}\n\nint main() {\n    \n    const int width = 3;\n    const int height = 2;\n    const int pitch = width * sizeof(float);\n    float d_disparity[width * height] = {0.0, 2.0, 0.0, 4.0, 0.0, 6.0};\n    float depth_scale = 2.0;\n\n    \n    convertKinectDisparityInPlace_cpu(d_disparity, pitch, width, height, depth_scale);\n\n    \n    printf(\"Resultant disparity values:\\n\");\n    for (int i = 0; i < width * height; i++) {\n        printf(\"%f \", d_disparity[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void convertKinectDisparityInPlace_kernel(float* d_disparity, int pitch, int width, int height, float depth_scale) {\n    const int x = blockIdx.x * blockDim.x + threadIdx.x;\n    const int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if ((x < width) && (y < height)) {\n        float* d_in = (float*)((char*)d_disparity + y * pitch) + x;\n        *d_in = (*d_in == 0.0f) ? 1 : (-depth_scale / *d_in);\n    }\n}\n\nint main() {\n    \n    int width = 640;   \n    int height = 480;  \n    float depth_scale = 0.001f;  \n\n    \n    float* h_disparity = (float*)malloc(width * height * sizeof(float));\n\n    \n\n    \n    float* d_disparity;\n    cudaMalloc((void**)&d_disparity, width * height * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((width + 15) / 16, (height + 15) / 16, 1);\n    dim3 blockSize(16, 16, 1);\n\n    \n    convertKinectDisparityInPlace_kernel<<<gridSize, blockSize>>>(d_disparity, width * sizeof(float), width, height, depth_scale);\n\n    \n\n    \n    cudaFree(d_disparity);\n\n    \n    free(h_disparity);\n\n    return 0;\n}\n"
    },
    {
        "id": "107",
        "c_code": "#include <stdio.h>\n\nvoid SparseMatmul_backward(float *a, float *b_grad, float *c_grad, int *indptr, int *indices, int p, int size, float *grad) {\n    for (int i = 0; i < size - 1; i++) {\n        for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {\n            int j = indices[jj];\n            for (int k = 0; k < p; k++) {\n                b_grad[j * p + k] += c_grad[i * p + k] * a[jj];\n            }\n        }\n    }\n}\n\nint main() {\n    \n    const int size = 3;\n    const int p = 2;\n    float a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    float b_grad[] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0};\n    float c_grad[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    float grad[size * p] = {0.0};\n\n    int indptr[] = {0, 2, 4};   \n    int indices[] = {1, 2, 0, 1};   \n\n    \n    SparseMatmul_backward(a, b_grad, c_grad, indptr, indices, p, size, grad);\n\n    \n    printf(\"Resultant gradient b_grad:\\n\");\n    for (int i = 0; i < size * p; i++) {\n        printf(\"%f \", b_grad[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void cuda_SparseMatmul_backward_kernel(float* a_in, float* b_in, float* c_in, int* indptr, int* indices, int p) {\n    int i = blockIdx.x;\n    int k = threadIdx.x;\n\n    for (int jj = indptr[i]; jj < indptr[i + 1]; jj++) {\n        int j = indices[jj];\n        b_in[j * p + k] += c_in[i * p + k] * a_in[jj];\n    }\n}\n\nint main() {\n    \n    int p = 256;  \n\n    \n    float* h_a = nullptr;  \n    float* h_b = nullptr;  \n    float* h_c = nullptr;  \n    int* h_indptr = nullptr;  \n    int* h_indices = nullptr;  \n\n    \n    float* d_a, *d_b, *d_c;\n    int* d_indptr, *d_indices;\n    cudaMalloc((void**)&d_a, sizeof(float));  \n    cudaMalloc((void**)&d_b, sizeof(float));  \n    cudaMalloc((void**)&d_c, sizeof(float));  \n    cudaMalloc((void**)&d_indptr, sizeof(int));  \n    cudaMalloc((void**)&d_indices, sizeof(int));  \n\n    \n\n    \n    dim3 gridSize(1, 1, 1);  \n    dim3 blockSize(1, 1, 1);  \n\n    \n    cuda_SparseMatmul_backward_kernel<<<gridSize, blockSize>>>(d_a, d_b, d_c, d_indptr, d_indices, p);\n\n    \n\n    \n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n    cudaFree(d_indptr);\n    cudaFree(d_indices);\n\n    \n    \n\n    return 0;\n}\n"
    },
    {
        "id": "108",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid subsample_ind_and_labels_cpu(int *d_ind_sub, const int *d_ind, unsigned int *d_label_sub, const unsigned int *d_label, int n_out, float inv_sub_factor) {\n    for (int ind_out = 0; ind_out < n_out; ind_out++) {\n        int ind_in = (int)floorf((float)(ind_out) * inv_sub_factor);\n        d_ind_sub[ind_out] = d_ind[ind_in];\n        d_label_sub[ind_out] = d_label[ind_in];\n    }\n}\n\nint main() {\n    \n    const int n_out = 3;\n    float inv_sub_factor = 0.5;\n    int d_ind[] = {1, 2, 3, 4, 5, 6};\n    unsigned int d_label[] = {10, 20, 30, 40, 50, 60};\n    int d_ind_sub[n_out];\n    unsigned int d_label_sub[n_out];\n\n    \n    subsample_ind_and_labels_cpu(d_ind_sub, d_ind, d_label_sub, d_label, n_out, inv_sub_factor);\n\n    \n    printf(\"Resultant subsampled indices and labels:\\n\");\n    for (int i = 0; i < n_out; i++) {\n        printf(\"Index: %d, Label: %u\\n\", d_ind_sub[i], d_label_sub[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <math.h>\n\n__global__ void subsample_ind_and_labels_GPU(int* d_ind_sub, const int* d_ind, unsigned int* d_label_sub, const unsigned int* d_label, int n_out, float inv_sub_factor) {\n    unsigned int ind_out = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (ind_out < n_out) {\n        int ind_in = (int)floorf((float)(ind_out) * inv_sub_factor);\n        d_ind_sub[ind_out] = d_ind[ind_in];\n        d_label_sub[ind_out] = d_label[ind_in];\n    }\n}\n\nint main() {\n    \n    int n_out = 512;  \n    float inv_sub_factor = 0.5f;  \n\n    \n    int* h_ind = nullptr;  \n    unsigned int* h_label = nullptr;  \n\n    \n    int* d_ind, *d_ind_sub;\n    unsigned int* d_label, *d_label_sub;\n    cudaMalloc((void**)&d_ind, sizeof(int));  \n    cudaMalloc((void**)&d_ind_sub, sizeof(int));  \n    cudaMalloc((void**)&d_label, sizeof(unsigned int));  \n    cudaMalloc((void**)&d_label_sub, sizeof(unsigned int));  \n\n    \n\n    \n    dim3 gridSize((n_out + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    subsample_ind_and_labels_GPU<<<gridSize, blockSize>>>(d_ind_sub, d_ind, d_label_sub, d_label, n_out, inv_sub_factor);\n\n    \n\n    \n    cudaFree(d_ind);\n    cudaFree(d_ind_sub);\n    cudaFree(d_label);\n    cudaFree(d_label_sub);\n\n    \n    \n\n    return 0;\n}\n"
    },
    {
        "id": "109",
        "c_code": "#include <stdio.h>\n\nvoid mxm_1d_cpu(double *a, const int m, double *b, const int n, double *c, const int p) {\n    for (int i = 0; i < m; i++) {\n        for (int k = 0; k < p; k++) {\n            double s = 0.0;\n            for (int j = 0; j < n; j++) {\n                s += a[j * m + i] * b[k * n + j];\n            }\n            c[k * m + i] = s;\n        }\n    }\n}\n\nint main() {\n    \n    const int m = 2;\n    const int n = 3;\n    const int p = 4;\n    double a[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    double b[] = {2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0};\n    double c[p * m];\n\n    \n    mxm_1d_cpu(a, m, b, n, c, p);\n\n    \n    printf(\"Resultant matrix c:\\n\");\n    for (int i = 0; i < p; i++) {\n        for (int j = 0; j < m; j++) {\n            printf(\"%f \", c[i * m + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void mxm_1d(double* a, const int m, double* b, const int n, double* c, const int p) {\n    const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i < m) {\n        for (int k = 0; k < p; k++) {\n            double s = 0.0;\n\n            for (int j = 0; j < n; j++) {\n                s += a[j * m + i] * b[k * n + j];\n            }\n\n            c[k * m + i] = s;\n        }\n    }\n}\n\nint main() {\n    \n    int m = 256;  \n    int n = 128;  \n    int p = 64;   \n\n    \n    double* h_a = nullptr;  \n    double* h_b = nullptr;  \n\n    \n    double* d_a, *d_b, *d_c;\n    cudaMalloc((void**)&d_a, sizeof(double));  \n    cudaMalloc((void**)&d_b, sizeof(double));  \n    cudaMalloc((void**)&d_c, sizeof(double));  \n\n    \n\n    \n    dim3 gridSize((m + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    mxm_1d<<<gridSize, blockSize>>>(d_a, m, d_b, n, d_c, p);\n\n    \n\n    \n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    \n    \n\n    return 0;\n}\n"
    },
    {
        "id": "11",
        "c_code": "#include <stdio.h>\n\nvoid set_sorting_offset(const int nrows, const int ncols, int *offsets) {\n    int tid;\n    for (tid = 0; tid <= ncols; tid++) {\n        offsets[tid] = tid * nrows;\n    }\n}\n\nint main() {\n    \n    int numRows = 3;\n    int numCols = 4;\n    int offsetArray[numCols + 1];\n\n    printf(\"\u539f\u59cb\u504f\u79fb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i <= numCols; i++) {\n        printf(\"%d \", offsetArray[i]);\n    }\n\n    \n    set_sorting_offset(numRows, numCols, offsetArray);\n\n    printf(\"\\n\u8bbe\u7f6e\u540e\u7684\u504f\u79fb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i <= numCols; i++) {\n        printf(\"%d \", offsetArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void set_sorting_offset(const int nrows, const int ncols, int* offsets) {\n    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    if (tid <= ncols) {\n        offsets[tid] = tid * nrows;\n    }\n}\n\nint main() {\n    \n    int nrows = 100;\n    int ncols = 10;\n\n    \n    int* h_offsets = (int*)malloc((ncols + 1) * sizeof(int));\n\n    \n    int* d_offsets;\n    cudaMalloc((void**)&d_offsets, (ncols + 1) * sizeof(int));\n\n    \n    int blockSize = 256;\n    int gridSize = (ncols + blockSize - 1) / blockSize;\n\n    \n    set_sorting_offset<<<gridSize, blockSize>>>(nrows, ncols, d_offsets);\n\n    \n    cudaMemcpy(h_offsets, d_offsets, (ncols + 1) * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < ncols + 1; ++i) {\n        printf(\"%d \", h_offsets[i]);\n    }\n\n    \n    free(h_offsets);\n    cudaFree(d_offsets);\n\n    return 0;\n}\n"
    },
    {
        "id": "110",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid fabsf_clamp_cpu(int N, float *X, int INCX, float clamp_min, float clamp_max) {\n    for (int i = 0; i < N; ++i) {\n        if (X[i * INCX] >= 0) {\n            X[i * INCX] = fmin(clamp_max, fmax(clamp_min, X[i * INCX]));\n        } else {\n            X[i * INCX] = fmin(-clamp_min, fmax(-clamp_max, X[i * INCX]));\n        }\n    }\n}\n\nint main() {\n    \n    const int N = 5;\n    const float clamp_min = -1.0;\n    const float clamp_max = 1.0;\n    float X[] = {-2.0, -1.0, 0.0, 1.0, 2.0};\n\n    \n    fabsf_clamp_cpu(N, X, 1, clamp_min, clamp_max);\n\n    \n    printf(\"Resultant array X:\\n\");\n    for (int i = 0; i < N; i++) {\n        printf(\"%f \", X[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <math.h>\n\n__global__ void fabsf_clamp_kernel(int N, float* X, int INCX, float clamp_min, float clamp_max) {\n    int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n\n    if (i < N) {\n        if (X[i * INCX] >= 0)\n            X[i * INCX] = fminf(clamp_max, fmaxf(clamp_min, X[i * INCX]));\n        else\n            X[i * INCX] = fminf(-clamp_min, fmaxf(-clamp_max, X[i * INCX]));\n    }\n}\n\nint main() {\n    \n    int N = 1024;  \n    float clamp_min = -1.0f;  \n    float clamp_max = 1.0f;   \n\n    \n    float* h_X = nullptr;  \n\n    \n    float* d_X;\n    cudaMalloc((void**)&d_X, sizeof(float));  \n\n    \n\n    \n    dim3 gridSize((N + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    fabsf_clamp_kernel<<<gridSize, blockSize>>>(N, d_X, 1, clamp_min, clamp_max);\n\n    \n\n    \n    cudaFree(d_X);\n\n    \n    \n\n    return 0;\n}\n"
    },
    {
        "id": "111",
        "c_code": "#include <stdio.h>\n\nvoid cpu_matrix_mult(int *h_a, int *h_b, int *h_result, int m, int n, int k) {\n    for (int i = 0; i < m; ++i) {\n        for (int j = 0; j < k; ++j) {\n            int tmp = 0.0;\n            for (int h = 0; h < n; ++h) {\n                tmp += h_a[i * n + h] * h_b[h * k + j];\n            }\n            h_result[i * k + j] = tmp;\n        }\n    }\n}\n\nint main() {\n    \n    const int m = 2;\n    const int n = 3;\n    const int k = 2;\n    int h_a[] = {1, 2, 3, 4, 5, 6};\n    int h_b[] = {2, 3, 4, 5, 6, 7};\n    int h_result[m * k];\n\n    \n    cpu_matrix_mult(h_a, h_b, h_result, m, n, k);\n\n    \n    printf(\"Resultant matrix h_result:\\n\");\n    for (int i = 0; i < m; i++) {\n        for (int j = 0; j < k; j++) {\n            printf(\"%d \", h_result[i * k + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void gpu_matrix_mult(int* a, int* b, int* c, int m, int n, int k) {\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    int sum = 0;\n\n    if (col < k && row < m) {\n        for (int i = 0; i < n; i++) {\n            sum += a[row * n + i] * b[i * k + col];\n        }\n\n        c[row * k + col] = sum;\n    }\n}\n\nint main() {\n    \n    int m = 256;  \n    int n = 128;  \n    int k = 64;   \n\n    \n    int* h_a = nullptr;  \n    int* h_b = nullptr;  \n\n    \n    int* d_a, *d_b, *d_c;\n    cudaMalloc((void**)&d_a, sizeof(int));  \n    cudaMalloc((void**)&d_b, sizeof(int));  \n    cudaMalloc((void**)&d_c, sizeof(int));  \n\n    \n\n    \n    dim3 gridSize((k + 15) / 16, (m + 15) / 16, 1);\n    dim3 blockSize(16, 16, 1);\n\n    \n    gpu_matrix_mult<<<gridSize, blockSize>>>(d_a, d_b, d_c, m, n, k);\n\n    \n\n    \n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    \n    \n\n    return 0;\n}\n"
    },
    {
        "id": "112",
        "c_code": "#include <stdio.h>\n\ninline void MulMatrixOnCPU(float *A, float *B, float *C, int nx, int ny) {\n    int i, j, k;\n    float sum = 0.0;\n    for (i = 0; i < nx; i++) {\n        for (j = 0; j < ny; j++) {\n            sum = 0.0;\n            for (k = 0; k < nx; k++) {\n                sum = sum + A[i * nx + k] * B[k * nx + j];\n            }\n            C[i * nx + j] = sum;\n        }\n    }\n}\n\nint main() {\n    \n    const int nx = 2;\n    const int ny = 2;\n    float A[] = {1.0, 2.0, 3.0, 4.0};\n    float B[] = {5.0, 6.0, 7.0, 8.0};\n    float C[nx * nx];\n\n    \n    MulMatrixOnCPU(A, B, C, nx, ny);\n\n    \n    printf(\"Resultant matrix C:\\n\");\n    for (int i = 0; i < nx; i++) {\n        for (int j = 0; j < nx; j++) {\n            printf(\"%f \", C[i * nx + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void MulMatrixOnGPU(float* A, float* B, float* C, int nx, int ny) {\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int j = threadIdx.y + blockIdx.y * blockDim.y;\n\n    if (i < nx && j < ny) {\n        float sum = 0.0;\n\n        for (int k = 0; k < nx; k++) {\n            sum += A[i * nx + k] * B[k * nx + j];\n        }\n\n        C[i * nx + j] = sum;\n    }\n}\n\nint main() {\n    \n    int nx = 256;  \n    int ny = 128;  \n\n    \n    float* h_A = nullptr;  \n    float* h_B = nullptr;  \n    float* h_C = new float[nx * ny];  \n\n    \n    float* d_A, *d_B, *d_C;\n    cudaMalloc((void**)&d_A, sizeof(float) * nx * nx);  \n    cudaMalloc((void**)&d_B, sizeof(float) * nx * nx);  \n    cudaMalloc((void**)&d_C, sizeof(float) * nx * nx);  \n\n    \n\n    \n    dim3 gridSize((nx + 15) / 16, (ny + 15) / 16, 1);\n    dim3 blockSize(16, 16, 1);\n\n    \n    MulMatrixOnGPU<<<gridSize, blockSize>>>(d_A, d_B, d_C, nx, ny);\n\n    \n\n    \n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n\n    \n    delete[] h_C;\n\n    return 0;\n}\n"
    },
    {
        "id": "113",
        "c_code": "#include <stdio.h>\n\nint matrixMulHost(float *h_M, float *h_N, float *h_P, int width) {\n    int Pvalue;\n    for (int row = 0; row < width; ++row) {\n        for (int col = 0; col < width; ++col) {\n            Pvalue = 0;\n            for (int k = 0; k < width; ++k) {\n                Pvalue += h_M[row * width + k] * h_N[k * width + col];\n            }\n            h_P[row * width + col] = Pvalue;\n        }\n    }\n    return 0;\n}\n\nint main() {\n    \n    const int width = 2;\n    float h_M[] = {1.0, 2.0, 3.0, 4.0};\n    float h_N[] = {5.0, 6.0, 7.0, 8.0};\n    float h_P[width * width];\n\n    \n    matrixMulHost(h_M, h_N, h_P, width);\n\n    \n    printf(\"Resultant matrix h_P:\\n\");\n    for (int i = 0; i < width; i++) {\n        for (int j = 0; j < width; j++) {\n            printf(\"%f \", h_P[i * width + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void MatrixMulKernel(float* d_M, float* d_N, float* d_P, int width) {\n    int Row = blockIdx.y * blockDim.y + threadIdx.y;\n    int Col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if ((Row < width) && (Col < width)) {\n        float Pvalue = 0;\n        for (int i = 0; i < width; ++i) {\n            Pvalue += d_M[Row * width + i] * d_N[i * width + Col];\n        }\n        d_P[Row * width + Col] = Pvalue;\n    }\n}\n\nint main() {\n    \n\n    \n    int width = 100; \n\n    float* h_M = (float*)malloc(width * width * sizeof(float));\n    float* h_N = (float*)malloc(width * width * sizeof(float));\n    float* h_P = (float*)malloc(width * width * sizeof(float));\n\n    float* d_M, * d_N, * d_P;\n    cudaMalloc((void**)&d_M, width * width * sizeof(float));\n    cudaMalloc((void**)&d_N, width * width * sizeof(float));\n    cudaMalloc((void**)&d_P, width * width * sizeof(float));\n\n    \n    cudaMemcpy(d_M, h_M, width * width * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_N, h_N, width * width * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16); \n    dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (width + blockSize.y - 1) / blockSize.y);\n    MatrixMulKernel<<<gridSize, blockSize>>>(d_M, d_N, d_P, width);\n\n    \n    cudaMemcpy(h_P, d_P, width * width * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_M);\n    free(h_N);\n    free(h_P);\n    cudaFree(d_M);\n    cudaFree(d_N);\n    cudaFree(d_P);\n\n    return 0;\n}\n"
    },
    {
        "id": "114",
        "c_code": "#include <stdio.h>\n\nvoid mmul_cpu(const float *A, const float *B, float *C, int r1, int c1, int r2, int c2) {\n    for (int idx = 0; idx < c2; idx++) {\n        for (int idy = 0; idy < r1; idy++) {\n            float temp = 0;\n            for (int i = 0; i < c1; i++) {\n                temp += A[idy * c1 + i] * B[i * c2 + idx];\n            }\n            C[idy * c2 + idx] = temp;\n        }\n    }\n}\n\nint main() {\n    \n    const int r1 = 2;\n    const int c1 = 3;\n    const int r2 = 3;\n    const int c2 = 2;\n    float A[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    float B[] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0};\n    float C[r1 * c2];\n\n    \n    mmul_cpu(A, B, C, r1, c1, r2, c2);\n\n    \n    printf(\"Resultant matrix C:\\n\");\n    for (int i = 0; i < r1; i++) {\n        for (int j = 0; j < c2; j++) {\n            printf(\"%f \", C[i * c2 + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void mmul(const float* A, const float* B, float* C, int r1, int c1, int r2, int c2) {\n    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n    int idy = threadIdx.y + blockDim.y * blockIdx.y;\n\n    if ((idx < c2) && (idy < c1)) {\n        float temp = 0;\n\n        for (int i = 0; i < c1; i++)\n            temp += A[idy * c1 + i] * B[i * c2 + idx];\n\n        C[idy * c2 + idx] = temp;\n    }\n}\n\nint main() {\n    \n    int r1 = 256;  \n    int c1 = 128;  \n    int r2 = 128;  \n    int c2 = 64;   \n\n    \n    float* h_A = nullptr;  \n    float* h_B = nullptr;  \n    float* h_C = new float[r1 * c2];  \n\n    \n    float* d_A, *d_B, *d_C;\n    cudaMalloc((void**)&d_A, sizeof(float) * r1 * c1);  \n    cudaMalloc((void**)&d_B, sizeof(float) * c1 * c2);  \n    cudaMalloc((void**)&d_C, sizeof(float) * r1 * c2);  \n\n    \n\n    \n    dim3 gridSize((c2 + 15) / 16, (r1 + 15) / 16, 1);\n    dim3 blockSize(16, 16, 1);\n\n    \n    mmul<<<gridSize, blockSize>>>(d_A, d_B, d_C, r1, c1, r2, c2);\n\n    \n\n    \n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n\n    \n    delete[] h_C;\n\n    return 0;\n}\n"
    },
    {
        "id": "115",
        "c_code": "#include <stdio.h>\n\nvoid Dot(float *C, float *A, float *B, const int r, const int c, const int n) {\n    float temp;\n    for (int i = 0; i < r; i++) {\n        for (int j = 0; j < c; j++) {\n            temp = 0.0;\n            for (int k = 0; k < n; k++) {\n                temp += A[i * n + k] * B[k * c + j];\n            }\n            C[i * c + j] = temp;\n        }\n    }\n}\n\nint main() {\n    \n    const int r = 2;\n    const int c = 2;\n    const int n = 3;\n    float A[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    float B[] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0};\n    float C[r * c];\n\n    \n    Dot(C, A, B, r, c, n);\n\n    \n    printf(\"Resultant matrix C:\\n\");\n    for (int i = 0; i < r; i++) {\n        for (int j = 0; j < c; j++) {\n            printf(\"%f \", C[i * c + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void Kernel_Dot_reduction2(float* dev_c, float* reduction, int r, const int c, const int n, int size_block) {\n    unsigned int i = blockDim.x * blockIdx.x + threadIdx.x;\n    unsigned int j = blockDim.y * blockIdx.y + threadIdx.y;\n\n    if (i >= r || j >= c) return;\n\n    float temp = 0;\n    for (int k = 0; k < size_block; k++) {\n        temp += reduction[i * (c * size_block) + j * size_block + k];\n    }\n\n    dev_c[i * c + j] = temp;\n}\n\nint main() {\n    \n\n    \n    int r = 100; \n    int c = 100;\n    int n = 100;\n    int size_block = 16;\n\n    float* h_reduction = (float*)malloc(r * c * n * sizeof(float));\n    float* h_dev_c = (float*)malloc(r * c * sizeof(float));\n\n    float* d_reduction, * d_dev_c;\n    cudaMalloc((void**)&d_reduction, r * c * n * sizeof(float));\n    cudaMalloc((void**)&d_dev_c, r * c * sizeof(float));\n\n    \n    cudaMemcpy(d_reduction, h_reduction, r * c * n * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16);\n    dim3 gridSize((r + blockSize.x - 1) / blockSize.x, (c + blockSize.y - 1) / blockSize.y);\n    Kernel_Dot_reduction2<<<gridSize, blockSize>>>(d_dev_c, d_reduction, r, c, n, size_block);\n\n    \n    cudaMemcpy(h_dev_c, d_dev_c, r * c * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_reduction);\n    free(h_dev_c);\n    cudaFree(d_reduction);\n    cudaFree(d_dev_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "116",
        "c_code": "#include <stdio.h>\n\nvoid Forwardsub_cpu(double *RES, double *LS, double *LW, double *LPR, int NI, int NJ, int Start, int J, int n) {\n    for (int i = 0; i < n; i++) {\n        int IJ = ((Start + i) * NI) + (J - (Start + i));\n        RES[IJ] = (RES[IJ] - LS[IJ] * RES[IJ - 1] - LW[IJ] * RES[IJ - NJ]) * LPR[IJ];\n    }\n}\n\nint main() {\n    \n    const int NI = 4;\n    const int NJ = 4;\n    const int Start = 1;\n    const int J = 2;\n    const int n = 2;\n    double RES[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};\n    double LS[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6};\n    double LW[] = {2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5};\n    double LPR[] = {0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16};\n\n    \n    Forwardsub_cpu(RES, LS, LW, LPR, NI, NJ, Start, J, n);\n\n    \n    printf(\"Resultant array RES:\\n\");\n    for (int i = 0; i < NI * NJ; i++) {\n        printf(\"%f \", RES[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void Forwardsub(double* RES, double* LS, double* LW, double* LPR, int NI, int NJ, int Start, int J, int n) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    \n    if (i < n) {\n        int IJ = ((Start + i) * NI) + (J - (Start + i));\n        RES[IJ] = (RES[IJ] - LS[IJ] * RES[IJ - 1] - LW[IJ] * RES[IJ - NJ]) * LPR[IJ];\n    }\n}\n\nint main() {\n    \n\n    \n    int NI = 100; \n    int NJ = 100;\n    int Start = 0;\n    int J = 10;\n    int n = 50;\n\n    double* h_RES = (double*)malloc(NI * NJ * sizeof(double));\n    double* h_LS = (double*)malloc(NI * NJ * sizeof(double));\n    double* h_LW = (double*)malloc(NI * NJ * sizeof(double));\n    double* h_LPR = (double*)malloc(NI * NJ * sizeof(double));\n\n    double* d_RES, * d_LS, * d_LW, * d_LPR;\n    cudaMalloc((void**)&d_RES, NI * NJ * sizeof(double));\n    cudaMalloc((void**)&d_LS, NI * NJ * sizeof(double));\n    cudaMalloc((void**)&d_LW, NI * NJ * sizeof(double));\n    cudaMalloc((void**)&d_LPR, NI * NJ * sizeof(double));\n\n    \n    cudaMemcpy(d_RES, h_RES, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_LS, h_LS, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_LW, h_LW, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_LPR, h_LPR, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16);\n    dim3 gridSize((n + blockSize.x - 1) / blockSize.x, 1);\n    Forwardsub<<<gridSize, blockSize>>>(d_RES, d_LS, d_LW, d_LPR, NI, NJ, Start, J, n);\n\n    \n    cudaMemcpy(h_RES, d_RES, NI * NJ * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_RES);\n    free(h_LS);\n    free(h_LW);\n    free(h_LPR);\n    cudaFree(d_RES);\n    cudaFree(d_LS);\n    cudaFree(d_LW);\n    cudaFree(d_LPR);\n\n    return 0;\n}\n"
    },
    {
        "id": "117",
        "c_code": "#include <stdio.h>\n\nvoid cpu_rows_dc_offset_remove_layer_kernel(float *output, float *input, unsigned int width, unsigned int height, unsigned int depth) {\n    for (unsigned int channel = 0; channel < depth; channel++)\n        for (unsigned int row = 0; row < height; row++)\n            for (unsigned int column = 0; column < (width - 1); column++) {\n                unsigned int idx = (channel * height + row) * width + column;\n                output[idx] = input[idx] - input[idx + 1];\n            }\n}\n\nint main() {\n    \n    const unsigned int width = 3;\n    const unsigned int height = 2;\n    const unsigned int depth = 2;\n    float input[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0};\n    float output[width * height * depth];\n\n    \n    cpu_rows_dc_offset_remove_layer_kernel(output, input, width, height, depth);\n\n    \n    printf(\"Resultant array output:\\n\");\n    for (unsigned int channel = 0; channel < depth; channel++) {\n        for (unsigned int row = 0; row < height; row++) {\n            for (unsigned int column = 0; column < width; column++) {\n                unsigned int idx = (channel * height + row) * width + column;\n                printf(\"%f \", output[idx]);\n            }\n            printf(\"\\n\");\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void cuda_rows_dc_offset_remove_layer_kernel(float* output, float* input, unsigned int width, unsigned int height, unsigned int depth) {\n    unsigned int column = threadIdx.x + blockIdx.x * blockDim.x;\n    unsigned int row = threadIdx.y + blockIdx.y * blockDim.y;\n    unsigned int channel = threadIdx.z + blockIdx.z * blockDim.z;\n\n    if (channel < depth && row < height && column < (width - 1)) {\n        unsigned int idx = (channel * height + row) * width + column;\n        output[idx] = input[idx] - input[idx + 1];\n    }\n}\n\nint main() {\n    \n\n    \n    unsigned int width = 100; \n    unsigned int height = 100;\n    unsigned int depth = 3;\n\n    float* h_output = (float*)malloc(width * height * depth * sizeof(float));\n    float* h_input = (float*)malloc(width * height * depth * sizeof(float));\n\n    float* d_output, * d_input;\n    cudaMalloc((void**)&d_output, width * height * depth * sizeof(float));\n    cudaMalloc((void**)&d_input, width * height * depth * sizeof(float));\n\n    \n    cudaMemcpy(d_output, h_output, width * height * depth * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_input, h_input, width * height * depth * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16, 1); \n    dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y, (depth + blockSize.z - 1) / blockSize.z);\n    cuda_rows_dc_offset_remove_layer_kernel<<<gridSize, blockSize>>>(d_output, d_input, width, height, depth);\n\n    \n    cudaMemcpy(h_output, d_output, width * height * depth * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_output);\n    free(h_input);\n    cudaFree(d_output);\n    cudaFree(d_input);\n\n    return 0;\n}\n"
    },
    {
        "id": "118",
        "c_code": "#include <stdio.h>\n\nvoid cpu_cross_correlate(float *Isg, float *Iss, float *sp, float *gp, int npml, int nnz, int nnx) {\n    for (int i1 = npml; i1 < nnz - npml; i1++) {\n        for (int i2 = npml; i2 < nnx - npml; i2++) {\n            int id = i1 + i2 * nnz;\n            float ps = sp[id];\n            float pg = gp[id];\n            Isg[id] += ps * pg;\n            Iss[id] += ps * ps;\n        }\n    }\n}\n\nint main() {\n    \n    const int npml = 1;\n    const int nnz = 4;\n    const int nnx = 3;\n    float sp[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0};\n    float gp[] = {12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0};\n    float Isg[nnz * nnx] = {0};\n    float Iss[nnz * nnx] = {0};\n\n    \n    cpu_cross_correlate(Isg, Iss, sp, gp, npml, nnz, nnx);\n\n    \n    printf(\"Resultant arrays Isg and Iss:\\n\");\n    for (int i2 = 0; i2 < nnx; i2++) {\n        for (int i1 = 0; i1 < nnz; i1++) {\n            int id = i1 + i2 * nnz;\n            printf(\"Isg[%d]: %f, Iss[%d]: %f\\n\", id, Isg[id], id, Iss[id]);\n        }\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void cuda_cross_correlate(float* Isg, float* Iss, float* sp, float* gp, int npml, int nnz, int nnx) {\n    int i1 = threadIdx.x + blockDim.x * blockIdx.x;\n    int i2 = threadIdx.y + blockDim.y * blockIdx.y;\n    int id = i1 + i2 * nnz;\n\n    if (i1 >= npml && i1 < nnz - npml && i2 >= npml && i2 < nnx - npml) {\n        float ps = sp[id];\n        float pg = gp[id];\n        Isg[id] += ps * pg;\n        Iss[id] += ps * ps;\n    }\n}\n\nint main() {\n    \n\n    \n    int npml = 5; \n    int nnz = 100;\n    int nnx = 100;\n\n    float* h_Isg = (float*)malloc(nnz * nnx * sizeof(float));\n    float* h_Iss = (float*)malloc(nnz * nnx * sizeof(float));\n    float* h_sp = (float*)malloc(nnz * nnx * sizeof(float));\n    float* h_gp = (float*)malloc(nnz * nnx * sizeof(float));\n\n    float* d_Isg, * d_Iss, * d_sp, * d_gp;\n    cudaMalloc((void**)&d_Isg, nnz * nnx * sizeof(float));\n    cudaMalloc((void**)&d_Iss, nnz * nnx * sizeof(float));\n    cudaMalloc((void**)&d_sp, nnz * nnx * sizeof(float));\n    cudaMalloc((void**)&d_gp, nnz * nnx * sizeof(float));\n\n    \n    cudaMemcpy(d_Isg, h_Isg, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_Iss, h_Iss, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_sp, h_sp, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_gp, h_gp, nnz * nnx * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16); \n    dim3 gridSize((nnz + blockSize.x - 1) / blockSize.x, (nnx + blockSize.y - 1) / blockSize.y);\n    cuda_cross_correlate<<<gridSize, blockSize>>>(d_Isg, d_Iss, d_sp, d_gp, npml, nnz, nnx);\n\n    \n    cudaMemcpy(h_Isg, d_Isg, nnz * nnx * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_Iss, d_Iss, nnz * nnx * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_Isg);\n    free(h_Iss);\n    free(h_sp);\n    free(h_gp);\n    cudaFree(d_Isg);\n    cudaFree(d_Iss);\n    cudaFree(d_sp);\n    cudaFree(d_gp);\n\n    return 0;\n}\n"
    },
    {
        "id": "119",
        "c_code": "#include <stdio.h>\n\nvoid colorConvert(unsigned char *grayImage, unsigned char *colorImage, int rows, int columns) {\n    for (int column = 0; column < columns; column++) {\n        for (int row = 0; row < rows; row++) {\n            int offset = column + (columns * row);\n            unsigned char grayValue = 0.07 * colorImage[offset * 3] + 0.71 * colorImage[offset * 3 + 1] + 0.21 * colorImage[offset * 3 + 2];\n            grayImage[offset] = grayValue;\n        }\n    }\n}\n\nint main() {\n    \n    const int rows = 2;\n    const int columns = 2;\n    unsigned char colorImage[] = {255, 0, 0, 0, 255, 0, 0, 0, 255, 128, 128, 128};\n    unsigned char grayImage[rows * columns];\n\n    \n    colorConvert(grayImage, colorImage, rows, columns);\n\n    \n    printf(\"Resultant array grayImage:\\n\");\n    for (int row = 0; row < rows; row++) {\n        for (int column = 0; column < columns; column++) {\n            int offset = column + (columns * row);\n            printf(\"%u \", grayImage[offset]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void colorConvert(unsigned char* grayImage, unsigned char* colorImage, int rows, int columns) {\n    int column = blockIdx.x * blockDim.x + threadIdx.x;\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if ((column < columns) && (row < rows)) {\n        int offset = column + (columns * row);\n        unsigned char grayValue = 0.07 * colorImage[offset * 3] + 0.71 * colorImage[offset * 3 + 1] + 0.21 * colorImage[offset * 3 + 2];\n        grayImage[offset] = grayValue;\n    }\n}\n\nint main() {\n    \n\n    \n    int rows = 100; \n    int columns = 100;\n\n    unsigned char* h_grayImage = (unsigned char*)malloc(rows * columns * sizeof(unsigned char));\n    unsigned char* h_colorImage = (unsigned char*)malloc(rows * columns * 3 * sizeof(unsigned char));\n\n    unsigned char* d_grayImage, * d_colorImage;\n    cudaMalloc((void**)&d_grayImage, rows * columns * sizeof(unsigned char));\n    cudaMalloc((void**)&d_colorImage, rows * columns * 3 * sizeof(unsigned char));\n\n    \n    cudaMemcpy(d_grayImage, h_grayImage, rows * columns * sizeof(unsigned char), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_colorImage, h_colorImage, rows * columns * 3 * sizeof(unsigned char), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16); \n    dim3 gridSize((columns + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y);\n    colorConvert<<<gridSize, blockSize>>>(d_grayImage, d_colorImage, rows, columns);\n\n    \n    cudaMemcpy(h_grayImage, d_grayImage, rows * columns * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_grayImage);\n    free(h_colorImage);\n    cudaFree(d_grayImage);\n    cudaFree(d_colorImage);\n\n    return 0;\n}\n"
    },
    {
        "id": "12",
        "c_code": "#include <stdio.h>\n\nvoid dot_cpu(float *c, float *a, float *b, int size) {\n    int t_id;\n    for (t_id = 0; t_id < size; t_id++) {\n        c[t_id] = a[t_id] * b[t_id];\n    }\n}\n\nint main() {\n    \n    int vectorSize = 5;\n    float vectorA[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float vectorB[] = {0.5, 1.5, 2.5, 3.5, 4.5};\n    float resultVector[vectorSize];\n\n    printf(\"\u5411\u91cf A\uff1a\");\n    for (int i = 0; i < vectorSize; i++) {\n        printf(\"%.2f \", vectorA[i]);\n    }\n\n    printf(\"\\n\u5411\u91cf B\uff1a\");\n    for (int i = 0; i < vectorSize; i++) {\n        printf(\"%.2f \", vectorB[i]);\n    }\n\n    \n    dot_cpu(resultVector, vectorA, vectorB, vectorSize);\n\n    printf(\"\\n\u70b9\u4e58\u540e\u7684\u5411\u91cf C\uff1a\");\n    for (int i = 0; i < vectorSize; i++) {\n        printf(\"%.2f \", resultVector[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void dotKernel(float* c, float* a, float* b) {\n    int t_id = blockIdx.x * blockDim.x + threadIdx.x;\n    c[t_id] = a[t_id] * b[t_id];\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float* h_a = (float*)malloc(arraySize * sizeof(float));\n    float* h_b = (float*)malloc(arraySize * sizeof(float));\n    float* h_c = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_a[i] = static_cast<float>(i);\n        h_b[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_a;\n    float* d_b;\n    float* d_c;\n    cudaMalloc((void**)&d_a, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_b, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_c, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    dotKernel<<<gridSize, blockSize>>>(d_c, d_a, d_b);\n\n    \n    cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_c[i]);\n    }\n\n    \n    free(h_a);\n    free(h_b);\n    free(h_c);\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "120",
        "c_code": "#include <stdio.h>\n\nvoid init_image_array_CPU(unsigned long long int *image, int pixels_per_image) {\n    for (int my_pixel = 0; my_pixel < pixels_per_image; my_pixel++) {\n        image[my_pixel] = (unsigned long long int)(0);\n        my_pixel += pixels_per_image;\n        image[my_pixel] = (unsigned long long int)(0);\n        my_pixel += pixels_per_image;\n        image[my_pixel] = (unsigned long long int)(0);\n        my_pixel += pixels_per_image;\n        image[my_pixel] = (unsigned long long int)(0);\n    }\n}\n\nint main() {\n    \n    const int pixels_per_image = 4;\n    unsigned long long int image[pixels_per_image * 4]; \n\n    \n    init_image_array_CPU(image, pixels_per_image);\n\n    \n    printf(\"Resultant array image:\\n\");\n    for (int i = 0; i < pixels_per_image * 4; i++) {\n        printf(\"%llu \", image[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n \n#include <stdio.h>\n\n\n__global__ void init_image_array_GPU(unsigned long long int* image, int pixels_per_image) {\n    int my_pixel = threadIdx.x + blockIdx.x * blockDim.x;\n\n    while (my_pixel < pixels_per_image * 4) {\n        image[my_pixel] = static_cast<unsigned long long int>(0);\n        my_pixel += blockDim.x * gridDim.x;\n    }\n}\n\nint main() {\n    \n\n    \n    int pixels_per_image = 1000; \n    int num_blocks = 100;\n    int threads_per_block = 256;\n\n    unsigned long long int* h_image = (unsigned long long int*)malloc(pixels_per_image * 4 * sizeof(unsigned long long int));\n    unsigned long long int* d_image;\n    cudaMalloc((void**)&d_image, pixels_per_image * 4 * sizeof(unsigned long long int));\n\n    \n    cudaMemcpy(d_image, h_image, pixels_per_image * 4 * sizeof(unsigned long long int), cudaMemcpyHostToDevice);\n\n    \n    init_image_array_GPU<<<num_blocks, threads_per_block>>>(d_image, pixels_per_image);\n\n    \n    cudaMemcpy(h_image, d_image, pixels_per_image * 4 * sizeof(unsigned long long int), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_image);\n    cudaFree(d_image);\n\n    return 0;\n}\n"
    },
    {
        "id": "121",
        "c_code": "#include <stdio.h>\n\nvoid diffusion(const double *x0, double *x1, int nx, int ny, double dt) {\n    int i, j;\n    auto width = nx + 2;\n    for (j = 1; j < ny + 1; ++j) {\n        for (i = 1; i < nx + 1; ++i) {\n            auto pos = i + j * width;\n            x1[pos] = x0[pos] + dt * (-4. * x0[pos] + x0[pos - width] + x0[pos + width] + x0[pos - 1] + x0[pos + 1]);\n        }\n    }\n}\n\nint main() {\n    \n    const int nx = 2;\n    const int ny = 2;\n    const double dt = 0.1;\n    double x0[(nx + 2) * (ny + 2)] = {0.0}; \n    double x1[(nx + 2) * (ny + 2)] = {0.0};\n\n    \n    diffusion(x0, x1, nx, ny, dt);\n\n    \n    printf(\"Resultant array x1:\\n\");\n    for (int j = 0; j < ny + 2; j++) {\n        for (int i = 0; i < nx + 2; i++) {\n            auto pos = i + j * (nx + 2);\n            printf(\"%f \", x1[pos]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void diffusion(double* x0, double* x1, int nx, int ny, double dt) {\n    int i = threadIdx.x + blockDim.x * blockIdx.x + 1;\n    int j = threadIdx.y + blockDim.y * blockIdx.y + 1;\n\n    if (i < nx - 1 && j < ny - 1) {\n        int pos = nx * j + i;\n        x1[pos] = x0[pos] + dt * (-4. * x0[pos] + x0[pos - 1] + x0[pos + 1] + x0[pos - nx] + x0[pos + nx]);\n    }\n}\n\nint main() {\n    \n\n    \n    int nx = 100; \n    int ny = 100;\n    double dt = 0.01;\n\n    double* h_x0 = (double*)malloc(nx * ny * sizeof(double));\n    double* h_x1 = (double*)malloc(nx * ny * sizeof(double));\n\n    double* d_x0, * d_x1;\n    cudaMalloc((void**)&d_x0, nx * ny * sizeof(double));\n    cudaMalloc((void**)&d_x1, nx * ny * sizeof(double));\n\n    \n    cudaMemcpy(d_x0, h_x0, nx * ny * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16); \n    dim3 gridSize((nx + blockSize.x - 2) / blockSize.x, (ny + blockSize.y - 2) / blockSize.y);\n    diffusion<<<gridSize, blockSize>>>(d_x0, d_x1, nx, ny, dt);\n\n    \n    cudaMemcpy(h_x1, d_x1, nx * ny * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_x0);\n    free(h_x1);\n    cudaFree(d_x0);\n    cudaFree(d_x1);\n\n    return 0;\n}\n"
    },
    {
        "id": "122",
        "c_code": "#include <stdio.h>\n\nvoid compute_b_minus_Rx(double *out, double *x, double *b, double *cotans, int *neighbors, int meshStride, int n) {\n    for (int i = 0; i < n; i++) {\n        out[i] = b[i];\n        for (int iN = 0; iN < meshStride; ++iN) {\n            int neighbor = neighbors[i * meshStride + iN];\n            double weight = cotans[i * meshStride + iN];\n            out[i] += weight * x[neighbor];\n        }\n    }\n}\n\nint main() {\n    \n    const int n = 3;\n    const int meshStride = 2;\n    double x[] = {1.0, 2.0, 3.0};\n    double b[] = {4.0, 5.0, 6.0};\n    double cotans[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6};\n    int neighbors[] = {1, 2, 0, 2, 0, 1};\n    double out[n];\n\n    \n    compute_b_minus_Rx(out, x, b, cotans, neighbors, meshStride, n);\n\n    \n    printf(\"Resultant array out:\\n\");\n    for (int i = 0; i < n; i++) {\n        printf(\"%f \", out[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void compute_b_minus_Rx(double* out, double* x, double* b, double* cotans, int* neighbors, int meshStride, int n) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = gridDim.x * blockDim.x;\n\n    for (int i = index; i < n; i += stride) {\n        out[i] = b[i];\n\n        for (int iN = 0; iN < meshStride; ++iN) {\n            int neighbor = neighbors[i * meshStride + iN];\n            double weight = cotans[i * meshStride + iN];\n            out[i] += weight * x[neighbor];\n        }\n    }\n}\n\nint main() {\n    \n\n    \n    int n = 100; \n    int meshStride = 5; \n\n    double* h_out = (double*)malloc(n * sizeof(double));\n    double* h_x = (double*)malloc(n * sizeof(double));\n    double* h_b = (double*)malloc(n * sizeof(double));\n    double* h_cotans = (double*)malloc(n * meshStride * sizeof(double));\n    int* h_neighbors = (int*)malloc(n * meshStride * sizeof(int));\n\n    double* d_out, * d_x, * d_b, * d_cotans;\n    int* d_neighbors;\n\n    cudaMalloc((void**)&d_out, n * sizeof(double));\n    cudaMalloc((void**)&d_x, n * sizeof(double));\n    cudaMalloc((void**)&d_b, n * sizeof(double));\n    cudaMalloc((void**)&d_cotans, n * meshStride * sizeof(double));\n    cudaMalloc((void**)&d_neighbors, n * meshStride * sizeof(int));\n\n    \n    cudaMemcpy(d_x, h_x, n * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, n * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_cotans, h_cotans, n * meshStride * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_neighbors, h_neighbors, n * meshStride * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize((n + blockSize.x - 1) / blockSize.x);\n    compute_b_minus_Rx<<<gridSize, blockSize>>>(d_out, d_x, d_b, d_cotans, d_neighbors, meshStride, n);\n\n    \n    cudaMemcpy(h_out, d_out, n * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_out);\n    free(h_x);\n    free(h_b);\n    free(h_cotans);\n    free(h_neighbors);\n    cudaFree(d_out);\n    cudaFree(d_x);\n    cudaFree(d_b);\n    cudaFree(d_cotans);\n    cudaFree(d_neighbors);\n\n    return 0;\n}\n"
    },
    {
        "id": "123",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid binarize_weights(float *weights, int n, int size, float *binary) {\n    int i, f;\n    for (f = 0; f < n; ++f) {\n        float mean = 0;\n        for (i = 0; i < size; ++i) {\n            mean += fabs(weights[f * size + i]);\n        }\n        mean = mean / size;\n        for (i = 0; i < size; ++i) {\n            binary[f * size + i] = (weights[f * size + i] > 0) ? mean : -mean;\n        }\n    }\n}\n\nint main() {\n    \n    const int n = 2;\n    const int size = 3;\n    float weights[] = {1.0, -2.0, 3.0, -4.0, 5.0, -6.0};\n    float binary[n * size];\n\n    \n    binarize_weights(weights, n, size, binary);\n\n    \n    printf(\"Resultant array binary:\\n\");\n    for (int f = 0; f < n; f++) {\n        for (int i = 0; i < size; i++) {\n            printf(\"%f \", binary[f * size + i]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void binarize_weights_kernel(float* weights, int n, int size, float* binary) {\n    int f = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n\n    if (f >= n)\n        return;\n\n    int i = 0;\n    float mean = 0;\n\n    for (i = 0; i < size; ++i) {\n        mean += abs(weights[f * size + i]);\n    }\n\n    mean = mean / size;\n\n    for (i = 0; i < size; ++i) {\n        binary[f * size + i] = (weights[f * size + i] > 0) ? mean : -mean;\n    }\n}\n\nint main() {\n    \n\n    \n    int n = 100; \n    int size = 50; \n\n    float* h_weights = (float*)malloc(n * size * sizeof(float));\n    float* h_binary = (float*)malloc(n * size * sizeof(float));\n\n    float* d_weights, * d_binary;\n    cudaMalloc((void**)&d_weights, n * size * sizeof(float));\n    cudaMalloc((void**)&d_binary, n * size * sizeof(float));\n\n    \n    cudaMemcpy(d_weights, h_weights, n * size * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize((n * size + blockSize.x - 1) / blockSize.x);\n    binarize_weights_kernel<<<gridSize, blockSize>>>(d_weights, n, size, d_binary);\n\n    \n    cudaMemcpy(h_binary, d_binary, n * size * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_weights);\n    free(h_binary);\n    cudaFree(d_weights);\n    cudaFree(d_binary);\n\n    return 0;\n}\n"
    },
    {
        "id": "124",
        "c_code": "#include <stdio.h>\n\nvoid gather_points_kernel(int b, int c, int n, int m, const float *points, const int *idx, float *out) {\n    for (int i = 0; i < b; i++) {\n        for (int l = 0; l < c; l++) {\n            for (int j = 0; j < m; j++) {\n                int a = idx[i * m + j];\n                out[(i * c + l) * m + j] = points[(i * c + l) * n + a];\n            }\n        }\n    }\n}\n\nint main() {\n    \n    const int b = 2;\n    const int c = 3;\n    const int n = 4;\n    const int m = 5;\n    float points[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};\n    int idx[] = {1, 3, 0, 2, 1, 3, 0, 2, 1, 3};\n    float out[b * c * m];\n\n    \n    gather_points_kernel(b, c, n, m, points, idx, out);\n\n    \n    printf(\"Resultant array out:\\n\");\n    for (int i = 0; i < b; i++) {\n        for (int l = 0; l < c; l++) {\n            for (int j = 0; j < m; j++) {\n                printf(\"%f \", out[(i * c + l) * m + j]);\n            }\n            printf(\"\\n\");\n        }\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void gather_points_kernel(int b, int c, int n, int m, const float* __restrict__ points, const int* __restrict__ idx, float* __restrict__ out) {\n    for (int i = blockIdx.x; i < b; i += gridDim.x) {\n        for (int l = blockIdx.y; l < c; l += gridDim.y) {\n            for (int j = threadIdx.x; j < m; j += blockDim.x) {\n                int a = idx[i * m + j];\n                out[(i * c + l) * m + j] = points[(i * c + l) * n + a];\n            }\n        }\n    }\n}\n\nint main() {\n    \n\n    \n    int b = 100; \n    int c = 3;\n    int n = 500;\n    int m = 10;\n\n    float* h_points = (float*)malloc(b * c * n * sizeof(float));\n    int* h_idx = (int*)malloc(b * m * sizeof(int));\n    float* h_out = (float*)malloc(b * c * m * sizeof(float));\n\n    float* d_points, * d_out;\n    int* d_idx;\n\n    cudaMalloc((void**)&d_points, b * c * n * sizeof(float));\n    cudaMalloc((void**)&d_idx, b * m * sizeof(int));\n    cudaMalloc((void**)&d_out, b * c * m * sizeof(float));\n\n    \n    cudaMemcpy(d_points, h_points, b * c * n * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_idx, h_idx, b * m * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize(b, c);  \n    gather_points_kernel<<<gridSize, blockSize>>>(b, c, n, m, d_points, d_idx, d_out);\n\n    \n    cudaMemcpy(h_out, d_out, b * c * m * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_points);\n    free(h_idx);\n    free(h_out);\n    cudaFree(d_points);\n    cudaFree(d_idx);\n    cudaFree(d_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "125",
        "c_code": "#include <stdio.h>\n\nvoid matrix_mult(int left_rows, int shared_dimensions, int right_columns, float *left, float *right, float *result) {\n    int row, column, cell;\n    for (row = 0; row < left_rows; row++) {\n        for (column = 0; column < right_columns; column++) {\n            result[row * right_columns + column] = 0;\n            for (cell = 0; cell < shared_dimensions; cell++) {\n                result[row * right_columns + column] += left[row * shared_dimensions + cell] * right[cell * right_columns + column];\n            }\n        }\n    }\n}\n\nint main() {\n    \n    const int left_rows = 2;\n    const int shared_dimensions = 3;\n    const int right_columns = 4;\n    float left[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    float right[] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0};\n    float result[left_rows * right_columns];\n\n    \n    matrix_mult(left_rows, shared_dimensions, right_columns, left, right, result);\n\n    \n    printf(\"Resultant array result:\\n\");\n    for (int i = 0; i < left_rows; i++) {\n        for (int j = 0; j < right_columns; j++) {\n            printf(\"%f \", result[i * right_columns + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void gpu_matrix_mult(int left_rows, int shared_dimensions, int right_columns, float* left, float* right, float* result) {\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int column = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (row < left_rows && column < right_columns) {\n        int index = row * right_columns + column;\n        result[index] = 0;\n\n        for (int cell = 0; cell < shared_dimensions; cell++) {\n            result[index] += left[row * shared_dimensions + cell] * right[cell * right_columns + column];\n        }\n    }\n}\n\nint main() {\n    \n\n    \n    int left_rows = 100; \n    int shared_dimensions = 50;\n    int right_columns = 200;\n\n    float* h_left = (float*)malloc(left_rows * shared_dimensions * sizeof(float));\n    float* h_right = (float*)malloc(shared_dimensions * right_columns * sizeof(float));\n    float* h_result = (float*)malloc(left_rows * right_columns * sizeof(float));\n\n    float* d_left, * d_right, * d_result;\n    cudaMalloc((void**)&d_left, left_rows * shared_dimensions * sizeof(float));\n    cudaMalloc((void**)&d_right, shared_dimensions * right_columns * sizeof(float));\n    cudaMalloc((void**)&d_result, left_rows * right_columns * sizeof(float));\n\n    \n    cudaMemcpy(d_left, h_left, left_rows * shared_dimensions * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_right, h_right, shared_dimensions * right_columns * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16); \n    dim3 gridSize((right_columns + blockSize.x - 1) / blockSize.x, (left_rows + blockSize.y - 1) / blockSize.y);\n    gpu_matrix_mult<<<gridSize, blockSize>>>(left_rows, shared_dimensions, right_columns, d_left, d_right, d_result);\n\n    \n    cudaMemcpy(h_result, d_result, left_rows * right_columns * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_left);\n    free(h_right);\n    free(h_result);\n    cudaFree(d_left);\n    cudaFree(d_right);\n    cudaFree(d_result);\n\n    return 0;\n}\n"
    },
    {
        "id": "126",
        "c_code": "#include <stdio.h>\n\nvoid matrixMultiplication_cpu(int *host_a, int *host_b, int *host_c, int row_a, int col_a, int col_b) {\n    for (int i = 0; i < row_a; ++i) {\n        for (int j = 0; j < col_b; ++j) {\n            int tmp = 0;\n            for (int k = 0; k < col_a; ++k) {\n                tmp += host_a[i * col_a + k] * host_b[k * col_b + j];\n            }\n            host_c[i * col_b + j] = tmp;\n        }\n    }\n}\n\nint main() {\n    \n    const int row_a = 2;\n    const int col_a = 3;\n    const int col_b = 4;\n    int host_a[] = {1, 2, 3, 4, 5, 6};\n    int host_b[] = {7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18};\n    int host_c[row_a * col_b];\n\n    \n    matrixMultiplication_cpu(host_a, host_b, host_c, row_a, col_a, col_b);\n\n    \n    printf(\"Resultant array host_c:\\n\");\n    for (int i = 0; i < row_a; i++) {\n        for (int j = 0; j < col_b; j++) {\n            printf(\"%d \", host_c[i * col_b + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void matrixMultiplication(int* dev_a, int* dev_b, int* dev_c, int row_a, int col_a, int col_b) {\n    int row = threadIdx.y + blockIdx.y * blockDim.y;\n    int col = threadIdx.x + blockIdx.x * blockDim.x;\n    int ret = 0;\n\n    if (row < row_a && col < col_b) {\n        for (int i = 0; i < col_a; ++i) {\n            ret += dev_a[row * col_a + i] * dev_b[i * col_b + col];\n        }\n\n        dev_c[row * col_b + col] = ret;\n    }\n}\n\nint main() {\n    \n\n    \n    int row_a = 100; \n    int col_a = 50;\n    int col_b = 200;\n\n    int* h_a = (int*)malloc(row_a * col_a * sizeof(int));\n    int* h_b = (int*)malloc(col_a * col_b * sizeof(int));\n    int* h_c = (int*)malloc(row_a * col_b * sizeof(int));\n\n    int* d_a, * d_b, * d_c;\n    cudaMalloc((void**)&d_a, row_a * col_a * sizeof(int));\n    cudaMalloc((void**)&d_b, col_a * col_b * sizeof(int));\n    cudaMalloc((void**)&d_c, row_a * col_b * sizeof(int));\n\n    \n    cudaMemcpy(d_a, h_a, row_a * col_a * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, col_a * col_b * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16); \n    dim3 gridSize((col_b + blockSize.x - 1) / blockSize.x, (row_a + blockSize.y - 1) / blockSize.y);\n    matrixMultiplication<<<gridSize, blockSize>>>(d_a, d_b, d_c, row_a, col_a, col_b);\n\n    \n    cudaMemcpy(h_c, d_c, row_a * col_b * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_a);\n    free(h_b);\n    free(h_c);\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "127",
        "c_code": "#include <stdio.h>\n\nvoid Backwardsub(double *U, double *RES, double *UN, double *UE, double *LPR, int NI, int NJ, int End, int J, int n) {\n    for (int i = 0; i < n; i++) {\n        int IJ = ((End - i) * NI) + (J - (End - i));\n        RES[IJ] = RES[IJ] - UN[IJ] * RES[IJ + 1] - UE[IJ] * RES[IJ + NJ];\n        U[IJ] = U[IJ] + RES[IJ];\n    }\n}\n\nint main() {\n    \n    const int NI = 3;\n    const int NJ = 3;\n    const int End = 1;\n    const int J = 1;\n    const int n = 1;\n    double U[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};\n    double RES[] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};\n    double UN[] = {1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0};\n    double UE[] = {2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0};\n    double LPR[] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};\n\n    \n    Backwardsub(U, RES, UN, UE, LPR, NI, NJ, End, J, n);\n\n    \n    printf(\"Resultant array U:\\n\");\n    for (int i = 0; i < NI; i++) {\n        for (int j = 0; j < NJ; j++) {\n            printf(\"%f \", U[i * NJ + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void Backwardsub(double* U, double* RES, double* UN, double* UE, double* LPR, int NI, int NJ, int End, int J, int n) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i < n) {\n        int IJ = ((End - i) * NI) + (J - (End - i));\n        RES[IJ] = RES[IJ] - UN[IJ] * RES[IJ + 1] - UE[IJ] * RES[IJ + NJ];\n        U[IJ] = U[IJ] + RES[IJ];\n    }\n}\n\nint main() {\n    \n\n    \n    int NI = 100; \n    int NJ = 100;\n    int End = 50;\n    int J = 25;\n    int n = 10;\n\n    double* h_U = (double*)malloc(NI * NJ * sizeof(double));\n    double* h_RES = (double*)malloc(NI * NJ * sizeof(double));\n    double* h_UN = (double*)malloc(NI * NJ * sizeof(double));\n    double* h_UE = (double*)malloc(NI * NJ * sizeof(double));\n    double* h_LPR = (double*)malloc(NI * NJ * sizeof(double));\n\n    double* d_U, * d_RES, * d_UN, * d_UE, * d_LPR;\n    cudaMalloc((void**)&d_U, NI * NJ * sizeof(double));\n    cudaMalloc((void**)&d_RES, NI * NJ * sizeof(double));\n    cudaMalloc((void**)&d_UN, NI * NJ * sizeof(double));\n    cudaMalloc((void**)&d_UE, NI * NJ * sizeof(double));\n    cudaMalloc((void**)&d_LPR, NI * NJ * sizeof(double));\n\n    \n    cudaMemcpy(d_U, h_U, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_RES, h_RES, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_UN, h_UN, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_UE, h_UE, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_LPR, h_LPR, NI * NJ * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize((n + blockSize.x - 1) / blockSize.x);\n    Backwardsub<<<gridSize, blockSize>>>(d_U, d_RES, d_UN, d_UE, d_LPR, NI, NJ, End, J, n);\n\n    \n    cudaMemcpy(h_U, d_U, NI * NJ * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_U);\n    free(h_RES);\n    free(h_UN);\n    free(h_UE);\n    free(h_LPR);\n    cudaFree(d_U);\n    cudaFree(d_RES);\n    cudaFree(d_UN);\n    cudaFree(d_UE);\n    cudaFree(d_LPR);\n\n    return 0;\n}\n"
    },
    {
        "id": "128",
        "c_code": "#include <stdio.h>\n\nvoid convolution_cpu_1d(float *input, const float *mask, float *output, int array_size, int mask_size) {\n    int MASK_RADIUS = mask_size / 2;\n    float temp = 0.0f;\n    int ELEMENT_INDEX = 0;\n\n    for (int i = 0; i < array_size; i++) {\n        temp = 0;\n\n        for (int j = 0; j < mask_size; j++) {\n            ELEMENT_INDEX = i - MASK_RADIUS + j;\n\n            if (!(ELEMENT_INDEX < 0 || ELEMENT_INDEX > (array_size - 1))) {\n                temp += input[ELEMENT_INDEX] * mask[j];\n            }\n        }\n\n        output[i] = temp;\n    }\n}\n\nint main() {\n    \n    const int array_size = 10;\n    const int mask_size = 3;\n    float input[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0};\n    float mask[] = {0.1, 0.2, 0.1};\n    float output[array_size];\n\n    \n    convolution_cpu_1d(input, mask, output, array_size, mask_size);\n\n    \n    printf(\"Resultant array output:\\n\");\n    for (int i = 0; i < array_size; i++) {\n        printf(\"%f \", output[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void convolution_gpu_1d_naive(float* input, float* mask, float* output, int array_size, int mask_size) {\n    int gid = blockIdx.x * blockDim.x + threadIdx.x;\n    int MASK_RADIUS = mask_size / 2;\n    int ELEMENT_INDEX = 0;\n    float temp = 0.0f;\n\n    if (gid < array_size) {\n        for (int j = 0; j < mask_size; j++) {\n            ELEMENT_INDEX = gid - MASK_RADIUS + j;\n            if (!(ELEMENT_INDEX < 0 || ELEMENT_INDEX > (array_size - 1))) {\n                temp += input[ELEMENT_INDEX] * mask[j];\n            }\n        }\n\n        output[gid] = temp;\n    }\n}\n\nint main() {\n    \n\n    \n    int array_size = 100; \n    int mask_size = 5;    \n\n    float* h_input = (float*)malloc(array_size * sizeof(float));\n    float* h_mask = (float*)malloc(mask_size * sizeof(float));\n    float* h_output = (float*)malloc(array_size * sizeof(float));\n\n    float* d_input, * d_mask, * d_output;\n    cudaMalloc((void**)&d_input, array_size * sizeof(float));\n    cudaMalloc((void**)&d_mask, mask_size * sizeof(float));\n    cudaMalloc((void**)&d_output, array_size * sizeof(float));\n\n    \n    cudaMemcpy(d_input, h_input, array_size * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_mask, h_mask, mask_size * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize((array_size + blockSize.x - 1) / blockSize.x);\n    convolution_gpu_1d_naive<<<gridSize, blockSize>>>(d_input, d_mask, d_output, array_size, mask_size);\n\n    \n    cudaMemcpy(h_output, d_output, array_size * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_input);\n    free(h_mask);\n    free(h_output);\n    cudaFree(d_input);\n    cudaFree(d_mask);\n    cudaFree(d_output);\n\n    return 0;\n}\n"
    },
    {
        "id": "129",
        "c_code": "#include <stdio.h>\n\nvoid getRho(const int numOfNucl, const double *psi, const double *occNo, double *rho, const char debug) {\n    *rho = 0;\n\n    for (int i = 0; i < numOfNucl; ++i)\n        *rho += occNo[i] * psi[i] * psi[i];\n\n    if (debug == 1)\n        printf(\"DEBUG: Print of RHO:\\nRHO = %f\\nThis is the last line (RHO).\\n\\n\", *rho);\n}\n\nint main() {\n    \n    const int numOfNucl = 3;\n    const char debug = 1;\n    double psi[] = {0.1, 0.2, 0.3};\n    double occNo[] = {1.0, 2.0, 3.0};\n    double rho;\n\n    \n    getRho(numOfNucl, psi, occNo, &rho, debug);\n\n    \n    printf(\"Resultant RHO: %f\\n\", rho);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void getRho_cuda(const double* psi, const double* occNo, double* rho) {\n    extern __shared__ double dcopy[];\n\n    dcopy[threadIdx.x] = occNo[threadIdx.x] * psi[threadIdx.x] * psi[threadIdx.x];\n\n    __syncthreads();\n\n    for (int tc = blockDim.x, stepSize = 1; tc > 0; tc >>= 1, stepSize <<= 1) {\n        int pa = threadIdx.x * stepSize;\n        int pb = pa + stepSize;\n\n        if (pb < blockDim.x) {\n            dcopy[pa] += dcopy[pb];\n        }\n    }\n\n    if (threadIdx.x == 0) {\n        *rho = dcopy[0];\n    }\n}\n\nint main() {\n    \n\n    \n    int array_size = 100; \n\n    double* h_psi = (double*)malloc(array_size * sizeof(double));\n    double* h_occNo = (double*)malloc(array_size * sizeof(double));\n    double* h_rho = (double*)malloc(sizeof(double));\n\n    double* d_psi, * d_occNo, * d_rho;\n    cudaMalloc((void**)&d_psi, array_size * sizeof(double));\n    cudaMalloc((void**)&d_occNo, array_size * sizeof(double));\n    cudaMalloc((void**)&d_rho, sizeof(double));\n\n    \n    cudaMemcpy(d_psi, h_psi, array_size * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_occNo, h_occNo, array_size * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize(1);    \n    int sharedMemorySize = blockSize.x * sizeof(double);\n\n    getRho_cuda<<<gridSize, blockSize, sharedMemorySize>>>(d_psi, d_occNo, d_rho);\n\n    \n    cudaMemcpy(h_rho, d_rho, sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_psi);\n    free(h_occNo);\n    free(h_rho);\n    cudaFree(d_psi);\n    cudaFree(d_occNo);\n    cudaFree(d_rho);\n\n    return 0;\n}\n"
    },
    {
        "id": "13",
        "c_code": "#include <stdio.h>\n\nvoid matDiagAddInplace_cpu(double *mat, double alpha, int dim) {\n    for (int i = 0; i < dim; i++) {\n        mat[i * dim + i] += alpha;\n    }\n}\n\nint main() {\n    \n    int matrixDim = 3;\n    double matrix[3][3] = {{1.1, 2.2, 3.3},\n                           {4.4, 5.5, 6.6},\n                           {7.7, 8.8, 9.9}};\n    double alpha = 10.0;\n\n    printf(\"\u539f\u59cb\u77e9\u9635\uff1a\\n\");\n    for (int i = 0; i < matrixDim; i++) {\n        for (int j = 0; j < matrixDim; j++) {\n            printf(\"%.2f \", matrix[i][j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    matDiagAddInplace_cpu((double *)matrix, alpha, matrixDim);\n\n    printf(\"\\n\u5bf9\u89d2\u7ebf\u5143\u7d20\u52a0\u4e0a\u5e38\u6570\u540e\u7684\u77e9\u9635\uff1a\\n\");\n    for (int i = 0; i < matrixDim; i++) {\n        for (int j = 0; j < matrixDim; j++) {\n            printf(\"%.2f \", matrix[i][j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void matDiagAddInplaceKernel(double* mat, double alpha, int dim) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < dim) {\n        mat[i * dim + i] += alpha;\n    }\n}\n\nint main() {\n    \n    int matrixDim = 5;\n\n    \n    double* h_mat = (double*)malloc(matrixDim * matrixDim * sizeof(double));\n\n    \n    for (int i = 0; i < matrixDim * matrixDim; ++i) {\n        h_mat[i] = static_cast<double>(i);\n    }\n\n    \n    double* d_mat;\n    cudaMalloc((void**)&d_mat, matrixDim * matrixDim * sizeof(double));\n\n    \n    cudaMemcpy(d_mat, h_mat, matrixDim * matrixDim * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (matrixDim * matrixDim + blockSize - 1) / blockSize;\n\n    \n    matDiagAddInplaceKernel<<<gridSize, blockSize>>>(d_mat, 2.0, matrixDim);\n\n    \n    cudaMemcpy(h_mat, d_mat, matrixDim * matrixDim * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < matrixDim; ++i) {\n        for (int j = 0; j < matrixDim; ++j) {\n            printf(\"%f \", h_mat[i * matrixDim + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    free(h_mat);\n    cudaFree(d_mat);\n\n    return 0;\n}\n"
    },
    {
        "id": "130",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid colLog2SumExp2_cpu(const double *mat, double *buf, int m, int n) {\n    for (int j = 0; j < n; j++) {\n        double maximum = mat[j];\n\n        for (int i = 1; i < m; i++) {\n            if (mat[i * n + j] > maximum) {\n                maximum = mat[i * n + j];\n            }\n        }\n\n        double res = 0.0;\n\n        for (int i = 0; i < m; i++) {\n            res += exp(mat[i * n + j] - maximum);\n        }\n\n        buf[j] = log2(res) + maximum;\n    }\n}\n\nint main() {\n    \n    const int m = 3;\n    const int n = 2;\n    double mat[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    double buf[n];\n\n    \n    colLog2SumExp2_cpu(mat, buf, m, n);\n\n    \n    for (int j = 0; j < n; j++) {\n        printf(\"Resultant buf[%d]: %f\\n\", j, buf[j]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void colLog2SumExp2Kernel(const double* mat, double* buf, int m, int n) {\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (j < n) {\n        double maximum = mat[j];\n\n        for (int i = 1; i < m; i++) {\n            if (mat[i * n + j] > maximum) {\n                maximum = mat[i * n + j];\n            }\n        }\n\n        double res = 0.0;\n\n        for (int i = 0; i < m; i++) {\n            res += mat[i * n + j] - maximum;\n        }\n\n        buf[j] = res + maximum;\n    }\n}\n\nint main() {\n    \n\n    \n    int m = 100; \n    int n = 50;  \n\n    double* h_mat = (double*)malloc(m * n * sizeof(double));\n    double* h_buf = (double*)malloc(n * sizeof(double));\n\n    double* d_mat, * d_buf;\n    cudaMalloc((void**)&d_mat, m * n * sizeof(double));\n    cudaMalloc((void**)&d_buf, n * sizeof(double));\n\n    \n    cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize((n + blockSize.x - 1) / blockSize.x);\n\n    colLog2SumExp2Kernel<<<gridSize, blockSize>>>(d_mat, d_buf, m, n);\n\n    \n    cudaMemcpy(h_buf, d_buf, n * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_mat);\n    free(h_buf);\n    cudaFree(d_mat);\n    cudaFree(d_buf);\n\n    return 0;\n}\n"
    },
    {
        "id": "131",
        "c_code": "#include <stdio.h>\n\nvoid bitPrune_cpu(unsigned char *out, float *in, int frontPrune, int outputlength, int inputLength, int n) {\n    for (int i = 0; i < n; i++) {\n        int batch = i / outputlength;\n        int indexInBatch = i % outputlength;\n        int batchInJump = batch * inputLength;\n        int indexOutBatch = i % outputlength;\n        int batchOutJump = batch * outputlength;\n        int frontJump = frontPrune;\n        out[batchOutJump + indexOutBatch] = (char)(in[batchInJump + frontJump + indexInBatch] > 0);\n    }\n}\n\nint main() {\n    \n    const int outputlength = 4;\n    const int inputLength = 6;\n    const int n = 8;\n    float in[] = {1.0, -2.0, 3.0, -4.0, 5.0, -6.0, 7.0, -8.0};\n    unsigned char out[n];\n\n    \n    bitPrune_cpu(out, in, 1, outputlength, inputLength, n);\n\n    \n    for (int i = 0; i < n; i++) {\n        printf(\"Resultant out[%d]: %d\\n\", i, out[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void bitPrune(unsigned char *out, float *in, int frontPrune, int outputLength, int inputLength, int n) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i >= n) {\n        return;\n    }\n\n    int batch = i / outputLength;\n    int indexInBatch = i % outputLength;\n\n    int batchInJump = batch * inputLength;\n    int indexOutBatch = i % outputLength;\n    int batchOutJump = batch * outputLength;\n\n    int frontJump = frontPrune;\n    out[batchOutJump + indexOutBatch] = (char)(in[batchInJump + frontJump + indexInBatch] > 0);\n}\n\nint main() {\n    \n    int frontPrune = 10; \n    int outputLength = 100; \n    int inputLength = 120; \n    int n = 1000; \n\n    unsigned char *out; \n    float *in; \n\n    \n    cudaSetDevice(0);\n\n    \n    unsigned char *d_out;\n    float *d_in;\n\n    cudaMalloc((void **)&d_out, n * outputLength * sizeof(unsigned char));\n    cudaMalloc((void **)&d_in, n * inputLength * sizeof(float));\n\n    \n    cudaMemcpy(d_in, in, n * inputLength * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    bitPrune<<<blocksPerGrid, threadsPerBlock>>>(d_out, d_in, frontPrune, outputLength, inputLength, n);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(out, d_out, n * outputLength * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_out);\n    cudaFree(d_in);\n\n    return 0;\n}\n"
    },
    {
        "id": "132",
        "c_code": "#include <stdio.h>\n\nvoid residual(double *out, double *x, double *b, double *cotans, int *neighbors, double *diag, int meshStride, int n) {\n    for (int i = 0; i < n; i++) {\n        out[i] = diag[i] * x[i] - b[i];\n        for (int iN = 0; iN < meshStride; ++iN) {\n            int neighbor = neighbors[i * meshStride + iN];\n            double weight = cotans[i * meshStride + iN];\n            out[i] -= weight * x[neighbor];\n        }\n    }\n}\n\nint main() {\n    \n    const int n = 5;\n    double x[] = {1.0, 2.0, 3.0, 4.0, 5.0};\n    double b[] = {10.0, 20.0, 30.0, 40.0, 50.0};\n    double cotans[] = {0.1, 0.2, 0.3, 0.4, 0.5};\n    int neighbors[] = {1, 0, 2, 1, 3, 2, 4, 3, 0, 4, 3, 2};\n    double diag[] = {2.0, 3.0, 4.0, 5.0, 6.0};\n    double out[n];\n\n    \n    residual(out, x, b, cotans, neighbors, diag, 3, n);\n\n    \n    for (int i = 0; i < n; i++) {\n        printf(\"Resultant out[%d]: %f\\n\", i, out[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void residual(double* out, double* x, double* b, double* cotans, int* neighbors, double* diag, int meshStride, int n) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = gridDim.x * blockDim.x;\n\n    for (int i = index; i < n; i += stride) {\n        out[i] = diag[i] * x[i] - b[i];\n\n        for (int iN = 0; iN < meshStride; ++iN) {\n            int neighbor = neighbors[i * meshStride + iN];\n            double weight = cotans[i * meshStride + iN];\n            out[i] -= weight * x[neighbor];\n        }\n    }\n}\n\nint main() {\n    \n\n    \n    int n = 100; \n    int meshStride = 6; \n\n    double* h_out = (double*)malloc(n * sizeof(double));\n    double* h_x = (double*)malloc(n * sizeof(double));\n    double* h_b = (double*)malloc(n * sizeof(double));\n    double* h_cotans = (double*)malloc(n * meshStride * sizeof(double));\n    int* h_neighbors = (int*)malloc(n * meshStride * sizeof(int));\n    double* h_diag = (double*)malloc(n * sizeof(double));\n\n    double* d_out, * d_x, * d_b, * d_cotans, * d_diag;\n    int* d_neighbors;\n\n    cudaMalloc((void**)&d_out, n * sizeof(double));\n    cudaMalloc((void**)&d_x, n * sizeof(double));\n    cudaMalloc((void**)&d_b, n * sizeof(double));\n    cudaMalloc((void**)&d_cotans, n * meshStride * sizeof(double));\n    cudaMalloc((void**)&d_neighbors, n * meshStride * sizeof(int));\n    cudaMalloc((void**)&d_diag, n * sizeof(double));\n\n    \n    cudaMemcpy(d_out, h_out, n * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_x, h_x, n * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, n * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_cotans, h_cotans, n * meshStride * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_neighbors, h_neighbors, n * meshStride * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_diag, h_diag, n * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize((n + blockSize.x - 1) / blockSize.x);\n\n    residual<<<gridSize, blockSize>>>(d_out, d_x, d_b, d_cotans, d_neighbors, d_diag, meshStride, n);\n\n    \n    cudaMemcpy(h_out, d_out, n * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_out);\n    free(h_x);\n    free(h_b);\n    free(h_cotans);\n    free(h_neighbors);\n    free(h_diag);\n\n    cudaFree(d_out);\n    cudaFree(d_x);\n    cudaFree(d_b);\n    cudaFree(d_cotans);\n    cudaFree(d_neighbors);\n    cudaFree(d_diag);\n\n    return 0;\n}\n"
    },
    {
        "id": "133",
        "c_code": "#include <stdio.h>\n\nvoid forward_avgpool_layer(int batch, int c, int h, int w, float *input, float *output) {\n    int b, i, k;\n    for (b = 0; b < batch; ++b) {\n        for (k = 0; k < c; ++k) {\n            int out_index = k + b * c;\n            output[out_index] = 0;\n            for (i = 0; i < h * w; ++i) {\n                int in_index = i + h * w * (k + b * c);\n                output[out_index] += input[in_index];\n            }\n            output[out_index] /= h * w;\n        }\n    }\n}\n\nint main() {\n    \n    const int batch = 2;\n    const int channels = 3;\n    const int height = 4;\n    const int width = 4;\n\n    float input[batch * channels * height * width];\n    float output[batch * channels];\n\n    \n\n    \n    forward_avgpool_layer(batch, channels, height, width, input, output);\n\n    \n    for (int b = 0; b < batch; ++b) {\n        for (int c = 0; c < channels; ++c) {\n            printf(\"Resultant output[%d][%d]: %f\\n\", b, c, output[c + b * channels]);\n        }\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void forward_avgpool_layer_kernel(int n, int w, int h, int c, float* input, float* output) {\n    int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n\n    if (id >= n)\n        return;\n\n    int k = id % c;\n    id /= c;\n    int b = id;\n\n    int i;\n    int out_index = (k + c * b);\n    output[out_index] = 0;\n\n    for (i = 0; i < w * h; ++i) {\n        int in_index = i + h * w * (k + b * c);\n        output[out_index] += input[in_index];\n    }\n\n    output[out_index] /= w * h;\n}\n\nint main() {\n    \n\n    \n    int n = 100; \n    int w = 32;  \n    int h = 32;  \n    int c = 3;   \n\n    float* h_input = (float*)malloc(n * w * h * c * sizeof(float));\n    float* h_output = (float*)malloc(n * c * sizeof(float));\n\n    float* d_input, * d_output;\n    cudaMalloc((void**)&d_input, n * w * h * c * sizeof(float));\n    cudaMalloc((void**)&d_output, n * c * sizeof(float));\n\n    \n    cudaMemcpy(d_input, h_input, n * w * h * c * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize((n + blockSize.x - 1) / blockSize.x, 1); \n\n    forward_avgpool_layer_kernel<<<gridSize, blockSize>>>(n, w, h, c, d_input, d_output);\n\n    \n    cudaMemcpy(h_output, d_output, n * c * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_input);\n    free(h_output);\n    cudaFree(d_input);\n    cudaFree(d_output);\n\n    return 0;\n}\n"
    },
    {
        "id": "134",
        "c_code": "#include <stdio.h>\n\nvoid convolutionColumnCPU(float *h_Dst, float *h_Src, float *h_Filter, int imageW, int imageH, int filterR) {\n    int x, y, k;\n    for (y = 0; y < imageH; y++) {\n        for (x = 0; x < imageW; x++) {\n            float sum = 0;\n            for (k = -filterR; k <= filterR; k++) {\n                int d = y + k;\n                if (d >= 0 && d < imageH) {\n                    sum += h_Src[d * imageW + x] * h_Filter[filterR - k];\n                }\n            }\n            h_Dst[y * imageW + x] = sum;\n        }\n    }\n}\n\nint main() {\n    \n    const int imageW = 4;\n    const int imageH = 4;\n    const int filterR = 1;\n\n    float h_Src[imageH * imageW];\n    float h_Filter[2 * filterR + 1];\n    float h_Dst[imageH * imageW];\n\n    \n\n    \n    convolutionColumnCPU(h_Dst, h_Src, h_Filter, imageW, imageH, filterR);\n\n    \n    for (int y = 0; y < imageH; ++y) {\n        for (int x = 0; x < imageW; ++x) {\n            printf(\"Resultant h_Dst[%d][%d]: %f\\n\", y, x, h_Dst[y * imageW + x]);\n        }\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void kernel_columns(const float* filter, const float* buffer, float* output, int imageW, int imageH, int filterR) {\n    int idx_x = threadIdx.x + blockDim.x * blockIdx.x;\n    int idx_y = threadIdx.y + blockDim.y * blockIdx.y;\n    int grid_width = gridDim.x * blockDim.x;\n    int idx = grid_width * idx_y + idx_x;\n\n    float sum = 0;\n\n    for (int k = -filterR; k <= filterR; k++) {\n        int d = idx_y + k;\n\n        if (d >= 0 && d < imageH) {\n            sum += buffer[d * imageW + idx_x] * filter[filterR - k];\n        }\n    }\n\n    output[idx] = sum;\n}\n\nint main() {\n    \n\n    \n    int imageW = 512;    \n    int imageH = 512;    \n    int filterR = 3;     \n\n    float* h_filter = (float*)malloc((2 * filterR + 1) * sizeof(float));\n    float* h_buffer = (float*)malloc(imageW * imageH * sizeof(float));\n    float* h_output = (float*)malloc(imageW * imageH * sizeof(float));\n\n    float* d_filter, * d_buffer, * d_output;\n    cudaMalloc((void**)&d_filter, (2 * filterR + 1) * sizeof(float));\n    cudaMalloc((void**)&d_buffer, imageW * imageH * sizeof(float));\n    cudaMalloc((void**)&d_output, imageW * imageH * sizeof(float));\n\n    \n    cudaMemcpy(d_filter, h_filter, (2 * filterR + 1) * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_buffer, h_buffer, imageW * imageH * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16); \n    dim3 gridSize((imageW + blockSize.x - 1) / blockSize.x, (imageH + blockSize.y - 1) / blockSize.y);\n\n    kernel_columns<<<gridSize, blockSize>>>(d_filter, d_buffer, d_output, imageW, imageH, filterR);\n\n    \n    cudaMemcpy(h_output, d_output, imageW * imageH * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_filter);\n    free(h_buffer);\n    free(h_output);\n    cudaFree(d_filter);\n    cudaFree(d_buffer);\n    cudaFree(d_output);\n\n    return 0;\n}\n"
    },
    {
        "id": "135",
        "c_code": "#include <stdio.h>\n\nvoid matrMult(float *A, float *B, float *C, int rowsA, int colsA, int colsB) {\n    for (int i = 0; i < rowsA; ++i) {\n        for (int j = 0; j < colsB; ++j) {\n            for (int k = 0; k < colsA; ++k) {\n                C[i * colsB + j] += A[i * colsA + k] * B[k * colsB + j];\n            }\n        }\n    }\n}\n\nint main() {\n    \n    const int rowsA = 2;\n    const int colsA = 3;\n    const int colsB = 2;\n\n    float A[rowsA * colsA] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    float B[colsA * colsB] = {7.0, 8.0, 9.0, 10.0, 11.0, 12.0};\n    float C[rowsA * colsB] = {0.0};\n\n    \n    matrMult(A, B, C, rowsA, colsA, colsB);\n\n    \n    for (int i = 0; i < rowsA; ++i) {\n        for (int j = 0; j < colsB; ++j) {\n            printf(\"Resultant C[%d][%d]: %f\\n\", i, j, C[i * colsB + j]);\n        }\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void gpuMatrMultD(float* Ad, float* Bd, float* Cd, int rowsA, int colsA, int colsB) {\n    int bIndx = blockIdx.x;\n    int bIndy = blockIdx.y;\n    int tIndx = threadIdx.x;\n    int tIndy = threadIdx.y;\n\n    Cd[(blockDim.x * bIndx + tIndx) * colsB + blockDim.y * bIndy + tIndy] = 0;\n\n    for (int k = 0; k < colsA; ++k) {\n        Cd[(blockDim.x * bIndx + tIndx) * colsB + blockDim.y * bIndy + tIndy] +=\n            Ad[(blockDim.x * bIndx + tIndx) * colsA + k] * Bd[k * colsB + blockDim.y * bIndy + tIndy];\n    }\n}\n\nint main() {\n    \n\n    \n    int rowsA = 512;    \n    int colsA = 256;    \n    int colsB = 128;    \n\n    float* h_Ad = (float*)malloc(rowsA * colsA * sizeof(float));\n    float* h_Bd = (float*)malloc(colsA * colsB * sizeof(float));\n    float* h_Cd = (float*)malloc(rowsA * colsB * sizeof(float));\n\n    float* d_Ad, * d_Bd, * d_Cd;\n    cudaMalloc((void**)&d_Ad, rowsA * colsA * sizeof(float));\n    cudaMalloc((void**)&d_Bd, colsA * colsB * sizeof(float));\n    cudaMalloc((void**)&d_Cd, rowsA * colsB * sizeof(float));\n\n    \n    cudaMemcpy(d_Ad, h_Ad, rowsA * colsA * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_Bd, h_Bd, colsA * colsB * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16); \n    dim3 gridSize((colsB + blockSize.x - 1) / blockSize.x, (rowsA + blockSize.y - 1) / blockSize.y);\n\n    gpuMatrMultD<<<gridSize, blockSize>>>(d_Ad, d_Bd, d_Cd, rowsA, colsA, colsB);\n\n    \n    cudaMemcpy(h_Cd, d_Cd, rowsA * colsB * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_Ad);\n    free(h_Bd);\n    free(h_Cd);\n    cudaFree(d_Ad);\n    cudaFree(d_Bd);\n    cudaFree(d_Cd);\n\n    return 0;\n}\n"
    },
    {
        "id": "136",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid add_sources_d(const float *const model, float *wfp, const float *const source_amplitude,\n                   const int *const sources_z, const int *const sources_x,\n                   const int nz, const int nx, const int nt, const int ns, const int it) {\n    int x, b;\n\n    for (x = 0; x < nx; x++) {\n        for (b = 0; b < ns; b++) {\n            int i = sources_z[b * ns + x] * nx + sources_x[b * ns + x];\n            int ib = b * nz * nx + i;\n            wfp[ib] += source_amplitude[b * ns * nt + x * nt + it] * model[i];\n        }\n    }\n}\n\nint main() {\n    \n    const int nz = 3;\n    const int nx = 4;\n    const int nt = 5;\n    const int ns = 2;\n    const int it = 3;\n\n    float *model = (float *)malloc(nz * nx * sizeof(float));\n    float *wfp = (float *)malloc(ns * nz * nx * sizeof(float));\n    float *source_amplitude = (float *)malloc(ns * nt * nx * sizeof(float));\n    int *sources_z = (int *)malloc(ns * nx * sizeof(int));\n    int *sources_x = (int *)malloc(ns * nx * sizeof(int));\n\n    \n    for (int i = 0; i < nz * nx; ++i) {\n        model[i] = i + 1.0;\n    }\n\n    for (int i = 0; i < ns * nz * nx; ++i) {\n        wfp[i] = 0.0;\n    }\n\n    for (int i = 0; i < ns * nt * nx; ++i) {\n        source_amplitude[i] = i + 0.5;\n    }\n\n    for (int i = 0; i < ns * nx; ++i) {\n        sources_z[i] = i % nz;\n        sources_x[i] = i % nx;\n    }\n\n    \n    add_sources_d(model, wfp, source_amplitude, sources_z, sources_x, nz, nx, nt, ns, it);\n\n    \n    for (int i = 0; i < ns * nz * nx; ++i) {\n        printf(\"Resultant wfp[%d]: %f\\n\", i, wfp[i]);\n    }\n\n    \n    free(model);\n    free(wfp);\n    free(source_amplitude);\n    free(sources_z);\n    free(sources_x);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void add_sources_d(const float* const model, float* wfp, const float* const source_amplitude,\n                               const int* const sources_z, const int* const sources_x, const int nz, const int nx,\n                               const int nt, const int ns, const int it) {\n    int x = threadIdx.x;\n    int b = blockIdx.x;\n    int i = sources_z[b * ns + x] * nx + sources_x[b * ns + x];\n    int ib = b * nz * nx + i;\n    wfp[ib] += source_amplitude[b * ns * nt + x * nt + it] * model[i];\n}\n\nint main() {\n    \n\n    \n    int nz = 100;    \n    int nx = 100;    \n    int nt = 100;    \n    int ns = 10;     \n\n    float* h_model = (float*)malloc(nz * nx * sizeof(float));\n    float* h_wfp = (float*)malloc(nz * nx * ns * sizeof(float));\n    float* h_source_amplitude = (float*)malloc(ns * nt * sizeof(float));\n    int* h_sources_z = (int*)malloc(ns * sizeof(int));\n    int* h_sources_x = (int*)malloc(ns * sizeof(int));\n\n    float* d_model, * d_wfp, * d_source_amplitude;\n    int* d_sources_z, * d_sources_x;\n\n    cudaMalloc((void**)&d_model, nz * nx * sizeof(float));\n    cudaMalloc((void**)&d_wfp, nz * nx * ns * sizeof(float));\n    cudaMalloc((void**)&d_source_amplitude, ns * nt * sizeof(float));\n    cudaMalloc((void**)&d_sources_z, ns * sizeof(int));\n    cudaMalloc((void**)&d_sources_x, ns * sizeof(int));\n\n    \n    cudaMemcpy(d_model, h_model, nz * nx * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_wfp, h_wfp, nz * nx * ns * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_source_amplitude, h_source_amplitude, ns * nt * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_sources_z, h_sources_z, ns * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_sources_x, h_sources_x, ns * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16); \n    dim3 gridSize(ns);\n\n    int it = 0; \n\n    add_sources_d<<<gridSize, blockSize>>>(d_model, d_wfp, d_source_amplitude, d_sources_z, d_sources_x, nz, nx, nt, ns, it);\n\n    \n    cudaMemcpy(h_wfp, d_wfp, nz * nx * ns * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_model);\n    free(h_wfp);\n    free(h_source_amplitude);\n    free(h_sources_z);\n    free(h_sources_x);\n\n    cudaFree(d_model);\n    cudaFree(d_wfp);\n    cudaFree(d_source_amplitude);\n    cudaFree(d_sources_z);\n    cudaFree(d_sources_x);\n\n    return 0;\n}\n"
    },
    {
        "id": "137",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n\nvoid variance_cpu(float *x, float *mean, int batch, int filters, int spatial, float *variance) {\n    float scale = 1. / (batch * spatial - 1);\n    int i, j, k;\n\n    for (i = 0; i < filters; ++i) {\n        variance[i] = 0;\n\n        for (j = 0; j < batch; ++j) {\n            for (k = 0; k < spatial; ++k) {\n                int index = j * filters * spatial + i * spatial + k;\n                variance[i] += pow((x[index] - mean[i]), 2);\n            }\n        }\n\n        variance[i] *= scale;\n    }\n}\n\nint main() {\n    \n    const int batch = 2;\n    const int filters = 3;\n    const int spatial = 4;\n\n    float *x = (float *)malloc(batch * filters * spatial * sizeof(float));\n    float *mean = (float *)malloc(filters * sizeof(float));\n    float *variance = (float *)malloc(filters * sizeof(float));\n\n    \n    for (int i = 0; i < batch * filters * spatial; ++i) {\n        x[i] = i + 1.0;\n    }\n\n    for (int i = 0; i < filters; ++i) {\n        mean[i] = i + 0.5;\n    }\n\n    \n    variance_cpu(x, mean, batch, filters, spatial, variance);\n\n    \n    for (int i = 0; i < filters; ++i) {\n        printf(\"Resultant variance[%d]: %f\\n\", i, variance[i]);\n    }\n\n    \n    free(x);\n    free(mean);\n    free(variance);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <math.h>\n\n\n__global__ void variance_kernel(float* x, float* mean, int batch, int filters, int spatial, float* variance) {\n    float scale = 1.f / (batch * spatial - 1);\n    int j, k;\n    int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n\n    if (i >= filters)\n        return;\n\n    variance[i] = 0;\n\n    for (j = 0; j < batch; ++j) {\n        for (k = 0; k < spatial; ++k) {\n            int index = j * filters * spatial + i * spatial + k;\n            variance[i] += powf((x[index] - mean[i]), 2);\n        }\n    }\n\n    variance[i] *= scale;\n}\n\nint main() {\n    \n\n    \n    int batch = 32;     \n    int filters = 64;   \n    int spatial = 128;  \n\n    float* h_x = (float*)malloc(batch * filters * spatial * sizeof(float));\n    float* h_mean = (float*)malloc(filters * sizeof(float));\n    float* h_variance = (float*)malloc(filters * sizeof(float));\n\n    float* d_x, * d_mean, * d_variance;\n    cudaMalloc((void**)&d_x, batch * filters * spatial * sizeof(float));\n    cudaMalloc((void**)&d_mean, filters * sizeof(float));\n    cudaMalloc((void**)&d_variance, filters * sizeof(float));\n\n    \n    cudaMemcpy(d_x, h_x, batch * filters * spatial * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_mean, h_mean, filters * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize((filters + blockSize.x - 1) / blockSize.x, 1);\n\n    variance_kernel<<<gridSize, blockSize>>>(d_x, d_mean, batch, filters, spatial, d_variance);\n\n    \n    cudaMemcpy(h_variance, d_variance, filters * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_x);\n    free(h_mean);\n    free(h_variance);\n    cudaFree(d_x);\n    cudaFree(d_mean);\n    cudaFree(d_variance);\n\n    return 0;\n}\n"
    },
    {
        "id": "138",
        "c_code": "#include <stdio.h>\n\nvoid grad_y_cpu(const float *u, float *grad, long depth, long rows, long cols) {\n    for (int x = 0; x < cols; x++) {\n        for (int y = 0; y < rows; y++) {\n            for (int z = 0; z < depth; z++) {\n                unsigned long size2d = rows * cols;\n                unsigned long long idx = z * size2d + y * cols + x;\n                float uidx = u[idx];\n\n                if (y > 0) {\n                    grad[idx] = (uidx - u[z * size2d + (y - 1) * cols + x]);\n                }\n            }\n        }\n    }\n}\n\nint main() {\n    \n    long depth = 3;\n    long rows = 4;\n    long cols = 5;\n\n    \n    float u[depth * rows * cols];\n\n    \n    for (int i = 0; i < depth * rows * cols; i++) {\n        u[i] = 1.0f;\n    }\n\n    \n    float grad[depth * rows * cols];\n\n    \n    grad_y_cpu(u, grad, depth, rows, cols);\n\n    \n    for (int i = 0; i < depth * rows * cols; i++) {\n        printf(\"%f \", grad[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void grad_y(const float* u, float* grad, long depth, long rows, long cols) {\n    unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;\n    unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;\n    unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;\n\n    if (x >= cols || y >= rows || z >= depth)\n        return;\n\n    unsigned long size2d = rows * cols;\n    unsigned long long idx = z * size2d + y * cols + x;\n    float uidx = u[idx];\n\n    if (y - 1 >= 0 && y < rows) {\n        grad[idx] = (uidx - u[z * size2d + (y - 1) * cols + x]);\n    }\n}\n\nint main() {\n    \n\n    \n    long depth = 16;  \n    long rows = 128;  \n    long cols = 128;  \n\n    float* h_u = (float*)malloc(depth * rows * cols * sizeof(float));\n    float* h_grad = (float*)malloc(depth * rows * cols * sizeof(float));\n\n    float* d_u, *d_grad;\n    cudaMalloc((void**)&d_u, depth * rows * cols * sizeof(float));\n    cudaMalloc((void**)&d_grad, depth * rows * cols * sizeof(float));\n\n    \n    cudaMemcpy(d_u, h_u, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16, 1); \n    dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y, (depth + blockSize.z - 1) / blockSize.z);\n\n    grad_y<<<gridSize, blockSize>>>(d_u, d_grad, depth, rows, cols);\n\n    \n    cudaMemcpy(h_grad, d_grad, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_u);\n    free(h_grad);\n    cudaFree(d_u);\n    cudaFree(d_grad);\n\n    return 0;\n}\n"
    },
    {
        "id": "139",
        "c_code": "#include <stdio.h>\n\nvoid grad_x_cpu(const float *u, float *grad, long depth, long rows, long cols) {\n    for (int x = 0; x < cols; x++) {\n        for (int y = 0; y < rows; y++) {\n            for (int z = 0; z < depth; z++) {\n                unsigned long size2d = rows * cols;\n                unsigned long long idx = z * size2d + y * cols + x;\n                float uidx = u[idx];\n\n                if (x > 0) {\n                    grad[idx] = (uidx - u[z * size2d + y * cols + (x - 1)]);\n                }\n            }\n        }\n    }\n}\n\nint main() {\n    \n    long depth = 3;\n    long rows = 4;\n    long cols = 5;\n\n    \n    float u[depth * rows * cols];\n\n    \n    for (int i = 0; i < depth * rows * cols; i++) {\n        u[i] = 1.0f;\n    }\n\n    \n    float grad[depth * rows * cols];\n\n    \n    grad_x_cpu(u, grad, depth, rows, cols);\n\n    \n    for (int i = 0; i < depth * rows * cols; i++) {\n        printf(\"%f \", grad[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void grad_x(const float* u, float* grad, long depth, long rows, long cols) {\n    unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;\n    unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;\n    unsigned long z = threadIdx.z + blockIdx.z *blockDim.z;\n\n    if (x >= cols || y >= rows || z >= depth)\n        return;\n\n    unsigned long size2d = rows * cols;\n    unsigned long long idx = z * size2d + y * cols + x;\n    float uidx = u[idx];\n\n    if (x - 1 >= 0 && x < cols) {\n        grad[idx] = (uidx - u[z * size2d + y * cols + (x - 1)]);\n    }\n}\n\nint main() {\n    \n\n    \n    long depth = 16;  \n    long rows = 128;  \n    long cols = 128;  \n\n    float* h_u = (float*)malloc(depth * rows * cols * sizeof(float));\n    float* h_grad = (float*)malloc(depth * rows * cols * sizeof(float));\n\n    float* d_u, *d_grad;\n    cudaMalloc((void**)&d_u, depth * rows * cols * sizeof(float));\n    cudaMalloc((void**)&d_grad, depth * rows * cols * sizeof(float));\n\n    \n    cudaMemcpy(d_u, h_u, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16, 1); \n    dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y, (depth + blockSize.z - 1) / blockSize.z);\n\n    grad_x<<<gridSize, blockSize>>>(d_u, d_grad, depth, rows, cols);\n\n    \n    cudaMemcpy(h_grad, d_grad, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_u);\n    free(h_grad);\n    cudaFree(d_u);\n    cudaFree(d_grad);\n\n    return 0;\n}\n"
    },
    {
        "id": "14",
        "c_code": "#include <stdio.h>\n\nvoid cpuAddCorrAndCorrection(float *L, float *r, int N) {\n    for (int u = 0; u < N; u++) {\n        L[u] -= r[u];\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float arrayL[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float arrayR[] = {0.5, 1.5, 2.5, 3.5, 4.5};\n\n    printf(\"\u6570\u7ec4 L\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayL[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 R\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayR[i]);\n    }\n\n    \n    cpuAddCorrAndCorrection(arrayL, arrayR, arraySize);\n\n    printf(\"\\n\u76f8\u52a0\u540e\u7684\u6570\u7ec4 L\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayL[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void cudaAddCorrAndCorrection(float* L, float* r, int N) {\n    int u = (blockIdx.x * blockDim.x) + threadIdx.x;\n    if (u >= N)\n        return;\n    \n    L[u] -= r[u];\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float* h_L = (float*)malloc(arraySize * sizeof(float));\n    float* h_r = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_L[i] = static_cast<float>(i);\n        h_r[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_L;\n    float* d_r;\n    cudaMalloc((void**)&d_L, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_r, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_L, h_L, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_r, h_r, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    cudaAddCorrAndCorrection<<<gridSize, blockSize>>>(d_L, d_r, arraySize);\n\n    \n    cudaMemcpy(h_L, d_L, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_L[i]);\n    }\n\n    \n    free(h_L);\n    free(h_r);\n    cudaFree(d_L);\n    cudaFree(d_r);\n\n    return 0;\n}\n"
    },
    {
        "id": "140",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid GraphSum_forward(float *in, float *out, int *indptr, int *indices, int dim, int size) {\n    for (int src = 0; src < size - 1; src++) {\n        for (int i = indptr[src]; i < indptr[src + 1]; i++) {\n            int dst = indices[i];\n            float coef = 1.0 / sqrtf((indptr[src + 1] - indptr[src]) * (indptr[dst + 1] - indptr[dst]));\n\n            for (int j = 0; j < dim; j++) {\n                out[src * dim + j] += coef * in[dst * dim + j];\n            }\n        }\n    }\n}\n\nint main() {\n    \n    int dim = 3; \n    int size = 4; \n\n    \n    int indptr[5] = {0, 2, 3, 5, 7};\n    int indices[7] = {1, 2, 0, 3, 0, 2, 3};\n\n    \n    float in[size * dim];\n    float out[size * dim];\n\n    \n    for (int i = 0; i < size * dim; i++) {\n        in[i] = 1.0f;\n        out[i] = 0.0f; \n    }\n\n    \n    GraphSum_forward(in, out, indptr, indices, dim, size);\n\n    \n    for (int i = 0; i < size * dim; i++) {\n        printf(\"%f \", out[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <math.h>\n\n\n__global__ void cuda_GraphSum_forward_kernel(float* d_in_data, float* d_out_data, int* d_indptr, int* d_indices, int dim, int numNodes) {\n    int src = blockIdx.x;\n    int j = threadIdx.x;\n    int ptr_src_0 = d_indptr[src];\n    int ptr_stc_1 = d_indptr[src + 1];\n\n    for (int i = ptr_src_0; i < ptr_stc_1; i++) {\n        int dst = d_indices[i];\n        float coef = 1.0 / sqrtf((ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst]));\n        d_out_data[src * dim + j] += coef * d_in_data[dst * dim + j];\n    }\n}\n\nint main() {\n    \n\n    \n    int dim = 256;  \n    int numNodes = 128;  \n\n    float* h_d_in_data = (float*)malloc(numNodes * dim * sizeof(float));\n    float* h_d_out_data = (float*)malloc(numNodes * dim * sizeof(float));\n    int* h_d_indptr = ;\n    int* h_d_indices = ;\n\n    float* d_d_in_data, *d_d_out_data;\n    int* d_d_indptr, *d_d_indices;\n    cudaMalloc((void**)&d_d_in_data, numNodes * dim * sizeof(float));\n    cudaMalloc((void**)&d_d_out_data, numNodes * dim * sizeof(float));\n    cudaMalloc((void**)&d_d_indptr, );\n    cudaMalloc((void**)&d_d_indices, );\n\n    \n    cudaMemcpy(d_d_in_data, h_d_in_data, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_d_out_data, h_d_out_data, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_d_indptr, h_d_indptr, , cudaMemcpyHostToDevice);\n    cudaMemcpy(d_d_indices, h_d_indices, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize(numNodes);\n\n    cuda_GraphSum_forward_kernel<<<gridSize, blockSize>>>(d_d_in_data, d_d_out_data, d_d_indptr, d_d_indices, dim, numNodes);\n\n    \n    cudaMemcpy(h_d_out_data, d_d_out_data, numNodes * dim * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_d_in_data);\n    free(h_d_out_data);\n    cudaFree(d_d_in_data);\n    cudaFree(d_d_out_data);\n    cudaFree(d_d_indptr);\n    cudaFree(d_d_indices);\n\n    return 0;\n}\n"
    },
    {
        "id": "141",
        "c_code": "#include <stdio.h>\n\nvoid apply_grayscale(const unsigned char *image, unsigned char *grayimg, int width, int height);\n\nint main() {\n    \n    \n    int width = 100;  \n    int height = 100; \n\n    \n    unsigned char image[width * height * 3];\n\n    \n    unsigned char grayimg[width * height];\n\n    \n    apply_grayscale(image, grayimg, width, height);\n\n    \n    \n    for (int y = 0; y < height; y++) {\n        for (int x = 0; x < width; x++) {\n            printf(\"%u \", grayimg[y * width + x]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n\nvoid apply_grayscale(const unsigned char *image, unsigned char *grayimg, int width, int height) {\n    for (int y = 0; y < height; y++) {\n        for (int x = 0; x < width; x++) {\n            const unsigned char R = image[(y * width + x) * 3 + 0];\n            const unsigned char G = image[(y * width + x) * 3 + 1];\n            const unsigned char B = image[(y * width + x) * 3 + 2];\n            unsigned char gray = (307 * R + 604 * G + 113 * B) >> 10;\n            grayimg[y * width + x] = gray;\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void apply_grayscale(unsigned char* grayimg, const unsigned char* image, int width, int height) {\n    unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;\n    unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (x < width && y < height) {\n        const unsigned char R = image[(y * width + x) * 3 + 0];\n        const unsigned char G = image[(y * width + x) * 3 + 1];\n        const unsigned char B = image[(y * width + x) * 3 + 2];\n        unsigned char gray = (307 * R + 604 * G + 113 * B) >> 10;\n        grayimg[y * width + x] = gray;\n    }\n}\n\nint main() {\n    \n\n    \n    int width = 512;  \n    int height = 512;  \n\n    unsigned char* h_image = ;\n    unsigned char* h_grayimg = (unsigned char*)malloc(width * height * sizeof(unsigned char));\n\n    unsigned char* d_image, *d_grayimg;\n    cudaMalloc((void**)&d_image, width * height * 3 * sizeof(unsigned char));\n    cudaMalloc((void**)&d_grayimg, width * height * sizeof(unsigned char));\n\n    \n    cudaMemcpy(d_image, h_image, width * height * 3 * sizeof(unsigned char), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16); \n    dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y);\n\n    apply_grayscale<<<gridSize, blockSize>>>(d_grayimg, d_image, width, height);\n\n    \n    cudaMemcpy(h_grayimg, d_grayimg, width * height * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_grayimg);\n    cudaFree(d_image);\n    cudaFree(d_grayimg);\n\n    return 0;\n}\n"
    },
    {
        "id": "142",
        "c_code": "#include <stdio.h>\n\nvoid getOffsetBox_cpu(const int *clsIndex, const float *max_coordinate, float *offset, int dims, int batchSize, const float *before_nms_boxes);\n\nint main() {\n    \n    \n    int dims = 10;         \n    int batchSize = 5;     \n\n    \n    int clsIndex[batchSize * dims];\n    float max_coordinate[batchSize * dims * 4];\n    float offset[batchSize * dims];\n    float before_nms_boxes[batchSize * dims * 4];\n\n    \n    getOffsetBox_cpu(clsIndex, max_coordinate, offset, dims, batchSize, before_nms_boxes);\n\n    \n    \n    for (int i = 0; i < batchSize; i++) {\n        for (int j = 0; j < dims; j++) {\n            printf(\"%f \", offset[i * dims + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n\nvoid getOffsetBox_cpu(const int *clsIndex, const float *max_coordinate, float *offset, int dims, int batchSize, const float *before_nms_boxes) {\n    for (int tid = 0; tid < dims; tid++) {\n        int numPerbatch = dims;\n        for (int i = 0; i < batchSize; i++) {\n            if (before_nms_boxes[i * dims * 4 + tid * 4] == -1) {\n                offset[i * numPerbatch + tid] = 0;\n            } else {\n                offset[i * numPerbatch + tid] = clsIndex[i * numPerbatch + tid] * (max_coordinate[i * dims * 4] + 1);\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void getOffsetBox(const int* clsIndex, const float* max_coordinate, float* offset, int dims, int batchSize, const float* before_nms_boxes) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid >= dims) {\n        return;\n    }\n\n    int numPerbatch = dims;\n\n    for (int i = 0; i < batchSize; i++) {\n        if (before_nms_boxes[i * dims * 4 + tid * 4] == (-1)) {\n            offset[i * numPerbatch + tid] = 0;\n        } else {\n            offset[i * numPerbatch + tid] = clsIndex[i * numPerbatch + tid] * (max_coordinate[i * dims * 4] + 1);\n        }\n    }\n}\n\nint main() {\n    \n\n    \n    int dims = 256;  \n    int batchSize = 128;  \n\n    int* h_clsIndex = ;\n    float* h_max_coordinate = ;\n    float* h_offset = (float*)malloc(batchSize * dims * sizeof(float));\n    float* h_before_nms_boxes = ;\n\n    int* d_clsIndex;\n    float* d_max_coordinate, *d_offset, *d_before_nms_boxes;\n    cudaMalloc((void**)&d_clsIndex, batchSize * dims * sizeof(int));\n    cudaMalloc((void**)&d_max_coordinate, batchSize * dims * 4 * sizeof(float));\n    cudaMalloc((void**)&d_offset, batchSize * dims * sizeof(float));\n    cudaMalloc((void**)&d_before_nms_boxes, batchSize * dims * 4 * sizeof(float));\n\n    \n    cudaMemcpy(d_clsIndex, h_clsIndex, batchSize * dims * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_max_coordinate, h_max_coordinate, batchSize * dims * 4 * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_before_nms_boxes, h_before_nms_boxes, batchSize * dims * 4 * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize((dims + blockSize.x - 1) / blockSize.x, 1);\n\n    getOffsetBox<<<gridSize, blockSize>>>(d_clsIndex, d_max_coordinate, d_offset, dims, batchSize, d_before_nms_boxes);\n\n    \n    cudaMemcpy(h_offset, d_offset, batchSize * dims * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    free(h_offset);\n    cudaFree(d_clsIndex);\n    cudaFree(d_max_coordinate);\n    cudaFree(d_offset);\n    cudaFree(d_before_nms_boxes);\n\n    return 0;\n}\n"
    },
    {
        "id": "143",
        "c_code": "#include <stdio.h>\n\nvoid sgemm_kernelCPU(const float *host_inputArray1, const float *host_inputArray2, float *host_inputArray3, int M, int N, int K, float alpha, float beta);\n\nint main() {\n    \n    \n    int M = 3;  \n    int N = 4;\n    int K = 5;\n\n    \n    float host_inputArray1[M * K];\n    float host_inputArray2[K * N];\n    float host_inputArray3[M * N];\n\n    \n    for (int i = 0; i < M * K; i++) {\n        host_inputArray1[i] = i + 1;\n    }\n\n    for (int i = 0; i < K * N; i++) {\n        host_inputArray2[i] = i + 1;\n    }\n\n    for (int i = 0; i < M * N; i++) {\n        host_inputArray3[i] = 0;\n    }\n\n    \n    sgemm_kernelCPU(host_inputArray1, host_inputArray2, host_inputArray3, M, N, K, 1.0, 0.0);\n\n    \n    \n    for (int i = 0; i < M; i++) {\n        for (int j = 0; j < N; j++) {\n            printf(\"%f \", host_inputArray3[i * N + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n\nvoid sgemm_kernelCPU(const float *host_inputArray1, const float *host_inputArray2, float *host_inputArray3, int M, int N, int K, float alpha, float beta) {\n    for (int row = 0; row < M; row++) {\n        for (int column = 0; column < N; column++) {\n            float element_c = 0.f;\n            for (int e = 0; e < K; e++) {\n                element_c += host_inputArray1[row * K + e] * host_inputArray2[e * N + column];\n            }\n            host_inputArray3[row * N + column] = alpha * element_c + beta * host_inputArray3[row * N + column];\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void sgemm_kernelGPU(const float* host_inputArray1, const float* host_inputArray2, float* host_inputArray3, int M, int N, int K, float alpha, float beta) {\n    int column = blockIdx.x * blockDim.x + threadIdx.x;\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (row < M && column < N) {\n        float element_c = 0.f;\n\n        for (int eachElement = 0; eachElement < K; eachElement++) {\n            element_c += host_inputArray1[row * K + eachElement] * host_inputArray2[eachElement * N + column];\n        }\n\n        host_inputArray3[row * N + column] = alpha * element_c + beta * host_inputArray3[row * N + column];\n    }\n}\n\nint main() {\n    \n\n    \n    int M = 512;  \n    int N = 512;  \n    int K = 256;  \n\n    float* h_inputArray1 = ;\n    float* h_inputArray2 = ;\n    float* h_inputArray3 = ;\n\n    float* d_inputArray1, *d_inputArray2, *d_inputArray3;\n    cudaMalloc((void**)&d_inputArray1, M * K * sizeof(float));\n    cudaMalloc((void**)&d_inputArray2, K * N * sizeof(float));\n    cudaMalloc((void**)&d_inputArray3, M * N * sizeof(float));\n\n    \n    cudaMemcpy(d_inputArray1, h_inputArray1, M * K * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_inputArray2, h_inputArray2, K * N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_inputArray3, h_inputArray3, M * N * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(16, 16);  \n    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, (M + blockSize.y - 1) / blockSize.y);\n\n    sgemm_kernelGPU<<<gridSize, blockSize>>>(d_inputArray1, d_inputArray2, d_inputArray3, M, N, K, 1.0f, 0.0f);\n\n    \n    cudaMemcpy(h_inputArray3, d_inputArray3, M * N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_inputArray1);\n    cudaFree(d_inputArray2);\n    cudaFree(d_inputArray3);\n\n    return 0;\n}\n"
    },
    {
        "id": "144",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid GraphSum_backward(float *in_grad, float *out_grad, int *indptr, int *indices, int size, int dim);\n\nint main() {\n    \n    \n    int size = 5;  \n    int dim = 3;   \n\n    \n    float in_grad[size * dim];\n    float out_grad[size * dim];\n    int indptr[size + 1];\n    int indices[10] = {0, 1, 1, 2, 0, 2, 3, 4, 4, 3};  \n\n    \n    for (int i = 0; i < size * dim; i++) {\n        in_grad[i] = 0;\n        out_grad[i] = i + 1;\n    }\n\n    for (int i = 0; i < size + 1; i++) {\n        indptr[i] = i * 2;  \n    }\n\n    \n    GraphSum_backward(in_grad, out_grad, indptr, indices, size, dim);\n\n    \n    \n    for (int i = 0; i < size; i++) {\n        for (int j = 0; j < dim; j++) {\n            printf(\"%f \", in_grad[i * dim + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n\nvoid GraphSum_backward(float *in_grad, float *out_grad, int *indptr, int *indices, int size, int dim) {\n    for (int src = 0; src < size - 1; src++) {\n        for (int i = indptr[src]; i < indptr[src + 1]; i++) {\n            int dst = indices[i];\n            float coef = 1.0 / sqrtf((indptr[src + 1] - indptr[src]) * (indptr[dst + 1] - indptr[dst]));\n            for (int j = 0; j < dim; j++) {\n                in_grad[src * dim + j] += coef * out_grad[dst * dim + j];\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <math.h>\n\n\n__global__ void cuda_GraphSum_backward_kernel(float* d_in_grad, float* d_out_grad, int* d_indptr, int* d_indices, int dim, int numNodes) {\n    int src = blockIdx.x;\n    int j = threadIdx.x;\n    int ptr_src_0 = d_indptr[src];\n    int ptr_stc_1 = d_indptr[src + 1];\n\n    #pragma unroll\n    for (int i = ptr_src_0; i < ptr_stc_1; i++) {\n        int dst = d_indices[i];\n        float coef = 1.0 / sqrtf((ptr_stc_1 - ptr_src_0) * (d_indptr[dst + 1] - d_indptr[dst]));\n\n        d_in_grad[src * dim + j] += coef * d_out_grad[dst * dim + j];\n    }\n}\n\nint main() {\n    \n\n    \n    int dim = 256;  \n    int numNodes = 128;  \n\n    float* h_d_in_grad = ;\n    float* h_d_out_grad = ;\n    int* h_d_indptr = ;\n    int* h_d_indices = ;\n\n    float* d_d_in_grad, *d_d_out_grad;\n    int* d_d_indptr, *d_d_indices;\n\n    cudaMalloc((void**)&d_d_in_grad, numNodes * dim * sizeof(float));\n    cudaMalloc((void**)&d_d_out_grad, numNodes * dim * sizeof(float));\n    cudaMalloc((void**)&d_d_indptr, (numNodes + 1) * sizeof(int));\n    cudaMalloc((void**)&d_d_indices, );\n\n    \n    cudaMemcpy(d_d_in_grad, h_d_in_grad, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_d_out_grad, h_d_out_grad, numNodes * dim * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_d_indptr, h_d_indptr, (numNodes + 1) * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_d_indices, h_d_indices, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256); \n    dim3 gridSize(numNodes);\n\n    cuda_GraphSum_backward_kernel<<<gridSize, blockSize>>>(d_d_in_grad, d_d_out_grad, d_d_indptr, d_d_indices, dim, numNodes);\n\n    \n    cudaMemcpy(h_d_in_grad, d_d_in_grad, numNodes * dim * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_d_in_grad);\n    cudaFree(d_d_out_grad);\n    cudaFree(d_d_indptr);\n    cudaFree(d_d_indices);\n\n    return 0;\n}\n"
    },
    {
        "id": "145",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid CDFfunction(float *median, float *stdvLogNormalFrame, float *MeanLogNormalFrame, unsigned char *currentFrame, int pixelsPerFrame);\n\nint main() {\n    \n    \n    int pixelsPerFrame = 100;  \n\n    \n    float median[pixelsPerFrame];\n    float stdvLogNormalFrame[pixelsPerFrame];\n    float MeanLogNormalFrame[pixelsPerFrame];\n    unsigned char currentFrame[pixelsPerFrame];\n\n    \n    for (int i = 0; i < pixelsPerFrame; i++) {\n        median[i] = 10.0;\n        stdvLogNormalFrame[i] = 2.0;\n        MeanLogNormalFrame[i] = 5.0;\n        currentFrame[i] = i % 256;  \n    }\n\n    \n    CDFfunction(median, stdvLogNormalFrame, MeanLogNormalFrame, currentFrame, pixelsPerFrame);\n\n    \n    \n    for (int i = 0; i < pixelsPerFrame; i++) {\n        printf(\"%u \", currentFrame[i]);\n    }\n\n    return 0;\n}\n\nvoid CDFfunction(float *median, float *stdvLogNormalFrame, float *MeanLogNormalFrame, unsigned char *currentFrame, int pixelsPerFrame) {\n    int pixel;\n    for (pixel = 0; pixel < pixelsPerFrame; pixel++) {\n        float newvalue;\n        float x = currentFrame[pixel];\n        newvalue = -((log(x) - median[pixel]) - MeanLogNormalFrame[pixel]) / (sqrt(2.0) * stdvLogNormalFrame[pixel]);\n        float summ = 0.5f + 0.5f * erf(newvalue);\n        if (summ >= 0.3) {\n            currentFrame[pixel] = (unsigned char)255;\n        } else {\n            currentFrame[pixel] = (unsigned char)0;\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <math.h>\n\n\n__global__ void CDFfunction(float* median, float* stdvLogNormalFrame, float* MeanLogNormalFrame, unsigned char* currentFrame, int pixelsPerFrame) {\n    int pixel = threadIdx.x + blockIdx.x * blockDim.x;\n\n    if (pixel < pixelsPerFrame) {\n        float newvalue;\n        float x = currentFrame[pixel];\n\n        newvalue = -((logf(x) - median[pixel]) - MeanLogNormalFrame[pixel]) / (sqrtf(2) * stdvLogNormalFrame[pixel]);\n\n        float summ = 0.5f + 0.5f * erff(newvalue);\n\n        if (summ >= 0.3) {\n            currentFrame[pixel] = (unsigned char)255;\n        } else {\n            currentFrame[pixel] = (unsigned char)0;\n        }\n    }\n}\n\nint main() {\n    \n\n    \n    int pixelsPerFrame = 1024;  \n\n    float* h_median = ;\n    float* h_stdvLogNormalFrame = ;\n    float* h_MeanLogNormalFrame = ;\n    unsigned char* h_currentFrame = ;\n\n    float* d_median, *d_stdvLogNormalFrame, *d_MeanLogNormalFrame;\n    unsigned char* d_currentFrame;\n\n    cudaMalloc((void**)&d_median, pixelsPerFrame * sizeof(float));\n    cudaMalloc((void**)&d_stdvLogNormalFrame, pixelsPerFrame * sizeof(float));\n    cudaMalloc((void**)&d_MeanLogNormalFrame, pixelsPerFrame * sizeof(float));\n    cudaMalloc((void**)&d_currentFrame, pixelsPerFrame * sizeof(unsigned char));\n\n    \n    cudaMemcpy(d_median, h_median, pixelsPerFrame * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_stdvLogNormalFrame, h_stdvLogNormalFrame, pixelsPerFrame * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_MeanLogNormalFrame, h_MeanLogNormalFrame, pixelsPerFrame * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_currentFrame, h_currentFrame, pixelsPerFrame * sizeof(unsigned char), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);  \n    dim3 gridSize((pixelsPerFrame + blockSize.x - 1) / blockSize.x);\n\n    CDFfunction<<<gridSize, blockSize>>>(d_median, d_stdvLogNormalFrame, d_MeanLogNormalFrame, d_currentFrame, pixelsPerFrame);\n\n    \n    cudaMemcpy(h_currentFrame, d_currentFrame, pixelsPerFrame * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_median);\n    cudaFree(d_stdvLogNormalFrame);\n    cudaFree(d_MeanLogNormalFrame);\n    cudaFree(d_currentFrame);\n\n    return 0;\n}\n"
    },
    {
        "id": "146",
        "c_code": "#include <stdio.h>\n\nvoid mul(float *M, float *N, float *K, float height_M, float width_N, float width_M);\n\nint main() {\n    \n    \n    float height_M = 3;\n    float width_N = 4;\n    float width_M = 2;\n\n    \n    float M[height_M * width_M];\n    float N[width_M * width_N];\n    float K[height_M * width_N];\n\n    \n    for (int i = 0; i < height_M * width_M; i++) {\n        M[i] = i + 1;\n    }\n\n    for (int i = 0; i < width_M * width_N; i++) {\n        N[i] = i + 2;\n    }\n\n    \n    mul(M, N, K, height_M, width_N, width_M);\n\n    \n    \n    for (int i = 0; i < height_M; i++) {\n        for (int j = 0; j < width_N; j++) {\n            printf(\"%f \", K[i * (int)width_N + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n\nvoid mul(float *M, float *N, float *K, float height_M, float width_N, float width_M) {\n    for (int i = 0; i < height_M; i++) {\n        for (int j = 0; j < width_N; j++) {\n            float sum = 0;\n            for (int k = 0; k < width_M; k++) {\n                float a = M[i * (int)width_M + k];\n                float b = N[k * (int)width_N + j];\n                sum += a * b;\n            }\n            K[i * (int)width_N + j] = sum;\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void matrixmul(float* Md, float* Nd, float* Pd, float width, float width_blk, float height_blk, float width_M, float width_N, float height_M, int m, int n) {\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n    int Row = by * width_blk + ty;\n    int Col = bx * height_blk + tx;\n    float pValue = 0;\n\n    if (Col < (int)width_N && Row < (int)height_M) {\n        for (int i = 0; i < width; i++) {\n            float Melement = Md[Row * (int)width_M + i];\n            float Nelement = Nd[i * (int)width_N + Col];\n            pValue += Melement * Nelement;\n        }\n        Pd[Row * (int)width_N + Col] = pValue;\n    }\n}\n\nint main() {\n    \n\n    \n    float* h_Md = ;\n    float* h_Nd = ;\n    float* h_Pd = ;\n\n    float* d_Md, *d_Nd, *d_Pd;\n\n    cudaMalloc((void**)&d_Md, );\n    cudaMalloc((void**)&d_Nd, );\n    cudaMalloc((void**)&d_Pd, );\n\n    \n    cudaMemcpy(d_Md, h_Md, , cudaMemcpyHostToDevice);\n    cudaMemcpy(d_Nd, h_Nd, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize();\n    dim3 gridSize();\n\n    matrixmul<<<gridSize, blockSize>>>(d_Md, d_Nd, d_Pd, );\n\n    \n    cudaMemcpy(h_Pd, d_Pd, , cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_Md);\n    cudaFree(d_Nd);\n    cudaFree(d_Pd);\n\n    return 0;\n}\n"
    },
    {
        "id": "147",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid softmax_x_ent_cpu(int n, float *pred, float *truth, float *delta, float *error);\n\nint main() {\n    \n    \n    int n = 5;  \n\n    \n    float pred[n];\n    float truth[n];\n    float delta[n];\n    float error[n];\n\n    \n    for (int i = 0; i < n; i++) {\n        pred[i] = 0.2;\n        truth[i] = (i == 2) ? 1.0 : 0.0;  \n    }\n\n    \n    softmax_x_ent_cpu(n, pred, truth, delta, error);\n\n    \n    \n    printf(\"Error: \");\n    for (int i = 0; i < n; i++) {\n        printf(\"%f \", error[i]);\n    }\n    printf(\"\\n\");\n\n    printf(\"Delta: \");\n    for (int i = 0; i < n; i++) {\n        printf(\"%f \", delta[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid softmax_x_ent_cpu(int n, float *pred, float *truth, float *delta, float *error) {\n    int i;\n    for (i = 0; i < n; ++i) {\n        float t = truth[i];\n        float p = pred[i];\n        error[i] = (t) ? -log(p) : 0;\n        delta[i] = t - p;\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <math.h>\n\n\n__global__ void softmax_kernel(float* input, int n, int batch, int batch_offset, int groups, int group_offset, int stride, float temp, float* output) {\n    int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n    if (id >= batch * groups)\n        return;\n\n    int b = id / groups;\n    int g = id % groups;\n    int i;\n    float sum = 0;\n    float largest = -INFINITY;\n\n    for (i = 0; i < n; ++i) {\n        int val = (input + b * batch_offset + g * group_offset)[i * stride];\n        largest = (val > largest) ? val : largest;\n    }\n\n    for (i = 0; i < n; ++i) {\n        float e = expf((input + b * batch_offset + g * group_offset)[i * stride] / temp - largest / temp);\n        sum += e;\n        (output + b * batch_offset + g * group_offset)[i * stride] = e;\n    }\n\n    for (i = 0; i < n; ++i) {\n        (output + b * batch_offset + g * group_offset)[i * stride] /= sum;\n    }\n}\n\nint main() {\n    \n\n    \n    float* h_input = ;\n    float* h_output = ;\n\n    float* d_input, *d_output;\n\n    cudaMalloc((void**)&d_input, );\n    cudaMalloc((void**)&d_output, );\n\n    \n    cudaMemcpy(d_input, h_input, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize();\n    dim3 gridSize();\n\n    softmax_kernel<<<gridSize, blockSize>>>(d_input, , d_output);\n\n    \n    cudaMemcpy(h_output, d_output, , cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_input);\n    cudaFree(d_output);\n\n    return 0;\n}\n"
    },
    {
        "id": "148",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n\nvoid normalize_img(double *image, long int image_size, int bands);\n\nint main() {\n    \n    \n    long int image_size = 10;  \n    int bands = 3;             \n\n    \n    double *image = (double *)malloc(image_size * bands * sizeof(double));\n\n    \n    for (long int i = 0; i < image_size * bands; i++) {\n        image[i] = i + 1;\n    }\n\n    \n    normalize_img(image, image_size, bands);\n\n    \n    \n    for (int i = 0; i < bands; i++) {\n        for (long int j = 0; j < image_size; j++) {\n            printf(\"%f \", image[i * image_size + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    free(image);\n\n    return 0;\n}\n\nvoid normalize_img(double *image, long int image_size, int bands) {\n    long int i, j;\n    long int row;\n    double *D = (double *)calloc(image_size, sizeof(double));\n\n    for (i = 0; i < image_size * bands; i++) {\n        D[i % image_size] += image[i];\n    }\n\n    for (i = 0; i < image_size; i++) {\n        D[i] = pow(D[i] + 1.0e-16, -1);\n    }\n\n    for (i = 0; i < bands; i++) {\n        row = i * image_size;\n        for (j = 0; j < image_size; j++) {\n            image[row + j] = image[row + j] * D[j];\n        }\n    }\n\n    free(D);\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void normalizacion(float* image_c, int bands, long int image_size, float* normM_c, float* normM1_c) {\n    long int j, i;\n    float norm_val = 0, aux = 0, pixel = 0;\n\n    i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i < image_size) {\n        for (j = 0; j < bands; j++) {\n            norm_val += image_c[j * image_size + i];\n        }\n\n        norm_val = 1.0 / (norm_val + 1.0e-16);\n\n        for (j = 0; j < bands; j++) {\n            pixel = image_c[j * image_size + i] * norm_val;\n            image_c[j * image_size + i] = pixel;\n            aux += pixel * pixel;\n        }\n\n        normM_c[i] = aux;\n        normM1_c[i] = aux;\n    }\n}\n\nint main() {\n    \n\n    \n    float* h_image = ;\n    float* h_normM = ;\n    float* h_normM1 = ;\n\n    float* d_image, *d_normM, *d_normM1;\n\n    cudaMalloc((void**)&d_image, );\n    cudaMalloc((void**)&d_normM, );\n    cudaMalloc((void**)&d_normM1, );\n\n    \n    cudaMemcpy(d_image, h_image, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize();\n    dim3 gridSize();\n\n    normalizacion<<<gridSize, blockSize>>>(d_image, , d_normM, d_normM1);\n\n    \n    cudaMemcpy(h_normM, d_normM, , cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_normM1, d_normM1, , cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_image);\n    cudaFree(d_normM);\n    cudaFree(d_normM1);\n\n    return 0;\n}\n"
    },
    {
        "id": "149",
        "c_code": "#include <stdio.h>\n\nvoid permuteData_cpu(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize);\n\nint main() {\n    \n    \n    int num = 2;           \n    int devideNum = 3;     \n    int featureSize = 4;   \n    int priorNum = 2;      \n    int batchSize = 2;     \n\n    \n    float *input = (float *)malloc(batchSize * num * devideNum * priorNum * featureSize * sizeof(float));\n    float *output = (float *)malloc(batchSize * num * devideNum * priorNum * sizeof(float));\n\n    \n    for (int i = 0; i < batchSize * num * devideNum * priorNum * featureSize; i++) {\n        input[i] = i + 1;\n    }\n\n    \n    permuteData_cpu(input, output, num, devideNum, featureSize, priorNum, batchSize);\n\n    \n    \n    for (int i = 0; i < batchSize; i++) {\n        for (int j = 0; j < num * devideNum * priorNum; j++) {\n            printf(\"%f \", output[i * num * devideNum * priorNum + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    free(input);\n    free(output);\n\n    return 0;\n}\n\nvoid permuteData_cpu(const float *input, float *output, int num, int devideNum, int featureSize, int priorNum, int batchSize) {\n    for (int tid = 0; tid < num; tid++) {\n        int numPerbatch = num * devideNum * priorNum;\n        for (int s = 0; s < batchSize; s++) {\n            for (int i = 0; i < priorNum; i++) {\n                for (int j = 0; j < devideNum; j++) {\n                    output[s * numPerbatch + tid * priorNum * devideNum + i * devideNum + j] =\n                        input[s * numPerbatch + (i * devideNum * featureSize) + (j * featureSize) + tid];\n                }\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void permuteData(const float* input, float* output, int num, int devideNum, int featureSize, int priorNum, int batchSize) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid >= num) {\n        return;\n    }\n\n    int numPerbatch = num * devideNum * priorNum;\n\n    for (int s = 0; s < batchSize; s++) {\n        for (int i = 0; i < priorNum; i++) {\n            for (int j = 0; j < devideNum; j++) {\n                output[s * numPerbatch + tid * priorNum * devideNum + i * devideNum + j] = input[s * numPerbatch + (i * devideNum * featureSize) + (j * featureSize) + tid];\n            }\n        }\n    }\n}\n\nint main() {\n    \n\n    \n    float* h_input = ;\n    float* h_output = ;\n\n    float* d_input, *d_output;\n\n    cudaMalloc((void**)&d_input, );\n    cudaMalloc((void**)&d_output, );\n\n    \n    cudaMemcpy(d_input, h_input, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize();\n    dim3 gridSize();\n\n    permuteData<<<gridSize, blockSize>>>(d_input, d_output, );\n\n    \n    cudaMemcpy(h_output, d_output, , cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_input);\n    cudaFree(d_output);\n\n    return 0;\n}\n"
    },
    {
        "id": "15",
        "c_code": "#include <stdio.h>\n\nvoid fill_cpu(int N, float ALPHA, float *X, int INCX) {\n    int i;\n    for (i = 0; i < N; ++i) {\n        X[i * INCX] = ALPHA;\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float alpha = 2.0;\n    int incX = 2;\n\n    printf(\"\u539f\u59cb\u6570\u7ec4 X\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayX[i]);\n    }\n\n    \n    fill_cpu(arraySize, alpha, arrayX, incX);\n\n    printf(\"\\n\u586b\u5145\u540e\u7684\u6570\u7ec4 X\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayX[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void fill_kernel(int N, float ALPHA, float* X, int INCX) {\n    int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n    if (i < N)\n        X[i * INCX] = ALPHA;\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float ALPHA = 2.0;\n    int INCX = 2;\n\n    \n    float* h_X = (float*)malloc(arraySize * sizeof(float));\n\n    \n    float* d_X;\n    cudaMalloc((void**)&d_X, arraySize * sizeof(float));\n\n    \n    dim3 blockSize(256, 1, 1);\n    dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1, 1);\n\n    \n    fill_kernel<<<gridSize, blockSize>>>(arraySize, ALPHA, d_X, INCX);\n\n    \n    cudaMemcpy(h_X, d_X, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_X[i]);\n    }\n\n    \n    free(h_X);\n    cudaFree(d_X);\n\n    return 0;\n}\n"
    },
    {
        "id": "150",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid cpuSimpleCorrelator(float *xi, float *xq, float *sr, float *si, int sLength, float *L, int uLength);\n\nint main() {\n    \n    \n    int sLength = 5;   \n    int uLength = 8;   \n\n    \n    float xi[uLength + sLength];\n    float xq[uLength + sLength];\n    float sr[uLength];\n    float si[uLength];\n    float L[uLength];\n\n    \n    for (int i = 0; i < uLength + sLength; i++) {\n        xi[i] = i + 1;\n        xq[i] = i + 2;\n    }\n\n    for (int i = 0; i < uLength; i++) {\n        sr[i] = i + 3;\n        si[i] = i + 4;\n    }\n\n    \n    cpuSimpleCorrelator(xi, xq, sr, si, sLength, L, uLength);\n\n    \n    \n    for (int i = 0; i < uLength; i++) {\n        printf(\"%f \", L[i]);\n    }\n\n    return 0;\n}\n\nvoid cpuSimpleCorrelator(float *xi, float *xq, float *sr, float *si, int sLength, float *L, int uLength) {\n    for (int u = 0; u < uLength; u++) {\n        float real = 0;\n        float imag = 0;\n        float a, b, c, d;\n\n        for (int n = u; n < u + sLength; n++) {\n            a = xi[n];\n            b = xq[n];\n            c = sr[n - u];\n            d = si[n - u] * (-1);\n            real += (a * c) - (b * d);\n            imag += (a * d) + (b * c);\n        }\n\n        L[u] = sqrt(real * real + imag * imag);\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <math.h>\n\n\n__global__ void cudaSimpleCorrelator(float* xi, float* xq, float* sr, float* si, int sLength, float* L, int uLength) {\n    int u = (blockIdx.x * blockDim.x) + threadIdx.x;\n\n    if (u >= uLength)\n        return;\n\n    float real = 0;\n    float imag = 0;\n    float a, b, c, d;\n\n    for (int n = u; n < u + sLength; n++) {\n        a = xi[n];\n        b = xq[n];\n        c = sr[n - u];\n        d = si[n - u] * (-1);\n\n        real += (a * c) - (b * d);\n        imag += (a * d) + (b * c);\n    }\n\n    L[u] = sqrt(real * real + imag * imag);\n}\n\nint main() {\n    \n\n    \n    float* h_xi = ;\n    float* h_xq = ;\n    float* h_sr = ;\n    float* h_si = ;\n    float* h_L = ;\n\n    float* d_xi, *d_xq, *d_sr, *d_si, *d_L;\n\n    cudaMalloc((void**)&d_xi, );\n    cudaMalloc((void**)&d_xq, );\n    cudaMalloc((void**)&d_sr, );\n    cudaMalloc((void**)&d_si, );\n    cudaMalloc((void**)&d_L, );\n\n    \n    cudaMemcpy(d_xi, h_xi, , cudaMemcpyHostToDevice);\n    cudaMemcpy(d_xq, h_xq, , cudaMemcpyHostToDevice);\n    cudaMemcpy(d_sr, h_sr, , cudaMemcpyHostToDevice);\n    cudaMemcpy(d_si, h_si, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize();\n    dim3 gridSize();\n\n    cudaSimpleCorrelator<<<gridSize, blockSize>>>(d_xi, d_xq, d_sr, d_si, );\n\n    \n    cudaMemcpy(h_L, d_L, , cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_xi);\n    cudaFree(d_xq);\n    cudaFree(d_sr);\n    cudaFree(d_si);\n    cudaFree(d_L);\n\n    return 0;\n}\n"
    },
    {
        "id": "151",
        "c_code": "#include <stdio.h>\n\nvoid convertKinectDisparityToRegularDisparity_cpu(float *d_regularDisparity, int d_regularDisparityPitch, const float *d_KinectDisparity, int d_KinectDisparityPitch, int width, int height);\n\nint main() {\n    \n    \n    int width = 5;\n    int height = 3;\n\n    \n    float d_KinectDisparity[height][width];\n    float d_regularDisparity[height][width];\n\n    \n    for (int y = 0; y < height; y++) {\n        for (int x = 0; x < width; x++) {\n            d_KinectDisparity[y][x] = x + y + 1;\n        }\n    }\n\n    \n    convertKinectDisparityToRegularDisparity_cpu((float *)d_regularDisparity, width * sizeof(float), (float *)d_KinectDisparity, width * sizeof(float), width, height);\n\n    \n    \n    for (int y = 0; y < height; y++) {\n        for (int x = 0; x < width; x++) {\n            printf(\"%f \", d_regularDisparity[y][x]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n\nvoid convertKinectDisparityToRegularDisparity_cpu(float *d_regularDisparity, int d_regularDisparityPitch, const float *d_KinectDisparity, int d_KinectDisparityPitch, int width, int height) {\n    for (int x = 0; x < width; x++) {\n        for (int y = 0; y < height; y++) {\n            float d_in = *((float *)((char *)d_KinectDisparity + y * d_KinectDisparityPitch) + x);\n            float d_out = (d_in == 0.0f) ? 1 : -d_in;\n            *((float *)((char *)d_regularDisparity + y * d_regularDisparityPitch) + x) = d_out;\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void convertKinectDisparityToRegularDisparity_kernel(float* d_regularDisparity, int d_regularDisparityPitch,\n                                                               const float* d_KinectDisparity, int d_KinectDisparityPitch,\n                                                               int width, int height) {\n    const int x = blockIdx.x * blockDim.x + threadIdx.x;\n    const int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if ((x < width) && (y < height)) {\n        float d_in = *((float*)((char*)d_KinectDisparity + y * d_KinectDisparityPitch) + x);\n        float d_out = (d_in == 0.0f) ? 1 : -d_in;\n        *((float*)((char*)d_regularDisparity + y * d_regularDisparityPitch) + x) = d_out;\n    }\n}\n\nint main() {\n    \n\n    \n    float* h_KinectDisparity = ;\n    float* h_regularDisparity = ;\n\n    float* d_KinectDisparity, *d_regularDisparity;\n\n    cudaMalloc((void**)&d_KinectDisparity, );\n    cudaMalloc((void**)&d_regularDisparity, );\n\n    \n    cudaMemcpy(d_KinectDisparity, h_KinectDisparity, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize();\n    dim3 gridSize();\n\n    convertKinectDisparityToRegularDisparity_kernel<<<gridSize, blockSize>>>(d_regularDisparity, );\n\n    \n    cudaMemcpy(h_regularDisparity, d_regularDisparity, , cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_KinectDisparity);\n    cudaFree(d_regularDisparity);\n\n    return 0;\n}\n"
    },
    {
        "id": "152",
        "c_code": "#include <stdio.h>\n\nvoid runFilterCpu(float *I, float *Q, int samplesLength, float *filter, int filterLength, float *filtered_I, float *filtered_Q, int convLength);\n\nint main() {\n    \n    \n    int samplesLength = 10;\n    int filterLength = 3;\n    int convLength = samplesLength - filterLength + 1;\n\n    \n    float I[samplesLength];\n    float Q[samplesLength];\n    float filter[filterLength];\n    float filtered_I[convLength];\n    float filtered_Q[convLength];\n\n    \n    for (int i = 0; i < samplesLength; i++) {\n        I[i] = i + 1;\n        Q[i] = i + 2;\n    }\n\n    for (int i = 0; i < filterLength; i++) {\n        filter[i] = i + 1;\n    }\n\n    \n    runFilterCpu(I, Q, samplesLength, filter, filterLength, filtered_I, filtered_Q, convLength);\n\n    \n    \n    printf(\"Filtered I: \");\n    for (int i = 0; i < convLength; i++) {\n        printf(\"%f \", filtered_I[i]);\n    }\n    printf(\"\\n\");\n\n    printf(\"Filtered Q: \");\n    for (int i = 0; i < convLength; i++) {\n        printf(\"%f \", filtered_Q[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid runFilterCpu(float *I, float *Q, int samplesLength, float *filter, int filterLength, float *filtered_I, float *filtered_Q, int convLength) {\n    for (int sampleIndex = 0; sampleIndex < convLength; sampleIndex++) {\n        int index;\n        float sumI, sumQ;\n        sumI = 0;\n        sumQ = 0;\n\n        for (int j = sampleIndex - filterLength + 1; j <= sampleIndex; j++) {\n            index = sampleIndex - j;\n\n            if ((j < samplesLength) && (j >= 0)) {\n                sumI += filter[index] * I[j];\n                sumQ += filter[index] * Q[j];\n            }\n        }\n\n        filtered_I[sampleIndex] = sumI;\n        filtered_Q[sampleIndex] = sumQ;\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void runFilterCuda(float* I, float* Q, int samplesLength, float* filter, int filterLength,\n                               float* filtered_I, float* filtered_Q, int convLength) {\n    int sampleIndex = (blockIdx.x * blockDim.x) + threadIdx.x;\n\n    if (sampleIndex >= convLength)\n        return;\n\n    int index;\n    float sumI, sumQ;\n\n    sumI = 0;\n    sumQ = 0;\n\n    for (int j = sampleIndex - filterLength + 1; j <= sampleIndex; j++) {\n        index = sampleIndex - j;\n\n        if ((j < samplesLength) && (j >= 0)) {\n            sumI += filter[index] * I[j];\n            sumQ += filter[index] * Q[j];\n        }\n    }\n\n    filtered_I[sampleIndex] = sumI;\n    filtered_Q[sampleIndex] = sumQ;\n}\n\nint main() {\n    \n\n    \n    float* h_I = ;\n    float* h_Q = ;\n    float* h_filter = ;\n    float* h_filtered_I = ;\n    float* h_filtered_Q = ;\n\n    float* d_I, *d_Q, *d_filter, *d_filtered_I, *d_filtered_Q;\n\n    cudaMalloc((void**)&d_I, );\n    cudaMalloc((void**)&d_Q, );\n    cudaMalloc((void**)&d_filter, );\n    cudaMalloc((void**)&d_filtered_I, );\n    cudaMalloc((void**)&d_filtered_Q, );\n\n    \n    cudaMemcpy(d_I, h_I, , cudaMemcpyHostToDevice);\n    cudaMemcpy(d_Q, h_Q, , cudaMemcpyHostToDevice);\n    cudaMemcpy(d_filter, h_filter, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize();\n    dim3 gridSize();\n\n    runFilterCuda<<<gridSize, blockSize>>>(d_I, d_Q, );\n\n    \n    cudaMemcpy(h_filtered_I, d_filtered_I, , cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_filtered_Q, d_filtered_Q, , cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_I);\n    cudaFree(d_Q);\n    cudaFree(d_filter);\n    cudaFree(d_filtered_I);\n    cudaFree(d_filtered_Q);\n\n    return 0;\n}\n"
    },
    {
        "id": "153",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid l2normalize_cpu(float *x, float *dx, int batch, int filters, int spatial);\n\nint main() {\n    \n    \n    int batch = 2;\n    int filters = 3;\n    int spatial = 4;\n\n    \n    float x[batch * filters * spatial];\n    float dx[batch * filters * spatial];\n\n    \n    for (int i = 0; i < batch * filters * spatial; i++) {\n        x[i] = i + 1;\n    }\n\n    \n    l2normalize_cpu(x, dx, batch, filters, spatial);\n\n    \n    \n    printf(\"Normalized x: \");\n    for (int i = 0; i < batch * filters * spatial; i++) {\n        printf(\"%f \", x[i]);\n    }\n    printf(\"\\n\");\n\n    printf(\"dx: \");\n    for (int i = 0; i < batch * filters * spatial; i++) {\n        printf(\"%f \", dx[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid l2normalize_cpu(float *x, float *dx, int batch, int filters, int spatial) {\n    int b, f, i;\n\n    for (b = 0; b < batch; ++b) {\n        for (i = 0; i < spatial; ++i) {\n            float sum = 0;\n\n            for (f = 0; f < filters; ++f) {\n                int index = b * filters * spatial + f * spatial + i;\n                sum += powf(x[index], 2);\n            }\n\n            sum = sqrtf(sum);\n\n            for (f = 0; f < filters; ++f) {\n                int index = b * filters * spatial + f * spatial + i;\n                x[index] /= sum;\n                dx[index] = (1 - x[index]) / sum;\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <math.h>\n\n\n__global__ void l2normalize_kernel(int N, float* x, float* dx, int batch, int filters, int spatial) {\n    int index = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n\n    if (index >= N)\n        return;\n\n    int b = index / spatial;\n    int i = index % spatial;\n    int f;\n    float sum = 0;\n\n    for (f = 0; f < filters; ++f) {\n        int index = b * filters * spatial + f * spatial + i;\n        sum += powf(x[index], 2);\n    }\n\n    sum = sqrtf(sum);\n\n    if (sum == 0)\n        sum = 1;\n\n    for (f = 0; f < filters; ++f) {\n        int index = b * filters * spatial + f * spatial + i;\n        x[index] /= sum;\n        dx[index] = (1 - x[index]) / sum;\n    }\n}\n\nint main() {\n    \n\n    \n    float* h_x = ;\n    float* h_dx = ;\n\n    float* d_x, *d_dx;\n\n    cudaMalloc((void**)&d_x, );\n    cudaMalloc((void**)&d_dx, );\n\n    \n    cudaMemcpy(d_x, h_x, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize();\n    dim3 gridSize();\n\n    int N = ;\n    int batch = ;\n    int filters = ;\n    int spatial = ;\n\n    l2normalize_kernel<<<gridSize, blockSize>>>(N, d_x, d_dx, batch, filters, spatial);\n\n    \n    cudaMemcpy(h_dx, d_dx, , cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_x);\n    cudaFree(d_dx);\n\n    return 0;\n}\n"
    },
    {
        "id": "154",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid distanceMatCalc(long int totalPixels, int availablePixels, int outPixelOffset, int patchSize, float *distMat, float *data, float filtSig);\n\nint main() {\n    \n    \n    long int totalPixels = 3;\n    int availablePixels = 2;\n    int outPixelOffset = 1;\n    int patchSize = 2;\n\n    \n    float distMat[availablePixels * totalPixels];\n    float data[totalPixels * patchSize * patchSize];\n\n    \n    for (long int i = 0; i < totalPixels * patchSize * patchSize; i++) {\n        data[i] = i + 1;\n    }\n\n    \n    distanceMatCalc(totalPixels, availablePixels, outPixelOffset, patchSize, distMat, data, 1.0);\n\n    \n    \n    for (long int i = 0; i < availablePixels * totalPixels; i++) {\n        printf(\"%f \", distMat[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid distanceMatCalc(long int totalPixels, int availablePixels, int outPixelOffset, int patchSize, float *distMat, float *data, float filtSig) {\n    for (long int i = 0; i < availablePixels * totalPixels; i++) {\n        int data_i = i / totalPixels + outPixelOffset;\n        int data_j = i % totalPixels;\n        float tmp = 0.0;\n\n        if (data_i != data_j) {\n            for (int elem = 0; elem < patchSize * patchSize; elem++) {\n                float diff = data[data_i * patchSize * patchSize + elem] - data[data_j * patchSize * patchSize + elem];\n                tmp += diff * diff;\n            }\n            tmp = exp(-tmp / filtSig);\n        }\n\n        distMat[i] = tmp;\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <math.h>\n\n\n__global__ void distanceMatCalc(long int totalPixels, int availablePixels, int outPixelOffset, int patchSize, float* distMat, float* data, float filtSig) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n\n    for (long int i = index; i < availablePixels * totalPixels; i += stride) {\n        int data_i = i / totalPixels + outPixelOffset;\n        int data_j = i % totalPixels;\n        float tmp = 0.0;\n\n        if (data_i != data_j) {\n            for (int elem = 0; elem < patchSize * patchSize; elem++) {\n                float diff = (data[data_i * patchSize * patchSize + elem] - data[data_j * patchSize * patchSize + elem]);\n                tmp += diff * diff;\n            }\n\n            tmp = exp(-tmp / filtSig);\n        }\n\n        distMat[i] = tmp;\n    }\n}\n\nint main() {\n    \n\n    \n    float* h_distMat = ;\n    float* h_data = ;\n\n    float* d_distMat, *d_data;\n\n    cudaMalloc((void**)&d_distMat, );\n    cudaMalloc((void**)&d_data, );\n\n    \n    cudaMemcpy(d_data, h_data, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize();\n    dim3 gridSize();\n\n    long int totalPixels = ;\n    int availablePixels = ;\n    int outPixelOffset = ;\n    int patchSize = ;\n    float filtSig = ;\n\n    distanceMatCalc<<<gridSize, blockSize>>>(totalPixels, availablePixels, outPixelOffset, patchSize, d_distMat, d_data, filtSig);\n\n    \n    cudaMemcpy(h_distMat, d_distMat, , cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_distMat);\n    cudaFree(d_data);\n\n    return 0;\n}\n"
    },
    {
        "id": "155",
        "c_code": "#include <stdio.h>\n\nvoid shortcut_kernel_cpu(int size, int minw, int minh, int minc, int stride, int sample, int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out);\n\nint main() {\n    \n    \n    int size = 3;\n    int minw = 2;\n    int minh = 2;\n    int minc = 2;\n    int stride = 2;\n    int sample = 3;\n    int batch = 4;\n    int w1 = 1;\n    int h1 = 1;\n    int c1 = 1;\n    int w2 = 2;\n    int h2 = 2;\n    int c2 = 2;\n\n    \n    float add[size * stride * w1 * h1 * c1 * batch];\n    float out[sample * w2 * h2 * c2 * batch];\n\n    \n    for (int i = 0; i < size * stride * w1 * h1 * c1 * batch; i++) {\n        add[i] = i + 1;\n    }\n\n    for (int i = 0; i < sample * w2 * h2 * c2 * batch; i++) {\n        out[i] = i + 2;\n    }\n\n    \n    shortcut_kernel_cpu(size, minw, minh, minc, stride, sample, batch, w1, h1, c1, add, w2, h2, c2, out);\n\n    \n    \n    for (int i = 0; i < sample * w2 * h2 * c2 * batch; i++) {\n        printf(\"%f \", out[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid shortcut_kernel_cpu(int size, int minw, int minh, int minc, int stride, int sample, int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out) {\n    for (int id = 0; id < size; id++) {\n        int i = id % minw;\n        id /= minw;\n        int j = id % minh;\n        id /= minh;\n        int k = id % minc;\n        id /= minc;\n        int b = id % batch;\n\n        int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));\n        int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));\n\n        out[out_index] += add[add_index];\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void shortcut_kernel(int size, int minw, int minh, int minc, int stride, int sample, int batch,\n                                 int w1, int h1, int c1, float* add, int w2, int h2, int c2, float* out) {\n    int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n\n    if (id >= size)\n        return;\n\n    int i = id % minw;\n    id /= minw;\n    int j = id % minh;\n    id /= minh;\n    int k = id % minc;\n    id /= minc;\n    int b = id % batch;\n\n    int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));\n    int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));\n\n    atomicAdd(&out[out_index], add[add_index]);\n}\n\nint main() {\n    \n\n    \n    float* h_add = ;\n    float* h_out = ;\n\n    float* d_add, *d_out;\n\n    cudaMalloc((void**)&d_add, );\n    cudaMalloc((void**)&d_out, );\n\n    \n    cudaMemcpy(d_add, h_add, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize();\n    dim3 gridSize();\n\n    int size = ;\n    int minw = ;\n    int minh = ;\n    int minc = ;\n    int stride = ;\n    int sample = ;\n    int batch = ;\n    int w1 = ;\n    int h1 = ;\n    int c1 = ;\n    int w2 = ;\n    int h2 = ;\n    int c2 = ;\n\n    shortcut_kernel<<<gridSize, blockSize>>>(size, minw, minh, minc, stride, sample, batch, w1, h1, c1, d_add, w2, h2, c2, d_out);\n\n    \n    cudaMemcpy(h_out, d_out, , cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_add);\n    cudaFree(d_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "156",
        "c_code": "#include <stdio.h>\n\nfloat dot_cpu(int N, float *X, int INCX, float *Y, int INCY);\n\nint main() {\n    \n    \n    int N = 5;\n    int INCX = 1;\n    int INCY = 1;\n\n    \n    float X[N * INCX];\n    float Y[N * INCY];\n\n    \n    for (int i = 0; i < N; i++) {\n        X[i * INCX] = i + 1;\n        Y[i * INCY] = i + 2;\n    }\n\n    \n    float result = dot_cpu(N, X, INCX, Y, INCY);\n\n    \n    \n    printf(\"Dot Product: %f\\n\", result);\n\n    return 0;\n}\n\nfloat dot_cpu(int N, float *X, int INCX, float *Y, int INCY) {\n    int i;\n    float dot = 0;\n\n    for (i = 0; i < N; ++i) {\n        dot += X[i * INCX] * Y[i * INCY];\n    }\n\n    return dot;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void dot_kernel(float* output, float scale, int batch, int n, int size, float* delta) {\n    int index = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n    int f1 = index / n;\n    int f2 = index % n;\n\n    if (f2 <= f1)\n        return;\n\n    float sum = 0;\n    float norm1 = 0;\n    float norm2 = 0;\n    int b, i;\n\n    for (b = 0; b < batch; ++b) {\n        for (i = 0; i < size; ++i) {\n            int i1 = b * size * n + f1 * size + i;\n            int i2 = b * size * n + f2 * size + i;\n            sum += output[i1] * output[i2];\n            norm1 += output[i1] * output[i1];\n            norm2 += output[i2] * output[i2];\n        }\n    }\n\n    norm1 = sqrt(norm1);\n    norm2 = sqrt(norm2);\n    float norm = norm1 * norm2;\n    sum = sum / norm;\n\n    for (b = 0; b < batch; ++b) {\n        for (i = 0; i < size; ++i) {\n            int i1 = b * size * n + f1 * size + i;\n            int i2 = b * size * n + f2 * size + i;\n            delta[i1] += -scale * sum * output[i2] / norm;\n            delta[i2] += -scale * sum * output[i1] / norm;\n        }\n    }\n}\n\nint main() {\n    \n\n    \n    float* h_output = ;\n    float* h_delta = ;\n\n    float* d_output, *d_delta;\n\n    cudaMalloc((void**)&d_output, );\n    cudaMalloc((void**)&d_delta, );\n\n    \n    cudaMemcpy(d_output, h_output, , cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize();\n    dim3 gridSize();\n\n    int batch = ;\n    int n = ;\n    int size = ;\n    float scale = ;\n\n    dot_kernel<<<gridSize, blockSize>>>(d_output, scale, batch, n, size, d_delta);\n\n    \n    cudaMemcpy(h_delta, d_delta, , cudaMemcpyDeviceToHost);\n\n    \n\n    \n    cudaFree(d_output);\n    cudaFree(d_delta);\n\n    return 0;\n}\n"
    },
    {
        "id": "157",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid k_adam_kernel(float *m, float *v, float *w, const float *d, int max_size, float beta1, float beta2, float beta1_tpower, float beta2_tpower, float learning_rate);\n\nint main() {\n    \n    \n    int max_size = 5;\n    float beta1 = 0.9;\n    float beta2 = 0.999;\n    float beta1_tpower = 1.0;\n    float beta2_tpower = 1.0;\n    float learning_rate = 0.001;\n\n    \n    float m[max_size];\n    float v[max_size];\n    float w[max_size];\n    float d[max_size];\n\n    \n    for (int i = 0; i < max_size; i++) {\n        m[i] = i + 1;\n        v[i] = i + 2;\n        w[i] = i + 3;\n        d[i] = i + 4;\n    }\n\n    \n    k_adam_kernel(m, v, w, d, max_size, beta1, beta2, beta1_tpower, beta2_tpower, learning_rate);\n\n    \n    \n    printf(\"Updated w: \");\n    for (int i = 0; i < max_size; i++) {\n        printf(\"%f \", w[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid k_adam_kernel(float *m, float *v, float *w, const float *d, int max_size, float beta1, float beta2, float beta1_tpower, float beta2_tpower, float learning_rate) {\n    const float eps = 1e-8;\n\n    for (int i = 0; i < max_size; i++) {\n        float d_temp = d[i];\n        m[i] = m[i] * beta1 + d_temp * (1 - beta1);\n        v[i] = v[i] * beta2 + d_temp * d_temp * (1 - beta2);\n\n        float m_hat = m[i] / (1 - beta1_tpower);\n        float v_hat = sqrt(v[i] / (1 - beta2_tpower)) + eps;\n\n        w[i] += (m_hat / v_hat) * (-learning_rate);\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void k_adam_kernel(float *m, float *v, float *w, const float *d, int max_size, float beta1, float beta2, float beta1_tpower, float beta2_tpower, float learning_rate) {\n    const float eps = 1e-8;\n    \n    for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < max_size; i += blockDim.x * gridDim.x) {\n        float d_temp = d[i];\n        m[i] = m[i] * beta1 + d_temp * (1 - beta1);\n        v[i] = v[i] * beta2 + d_temp * d_temp * (1 - beta2);\n        float m_hat = m[i] / (1 - beta1_tpower);\n        float v_hat = __fsqrt_rn(v[i] / (1 - beta2_tpower)) + eps;\n        w[i] += (m_hat / v_hat) * (-learning_rate);\n    }\n}\n\nint main() {\n    \n    int max_size = 1000;\n    float *m, *v, *w, *d;  \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_m, *d_v, *d_w, *d_d;\n    cudaMalloc((void **)&d_m, max_size * sizeof(float));\n    cudaMalloc((void **)&d_v, max_size * sizeof(float));\n    cudaMalloc((void **)&d_w, max_size * sizeof(float));\n    cudaMalloc((void **)&d_d, max_size * sizeof(float));\n\n    \n    cudaMemcpy(d_m, m, max_size * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_v, v, max_size * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_w, w, max_size * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_d, d, max_size * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (max_size + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    k_adam_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_m, d_v, d_w, d_d, max_size, 0.9, 0.999, 0.9, 0.999, 0.001);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(w, d_w, max_size * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_m);\n    cudaFree(d_v);\n    cudaFree(d_w);\n    cudaFree(d_d);\n\n    return 0;\n}\n"
    },
    {
        "id": "158",
        "c_code": "#include <stdio.h>\n\nvoid convLayer_forward(int N, int M, int C, int H, int W, int K, float *X, float *Wk, float *Y);\n\nint main() {\n    \n    \n    int N = 1;\n    int M = 1;\n    int C = 1;\n    int H = 5;\n    int W = 5;\n    int K = 3;\n\n    \n    float X[N * C * H * W];\n    float Wk[M * C * K * K];\n    float Y[N * M * (H - K + 1) * (W - K + 1)];\n\n    \n    for (int i = 0; i < N * C * H * W; i++) {\n        X[i] = i + 1;\n    }\n\n    for (int i = 0; i < M * C * K * K; i++) {\n        Wk[i] = i + 2;\n    }\n\n    \n    convLayer_forward(N, M, C, H, W, K, X, Wk, Y);\n\n    \n    \n    for (int i = 0; i < N * M * (H - K + 1) * (W - K + 1); i++) {\n        printf(\"%f \", Y[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid convLayer_forward(int N, int M, int C, int H, int W, int K, float *X, float *Wk, float *Y) {\n    int n, m, c, h, w, p, q;\n    int H_out = H - K + 1;\n    int W_out = W - K + 1;\n\n    for (n = 0; n < N; n++)\n        for (m = 0; m < M; m++)\n            for (h = 0; h < H_out; h++)\n                for (w = 0; w < W_out; w++) {\n                    Y[n * M * H_out * W_out + m * H_out * W_out + h * W_out + w] = 0;\n\n                    for (c = 0; c < C; c++)\n                        for (p = 0; p < K; p++)\n                            for (q = 0; q < K; q++)\n                                Y[n * M * H_out * W_out + m * H_out * W_out + h * W_out + w] +=\n                                    X[n * C * H * W + c * H * W + (h + p) * W + (w + q)] * Wk[m * C * K * K + c * K * K + p * K + q];\n                }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void ConvLayerForward_Kernel(int C, int W_grid, int K, float *X, float *W, float *Y) {\n    int n, m, h, w, c, p, q;\n    \n    n = blockIdx.x;\n    m = blockIdx.y;\n    h = blockIdx.z / W_grid + threadIdx.y;\n    w = blockIdx.z % W_grid + threadIdx.x;\n\n    float acc = 0;\n\n    for (c = 0; c < C; c++) {\n        for (p = 0; p < K; p++) {\n            for (q = 0; q < K; q++) {\n                acc += X[n * C * W_grid * W_grid + c * W_grid * W_grid + (h + p) * W_grid + (w + q)] * W[m * C * K * K + c * K * K + p * K + q];\n            }\n        }\n    }\n\n    Y[n * W_grid * W_grid * W_grid + m * W_grid * W_grid + h * W_grid + w] = acc;\n}\n\nint main() {\n    \n    int C = 3, W_grid = 4, K = 3;  \n    float *X, *W, *Y;  \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_X, *d_W, *d_Y;\n    cudaMalloc((void **)&d_X, C * W_grid * W_grid * sizeof(float));\n    cudaMalloc((void **)&d_W, C * K * K * sizeof(float));\n    cudaMalloc((void **)&d_Y, W_grid * W_grid * W_grid * sizeof(float));\n\n    \n    cudaMemcpy(d_X, X, C * W_grid * W_grid * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_W, W, C * K * K * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 threadsPerBlock(K, K);\n    dim3 blocksPerGrid(W_grid, W_grid, W_grid);\n\n    \n    ConvLayerForward_Kernel<<<blocksPerGrid, threadsPerBlock>>>(C, W_grid, K, d_X, d_W, d_Y);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(Y, d_Y, W_grid * W_grid * W_grid * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_X);\n    cudaFree(d_W);\n    cudaFree(d_Y);\n\n    return 0;\n}\n"
    },
    {
        "id": "159",
        "c_code": "#include <stdio.h>\n\nvoid opL23_cpu(float *vec, float *vec1, long depth, long rows, long cols);\n\nint main() {\n    \n    \n    long depth = 2;\n    long rows = 3;\n    long cols = 4;\n\n    \n    float vec[depth * rows * cols];\n    float vec1[depth * rows * cols];\n\n    \n    for (long i = 0; i < depth * rows * cols; i++) {\n        vec[i] = i + 1;\n        vec1[i] = i + 2;\n    }\n\n    \n    opL23_cpu(vec, vec1, depth, rows, cols);\n\n    \n    \n    for (long i = 0; i < depth * rows * cols; i++) {\n        printf(\"%f \", vec[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid opL23_cpu(float *vec, float *vec1, long depth, long rows, long cols) {\n    for (int x = 0; x < cols; x++) {\n        for (int y = 0; y < rows; y++) {\n            for (int z = 0; z < depth; z++) {\n                unsigned long long i = z * rows * cols + y * cols + x;\n                unsigned long long j = z * rows * cols + y * cols;\n                unsigned long size2d = cols;\n                unsigned long size3d = depth * rows * cols + rows * cols + cols;\n\n                if (i + cols + 1 >= size3d)\n                    return;\n\n                vec[i + cols] = 0.5 * (vec1[i + cols] + vec1[i]);\n\n                if (j + 1 >= size2d)\n                    return;\n\n                vec[j] = 0.5 * (vec1[j]);\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void opL23(float *vec, float *vec1, long depth, long rows, long cols) {\n    unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;\n    unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;\n    unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;\n    unsigned long long i = z * rows * cols + y * cols + x;\n    unsigned long long j = z * rows * cols + y * cols;\n    unsigned long size2d = cols;\n    unsigned long size3d = depth * rows * cols + rows * cols + cols;\n\n    if (x >= cols || y >= rows || z >= depth)\n        return;\n\n    if (i + cols + 1 >= size3d)\n        return;\n\n    vec[i + cols] = 0.5 * (vec1[i + cols] + vec1[i]);\n\n    if (j + 1 >= size2d)\n        return;\n\n    vec[j] = 0.5 * (vec1[j]);\n}\n\nint main() {\n    \n    long depth = 3, rows = 4, cols = 5;  \n    float *vec, *vec1;  \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_vec, *d_vec1;\n    cudaMalloc((void **)&d_vec, depth * rows * cols * sizeof(float));\n    cudaMalloc((void **)&d_vec1, depth * rows * cols * sizeof(float));\n\n    \n    cudaMemcpy(d_vec, vec, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_vec1, vec1, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 threadsPerBlock(16, 16, 1);\n    dim3 blocksPerGrid((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,\n                       (rows + threadsPerBlock.y - 1) / threadsPerBlock.y,\n                       (depth + threadsPerBlock.z - 1) / threadsPerBlock.z);\n\n    \n    opL23<<<blocksPerGrid, threadsPerBlock>>>(d_vec, d_vec1, depth, rows, cols);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(vec, d_vec, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_vec);\n    cudaFree(d_vec1);\n\n    return 0;\n}\n"
    },
    {
        "id": "16",
        "c_code": "#include <stdio.h>\n\nvoid scal_cpu(int N, float ALPHA, float *X, int INCX) {\n    int i;\n    for (i = 0; i < N; ++i) {\n        X[i * INCX] *= ALPHA;\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float alpha = 2.0;\n    int incX = 2;\n\n    printf(\"\u539f\u59cb\u6570\u7ec4 X\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayX[i]);\n    }\n\n    \n    scal_cpu(arraySize, alpha, arrayX, incX);\n\n    printf(\"\\n\u7f29\u653e\u540e\u7684\u6570\u7ec4 X\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayX[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void scal_kernel(int N, float ALPHA, float* X, int INCX) {\n    int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n    if (i < N)\n        X[i * INCX] *= ALPHA;\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float ALPHA = 2.0;\n    int INCX = 2;\n\n    \n    float* h_X = (float*)malloc(arraySize * sizeof(float));\n\n    \n    float* d_X;\n    cudaMalloc((void**)&d_X, arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_X[i] = static_cast<float>(i);\n    }\n\n    \n    cudaMemcpy(d_X, h_X, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256, 1, 1);\n    dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1, 1);\n\n    \n    scal_kernel<<<gridSize, blockSize>>>(arraySize, ALPHA, d_X, INCX);\n\n    \n    cudaMemcpy(h_X, d_X, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_X[i]);\n    }\n\n    \n    free(h_X);\n    cudaFree(d_X);\n\n    return 0;\n}\n"
    },
    {
        "id": "160",
        "c_code": "#include <stdio.h>\n\nvoid upsample_cpu(float *in, int w, int h, int c, int batch, int stride, int forward, float scale, float *out);\n\nint main() {\n    \n    \n    int w = 2;\n    int h = 2;\n    int c = 3;\n    int batch = 1;\n    int stride = 2;\n    int forward = 1; \n    float scale = 2.0;\n\n    \n    float in[batch * w * h * c];\n    float out[batch * w * h * c * stride * stride];\n\n    \n    for (int i = 0; i < batch * w * h * c; i++) {\n        in[i] = i + 1;\n    }\n\n    \n    upsample_cpu(in, w, h, c, batch, stride, forward, scale, out);\n\n    \n    \n    for (int i = 0; i < batch * w * h * c * stride * stride; i++) {\n        printf(\"%f \", out[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid upsample_cpu(float *in, int w, int h, int c, int batch, int stride, int forward, float scale, float *out) {\n    int i, j, k, b;\n\n    for (b = 0; b < batch; ++b) {\n        for (k = 0; k < c; ++k) {\n            for (j = 0; j < h * stride; ++j) {\n                for (i = 0; i < w * stride; ++i) {\n                    int in_index = b * w * h * c + k * w * h + (j / stride) * w + i / stride;\n                    int out_index = b * w * h * c * stride * stride + k * w * h * stride * stride + j * w * stride + i;\n\n                    if (forward)\n                        out[out_index] = scale * in[in_index];\n                    else\n                        in[in_index] += scale * out[out_index];\n                }\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void upsample_kernel(size_t N, float *x, int w, int h, int c, int batch, int stride, int forward, float scale, float *out) {\n    size_t i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n\n    if (i >= N)\n        return;\n\n    int out_index = i;\n    int out_w = i % (w * stride);\n    i = i / (w * stride);\n    int out_h = i % (h * stride);\n    i = i / (h * stride);\n    int out_c = i % c;\n    i = i / c;\n    int b = i % batch;\n    int in_w = out_w / stride;\n    int in_h = out_h / stride;\n    int in_c = out_c;\n    int in_index = b * w * h * c + in_c * w * h + in_h * w + in_w;\n\n    if (forward)\n        atomicAdd(out + out_index, scale * x[in_index]);\n    else\n        atomicAdd(x + in_index, scale * out[out_index]);\n}\n\nint main() {\n    \n    size_t N = 1000;\n    int w = 16, h = 16, c = 3, batch = 4, stride = 2, forward = 1;\n    float scale = 0.5;  \n    float *x, *out;  \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_x, *d_out;\n    cudaMalloc((void **)&d_x, N * sizeof(float));\n    cudaMalloc((void **)&d_out, N * sizeof(float));\n\n    \n    cudaMemcpy(d_x, x, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 threadsPerBlock(256);\n    dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x, 1);\n\n    \n    upsample_kernel<<<blocksPerGrid, threadsPerBlock>>>(N, d_x, w, h, c, batch, stride, forward, scale, d_out);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(out, d_out, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_x);\n    cudaFree(d_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "161",
        "c_code": "#include <stdio.h>\n\nvoid rgb2yuv_kernel(int img_size, unsigned char *gpu_img_in_r, unsigned char *gpu_img_in_g, unsigned char *gpu_img_in_b,\n                    unsigned char *gpu_img_out_y, unsigned char *gpu_img_out_u, unsigned char *gpu_img_out_v);\n\nint main() {\n    \n    \n    int img_size = 5;\n\n    \n    unsigned char gpu_img_in_r[img_size];\n    unsigned char gpu_img_in_g[img_size];\n    unsigned char gpu_img_in_b[img_size];\n    unsigned char gpu_img_out_y[img_size];\n    unsigned char gpu_img_out_u[img_size];\n    unsigned char gpu_img_out_v[img_size];\n\n    \n    for (int i = 0; i < img_size; i++) {\n        gpu_img_in_r[i] = i + 1;\n        gpu_img_in_g[i] = i + 2;\n        gpu_img_in_b[i] = i + 3;\n    }\n\n    \n    rgb2yuv_kernel(img_size, gpu_img_in_r, gpu_img_in_g, gpu_img_in_b, gpu_img_out_y, gpu_img_out_u, gpu_img_out_v);\n\n    \n    \n    printf(\"Y: \");\n    for (int i = 0; i < img_size; i++) {\n        printf(\"%u \", gpu_img_out_y[i]);\n    }\n    printf(\"\\n\");\n\n    printf(\"U: \");\n    for (int i = 0; i < img_size; i++) {\n        printf(\"%u \", gpu_img_out_u[i]);\n    }\n    printf(\"\\n\");\n\n    printf(\"V: \");\n    for (int i = 0; i < img_size; i++) {\n        printf(\"%u \", gpu_img_out_v[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid rgb2yuv_kernel(int img_size, unsigned char *gpu_img_in_r, unsigned char *gpu_img_in_g, unsigned char *gpu_img_in_b,\n                    unsigned char *gpu_img_out_y, unsigned char *gpu_img_out_u, unsigned char *gpu_img_out_v) {\n    unsigned char r, g, b;\n\n    for (int index = 0; index < img_size; index++) {\n        r = gpu_img_in_r[index];\n        g = gpu_img_in_g[index];\n        b = gpu_img_in_b[index];\n\n        gpu_img_out_y[index] = (unsigned char)(0.299 * r + 0.587 * g + 0.114 * b);\n        gpu_img_out_u[index] = (unsigned char)(-0.169 * r - 0.331 * g + 0.499 * b + 128);\n        gpu_img_out_v[index] = (unsigned char)(0.499 * r - 0.418 * g - 0.0813 * b + 128);\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void rgb2yuv_kernel(int img_size, unsigned char *gpu_img_in_r, unsigned char *gpu_img_in_g, unsigned char *gpu_img_in_b,\n                                unsigned char *gpu_img_out_y, unsigned char *gpu_img_out_u, unsigned char *gpu_img_out_v) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (index < img_size) {\n        unsigned char r = gpu_img_in_r[index];\n        unsigned char g = gpu_img_in_g[index];\n        unsigned char b = gpu_img_in_b[index];\n\n        gpu_img_out_y[index] = (unsigned char)(0.299 * r + 0.587 * g + 0.114 * b);\n        gpu_img_out_u[index] = (unsigned char)(-0.169 * r - 0.331 * g + 0.499 * b + 128);\n        gpu_img_out_v[index] = (unsigned char)(0.499 * r - 0.418 * g - 0.0813 * b + 128);\n    }\n}\n\nint main() {\n    \n    int img_size = 1000;  \n    unsigned char *gpu_img_in_r, *gpu_img_in_g, *gpu_img_in_b, *gpu_img_out_y, *gpu_img_out_u, *gpu_img_out_v;\n    \n\n    \n    cudaSetDevice(0);\n\n    \n    unsigned char *d_gpu_img_in_r, *d_gpu_img_in_g, *d_gpu_img_in_b, *d_gpu_img_out_y, *d_gpu_img_out_u, *d_gpu_img_out_v;\n    cudaMalloc((void **)&d_gpu_img_in_r, img_size * sizeof(unsigned char));\n    cudaMalloc((void **)&d_gpu_img_in_g, img_size * sizeof(unsigned char));\n    cudaMalloc((void **)&d_gpu_img_in_b, img_size * sizeof(unsigned char));\n    cudaMalloc((void **)&d_gpu_img_out_y, img_size * sizeof(unsigned char));\n    cudaMalloc((void **)&d_gpu_img_out_u, img_size * sizeof(unsigned char));\n    cudaMalloc((void **)&d_gpu_img_out_v, img_size * sizeof(unsigned char));\n\n    \n    cudaMemcpy(d_gpu_img_in_r, gpu_img_in_r, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_gpu_img_in_g, gpu_img_in_g, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_gpu_img_in_b, gpu_img_in_b, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (img_size + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    rgb2yuv_kernel<<<blocksPerGrid, threadsPerBlock>>>(img_size, d_gpu_img_in_r, d_gpu_img_in_g, d_gpu_img_in_b,\n                                                       d_gpu_img_out_y, d_gpu_img_out_u, d_gpu_img_out_v);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(gpu_img_out_y, d_gpu_img_out_y, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n    cudaMemcpy(gpu_img_out_u, d_gpu_img_out_u, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n    cudaMemcpy(gpu_img_out_v, d_gpu_img_out_v, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_gpu_img_in_r);\n    cudaFree(d_gpu_img_in_g);\n    cudaFree(d_gpu_img_in_b);\n    cudaFree(d_gpu_img_out_y);\n    cudaFree(d_gpu_img_out_u);\n    cudaFree(d_gpu_img_out_v);\n\n    return 0;\n}\n"
    },
    {
        "id": "162",
        "c_code": "#include <stdio.h>\n\nvoid getDRho(const int numOfNucl, const double *psi, const double **dpsi, const double *occNo, double *drho, const char debug);\n\nint main() {\n    \n    \n    int numOfNucl = 3;\n    double psi[] = {1.0, 2.0, 3.0};\n    double *dpsi[numOfNucl];\n    for (int i = 0; i < numOfNucl; ++i) {\n        dpsi[i] = new double[3]; \n        for (int j = 0; j < 3; ++j) {\n            dpsi[i][j] = i + j + 1.0;\n        }\n    }\n    double occNo[] = {0.5, 0.7, 0.9};\n    double drho[3];\n    char debug = 1; \n\n    \n    getDRho(numOfNucl, psi, (const double **)dpsi, occNo, drho, debug);\n\n    \n    \n    printf(\"DRHO: %f %f %f\\n\", drho[0], drho[1], drho[2]);\n\n    \n    for (int i = 0; i < numOfNucl; ++i) {\n        delete[] dpsi[i];\n    }\n\n    return 0;\n}\n\nvoid getDRho(const int numOfNucl, const double *psi, const double **dpsi, const double *occNo, double *drho, const char debug) {\n    drho[0] = 0;\n    drho[1] = 0;\n    drho[2] = 0;\n\n    for (int i = 0; i < numOfNucl; ++i) {\n        drho[0] = drho[0] + 2 * occNo[i] * psi[i] * dpsi[i][0];\n        drho[1] = drho[1] + 2 * occNo[i] * psi[i] * dpsi[i][1];\n        drho[2] = drho[2] + 2 * occNo[i] * psi[i] * dpsi[i][2];\n    }\n\n    if (debug == 1) {\n        printf(\"DEBUG \u2581 print \u2581 of \u2581 DRHO:\\n\");\n        printf(\"\\t%f\\t%f\\t%f\\n\", drho[0], drho[1], drho[2]);\n        printf(\"This \u2581 is \u2581 the \u2581 last \u2581 line ( DRHO ).\\n\\n\");\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void getDRho_cuda(const double *psi, const double *dpsi, const double *occNo, double *drho) {\n    extern __shared__ double dcopy[];\n\n    unsigned int idx = blockIdx.x + gridDim.x * threadIdx.x;\n\n    dcopy[threadIdx.x] = 2 * occNo[threadIdx.x] * psi[threadIdx.x] * dpsi[idx];\n\n    __syncthreads();\n\n    for (int tc = blockDim.x, stepSize = 1; tc > 0; tc >>= 1, stepSize <<= 1) {\n        int pa = threadIdx.x * stepSize;\n        int pb = pa + stepSize;\n\n        if (pb < blockDim.x)\n            dcopy[pa] += dcopy[pb];\n    }\n\n    if (threadIdx.x == 0) {\n        drho[blockIdx.x] = dcopy[0];\n    }\n}\n\nint main() {\n    \n    int block_size = 256; \n    int grid_size = 1000; \n    int shared_memory_size = block_size * sizeof(double);\n\n    double *psi, *dpsi, *occNo, *drho; \n\n    \n    cudaSetDevice(0);\n\n    \n    double *d_psi, *d_dpsi, *d_occNo, *d_drho;\n    cudaMalloc((void **)&d_psi, grid_size * block_size * sizeof(double));\n    cudaMalloc((void **)&d_dpsi, grid_size * block_size * sizeof(double));\n    cudaMalloc((void **)&d_occNo, block_size * sizeof(double));\n    cudaMalloc((void **)&d_drho, grid_size * sizeof(double));\n\n    \n    cudaMemcpy(d_psi, psi, grid_size * block_size * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_dpsi, dpsi, grid_size * block_size * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_occNo, occNo, block_size * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    dim3 threadsPerBlock(block_size);\n    dim3 blocksPerGrid(grid_size);\n\n    \n    getDRho_cuda<<<blocksPerGrid, threadsPerBlock, shared_memory_size>>>(d_psi, d_dpsi, d_occNo, d_drho);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(drho, d_drho, grid_size * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_psi);\n    cudaFree(d_dpsi);\n    cudaFree(d_occNo);\n    cudaFree(d_drho);\n\n    return 0;\n}\n"
    },
    {
        "id": "163",
        "c_code": "#include <stdio.h>\n\nvoid opL12_cpu(float *vec, float *vec1, long depth, long rows, long cols);\n\nint main() {\n    \n    \n    long depth = 3;\n    long rows = 4;\n    long cols = 5;\n\n    \n    float vec[depth * rows * cols];\n    float vec1[depth * rows * cols];\n\n    \n    for (long i = 0; i < depth * rows * cols; i++) {\n        vec[i] = i + 1;\n        vec1[i] = i + 2;\n    }\n\n    \n    opL12_cpu(vec, vec1, depth, rows, cols);\n\n    \n    \n    for (long i = 0; i < depth * rows * cols; i++) {\n        printf(\"%f \", vec[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid opL12_cpu(float *vec, float *vec1, long depth, long rows, long cols) {\n    for (int x = 0; x < cols; x++) {\n        for (int y = 0; y < rows; y++) {\n            for (int z = 0; z < depth; x++) {\n                unsigned long long i = z * rows * cols + y * cols + x;\n                unsigned long long j = z * rows * cols + y * cols;\n                unsigned long size2d = cols;\n                unsigned long size3d = depth * rows * cols + rows * cols + cols;\n\n                if (i + cols + 1 >= size3d)\n                    return;\n\n                vec[i + 1] = 0.25 * (vec1[i + 1] + vec1[i] + vec1[i + cols + 1] + vec1[i + cols]);\n\n                if (j + 1 >= size2d)\n                    return;\n\n                vec[j] = 0.25 * (vec1[j] + vec1[j + cols]);\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void opL12(float *vec, float *vec1, long depth, long rows, long cols) {\n    unsigned long x = threadIdx.x + blockIdx.x * blockDim.x;\n    unsigned long y = threadIdx.y + blockIdx.y * blockDim.y;\n    unsigned long z = threadIdx.z + blockIdx.z * blockDim.z;\n    unsigned long long i = z * rows * cols + y * cols + x;\n    unsigned long long j = z * rows * cols + y * cols;\n    unsigned long size2d = cols;\n    unsigned long size3d = depth * rows * cols + rows * cols + cols;\n\n    if (x >= cols || y >= rows || z >= depth)\n        return;\n\n    if (i + cols + 1 >= size3d)\n        return;\n\n    vec[i + 1] = 0.25 * (vec1[i + 1] + vec1[i] + vec1[i + cols + 1] + vec1[i + cols]);\n\n    if (j + 1 >= size2d)\n        return;\n\n    vec[j] = 0.25 * (vec1[j] + vec1[j + cols]);\n}\n\nint main() {\n    \n    long depth = 3, rows = 4, cols = 5;  \n    float *vec, *vec1;  \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_vec, *d_vec1;\n    cudaMalloc((void **)&d_vec, depth * rows * cols * sizeof(float));\n    cudaMalloc((void **)&d_vec1, depth * rows * cols * sizeof(float));\n\n    \n    cudaMemcpy(d_vec, vec, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_vec1, vec1, depth * rows * cols * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 threadsPerBlock(16, 16, 1);\n    dim3 blocksPerGrid((cols + threadsPerBlock.x - 1) / threadsPerBlock.x,\n                       (rows + threadsPerBlock.y - 1) / threadsPerBlock.y,\n                       (depth + threadsPerBlock.z - 1) / threadsPerBlock.z);\n\n    \n    opL12<<<blocksPerGrid, threadsPerBlock>>>(d_vec, d_vec1, depth, rows, cols);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(vec, d_vec, depth * rows * cols * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_vec);\n    cudaFree(d_vec1);\n\n    return 0;\n}\n"
    },
    {
        "id": "164",
        "c_code": "#include <stdio.h>\n\nvoid cpuBYUSimplified(float *xi, float *xq, float *sr, float *si, int N, int Lq, float *L);\n\nint main() {\n    \n    \n    int N = 10;\n    int Lq = 5;\n\n    \n    float xi[N * 8 * Lq];\n    float xq[N * 8 * Lq];\n    float sr[Lq];\n    float si[Lq];\n    float L[N];\n\n    \n    for (int i = 0; i < N * 8 * Lq; i++) {\n        xi[i] = i + 1;\n        xq[i] = i + 2;\n    }\n\n    for (int i = 0; i < Lq; i++) {\n        sr[i] = i + 3;\n        si[i] = i + 4;\n    }\n\n    \n    cpuBYUSimplified(xi, xq, sr, si, N, Lq, L);\n\n    \n    \n    for (int i = 0; i < N; i++) {\n        printf(\"%f \", L[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid cpuBYUSimplified(float *xi, float *xq, float *sr, float *si, int N, int Lq, float *L) {\n    for (int u = 0; u < N; u++) {\n        float uSum = 0;\n        float r_i, r_q, q_i, q_q;\n        float realPart, imagPart;\n\n        for (int k = 0; k <= 7; k++) {\n            realPart = 0;\n            imagPart = 0;\n\n            for (int l = 0; l < Lq; l++) {\n                r_i = xi[u + k * Lq + l];\n                r_q = xq[u + k * Lq + l];\n                q_i = sr[l];\n                q_q = si[l] * (-1);\n\n                realPart += (r_i * q_i) - (r_q * q_q);\n                imagPart += (r_i * q_q) + (r_q * q_i);\n            }\n\n            uSum += (realPart * realPart) + (imagPart * imagPart);\n        }\n\n        L[u] = uSum;\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void cudaBYUSimplified(float *xi, float *xq, float *sr, float *si, int N, int Lq, float *L) {\n    int u = (blockIdx.x * blockDim.x) + threadIdx.x;\n\n    if (u >= N)\n        return;\n\n    float uSum = 0;\n    float r_i, r_q, q_i, q_q;\n    float realPart, imagPart;\n\n    for (int k = 0; k <= 7; k++) {\n        realPart = 0;\n        imagPart = 0;\n\n        for (int l = 0; l < Lq; l++) {\n            r_i = xi[u + k * Lq + l];\n            r_q = xq[u + k * Lq + l];\n            q_i = sr[l];\n            q_q = si[l] * (-1);\n\n            realPart += (r_i * q_i) - (r_q * q_q);\n            imagPart += (r_i * q_q) + (r_q * q_i);\n        }\n\n        uSum += (realPart * realPart) + (imagPart * imagPart);\n    }\n\n    L[u] = uSum;\n}\n\nint main() {\n    \n    int N = 1000;  \n    int Lq = 10;   \n    float *xi, *xq, *sr, *si, *L;  \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_xi, *d_xq, *d_sr, *d_si, *d_L;\n    cudaMalloc((void **)&d_xi, N * 8 * Lq * sizeof(float));\n    cudaMalloc((void **)&d_xq, N * 8 * Lq * sizeof(float));\n    cudaMalloc((void **)&d_sr, Lq * sizeof(float));\n    cudaMalloc((void **)&d_si, Lq * sizeof(float));\n    cudaMalloc((void **)&d_L, N * sizeof(float));\n\n    \n    cudaMemcpy(d_xi, xi, N * 8 * Lq * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_xq, xq, N * 8 * Lq * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_sr, sr, Lq * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_si, si, Lq * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    cudaBYUSimplified<<<blocksPerGrid, threadsPerBlock>>>(d_xi, d_xq, d_sr, d_si, N, Lq, d_L);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(L, d_L, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_xi);\n    cudaFree(d_xq);\n    cudaFree(d_sr);\n    cudaFree(d_si);\n    cudaFree(d_L);\n\n    return 0;\n}\n"
    },
    {
        "id": "165",
        "c_code": "#include <stdio.h>\n#include <assert.h>\n\nvoid shortcut_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float s1, float s2, float *out);\n\nint main() {\n    \n    \n    int batch = 2;\n    int w1 = 4, h1 = 4, c1 = 3;\n    int w2 = 2, h2 = 2, c2 = 2;\n    float s1 = 0.5, s2 = 0.7;\n\n    \n    float add[w1 * h1 * c1 * batch];\n    float out[w2 * h2 * c2 * batch];\n\n    \n    for (int i = 0; i < w1 * h1 * c1 * batch; i++) {\n        add[i] = i + 1;\n    }\n\n    \n    shortcut_cpu(batch, w1, h1, c1, add, w2, h2, c2, s1, s2, out);\n\n    \n    \n    for (int i = 0; i < w2 * h2 * c2 * batch; i++) {\n        printf(\"%f \", out[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n\nvoid shortcut_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float s1, float s2, float *out) {\n    int stride = w1 / w2;\n    int sample = w2 / w1;\n\n    assert(stride == h1 / h2);\n    assert(sample == h2 / h1);\n\n    if (stride < 1)\n        stride = 1;\n    if (sample < 1)\n        sample = 1;\n\n    int minw = (w1 < w2) ? w1 : w2;\n    int minh = (h1 < h2) ? h1 : h2;\n    int minc = (c1 < c2) ? c1 : c2;\n\n    int i, j, k, b;\n\n    for (b = 0; b < batch; ++b) {\n        for (k = 0; k < minc; ++k) {\n            for (j = 0; j < minh; ++j) {\n                for (i = 0; i < minw; ++i) {\n                    int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));\n                    int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));\n                    out[out_index] = s1 * out[out_index] + s2 * add[add_index];\n                }\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void shortcut_kernel(int size, int minw, int minh, int minc, int stride, int sample, int batch, int w1, int h1, int c1,\n                                float *add, int w2, int h2, int c2, float s1, float s2, float *out) {\n    int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n\n    if (id >= size)\n        return;\n\n    int i = id % minw;\n    id /= minw;\n    int j = id % minh;\n    id /= minh;\n    int k = id % minc;\n    id /= minc;\n    int b = id % batch;\n\n    int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));\n    int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));\n\n    out[out_index] = s1 * out[out_index] + s2 * add[add_index];\n}\n\nint main() {\n    \n    int size = 1000;  \n    int minw = 16, minh = 16, minc = 3, stride = 2, sample = 2, batch = 4;\n    int w1 = 8, h1 = 8, c1 = 3, w2 = 8, h2 = 8, c2 = 3;\n    float s1 = 0.5, s2 = 0.5;  \n    float *add, *out;          \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_add, *d_out;\n    cudaMalloc((void **)&d_add, minw * stride * sizeof(float));\n    cudaMalloc((void **)&d_out, size * sizeof(float));\n\n    \n    cudaMemcpy(d_add, add, minw * stride * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    shortcut_kernel<<<blocksPerGrid, threadsPerBlock>>>(size, minw, minh, minc, stride, sample, batch, w1, h1, c1, d_add,\n                                                        w2, h2, c2, s1, s2, d_out);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(out, d_out, size * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_add);\n    cudaFree(d_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "166",
        "c_code": "#include <stdio.h>\n\nvoid get_before_nms_data_cpu(const float *boxes, const float *scores, const int *labels, const int *index, float *boxes_out, float *scores_out, int *labels_out, int dims);\n\nint main() {\n    \n    \n    int dims = 5;\n\n    \n    float boxes[dims * 4];\n    float scores[dims];\n    int labels[dims];\n    int index[dims];\n    float boxes_out[dims * 4];\n    float scores_out[dims];\n    int labels_out[dims];\n\n    \n    for (int i = 0; i < dims * 4; i++) {\n        boxes[i] = i + 1;\n    }\n\n    for (int i = 0; i < dims; i++) {\n        scores[i] = i + 0.1;\n        labels[i] = i;\n        index[i] = i % 2; \n    }\n\n    \n    get_before_nms_data_cpu(boxes, scores, labels, index, boxes_out, scores_out, labels_out, dims);\n\n    \n    \n    for (int i = 0; i < dims; i++) {\n        printf(\"Box %d: (%f, %f, %f, %f) - Score: %f - Label: %d\\n\", i,\n               boxes_out[i * 4], boxes_out[i * 4 + 1], boxes_out[i * 4 + 2], boxes_out[i * 4 + 3],\n               scores_out[i], labels_out[i]);\n    }\n\n    return 0;\n}\n\nvoid get_before_nms_data_cpu(const float *boxes, const float *scores, const int *labels, const int *index, float *boxes_out, float *scores_out, int *labels_out, int dims) {\n    for (int tid = 0; tid < dims; tid++) {\n        if (index[tid] == 0) {\n            boxes_out[tid * 4 + 0] = -1;\n            boxes_out[tid * 4 + 1] = -1;\n            boxes_out[tid * 4 + 2] = -1;\n            boxes_out[tid * 4 + 3] = -1;\n            scores_out[tid] = -1;\n            labels_out[tid] = -1;\n        } else {\n            boxes_out[tid * 4 + 0] = boxes[tid * 4 + 0];\n            boxes_out[tid * 4 + 1] = boxes[tid * 4 + 1];\n            boxes_out[tid * 4 + 2] = boxes[tid * 4 + 2];\n            boxes_out[tid * 4 + 3] = boxes[tid * 4 + 3];\n            scores_out[tid] = scores[tid];\n            labels_out[tid] = labels[tid];\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void get_before_nms_data(const float *boxes, const float *scores, const int *labels, const int *index,\n                                     float *boxes_out, float *scores_out, int *labels_out, int dims) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid >= dims) {\n        return;\n    }\n\n    if (index[tid] == 0) {\n        boxes_out[tid * 4 + 0] = -1;\n        boxes_out[tid * 4 + 1] = -1;\n        boxes_out[tid * 4 + 2] = -1;\n        boxes_out[tid * 4 + 3] = -1;\n        scores_out[tid] = -1;\n        labels_out[tid] = -1;\n    } else {\n        boxes_out[tid * 4 + 0] = boxes[tid * 4 + 0];\n        boxes_out[tid * 4 + 1] = boxes[tid * 4 + 1];\n        boxes_out[tid * 4 + 2] = boxes[tid * 4 + 2];\n        boxes_out[tid * 4 + 3] = boxes[tid * 4 + 3];\n        scores_out[tid] = scores[tid];\n        labels_out[tid] = labels[tid];\n    }\n}\n\nint main() {\n    \n    int dims = 1000;  \n    float *boxes, *scores, *boxes_out, *scores_out;  \n    int *labels, *index, *labels_out;                \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_boxes, *d_scores, *d_boxes_out, *d_scores_out;\n    int *d_labels, *d_index, *d_labels_out;\n\n    cudaMalloc((void **)&d_boxes, dims * 4 * sizeof(float));\n    cudaMalloc((void **)&d_scores, dims * sizeof(float));\n    cudaMalloc((void **)&d_labels, dims * sizeof(int));\n    cudaMalloc((void **)&d_index, dims * sizeof(int));\n    cudaMalloc((void **)&d_boxes_out, dims * 4 * sizeof(float));\n    cudaMalloc((void **)&d_scores_out, dims * sizeof(float));\n    cudaMalloc((void **)&d_labels_out, dims * sizeof(int));\n\n    \n    cudaMemcpy(d_boxes, boxes, dims * 4 * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_scores, scores, dims * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_labels, labels, dims * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_index, index, dims * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    get_before_nms_data<<<blocksPerGrid, threadsPerBlock>>>(d_boxes, d_scores, d_labels, d_index,\n                                                            d_boxes_out, d_scores_out, d_labels_out, dims);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(boxes_out, d_boxes_out, dims * 4 * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaMemcpy(scores_out, d_scores_out, dims * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaMemcpy(labels_out, d_labels_out, dims * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_boxes);\n    cudaFree(d_scores);\n    cudaFree(d_labels);\n    cudaFree(d_index);\n    cudaFree(d_boxes_out);\n    cudaFree(d_scores_out);\n    cudaFree(d_labels_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "167",
        "c_code": "#include <stdio.h>\n\n\nfloat im2col_get_pixel(const float *data_im, int height, int width, int channels, int row, int col, int channel, int pad) {\n    \n    \n    return 1.0;\n}\n\nvoid im2col_cpu(float *data_im, int channels, int height, int width, int ksize, int stride, int pad, float *data_col);\n\nint main() {\n    \n    \n    int channels = 3;\n    int height = 4;\n    int width = 4;\n    int ksize = 2;\n    int stride = 2;\n    int pad = 0;\n\n    \n    float data_im[channels * height * width];\n    float data_col[channels * ksize * ksize * ((height - ksize + 2 * pad) / stride + 1) * ((width - ksize + 2 * pad) / stride + 1)];\n\n    \n    for (int i = 0; i < channels * height * width; i++) {\n        data_im[i] = i + 1;\n    }\n\n    \n    im2col_cpu(data_im, channels, height, width, ksize, stride, pad, data_col);\n\n    \n    \n    for (int i = 0; i < channels * ksize * ksize * ((height - ksize + 2 * pad) / stride + 1) * ((width - ksize + 2 * pad) / stride + 1); i++) {\n        printf(\"data_col[%d] = %f\\n\", i, data_col[i]);\n    }\n\n    return 0;\n}\n\nvoid im2col_cpu(float *data_im, int channels, int height, int width, int ksize, int stride, int pad, float *data_col) {\n    int c, h, w;\n    int height_col = (height + 2 * pad - ksize) / stride + 1;\n    int width_col = (width + 2 * pad - ksize) / stride + 1;\n    int channels_col = channels * ksize * ksize;\n\n    for (c = 0; c < channels_col; ++c) {\n        int w_offset = c % ksize;\n        int h_offset = (c / ksize) % ksize;\n        int c_im = c / ksize / ksize;\n\n        for (h = 0; h < height_col; ++h) {\n            for (w = 0; w < width_col; ++w) {\n                int im_row = h_offset + h * stride;\n                int im_col = w_offset + w * stride;\n                int col_index = (c * height_col + h) * width_col + w;\n                data_col[col_index] = im2col_get_pixel(data_im, height, width, channels, im_row, im_col, c_im, pad);\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void im2col_gpu_kernel(const int n, const float *data_im, const int height, const int width, const int ksize,\n                                  const int pad, const int stride, const int height_col, const int width_col,\n                                  float *data_col) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    for (; index < n; index += blockDim.x * gridDim.x) {\n        int w_out = index % width_col;\n        int h_index = index / width_col;\n        int h_out = h_index % height_col;\n        int channel_in = h_index / height_col;\n        int channel_out = channel_in * ksize * ksize;\n        int h_in = h_out * stride - pad;\n        int w_in = w_out * stride - pad;\n\n        float *data_col_ptr = data_col;\n        data_col_ptr += (channel_out * height_col + h_out) * width_col + w_out;\n\n        const float *data_im_ptr = data_im;\n        data_im_ptr += (channel_in * height + h_in) * width + w_in;\n\n        for (int i = 0; i < ksize; ++i) {\n            for (int j = 0; j < ksize; ++j) {\n                int h = h_in + i;\n                int w = w_in + j;\n\n                *data_col_ptr = (h >= 0 && w >= 0 && h < height && w < width) ? data_im_ptr[i * width + j] : 0;\n                data_col_ptr += height_col * width_col;\n            }\n        }\n    }\n}\n\nint main() {\n    \n    int n = 1000;       \n    int height = 32;    \n    int width = 32;     \n    int ksize = 3;      \n    int pad = 1;        \n    int stride = 1;     \n    int height_col = 30; \n    int width_col = 30;  \n    float *data_im, *data_col; \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_data_im, *d_data_col;\n    cudaMalloc((void **)&d_data_im, height * width * sizeof(float));\n    cudaMalloc((void **)&d_data_col, height_col * width_col * ksize * ksize * n * sizeof(float));\n\n    \n    cudaMemcpy(d_data_im, data_im, height * width * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    im2col_gpu_kernel<<<blocksPerGrid, threadsPerBlock>>>(n, d_data_im, height, width, ksize, pad, stride,\n                                                          height_col, width_col, d_data_col);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(data_col, d_data_col, height_col * width_col * ksize * ksize * n * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_data_im);\n    cudaFree(d_data_col);\n\n    return 0;\n}\n"
    },
    {
        "id": "168",
        "c_code": "#include <stdio.h>\n\nvoid getTopkNum(const float *inputScore, const int *inputIndex, float *outputScore, int *outputIndex, float threshold, const int dims, int *anchorIndex, int *classIndex, const int classNum, int batchSize, int totalScoreNum);\n\nint main() {\n    \n    \n    int dims = 10;\n    int batchSize = 3;\n    int totalScoreNum = 5;\n    int classNum = 2;\n    float threshold = 0.5;\n\n    \n    float inputScore[batchSize * totalScoreNum];\n    int inputIndex[batchSize * totalScoreNum];\n    float outputScore[batchSize * dims];\n    int outputIndex[batchSize * dims];\n    int anchorIndex[batchSize * dims];\n    int classIndex[batchSize * dims];\n\n    \n    for (int i = 0; i < batchSize * totalScoreNum; i++) {\n        inputScore[i] = 0.1 * i;\n        inputIndex[i] = i;\n    }\n\n    \n    getTopkNum(inputScore, inputIndex, outputScore, outputIndex, threshold, dims, anchorIndex, classIndex, classNum, batchSize, totalScoreNum);\n\n    \n    \n    for (int i = 0; i < batchSize * dims; i++) {\n        printf(\"outputScore[%d] = %f, outputIndex[%d] = %d, anchorIndex[%d] = %d, classIndex[%d] = %d\\n\", i, outputScore[i], i, outputIndex[i], i, anchorIndex[i], i, classIndex[i]);\n    }\n\n    return 0;\n}\n\nvoid getTopkNum(const float *inputScore, const int *inputIndex, float *outputScore, int *outputIndex, float threshold, const int dims, int *anchorIndex, int *classIndex, const int classNum, int batchSize, int totalScoreNum) {\n    for (int tid = 0; tid < dims; tid++) {\n        for (int i = 0; i < batchSize; i++) {\n            if (inputScore[i * totalScoreNum + tid] >= threshold) {\n                outputScore[i * dims + tid] = inputScore[i * totalScoreNum + tid];\n                outputIndex[i * dims + tid] = inputIndex[i * totalScoreNum + tid];\n                anchorIndex[i * dims + tid] = outputIndex[i * dims + tid] / classNum;\n                classIndex[i * dims + tid] = outputIndex[i * dims + tid] % classNum;\n            } else {\n                outputScore[i * dims + tid] = 0.0f;\n                outputIndex[i * dims + tid] = -1;\n                anchorIndex[i * dims + tid] = -1;\n                classIndex[i * dims + tid] = -1;\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void getTopkNum(const float *inputScore, const int *inputIndex, float *outputScore, int *outputIndex,\n                            float threshold, const int dims, int *anchorIndex, int *classIndex, const int classNum,\n                            int batchSize, int totalScoreNum) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid >= dims) {\n        return;\n    }\n\n    for (int i = 0; i < batchSize; i++) {\n        if (inputScore[i * totalScoreNum + tid] >= threshold) {\n            outputScore[i * dims + tid] = inputScore[i * totalScoreNum + tid];\n            outputIndex[i * dims + tid] = inputIndex[i * totalScoreNum + tid];\n            anchorIndex[i * dims + tid] = outputIndex[i * dims + tid] / classNum;\n            classIndex[i * dims + tid] = outputIndex[i * dims + tid] % classNum;\n        } else {\n            outputScore[i * dims + tid] = 0.0f;\n            outputIndex[i * dims + tid] = -1;\n            anchorIndex[i * dims + tid] = -1;\n            classIndex[i * dims + tid] = -1;\n        }\n    }\n}\n\nint main() {\n    \n    int dims = 1000;        \n    float threshold = 0.5;  \n    int classNum = 10;      \n    int batchSize = 4;      \n    int totalScoreNum = 100; \n    float *inputScore, *outputScore; \n    int *inputIndex, *outputIndex, *anchorIndex, *classIndex; \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_inputScore, *d_outputScore;\n    int *d_inputIndex, *d_outputIndex, *d_anchorIndex, *d_classIndex;\n\n    cudaMalloc((void **)&d_inputScore, batchSize * totalScoreNum * sizeof(float));\n    cudaMalloc((void **)&d_inputIndex, batchSize * totalScoreNum * sizeof(int));\n    cudaMalloc((void **)&d_outputScore, batchSize * dims * sizeof(float));\n    cudaMalloc((void **)&d_outputIndex, batchSize * dims * sizeof(int));\n    cudaMalloc((void **)&d_anchorIndex, batchSize * dims * sizeof(int));\n    cudaMalloc((void **)&d_classIndex, batchSize * dims * sizeof(int));\n\n    \n    cudaMemcpy(d_inputScore, inputScore, batchSize * totalScoreNum * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_inputIndex, inputIndex, batchSize * totalScoreNum * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    getTopkNum<<<blocksPerGrid, threadsPerBlock>>>(d_inputScore, d_inputIndex, d_outputScore, d_outputIndex, threshold,\n                                                   dims, d_anchorIndex, d_classIndex, classNum, batchSize,\n                                                   totalScoreNum);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(outputScore, d_outputScore, batchSize * dims * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaMemcpy(outputIndex, d_outputIndex, batchSize * dims * sizeof(int), cudaMemcpyDeviceToHost);\n    cudaMemcpy(anchorIndex, d_anchorIndex, batchSize * dims * sizeof(int), cudaMemcpyDeviceToHost);\n    cudaMemcpy(classIndex, d_classIndex, batchSize * dims * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_inputScore);\n    cudaFree(d_inputIndex);\n    cudaFree(d_outputScore);\n    cudaFree(d_outputIndex);\n    cudaFree(d_anchorIndex);\n    cudaFree(d_classIndex);\n\n    return 0;\n}\n"
    },
    {
        "id": "169",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid fractal_cpu(const int width, const int frames, unsigned char *const pic);\n\nint main() {\n    \n    const int width = 800;\n    const int frames = 30;\n    unsigned char pic[width * width * frames];\n\n    \n    fractal_cpu(width, frames, pic);\n\n    \n    for (int frame = 0; frame < frames; frame++) {\n        printf(\"Frame %d:\\n\", frame);\n        for (int row = 0; row < width; row++) {\n            for (int col = 0; col < width; col++) {\n                printf(\"%4d \", pic[frame * width * width + row * width + col]);\n            }\n            printf(\"\\n\");\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n\nvoid fractal_cpu(const int width, const int frames, unsigned char *const pic) {\n    for (int i = 0; i < width * width * frames; i++) {\n        const float Delta = 0.00304f;\n        const float xMid = -0.055846456f;\n        const float yMid = -0.668311119f;\n        const int frame = i / (width * width);\n        float delta = Delta * powf(0.975f, frame);\n        const int col = i % width;\n        const float xMin = xMid - delta;\n        const float yMin = yMid - delta;\n        const float dw = 2.0f * delta / width;\n        const int row = (i / width) % width;\n        const float cy = yMin + row * dw;\n        const float cx = xMin + col * dw;\n        float x = cx;\n        float y = cy;\n        float x2, y2;\n        int count = 256;\n\n        do {\n            x2 = x * x;\n            y2 = y * y;\n            y = 2.0 * x * y + cy;\n            x = x2 - y2 + cx;\n            count--;\n        } while ((count > 0) && ((x2 + y2) <= 5.0));\n\n        pic[frame * width * width + row * width + col] = (unsigned char)count;\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void fractal(const int width, const int frames, unsigned char *const pic) {\n    const long i = threadIdx.x + blockIdx.x * (long)blockDim.x;\n\n    if (i > width * width * frames) {\n        return;\n    }\n\n    const float Delta = 0.00304f;\n    const float xMid = -0.055846456f;\n    const float yMid = -0.668311119f;\n\n    const int frame = i / (width * width);\n    float delta = Delta * powf(0.975f, frame);\n\n    const int col = i % width;\n    const float xMin = xMid - delta;\n    const float yMin = yMid - delta;\n\n    const float dw = 2.0f * delta / width;\n    const int row = (i / width) % width;\n\n    const float cy = yMin + row * dw;\n    const float cx = xMin + col * dw;\n\n    float x = cx;\n    float y = cy;\n    float x2, y2;\n    int count = 256;\n\n    do {\n        x2 = x * x;\n        y2 = y * y;\n        y = 2.0 * x * y + cy;\n        x = x2 - y2 + cx;\n        count--;\n    } while ((count > 0) && ((x2 + y2) <= 5.0));\n\n    pic[frame * width * width + row * width + col] = (unsigned char)count;\n}\n\nint main() {\n    \n    int width = 800;  \n    int frames = 100; \n    unsigned char *pic; \n\n    \n    cudaSetDevice(0);\n\n    \n    unsigned char *d_pic;\n    cudaMalloc((void **)&d_pic, frames * width * width * sizeof(unsigned char));\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (width * width * frames + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    fractal<<<blocksPerGrid, threadsPerBlock>>>(width, frames, d_pic);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(pic, d_pic, frames * width * width * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_pic);\n\n    return 0;\n}\n"
    },
    {
        "id": "17",
        "c_code": "#include <stdio.h>\n\nvoid PSIfill_cpu(float *array, int conv_length, int n) {\n    for (int i = 0; i < n; i++) {\n        array[i] = array[i % conv_length];\n    }\n}\n\nint main() {\n    \n    int arraySize = 8;\n    float inputArray[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8};\n    int convLength = 3;\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", inputArray[i]);\n    }\n\n    \n    PSIfill_cpu(inputArray, convLength, arraySize);\n\n    printf(\"\\nPSI \u586b\u5145\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", inputArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void PSIfill(float* array, int conv_length, int maxThreads) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i >= maxThreads)\n        return;\n    \n    array[i] = array[i % conv_length];\n}\n\nint main() {\n    \n    int arraySize = 1000;\n    int convLength = 10;\n\n    \n    float* h_array = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_array[i] = static_cast<float>(i);\n    }\n\n    \n    float* d_array;\n    cudaMalloc((void**)&d_array, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_array, h_array, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    PSIfill<<<gridSize, blockSize>>>(d_array, convLength, arraySize);\n\n    \n    cudaMemcpy(h_array, d_array, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_array[i]);\n    }\n\n    \n    free(h_array);\n    cudaFree(d_array);\n\n    return 0;\n}\n"
    },
    {
        "id": "170",
        "c_code": "#include <stdio.h>\n\nvoid bit8Channels_cpu(unsigned char *out, unsigned char *in, int channel, int n);\n\nint main() {\n    \n    const int n = 5;\n    const int channels = 3;\n    unsigned char in[n * 8] = {0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,\n                               0xFE, 0xDC, 0xBA, 0x98, 0x76, 0x54, 0x32, 0x10,\n                               0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88,\n                               0x99, 0xAA, 0xBB, 0xCC, 0xDD, 0xEE, 0xFF, 0x00,\n                               0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77};\n\n    \n    unsigned char out[n * channels];\n\n    \n    for (int ch = 1; ch <= channels; ++ch) {\n        bit8Channels_cpu(out, in, ch, n);\n        printf(\"Output for Channel %d:\\n\", ch);\n        for (int i = 0; i < n; ++i) {\n            printf(\"%02X \", out[i * channels + ch - 1]);\n        }\n        printf(\"\\n\\n\");\n    }\n\n    return 0;\n}\n\nvoid bit8Channels_cpu(unsigned char *out, unsigned char *in, int channel, int n) {\n    for (int i = 0; i < n; ++i) {\n        int firstIndexToGrab = i * 8;\n        unsigned char bit0 = (in[firstIndexToGrab + 0] & 0x01) << 0;\n        unsigned char bit1 = (in[firstIndexToGrab + 1] & 0x01) << 1;\n        unsigned char bit2 = (in[firstIndexToGrab + 2] & 0x01) << 2;\n        unsigned char bit3 = (in[firstIndexToGrab + 3] & 0x01) << 3;\n        unsigned char bit4 = (in[firstIndexToGrab + 4] & 0x01) << 4;\n        unsigned char bit5 = (in[firstIndexToGrab + 5] & 0x01) << 5;\n        unsigned char bit6 = (in[firstIndexToGrab + 6] & 0x01) << 6;\n        unsigned char bit7 = (in[firstIndexToGrab + 7] & 0x01) << 7;\n        unsigned char output = bit7 | bit6 | bit5 | bit4 | bit3 | bit2 | bit1 | bit0;\n        int outputIndex = i * 8 + channel - 1;\n        out[outputIndex] = output;\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void bit8Channels(unsigned char *out, unsigned char *in, int channel, int n) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i >= n) {\n        return;\n    }\n\n    int firstIndexToGrab = i * 8;\n    unsigned char bit0 = (in[firstIndexToGrab + 0] & 0x01) << 0;\n    unsigned char bit1 = (in[firstIndexToGrab + 1] & 0x01) << 1;\n    unsigned char bit2 = (in[firstIndexToGrab + 2] & 0x01) << 2;\n    unsigned char bit3 = (in[firstIndexToGrab + 3] & 0x01) << 3;\n    unsigned char bit4 = (in[firstIndexToGrab + 4] & 0x01) << 4;\n    unsigned char bit5 = (in[firstIndexToGrab + 5] & 0x01) << 5;\n    unsigned char bit6 = (in[firstIndexToGrab + 6] & 0x01) << 6;\n    unsigned char bit7 = (in[firstIndexToGrab + 7] & 0x01) << 7;\n\n    unsigned char output = bit7 | bit6 | bit5 | bit4 | bit3 | bit2 | bit1 | bit0;\n\n    int outputIndex = i * 8 + channel - 1;\n    out[outputIndex] = output;\n}\n\nint main() {\n    \n    int n = 1000; \n    int channel = 3; \n    unsigned char *out, *in; \n\n    \n    cudaSetDevice(0);\n\n    \n    unsigned char *d_out, *d_in;\n    cudaMalloc((void **)&d_out, n * 8 * sizeof(unsigned char));\n    cudaMalloc((void **)&d_in, n * 8 * sizeof(unsigned char));\n\n    \n    cudaMemcpy(d_in, in, n * 8 * sizeof(unsigned char), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    bit8Channels<<<blocksPerGrid, threadsPerBlock>>>(d_out, d_in, channel, n);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(out, d_out, n * 8 * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_out);\n    cudaFree(d_in);\n\n    return 0;\n}\n"
    },
    {
        "id": "171",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid *Match(int num_points, float *P, float *Q, int q_points, int *idx, int start, int end);\n\nint main() {\n    \n    const int num_points = 3;\n    const int q_points = 3;\n    const int points_per_coordinate = 3;\n    const int array_size = num_points * points_per_coordinate;\n    const int start = 0;\n    const int end = num_points;\n\n    \n    float P[array_size] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f, 9.0f};\n    float Q[array_size] = {10.0f, 11.0f, 12.0f, 13.0f, 14.0f, 15.0f, 16.0f, 17.0f, 18.0f};\n    \n    \n    int idx[num_points];\n\n    \n    Match(num_points, P, Q, q_points, idx, start, end);\n\n    \n    printf(\"Matching Indices:\\n\");\n    for (int i = 0; i < num_points; ++i) {\n        printf(\"P[%d] matches with Q[%d]\\n\", i, idx[i]);\n    }\n\n    return 0;\n}\n\nvoid *Match(int num_points, float *P, float *Q, int q_points, int *idx, int start, int end) {\n    float dist;\n    float max_dist;\n\n    for (int i = start; i < end; i++) {\n        max_dist = 1000000000.0f;\n\n        for (int j = 0; j < num_points; j++) {\n            dist = (P[0 + i * 3] - Q[0 + j * 3]) * (P[0 + i * 3] - Q[0 + j * 3]) +\n                   (P[1 + i * 3] - Q[1 + j * 3]) * (P[1 + i * 3] - Q[1 + j * 3]) +\n                   (P[2 + i * 3] - Q[2 + j * 3]) * (P[2 + i * 3] - Q[2 + j * 3]);\n\n            if (dist < max_dist) {\n                max_dist = dist;\n                idx[i] = j;\n            }\n        }\n    }\n\n    return (void *)0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void Match(float *P, float *Q, int q_points, int *idx) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    float min = 100000;\n    float d;\n    float xp = P[0 + i * 3];\n    float yp = P[1 + i * 3];\n    float zp = P[2 + i * 3];\n    float xq, yq, zq;\n    int j;\n\n    for (j = 0; j < q_points / 2; j++) {\n        xq = Q[0 + j * 3];\n        yq = Q[1 + j * 3];\n        zq = Q[2 + j * 3];\n        d = (xp - xq) * (xp - xq) + (yp - yq) * (yp - yq) + (zp - zq) * (zp - zq);\n        if (d < min) {\n            min = d;\n            idx[i] = j;\n        }\n    }\n\n    for (j = j; j < q_points; j++) {\n        xq = Q[0 + j * 3];\n        yq = Q[1 + j * 3];\n        zq = Q[2 + j * 3];\n        d = (xp - xq) * (xp - xq) + (yp - yq) * (yp - yq) + (zp - zq) * (zp - zq);\n        if (d < min) {\n            min = d;\n            idx[i] = j;\n        }\n    }\n}\n\nint main() {\n    \n    int q_points = 100; \n    float *P, *Q; \n    int *idx; \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_P, *d_Q;\n    int *d_idx;\n\n    cudaMalloc((void **)&d_P, 3 * sizeof(float));\n    cudaMalloc((void **)&d_Q, 3 * q_points * sizeof(float));\n    cudaMalloc((void **)&d_idx, sizeof(int));\n\n    \n    cudaMemcpy(d_P, P, 3 * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_Q, Q, 3 * q_points * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = 1; \n\n    \n    Match<<<blocksPerGrid, threadsPerBlock>>>(d_P, d_Q, q_points, d_idx);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(idx, d_idx, sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_P);\n    cudaFree(d_Q);\n    cudaFree(d_idx);\n\n    return 0;\n}\n"
    },
    {
        "id": "172",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid col2im_add_pixel(float *data_im, int height, int width, int channels, int im_row, int im_col, int c_im, int pad, float val) {\n    \n}\n\nvoid col2im_cpu(float *data_col, int channels, int height, int width, int ksize, int stride, int pad, float *data_im);\n\nint main() {\n    \n    const int channels = 3;\n    const int height = 4;\n    const int width = 4;\n    const int ksize = 2;\n    const int stride = 2;\n    const int pad = 0;\n\n    \n    float data_col[channels * ksize * ksize * ((height + 2 * pad - ksize) / stride + 1) * ((width + 2 * pad - ksize) / stride + 1)];\n    \n    \n    float data_im[channels * height * width];\n\n    \n    col2im_cpu(data_col, channels, height, width, ksize, stride, pad, data_im);\n\n    \n\n    return 0;\n}\n\nvoid col2im_cpu(float *data_col, int channels, int height, int width, int ksize, int stride, int pad, float *data_im) {\n    int c, h, w;\n    int height_col = (height + 2 * pad - ksize) / stride + 1;\n    int width_col = (width + 2 * pad - ksize) / stride + 1;\n    int channels_col = channels * ksize * ksize;\n\n    for (c = 0; c < channels_col; ++c) {\n        int w_offset = c % ksize;\n        int h_offset = (c / ksize) % ksize;\n        int c_im = c / ksize / ksize;\n\n        for (h = 0; h < height_col; ++h) {\n            for (w = 0; w < width_col; ++w) {\n                int im_row = h_offset + h * stride;\n                int im_col = w_offset + w * stride;\n                int col_index = (c * height_col + h) * width_col + w;\n                float val = data_col[col_index];\n\n                \n                col2im_add_pixel(data_im, height, width, channels, im_row, im_col, c_im, pad, val);\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void col2im_gpu_kernel(const int n, const float *data_col, const int height, const int width, const int ksize,\n                                  const int pad, const int stride, const int height_col, const int width_col,\n                                  float *data_im) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    for (; index < n; index += blockDim.x * gridDim.x) {\n        float val = 0;\n        int w = index % width + pad;\n        int h = (index / width) % height + pad;\n        int c = index / (width * height);\n        int w_col_start = (w < ksize) ? 0 : (w - ksize) / stride + 1;\n        int w_col_end = min(w / stride + 1, width_col);\n        int h_col_start = (h < ksize) ? 0 : (h - ksize) / stride + 1;\n        int h_col_end = min(h / stride + 1, height_col);\n        int offset = (c * ksize * ksize + h * ksize + w) * height_col * width_col;\n        int coeff_h_col = (1 - stride * ksize * height_col) * width_col;\n        int coeff_w_col = (1 - stride * height_col * width_col);\n\n        for (int h_col = h_col_start; h_col < h_col_end; ++h_col) {\n            for (int w_col = w_col_start; w_col < w_col_end; ++w_col) {\n                val += data_col[offset + h_col * coeff_h_col + w_col * coeff_w_col];\n            }\n        }\n\n        data_im[index] += val;\n    }\n}\n\nint main() {\n    \n    int n = 1000; \n    int height = 64; \n    int width = 64; \n    int ksize = 3; \n    int pad = 1; \n    int stride = 1; \n    int height_col = (height + 2 * pad - ksize) / stride + 1;\n    int width_col = (width + 2 * pad - ksize) / stride + 1;\n\n    float *data_col; \n    float *data_im; \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_data_col, *d_data_im;\n\n    cudaMalloc((void **)&d_data_col, n * sizeof(float));\n    cudaMalloc((void **)&d_data_im, n * sizeof(float));\n\n    \n    cudaMemcpy(d_data_col, data_col, n * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    col2im_gpu_kernel<<<blocksPerGrid, threadsPerBlock>>>(n, d_data_col, height, width, ksize, pad, stride,\n                                                           height_col, width_col, d_data_im);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(data_im, d_data_im, n * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_data_col);\n    cudaFree(d_data_im);\n\n    return 0;\n}\n"
    },
    {
        "id": "173",
        "c_code": "#include <stdio.h>\n\nvoid yuv2rgb_kernel(int img_size, unsigned char *gpu_img_in_y, unsigned char *gpu_img_in_u, unsigned char *gpu_img_in_v, \n                    unsigned char *gpu_img_out_r, unsigned char *gpu_img_out_g, unsigned char *gpu_img_out_b);\n\nint main() {\n    \n    const int img_size = 10;\n    unsigned char gpu_img_in_y[img_size];\n    unsigned char gpu_img_in_u[img_size];\n    unsigned char gpu_img_in_v[img_size];\n    unsigned char gpu_img_out_r[img_size];\n    unsigned char gpu_img_out_g[img_size];\n    unsigned char gpu_img_out_b[img_size];\n\n    \n    for (int i = 0; i < img_size; ++i) {\n        gpu_img_in_y[i] = 100;\n        gpu_img_in_u[i] = 50;\n        gpu_img_in_v[i] = 150;\n    }\n\n    \n    yuv2rgb_kernel(img_size, gpu_img_in_y, gpu_img_in_u, gpu_img_in_v, gpu_img_out_r, gpu_img_out_g, gpu_img_out_b);\n\n    \n    for (int i = 0; i < img_size; ++i) {\n        printf(\"(%d, %d, %d) -> (%d, %d, %d)\\n\", gpu_img_in_y[i], gpu_img_in_u[i], gpu_img_in_v[i],\n               gpu_img_out_r[i], gpu_img_out_g[i], gpu_img_out_b[i]);\n    }\n\n    return 0;\n}\n\nvoid yuv2rgb_kernel(int img_size, unsigned char *gpu_img_in_y, unsigned char *gpu_img_in_u, unsigned char *gpu_img_in_v, \n                    unsigned char *gpu_img_out_r, unsigned char *gpu_img_out_g, unsigned char *gpu_img_out_b) {\n    int rt, gt, bt;\n    int rt2, gt2, bt2;\n    \n    for (int index = 0; index < img_size; index++) {\n        rt = (int)(gpu_img_in_y[index] + 1.402 * (gpu_img_in_v[index] - 128));\n        gt = (int)(gpu_img_in_y[index] - 0.344 * (gpu_img_in_u[index] - 128) - 0.714 * (gpu_img_in_v[index] - 128));\n        bt = (int)gpu_img_in_y[index] + 1.772 * (gpu_img_in_u[index] - 128);\n\n        rt2 = (rt > 255) ? 255 : rt;\n        gt2 = (gt > 255) ? 255 : gt;\n        bt2 = (bt > 255) ? 255 : bt;\n\n        gpu_img_out_r[index] = (rt2 < 0) ? 0 : rt2;\n        gpu_img_out_g[index] = (gt2 < 0) ? 0 : gt2;\n        gpu_img_out_b[index] = (bt2 < 0) ? 0 : bt2;\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void yuv2rgb_kernel(int img_size, unsigned char *gpu_img_in_y, unsigned char *gpu_img_in_u,\n                               unsigned char *gpu_img_in_v, unsigned char *gpu_img_out_r,\n                               unsigned char *gpu_img_out_g, unsigned char *gpu_img_out_b) {\n    int rt, gt, bt;\n    int rt2, gt2, bt2;\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (index < img_size) {\n        rt = (int)(gpu_img_in_y[index] + 1.402 * (gpu_img_in_v[index] - 128));\n        gt = (int)(gpu_img_in_y[index] - 0.344 * (gpu_img_in_u[index] - 128) - 0.714 * (gpu_img_in_v[index] - 128));\n        bt = (int)gpu_img_in_y[index] + 1.772 * (gpu_img_in_u[index] - 128);\n\n        rt2 = (rt > 255) ? 255 : rt;\n        gt2 = (gt > 255) ? 255 : gt;\n        bt2 = (bt > 255) ? 255 : bt;\n\n        gpu_img_out_r[index] = (rt2 < 0) ? 0 : rt2;\n        gpu_img_out_b[index] = (bt2 < 0) ? 0 : bt2;\n        gpu_img_out_g[index] = (gt2 < 0) ? 0 : gt2;\n    }\n}\n\nint main() {\n    \n    int img_size = 1000; \n\n    unsigned char *gpu_img_in_y, *gpu_img_in_u, *gpu_img_in_v;\n    unsigned char *gpu_img_out_r, *gpu_img_out_g, *gpu_img_out_b;\n\n    \n    \n\n    \n    cudaSetDevice(0);\n\n    \n    unsigned char *d_gpu_img_in_y, *d_gpu_img_in_u, *d_gpu_img_in_v;\n    unsigned char *d_gpu_img_out_r, *d_gpu_img_out_g, *d_gpu_img_out_b;\n\n    cudaMalloc((void **)&d_gpu_img_in_y, img_size * sizeof(unsigned char));\n    cudaMalloc((void **)&d_gpu_img_in_u, img_size * sizeof(unsigned char));\n    cudaMalloc((void **)&d_gpu_img_in_v, img_size * sizeof(unsigned char));\n    cudaMalloc((void **)&d_gpu_img_out_r, img_size * sizeof(unsigned char));\n    cudaMalloc((void **)&d_gpu_img_out_g, img_size * sizeof(unsigned char));\n    cudaMalloc((void **)&d_gpu_img_out_b, img_size * sizeof(unsigned char));\n\n    \n    cudaMemcpy(d_gpu_img_in_y, gpu_img_in_y, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_gpu_img_in_u, gpu_img_in_u, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_gpu_img_in_v, gpu_img_in_v, img_size * sizeof(unsigned char), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (img_size + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    yuv2rgb_kernel<<<blocksPerGrid, threadsPerBlock>>>(img_size, d_gpu_img_in_y, d_gpu_img_in_u, d_gpu_img_in_v,\n                                                      d_gpu_img_out_r, d_gpu_img_out_g, d_gpu_img_out_b);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(gpu_img_out_r, d_gpu_img_out_r, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n    cudaMemcpy(gpu_img_out_g, d_gpu_img_out_g, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n    cudaMemcpy(gpu_img_out_b, d_gpu_img_out_b, img_size * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_gpu_img_in_y);\n    cudaFree(d_gpu_img_in_u);\n    cudaFree(d_gpu_img_in_v);\n    cudaFree(d_gpu_img_out_r);\n    cudaFree(d_gpu_img_out_g);\n    cudaFree(d_gpu_img_out_b);\n\n    return 0;\n}\n"
    },
    {
        "id": "174",
        "c_code": "#include <stdio.h>\n\nvoid get_boxes_for_nms_cpu(const float *boxes_before_nms, const float *offset, float *boxes_for_nms, int dims);\n\nint main() {\n    \n    const int dims = 5;  \n    float boxes_before_nms[dims * 4];  \n    float offset[dims];  \n    float boxes_for_nms[dims * 4];\n\n    \n    for (int i = 0; i < dims * 4; ++i) {\n        boxes_before_nms[i] = i + 1;\n    }\n    for (int i = 0; i < dims; ++i) {\n        offset[i] = 0.5;\n    }\n\n    \n    get_boxes_for_nms_cpu(boxes_before_nms, offset, boxes_for_nms, dims);\n\n    \n    for (int i = 0; i < dims * 4; ++i) {\n        printf(\"%f \", boxes_for_nms[i]);\n    }\n\n    return 0;\n}\n\nvoid get_boxes_for_nms_cpu(const float *boxes_before_nms, const float *offset, float *boxes_for_nms, int dims) {\n    for (int tid = 0; tid < dims; tid++) {\n        if (boxes_before_nms[tid * 4] == -1 && boxes_before_nms[tid * 4 + 1] == -1 &&\n            boxes_before_nms[tid * 4 + 2] == -1 && boxes_before_nms[tid * 4 + 3] == -1) {\n            boxes_for_nms[tid * 4] = -1;\n            boxes_for_nms[tid * 4 + 1] = -1;\n            boxes_for_nms[tid * 4 + 2] = -1;\n            boxes_for_nms[tid * 4 + 3] = -1;\n        } else {\n            boxes_for_nms[tid * 4] = boxes_before_nms[tid * 4] + offset[tid];\n            boxes_for_nms[tid * 4 + 1] = boxes_before_nms[tid * 4 + 1] + offset[tid];\n            boxes_for_nms[tid * 4 + 2] = boxes_before_nms[tid * 4 + 2] + offset[tid];\n            boxes_for_nms[tid * 4 + 3] = boxes_before_nms[tid * 4 + 3] + offset[tid];\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void get_boxes_for_nms(const float *boxes_before_nms, const float *offset, float *boxes_for_nms, int dims) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid >= dims) {\n        return;\n    }\n\n    if (boxes_before_nms[tid * 4 + 0] == (-1) && boxes_before_nms[tid * 4 + 1] == (-1) &&\n        boxes_before_nms[tid * 4 + 2] == (-1) && boxes_before_nms[tid * 4 + 3] == (-1)) {\n        boxes_for_nms[tid * 4 + 0] = (-1);\n        boxes_for_nms[tid * 4 + 1] = (-1);\n        boxes_for_nms[tid * 4 + 2] = (-1);\n        boxes_for_nms[tid * 4 + 3] = (-1);\n    } else {\n        boxes_for_nms[tid * 4 + 0] = boxes_before_nms[tid * 4 + 0] + offset[tid];\n        boxes_for_nms[tid * 4 + 1] = boxes_before_nms[tid * 4 + 1] + offset[tid];\n        boxes_for_nms[tid * 4 + 2] = boxes_before_nms[tid * 4 + 2] + offset[tid];\n        boxes_for_nms[tid * 4 + 3] = boxes_before_nms[tid * 4 + 3] + offset[tid];\n    }\n}\n\nint main() {\n    \n    int dims = 1000; \n\n    float *boxes_before_nms, *offset, *boxes_for_nms;\n\n    \n    \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_boxes_before_nms, *d_offset, *d_boxes_for_nms;\n\n    cudaMalloc((void **)&d_boxes_before_nms, dims * 4 * sizeof(float));\n    cudaMalloc((void **)&d_offset, dims * sizeof(float));\n    cudaMalloc((void **)&d_boxes_for_nms, dims * 4 * sizeof(float));\n\n    \n    cudaMemcpy(d_boxes_before_nms, boxes_before_nms, dims * 4 * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_offset, offset, dims * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    get_boxes_for_nms<<<blocksPerGrid, threadsPerBlock>>>(d_boxes_before_nms, d_offset, d_boxes_for_nms, dims);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(boxes_for_nms, d_boxes_for_nms, dims * 4 * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_boxes_before_nms);\n    cudaFree(d_offset);\n    cudaFree(d_boxes_for_nms);\n\n    return 0;\n}\n"
    },
    {
        "id": "175",
        "c_code": "#include <stdio.h>\n#include <assert.h>\n\nvoid eltwise_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out, int sum, int mult);\n\nint main() {\n    \n    const int batch = 2;\n    const int w1 = 4, h1 = 3, c1 = 2;\n    const int w2 = 2, h2 = 3, c2 = 1;\n    const int sum = 1, mult = 0;\n\n    \n    float add[batch * w1 * h1 * c1];\n    float out[w2 * h2 * c2 * batch];\n\n    \n    for (int i = 0; i < batch * w1 * h1 * c1; ++i) {\n        add[i] = i + 1;\n    }\n\n    \n    eltwise_cpu(batch, w1, h1, c1, add, w2, h2, c2, out, sum, mult);\n\n    \n    for (int i = 0; i < w2 * h2 * c2 * batch; ++i) {\n        printf(\"%f \", out[i]);\n    }\n\n    return 0;\n}\n\nvoid eltwise_cpu(int batch, int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out, int sum, int mult) {\n    int stride = w1 / w2;\n    int sample = w2 / w1;\n    assert(stride == h1 / h2);\n    assert(sample == h2 / h1);\n\n    if (stride < 1) stride = 1;\n    if (sample < 1) sample = 1;\n\n    int minw = (w1 < w2) ? w1 : w2;\n    int minh = (h1 < h2) ? h1 : h2;\n    int minc = (c1 < c2) ? c1 : c2;\n\n    int i, j, k, b;\n\n    if (mult == 1) {\n        for (b = 0; b < batch; ++b) {\n            for (k = 0; k < minc; ++k) {\n                for (j = 0; j < minh; ++j) {\n                    for (i = 0; i < minw; ++i) {\n                        int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));\n                        int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));\n                        out[out_index] = out[out_index] * add[add_index];\n                    }\n                }\n            }\n        }\n    } else if (sum == 1) {\n        for (b = 0; b < batch; ++b) {\n            for (k = 0; k < minc; ++k) {\n                for (j = 0; j < minh; ++j) {\n                    for (i = 0; i < minw; ++i) {\n                        int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));\n                        int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));\n                        out[out_index] = out[out_index] + add[add_index];\n                    }\n                }\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void eltwise_kernel(int size, int minw, int minh, int minc, int stride, int sample, int batch,\n                               int w1, int h1, int c1, float *add, int w2, int h2, int c2, float *out,\n                               int sum, int mult) {\n    int id = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n\n    if (id >= size) {\n        return;\n    }\n\n    int i = id % minw;\n    id /= minw;\n    int j = id % minh;\n    id /= minh;\n    int k = id % minc;\n    id /= minc;\n    int b = id % batch;\n\n    int out_index = i * sample + w2 * (j * sample + h2 * (k + c2 * b));\n    int add_index = i * stride + w1 * (j * stride + h1 * (k + c1 * b));\n\n    if (mult == 1)\n        out[out_index] = out[out_index] * add[add_index];\n    else if (sum == 1)\n        out[out_index] = out[out_index] + add[add_index];\n}\n\nint main() {\n    \n    int size = 1000; \n\n    float *add, *out;\n\n    \n    \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_add, *d_out;\n\n    cudaMalloc((void **)&d_add, size * sizeof(float));\n    cudaMalloc((void **)&d_out, size * sizeof(float));\n\n    \n    cudaMemcpy(d_add, add, size * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    eltwise_kernel<<<blocksPerGrid, threadsPerBlock>>>(size,  d_add, );\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(out, d_out, size * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_add);\n    cudaFree(d_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "176",
        "c_code": "#include <stdio.h>\n\nvoid decode_cpu(const float *anchor, const float *locData, float *predictBox, int dims, float scaleClamp, int batchSize);\n\nint main() {\n    \n    const int dims = 4;\n    const int batchSize = 2;\n    const float scaleClamp = 5.0;\n\n    \n    float anchor[batchSize * dims * 4];\n    float locData[batchSize * dims * 4];\n    float predictBox[batchSize * dims * 4];\n\n    \n    for (int i = 0; i < batchSize * dims * 4; ++i) {\n        anchor[i] = i + 1;\n        locData[i] = (i + 1) * 0.1;\n    }\n\n    \n    decode_cpu(anchor, locData, predictBox, dims, scaleClamp, batchSize);\n\n    \n    for (int i = 0; i < batchSize * dims * 4; ++i) {\n        printf(\"%f \", predictBox[i]);\n    }\n\n    return 0;\n}\n\nvoid decode_cpu(const float *anchor, const float *locData, float *predictBox, int dims, float scaleClamp, int batchSize) {\n    for (int tid = 0; tid < dims; tid++) {\n        for (int i = 0; i < batchSize; i++) {\n            float anchorW = anchor[i * dims * 4 + tid * 4 + 2] - anchor[i * dims * 4 + tid * 4];\n            float anchorH = anchor[i * dims * 4 + tid * 4 + 3] - anchor[i * dims * 4 + tid * 4 + 1];\n            float anchorCx = anchor[i * dims * 4 + tid * 4] + 0.5 * anchorW;\n            float anchorCy = anchor[i * dims * 4 + tid * 4 + 1] + 0.5 * anchorH;\n\n            float dx = locData[i * dims * 4 + tid * 4];\n            float dy = locData[i * dims * 4 + tid * 4 + 1];\n            float dw = locData[i * dims * 4 + tid * 4 + 2];\n            float dh = locData[i * dims * 4 + tid * 4 + 3];\n\n            if (dw > scaleClamp) {\n                dw = scaleClamp;\n            }\n            if (dh > scaleClamp) {\n                dh = scaleClamp;\n            }\n\n            float preCx = dx * anchorW + anchorCx;\n            float preCy = dy * anchorH + anchorCy;\n            float preW = anchorW * 0.5;\n            float preH = anchorH * 0.5;\n\n            predictBox[i * dims * 4 + tid * 4] = preCx - 0.5 * preW;\n            predictBox[i * dims * 4 + tid * 4 + 1] = preCy - 0.5 * preH;\n            predictBox[i * dims * 4 + tid * 4 + 2] = preCx + 0.5 * preW;\n            predictBox[i * dims * 4 + tid * 4 + 3] = preCy + 0.5 * preH;\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void decode(const float *anchor, const float *locData, float *predictBox,\n                       int dims, float scaleClamp, int batchSize) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid >= dims) {\n        return;\n    }\n\n    for (int i = 0; i < batchSize; i++) {\n        float anchorW = anchor[i * dims * 4 + tid * 4 + 2] - anchor[i * dims * 4 + tid * 4];\n        float anchorH = anchor[i * dims * 4 + tid * 4 + 3] - anchor[i * dims * 4 + tid * 4 + 1];\n        float anchorCx = anchor[i * dims * 4 + tid * 4] + 0.5 * anchorW;\n        float anchorCy = anchor[i * dims * 4 + tid * 4 + 1] + 0.5 * anchorH;\n\n        float dx = locData[i * dims * 4 + tid * 4];\n        float dy = locData[i * dims * 4 + tid * 4 + 1];\n        float dw = locData[i * dims * 4 + tid * 4 + 2];\n        float dh = locData[i * dims * 4 + tid * 4 + 3];\n\n        if (dw > scaleClamp) {\n            dw = scaleClamp;\n        }\n\n        if (dh > scaleClamp) {\n            dh = scaleClamp;\n        }\n\n        float preCx = dx * anchorW + anchorCx;\n        float preCy = dy * anchorH + anchorCy;\n        float preW = anchorW * 0.5;\n        float preH = anchorH * 0.5;\n\n        predictBox[i * dims * 4 + tid * 4] = preCx - 0.5 * preW;\n        predictBox[i * dims * 4 + tid * 4 + 1] = preCy - 0.5 * preH;\n        predictBox[i * dims * 4 + tid * 4 + 2] = preCx + 0.5 * preW;\n        predictBox[i * dims * 4 + tid * 4 + 3] = preCy + 0.5 * preH;\n    }\n}\n\nint main() {\n    \n    int dims = 1000;  \n    float scaleClamp = 1.0;  \n    int batchSize = 1;  \n\n    float *anchor, *locData, *predictBox;\n\n    \n    \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_anchor, *d_locData, *d_predictBox;\n\n    cudaMalloc((void **)&d_anchor, dims * 4 * batchSize * sizeof(float));\n    cudaMalloc((void **)&d_locData, dims * 4 * batchSize * sizeof(float));\n    cudaMalloc((void **)&d_predictBox, dims * 4 * batchSize * sizeof(float));\n\n    \n    cudaMemcpy(d_anchor, anchor, dims * 4 * batchSize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_locData, locData, dims * 4 * batchSize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (dims + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    decode<<<blocksPerGrid, threadsPerBlock>>>(d_anchor, d_locData, d_predictBox, dims, scaleClamp, batchSize);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(predictBox, d_predictBox, dims * 4 * batchSize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_anchor);\n    cudaFree(d_locData);\n    cudaFree(d_predictBox);\n\n    return 0;\n}\n"
    },
    {
        "id": "177",
        "c_code": "#include <stdio.h>\n\nvoid nlf_down_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data);\n\nint main() {\n    \n    const int n = 2;\n    const int channel = 3;\n    const int height = 4;\n    const int width = 4;\n    const int wsize = 5;\n\n    \n    float filters[n / channel * wsize * height * width];\n    float top_data[n * height * width];\n\n    \n    for (int i = 0; i < n / channel * wsize * height * width; ++i) {\n        filters[i] = i + 1;\n    }\n\n    for (int i = 0; i < n * height * width; ++i) {\n        top_data[i] = i + 1;\n    }\n\n    \n    nlf_down_forward_cpu(n, filters, channel, height, width, wsize, top_data);\n\n    \n    for (int i = 0; i < n * height * width; ++i) {\n        printf(\"%f \", top_data[i]);\n    }\n\n    return 0;\n}\n\nvoid nlf_down_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data) {\n    for (int index = 0; index < n; index++) {\n        int step = height * width;\n        int base = index * step;\n        int fbase = index / channel * wsize * step;\n\n        for (int row = 0; row < height; row++) {\n            for (int col = 0; col < width; col++) {\n                float temp = 0;\n                int r, c, shift;\n\n                r = row;\n                c = col;\n                shift = 0 * step + row * width + col;\n                temp += top_data[base + r * width + c] * filters[fbase + shift];\n\n                r = row - 1;\n                c = col;\n                shift = 1 * step + row * width + col;\n                if (r >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];\n                else temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n                r = row - 1;\n                c = col - 1;\n                shift = 2 * step + row * width + col;\n                if (r >= 0 && c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];\n                else temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n                r = row - 1;\n                c = col + 1;\n                shift = 3 * step + row * width + col;\n                if (r >= 0 && c < width) temp += top_data[base + r * width + c] * filters[fbase + shift];\n                else temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n                r = row;\n                c = col - 1;\n                shift = 4 * step + row * width + col;\n                if (c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];\n                else temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n                top_data[base + row * width + col] = temp;\n            }\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void nlf_down_forward(const int n, const float *filters, const int channel,\n                                 const int height, const int width, const int wsize, float *top_data) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (index >= n) {\n        return;\n    }\n\n    int step = height * width;\n    int base = index * step;\n    int fbase = index / channel * wsize * step;\n\n    for (int row = 0; row < height; row++) {\n        for (int col = 0; col < width; col++) {\n            float temp = 0;\n            int r, c, shift;\n\n            \n            r = row;\n            c = col;\n            shift = 0 * step + row * width + col;\n            temp += top_data[base + r * width + c] * filters[fbase + shift];\n\n            \n            r = row - 1;\n            c = col;\n            shift = 1 * step + row * width + col;\n            if (r >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];\n            else temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n            \n            r = row - 1;\n            c = col - 1;\n            shift = 2 * step + row * width + col;\n            if (r >= 0 && c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];\n            else temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n            \n            r = row - 1;\n            c = col + 1;\n            shift = 3 * step + row * width + col;\n            if (r >= 0 && c < width) temp += top_data[base + r * width + c] * filters[fbase + shift];\n            else temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n            \n            r = row;\n            c = col - 1;\n            shift = 4 * step + row * width + col;\n            if (c >= 0) temp += top_data[base + r * width + c] * filters[fbase + shift];\n            else temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n            top_data[base + row * width + col] = temp;\n        }\n    }\n}\n\nint main() {\n    \n    int n = 1000;  \n    int channel = 3;  \n    int height = 64;  \n    int width = 64;  \n    int wsize = 5;  \n\n    float *filters, *top_data;\n\n    \n    \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_filters, *d_top_data;\n\n    cudaMalloc((void **)&d_filters, n / channel * wsize * height * width * sizeof(float));\n    cudaMalloc((void **)&d_top_data, n * height * width * sizeof(float));\n\n    \n    cudaMemcpy(d_filters, filters, n / channel * wsize * height * width * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_top_data, top_data, n * height * width * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    nlf_down_forward<<<blocksPerGrid, threadsPerBlock>>>(n, d_filters, channel, height, width, wsize, d_top_data);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(top_data, d_top_data, n * height * width * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_filters);\n    cudaFree(d_top_data);\n\n    return 0;\n}\n"
    },
    {
        "id": "178",
        "c_code": "#include <stdio.h>\n\nvoid nlf_filter_left_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff);\n\nint main() {\n    \n    const int n = 2;\n    const int channel = 3;\n    const int height = 4;\n    const int width = 4;\n    const int wsize = 5;\n\n    \n    float bottom_data[n * channel * height * width];\n    float top_data[n * channel * height * width];\n    float temp_diff[n * channel * height * width];\n    float filters_diff[n / height * height * wsize];\n\n    \n    for (int i = 0; i < n * channel * height * width; ++i) {\n        bottom_data[i] = i + 1;\n        top_data[i] = i + 1;\n        temp_diff[i] = i + 1;\n    }\n\n    for (int i = 0; i < n / height * height * wsize; ++i) {\n        filters_diff[i] = i + 1;\n    }\n\n    \n    nlf_filter_left_backward_cpu(n, bottom_data, top_data, temp_diff, channel, height, width, wsize, filters_diff);\n\n    \n    for (int i = 0; i < n / height * height * wsize; ++i) {\n        printf(\"%f \", filters_diff[i]);\n    }\n\n    return 0;\n}\n\nvoid nlf_filter_left_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff) {\n    for (int index = 0; index < n; index++) {\n        int step = height * width;\n        int base = index / step * step * channel + index % step;\n        int fbase = index / step * step * wsize + index % step;\n        int row = index % step / width;\n        int col = index % step % width;\n\n        for (int i = 0; i < channel; i++) {\n            filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n            if (col + 1 < width)\n                filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base + 1 + i * step];\n            else\n                filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n            if (col + 1 < width && row - 1 >= 0)\n                filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * top_data[base - width + 1 + i * step];\n            else\n                filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n            if (col + 1 < width && row + 1 < height)\n                filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * top_data[base + width + 1 + i * step];\n            else\n                filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n            if (row + 1 < height)\n                filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base + width + i * step];\n            else\n                filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void nlf_filter_left_backward(const int n, const float *bottom_data, const float *top_data,\n                                          const float *temp_diff, const int channel,\n                                          const int height, const int width, const int wsize,\n                                          float *filters_diff) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (index >= n) {\n        return;\n    }\n\n    int step = height * width;\n    int base = index / step * step * channel + index % step;\n    int fbase = index / step * step * wsize + index % step;\n    int row = index % step / width;\n    int col = index % step % width;\n\n    for (int i = 0; i < channel; i++) {\n        filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n        if (col + 1 < width)\n            filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base + 1 + i * step];\n        else\n            filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n        if (col + 1 < width && row - 1 >= 0)\n            filters_diff[fbase + 2 * step] +=\n                temp_diff[base + i * step] * top_data[base - width + 1 + i * step];\n        else\n            filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n        if (col + 1 < width && row + 1 < height)\n            filters_diff[fbase + 3 * step] +=\n                temp_diff[base + i * step] * top_data[base + width + 1 + i * step];\n        else\n            filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n        if (row + 1 < height)\n            filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base + width + i * step];\n        else\n            filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n    }\n}\n\nint main() {\n    \n    int n = 1000;  \n    int channel = 3;  \n    int height = 64;  \n    int width = 64;  \n    int wsize = 5;  \n\n    float *bottom_data, *top_data, *temp_diff, *filters_diff;\n\n    \n    \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_bottom_data, *d_top_data, *d_temp_diff, *d_filters_diff;\n\n    cudaMalloc((void **)&d_bottom_data, n * height * width * channel * sizeof(float));\n    cudaMalloc((void **)&d_top_data, n * height * width * channel * sizeof(float));\n    cudaMalloc((void **)&d_temp_diff, n * height * width * channel * sizeof(float));\n    cudaMalloc((void **)&d_filters_diff, n * height * width * wsize * sizeof(float));\n\n    \n    cudaMemcpy(d_bottom_data, bottom_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_top_data, top_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_temp_diff, temp_diff, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    nlf_filter_left_backward<<<blocksPerGrid, threadsPerBlock>>>(n, d_bottom_data, d_top_data, d_temp_diff,\n                                                                 channel, height, width, wsize, d_filters_diff);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(filters_diff, d_filters_diff, n * height * width * wsize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_bottom_data);\n    cudaFree(d_top_data);\n    cudaFree(d_temp_diff);\n    cudaFree(d_filters_diff);\n\n    return 0;\n}\n"
    },
    {
        "id": "179",
        "c_code": "#include <stdio.h>\n\nvoid nlf_filter_down_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff);\n\nint main() {\n    \n    const int n = 2;\n    const int channel = 3;\n    const int height = 4;\n    const int width = 4;\n    const int wsize = 5;\n\n    \n    float bottom_data[n * channel * height * width];\n    float top_data[n * channel * height * width];\n    float temp_diff[n * channel * height * width];\n    float filters_diff[n / height * height * wsize];\n\n    \n    for (int i = 0; i < n * channel * height * width; ++i) {\n        bottom_data[i] = i + 1;\n        top_data[i] = i + 1;\n        temp_diff[i] = i + 1;\n    }\n\n    for (int i = 0; i < n / height * height * wsize; ++i) {\n        filters_diff[i] = i + 1;\n    }\n\n    \n    nlf_filter_down_backward_cpu(n, bottom_data, top_data, temp_diff, channel, height, width, wsize, filters_diff);\n\n    \n    for (int i = 0; i < n / height * height * wsize; ++i) {\n        printf(\"%f \", filters_diff[i]);\n    }\n\n    return 0;\n}\n\nvoid nlf_filter_down_backward_cpu(const int n, const float *bottom_data, const float *top_data, const float *temp_diff, const int channel, const int height, const int width, const int wsize, float *filters_diff) {\n    for (int index = 0; index < n; index++) {\n        int step = height * width;\n        int base = index / step * step * channel + index % step;\n        int fbase = index / step * step * wsize + index % step;\n        int row = index % step / width;\n        int col = index % step % width;\n\n        for (int i = 0; i < channel; i++) {\n            filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n            if (row - 1 >= 0)\n                filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base - width + i * step];\n            else\n                filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n            if (row - 1 >= 0 && col - 1 >= 0)\n                filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * top_data[base - width - 1 + i * step];\n            else\n                filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n            if (row - 1 >= 0 && col + 1 < width)\n                filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * top_data[base - width + 1 + i * step];\n            else\n                filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n            if (col - 1 >= 0)\n                filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base - 1 + i * step];\n            else\n                filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n        }\n    }\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void nlf_filter_down_backward(const int n, const float *bottom_data, const float *top_data,\n                                         const float *temp_diff, const int channel,\n                                         const int height, const int width, const int wsize,\n                                         float *filters_diff) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (index >= n) {\n        return;\n    }\n\n    int step = height * width;\n    int base = index / step * step * channel + index % step;\n    int fbase = index / step * step * wsize + index % step;\n    int row = index % step / width;\n    int col = index % step % width;\n\n    for (int i = 0; i < channel; i++) {\n        filters_diff[fbase] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n        if (row - 1 >= 0)\n            filters_diff[fbase + step] += temp_diff[base + i * step] * top_data[base - width + i * step];\n        else\n            filters_diff[fbase + step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n        if (row - 1 >= 0 && col - 1 >= 0)\n            filters_diff[fbase + 2 * step] +=\n                temp_diff[base + i * step] * top_data[base - width - 1 + i * step];\n        else\n            filters_diff[fbase + 2 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n        if (row - 1 >= 0 && col + 1 < width)\n            filters_diff[fbase + 3 * step] +=\n                temp_diff[base + i * step] * top_data[base - width + 1 + i * step];\n        else\n            filters_diff[fbase + 3 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n\n        if (col - 1 >= 0)\n            filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * top_data[base - 1 + i * step];\n        else\n            filters_diff[fbase + 4 * step] += temp_diff[base + i * step] * bottom_data[base + i * step];\n    }\n}\n\nint main() {\n    \n    int n = 1000;  \n    int channel = 3;  \n    int height = 64;  \n    int width = 64;  \n    int wsize = 5;  \n\n    float *bottom_data, *top_data, *temp_diff, *filters_diff;\n\n    \n    \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_bottom_data, *d_top_data, *d_temp_diff, *d_filters_diff;\n\n    cudaMalloc((void **)&d_bottom_data, n * height * width * channel * sizeof(float));\n    cudaMalloc((void **)&d_top_data, n * height * width * channel * sizeof(float));\n    cudaMalloc((void **)&d_temp_diff, n * height * width * channel * sizeof(float));\n    cudaMalloc((void **)&d_filters_diff, n * height * width * wsize * sizeof(float));\n\n    \n    cudaMemcpy(d_bottom_data, bottom_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_top_data, top_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_temp_diff, temp_diff, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    nlf_filter_down_backward<<<blocksPerGrid, threadsPerBlock>>>(n, d_bottom_data, d_top_data, d_temp_diff,\n                                                                channel, height, width, wsize, d_filters_diff);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(filters_diff, d_filters_diff, n * height * width * wsize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_bottom_data);\n    cudaFree(d_top_data);\n    cudaFree\n"
    },
    {
        "id": "18",
        "c_code": "#include <stdio.h>\n\nvoid host_add(float *c, float *a, float *b, int n) {\n    for (int k = 0; k < n; k++) {\n        c[k] = a[k] + b[k];\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5};\n    float resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 A\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayA[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 B\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayB[i]);\n    }\n\n    \n    host_add(resultArray, arrayA, arrayB, arraySize);\n\n    printf(\"\\n\u76f8\u52a0\u540e\u7684\u6570\u7ec4 C\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void gpu_add(float* c, float* a, float* b, int n) {\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\n    if (j < n) {\n        c[j] = a[j] + b[j];\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float* h_a = (float*)malloc(arraySize * sizeof(float));\n    float* h_b = (float*)malloc(arraySize * sizeof(float));\n    float* h_c = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_a[i] = static_cast<float>(i);\n        h_b[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_a;\n    float* d_b;\n    float* d_c;\n    cudaMalloc((void**)&d_a, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_b, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_c, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    gpu_add<<<gridSize, blockSize>>>(d_c, d_a, d_b, arraySize);\n\n    \n    cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_c[i]);\n    }\n\n    \n    free(h_a);\n    free(h_b);\n    free(h_c);\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "180",
        "c_code": "#include <stdio.h>\n\nvoid nlf_up_forward_cpu(const int n, const float *filters, const int channel, const int height, const int width, const int wsize, float *top_data) {\n    for (int index = 0; index < n; index++) {\n        int step = height * width;\n        int base = index * step;\n        int fbase = index / channel * wsize * step;\n        \n        for (int row = height - 1; row >= 0; row--) {\n            for (int col = width - 1; col >= 0; col--) {\n                float temp = 0;\n                int r = row;\n                int c = col;\n\n                int shift = 0 * step + row * width + col;\n                temp += top_data[base + r * width + c] * filters[fbase + shift];\n\n                r = row + 1;\n                c = col;\n                shift = 1 * step + row * width + col;\n                if (r < height)\n                    temp += top_data[base + r * width + c] * filters[fbase + shift];\n                else\n                    temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n                r = row + 1;\n                c = col - 1;\n                shift = 2 * step + row * width + col;\n                if (r < height && c >= 0)\n                    temp += top_data[base + r * width + c] * filters[fbase + shift];\n                else\n                    temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n                r = row + 1;\n                c = col + 1;\n                shift = 3 * step + row * width + col;\n                if (r < height && c < width)\n                    temp += top_data[base + r * width + c] * filters[fbase + shift];\n                else\n                    temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n                r = row;\n                c = col + 1;\n                shift = 4 * step + row * width + col;\n                if (c < width)\n                    temp += top_data[base + r * width + c] * filters[fbase + shift];\n                else\n                    temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n                top_data[base + row * width + col] = temp;\n            }\n        }\n    }\n}\n\nint main() {\n    \n    int n = 1; \n    int channel = 3; \n    int height = 4; \n    int width = 4; \n    int wsize = 3; \n\n    \n    float filters[n * wsize * channel * height * width];\n    float top_data[n * channel * height * width];\n\n    \n    nlf_up_forward_cpu(n, filters, channel, height, width, wsize, top_data);\n\n    \n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void nlf_up_forward(const int n, const float *filters, const int channel,\n                               const int height, const int width, const int wsize,\n                               float *top_data) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (index >= n) {\n        return;\n    }\n\n    int step = height * width;\n    int base = index * step;\n    int fbase = index / channel * wsize * step;\n\n    for (int row = height - 1; row >= 0; row--) {\n        for (int col = width - 1; col >= 0; col--) {\n            float temp = 0;\n            int r = row;\n            int c = col;\n            int shift = 0 * step + row * width + col;\n            temp += top_data[base + r * width + c] * filters[fbase + shift];\n\n            r = row + 1;\n            c = col;\n            shift = 1 * step + row * width + col;\n            if (r < height)\n                temp += top_data[base + r * width + c] * filters[fbase + shift];\n            else\n                temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n            r = row + 1;\n            c = col - 1;\n            shift = 2 * step + row * width + col;\n            if (r < height && c >= 0)\n                temp += top_data[base + r * width + c] * filters[fbase + shift];\n            else\n                temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n            r = row + 1;\n            c = col + 1;\n            shift = 3 * step + row * width + col;\n            if (r < height && c < width)\n                temp += top_data[base + r * width + c] * filters[fbase + shift];\n            else\n                temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n            r = row;\n            c = col + 1;\n            shift = 4 * step + row * width + col;\n            if (c < width)\n                temp += top_data[base + r * width + c] * filters[fbase + shift];\n            else\n                temp += top_data[base + row * width + col] * filters[fbase + shift];\n\n            top_data[base + row * width + col] = temp;\n        }\n    }\n}\n\nint main() {\n    \n    int n = 1000;  \n    int channel = 3;  \n    int height = 64;  \n    int width = 64;  \n    int wsize = 5;  \n\n    float *filters, *top_data;\n\n    \n    \n\n    \n    cudaSetDevice(0);\n\n    \n    float *d_filters, *d_top_data;\n\n    cudaMalloc((void **)&d_filters, n * height * width * channel * wsize * sizeof(float));\n    cudaMalloc((void **)&d_top_data, n * height * width * channel * sizeof(float));\n\n    \n    cudaMemcpy(d_filters, filters, n * height * width * channel * wsize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_top_data, top_data, n * height * width * channel * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int threadsPerBlock = 256;\n    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    nlf_up_forward<<<blocksPerGrid, threadsPerBlock>>>(n, d_filters, channel, height, width, wsize, d_top_data);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    cudaMemcpy(top_data, d_top_data, n * height * width * channel * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_filters);\n    cudaFree(d_top_data);\n\n    return 0;\n}\n"
    },
    {
        "id": "19",
        "c_code": "#include <stdio.h>\n\nvoid mul_Scalar_matrix(float *a, float value, float *c, int N) {\n    for (int idx = 0; idx < N; idx++) {\n        c[idx] = a[idx] * value;\n    }\n}\n\nint main() {\n    \n    int arraySize = 6;\n    float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};\n    float scalarValue = 2.0;\n    float resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 A\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayA[i]);\n    }\n\n    \n    mul_Scalar_matrix(arrayA, scalarValue, resultArray, arraySize);\n\n    printf(\"\\n\u6807\u91cf\u4e58\u6cd5\u540e\u7684\u6570\u7ec4 C\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void mul_Scalar_matrix(float* a, float value, float* c, int N) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < N) {\n        c[idx] = a[idx] * value;\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float value = 2.0;\n\n    \n    float* h_a = (float*)malloc(arraySize * sizeof(float));\n    float* h_c = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_a[i] = static_cast<float>(i);\n    }\n\n    \n    float* d_a;\n    float* d_c;\n    cudaMalloc((void**)&d_a, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_c, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    mul_Scalar_matrix<<<gridSize, blockSize>>>(d_a, value, d_c, arraySize);\n\n    \n    cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_c[i]);\n    }\n\n    \n    free(h_a);\n    free(h_c);\n    cudaFree(d_a);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "2",
        "c_code": "#include <stdio.h>\n\nvoid get_ev(double *old_arr, double *new_arr, int size) {\n    int tid;\n    for (tid = 0; tid < size; tid++) {\n        new_arr[tid] = old_arr[tid];\n    }\n}\n\nint main() {\n    \n    double old_array[] = {1.5, 2.3, 3.7, 4.2, 5.8};\n    int numElements = sizeof(old_array) / sizeof(old_array[0]);\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%.2f \", old_array[i]);\n    }\n\n    \n    double new_array[numElements];\n\n    \n    get_ev(old_array, new_array, numElements);\n\n    printf(\"\\n\u590d\u5236\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%.2f \", new_array[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void get_ev(double* old_arr, double* new_arr) {\n    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    new_arr[tid] = old_arr[tid];\n}\n\nint main() {\n    \n    int numElements = 1000;\n\n    \n    double* h_old_arr = (double*)malloc(numElements * sizeof(double));\n    double* h_new_arr = (double*)malloc(numElements * sizeof(double));\n\n    \n    for (int i = 0; i < numElements; ++i) {\n        h_old_arr[i] = static_cast<double>(i);\n    }\n\n    \n    double* d_old_arr;\n    double* d_new_arr;\n    cudaMalloc((void**)&d_old_arr, numElements * sizeof(double));\n    cudaMalloc((void**)&d_new_arr, numElements * sizeof(double));\n\n    \n    cudaMemcpy(d_old_arr, h_old_arr, numElements * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (numElements + blockSize - 1) / blockSize;\n\n    \n    get_ev<<<gridSize, blockSize>>>(d_old_arr, d_new_arr);\n\n    \n    cudaMemcpy(h_new_arr, d_new_arr, numElements * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_new_arr[i]);\n    }\n\n    \n    free(h_old_arr);\n    free(h_new_arr);\n    cudaFree(d_old_arr);\n    cudaFree(d_new_arr);\n\n    return 0;\n}\n"
    },
    {
        "id": "20",
        "c_code": "#include <stdio.h>\n\nvoid initWith_cpu(float num, float *a, int N) {\n    for (int i = 0; i < N; i++) {\n        a[i] = num;\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float arrayA[arraySize];\n    float initialValue = 3.14;\n\n    \n    initWith_cpu(initialValue, arrayA, arraySize);\n\n    printf(\"\u521d\u59cb\u5316\u540e\u7684\u6570\u7ec4 A\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayA[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void initWith(float num, float* a, int N) {\n    int index = threadIdx.x + blockIdx.x * blockDim.x;\n    int stride = blockDim.x * gridDim.x;\n    for (int i = index; i < N; i += stride) {\n        a[i] = num;\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float initialValue = 3.0;\n\n    \n    float* h_a = (float*)malloc(arraySize * sizeof(float));\n\n    \n    float* d_a;\n    cudaMalloc((void**)&d_a, arraySize * sizeof(float));\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    initWith<<<gridSize, blockSize>>>(initialValue, d_a, arraySize);\n\n    \n    cudaMemcpy(h_a, d_a, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_a[i]);\n    }\n\n    \n    free(h_a);\n    cudaFree(d_a);\n\n    return 0;\n}\n"
    },
    {
        "id": "21",
        "c_code": "#include <stdio.h>\n\nvoid zeroIndices_cpu(long *vec_out, const long N) {\n    for (int idx = 0; idx < N; idx++) {\n        vec_out[idx] = vec_out[idx] - vec_out[0];\n    }\n}\n\nint main() {\n    \n    int arraySize = 6;\n    long vector[arraySize] = {10, 20, 30, 40, 50, 60};\n\n    printf(\"\u539f\u59cb\u5411\u91cf\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%ld \", vector[i]);\n    }\n\n    \n    zeroIndices_cpu(vector, arraySize);\n\n    printf(\"\\n\u96f6\u5316\u540e\u7684\u5411\u91cf\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%ld \", vector[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void zeroIndices(long* vec_out, const long N) {\n    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n    if (idx < N) {\n        vec_out[idx] = vec_out[idx] - vec_out[0];\n    }\n}\n\nint main() {\n    \n    long arraySize = 1000;\n\n    \n    long* h_vec_out = (long*)malloc(arraySize * sizeof(long));\n\n    \n    for (long i = 0; i < arraySize; ++i) {\n        h_vec_out[i] = static_cast<long>(i);\n    }\n\n    \n    long* d_vec_out;\n    cudaMalloc((void**)&d_vec_out, arraySize * sizeof(long));\n\n    \n    cudaMemcpy(d_vec_out, h_vec_out, arraySize * sizeof(long), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    zeroIndices<<<gridSize, blockSize>>>(d_vec_out, arraySize);\n\n    \n    cudaMemcpy(h_vec_out, d_vec_out, arraySize * sizeof(long), cudaMemcpyDeviceToHost);\n\n    \n    for (long i = 0; i < 10; ++i) {\n        printf(\"%ld \", h_vec_out[i]);\n    }\n\n    \n    free(h_vec_out);\n    cudaFree(d_vec_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "22",
        "c_code": "#include <stdio.h>\n\nvoid saxpy_serial(const int dim, float a, float *x, float *y) {\n    for (int i = 0; i < dim; i++) {\n        y[i] += a * x[i];\n    }\n}\n\nint main() {\n    \n    int vectorSize = 5;\n    float vectorX[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float vectorY[] = {0.5, 1.5, 2.5, 3.5, 4.5};\n    float alpha = 2.0;\n\n    printf(\"\u5411\u91cf X\uff1a\");\n    for (int i = 0; i < vectorSize; i++) {\n        printf(\"%.2f \", vectorX[i]);\n    }\n\n    printf(\"\\n\u5411\u91cf Y\uff1a\");\n    for (int i = 0; i < vectorSize; i++) {\n        printf(\"%.2f \", vectorY[i]);\n    }\n\n    \n    saxpy_serial(vectorSize, alpha, vectorX, vectorY);\n\n    printf(\"\\nSAXPY \u540e\u7684\u5411\u91cf Y\uff1a\");\n    for (int i = 0; i < vectorSize; i++) {\n        printf(\"%.2f \", vectorY[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void saxpy_gpu(const int dim, float a, float* x, float* y) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < dim) {\n        y[i] = a * x[i] + y[i];\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float a = 2.0;\n    float* h_x = (float*)malloc(arraySize * sizeof(float));\n    float* h_y = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_x[i] = static_cast<float>(i);\n        h_y[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_x;\n    float* d_y;\n    cudaMalloc((void**)&d_x, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_y, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_y, h_y, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    saxpy_gpu<<<gridSize, blockSize>>>(arraySize, a, d_x, d_y);\n\n    \n    cudaMemcpy(h_y, d_y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_y[i]);\n    }\n\n    \n    free(h_x);\n    free(h_y);\n    cudaFree(d_x);\n    cudaFree(d_y);\n\n    return 0;\n}\n"
    },
    {
        "id": "23",
        "c_code": "#include <stdio.h>\n\nvoid getCanBusData(int *canData, int size) {\n    for (int idx = 0; idx < size; idx++) {\n        canData[idx] += 1;\n    }\n}\n\nint main() {\n    \n    int dataSize = 8;\n    int canData[dataSize] = {10, 20, 30, 40, 50, 60, 70, 80};\n\n    printf(\"\u539f\u59cb CAN \u6570\u636e\uff1a\");\n    for (int i = 0; i < dataSize; i++) {\n        printf(\"%d \", canData[i]);\n    }\n\n    \n    getCanBusData(canData, dataSize);\n\n    printf(\"\\n\u5904\u7406\u540e\u7684 CAN \u6570\u636e\uff1a\");\n    for (int i = 0; i < dataSize; i++) {\n        printf(\"%d \", canData[i]);\n    }\n\n    return 0;\n}\n#include <stdio.h>\n\nvoid getCanBusData(int *canData, int size) {\n    for (int idx = 0; idx < size; idx++) {\n        canData[idx] += 1;\n    }\n}\n\nint main() {\n    \n    int dataSize = 8;\n    int canData[dataSize] = {10, 20, 30, 40, 50, 60, 70, 80};\n\n    printf(\"\u539f\u59cb CAN \u6570\u636e\uff1a\");\n    for (int i = 0; i < dataSize; i++) {\n        printf(\"%d \", canData[i]);\n    }\n\n    \n    getCanBusData(canData, dataSize);\n\n    printf(\"\\n\u5904\u7406\u540e\u7684 CAN \u6570\u636e\uff1a\");\n    for (int i = 0; i < dataSize; i++) {\n        printf(\"%d \", canData[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void getCanBusData(int* canData, int size, int nthreads, int nblocks) {\n    int i;\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    for (i = idx; i < size; i += nthreads * nblocks) {\n        atomicAdd(&canData[i], 1);\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    int* h_canData = (int*)malloc(arraySize * sizeof(int));\n\n    \n    int* d_canData;\n    cudaMalloc((void**)&d_canData, arraySize * sizeof(int));\n\n    \n    cudaMemcpy(d_canData, h_canData, arraySize * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    getCanBusData<<<gridSize, blockSize>>>(d_canData, arraySize, blockSize, gridSize);\n\n    \n    cudaMemcpy(h_canData, d_canData, arraySize * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%d \", h_canData[i]);\n    }\n\n    \n    free(h_canData);\n    cudaFree(d_canData);\n\n    return 0;\n}\n"
    },
    {
        "id": "24",
        "c_code": "#include <stdio.h>\n\nvoid sum_array_cpu(float *a, float *b, float *c, const int size) {\n    for (int i = 0; i < size; ++i) {\n        c[i] = a[i] + b[i];\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5};\n    float resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 A\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayA[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 B\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayB[i]);\n    }\n\n    \n    sum_array_cpu(arrayA, arrayB, resultArray, arraySize);\n\n    printf(\"\\n\u6570\u7ec4 C\uff08\u548c\uff09\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void sum_array_1Dgrid_1Dblock(float* a, float* b, float* c, int nx) {\n    int gid = blockDim.x * blockIdx.x + threadIdx.x;\n    if (gid < nx) {\n        c[gid] = a[gid] + b[gid];\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float* h_a = (float*)malloc(arraySize * sizeof(float));\n    float* h_b = (float*)malloc(arraySize * sizeof(float));\n    float* h_c = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_a[i] = static_cast<float>(i);\n        h_b[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_a;\n    float* d_b;\n    float* d_c;\n    cudaMalloc((void**)&d_a, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_b, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_c, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    sum_array_1Dgrid_1Dblock<<<gridSize, blockSize>>>(d_a, d_b, d_c, arraySize);\n\n    \n    cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_c[i]);\n    }\n\n    \n    free(h_a);\n    free(h_b);\n    free(h_c);\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "25",
        "c_code": "#include <stdio.h>\n\nvoid matColMeanDiv_cpu(double *buf, int m, int n, double *tmp) {\n    for (int i = 0; i < n; i++) {\n        buf[i] = tmp[i] / m;\n    }\n}\n\nint main() {\n    \n    int numRows = 3;\n    int numCols = 4;\n    double matrix[numRows][numCols] = {{1.0, 2.0, 3.0, 4.0},\n                                       {5.0, 6.0, 7.0, 8.0},\n                                       {9.0, 10.0, 11.0, 12.0}};\n    double resultArray[numCols];\n\n    \n    double colMeanArray[numCols] = {0.0};\n    for (int i = 0; i < numRows; i++) {\n        for (int j = 0; j < numCols; j++) {\n            colMeanArray[j] += matrix[i][j];\n        }\n    }\n    for (int j = 0; j < numCols; j++) {\n        colMeanArray[j] /= numRows;\n    }\n\n    printf(\"\u539f\u59cb\u77e9\u9635\uff1a\\n\");\n    for (int i = 0; i < numRows; i++) {\n        for (int j = 0; j < numCols; j++) {\n            printf(\"%.2f \", matrix[i][j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    matColMeanDiv_cpu(resultArray, numRows, numCols, colMeanArray);\n\n    printf(\"\\n\u6bcf\u5217\u5747\u503c\u9664\u6cd5\u540e\u7684\u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < numCols; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void matColMeanDiv(double* buf, int m, int n, double* tmp) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < n) {\n        buf[i] = tmp[i] / static_cast<double>(m);\n    }\n}\n\nint main() {\n    \n    int rows = 1000;\n    int cols = 10;\n\n    \n    double* h_buf = (double*)malloc(cols * sizeof(double));\n    double* h_tmp = (double*)malloc(cols * sizeof(double));\n\n    \n    for (int i = 0; i < cols; ++i) {\n        h_tmp[i] = static_cast<double>(i);\n    }\n\n    \n    double* d_buf;\n    double* d_tmp;\n    cudaMalloc((void**)&d_buf, cols * sizeof(double));\n    cudaMalloc((void**)&d_tmp, cols * sizeof(double));\n\n    \n    cudaMemcpy(d_tmp, h_tmp, cols * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (cols + blockSize - 1) / blockSize;\n\n    \n    matColMeanDiv<<<gridSize, blockSize>>>(d_buf, rows, cols, d_tmp);\n\n    \n    cudaMemcpy(h_buf, d_buf, cols * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_buf[i]);\n    }\n\n    \n    free(h_buf);\n    free(h_tmp);\n    cudaFree(d_buf);\n    cudaFree(d_tmp);\n\n    return 0;\n}\n"
    },
    {
        "id": "26",
        "c_code": "#include <stdio.h>\n\nvoid dmul_Scalar_matrix(double *a, double value, double *c, int N) {\n    for (int idx = 0; idx < N; idx++) {\n        c[idx] = a[idx] * value;\n    }\n}\n\nint main() {\n    \n    int arraySize = 6;\n    double arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};\n    double scalarValue = 2.0;\n    double resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 A\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayA[i]);\n    }\n\n    \n    dmul_Scalar_matrix(arrayA, scalarValue, resultArray, arraySize);\n\n    printf(\"\\n\u6807\u91cf\u4e58\u6cd5\u540e\u7684\u6570\u7ec4 C\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void dmul_Scalar_matrix(double* a, double value, double* c, int N) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < N) {\n        c[idx] = a[idx] * value;\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    double value = 2.0;\n\n    \n    double* h_a = (double*)malloc(arraySize * sizeof(double));\n    double* h_c = (double*)malloc(arraySize * sizeof(double));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_a[i] = static_cast<double>(i);\n    }\n\n    \n    double* d_a;\n    double* d_c;\n    cudaMalloc((void**)&d_a, arraySize * sizeof(double));\n    cudaMalloc((void**)&d_c, arraySize * sizeof(double));\n\n    \n    cudaMemcpy(d_a, h_a, arraySize * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    dmul_Scalar_matrix<<<gridSize, blockSize>>>(d_a, value, d_c, arraySize);\n\n    \n    cudaMemcpy(h_c, d_c, arraySize * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_c[i]);\n    }\n\n    \n    free(h_a);\n    free(h_c);\n    cudaFree(d_a);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "27",
        "c_code": "#include <stdio.h>\n\nvoid countRangesGlobal(int size, int *A, int *B) {\n    for (int i = 0; i < size; i++) {\n        int x = A[i] / 100;\n        B[x] += 1;\n    }\n}\n\nint main() {\n    \n    int arraySize = 8;\n    int inputArray[] = {50, 120, 250, 350, 420, 550, 670, 800};\n    int resultArray[9] = {0}; \n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", inputArray[i]);\n    }\n\n    \n    countRangesGlobal(arraySize, inputArray, resultArray);\n\n    printf(\"\\n\u7edf\u8ba1\u540e\u7684\u6570\u7ec4 B\uff1a\");\n    for (int i = 0; i < 9; i++) {\n        printf(\"%d \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void countRangesGlobal(int size, int* A, int* B) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i >= size)\n        return;\n\n    int x = A[i] / 100;\n    atomicAdd(&B[x], 1);\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    int* h_A = (int*)malloc(arraySize * sizeof(int));\n    int* h_B = (int*)malloc(arraySize * sizeof(int));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_A[i] = i;\n        h_B[i] = 0;\n    }\n\n    \n    int* d_A;\n    int* d_B;\n    cudaMalloc((void**)&d_A, arraySize * sizeof(int));\n    cudaMalloc((void**)&d_B, arraySize * sizeof(int));\n\n    \n    cudaMemcpy(d_A, h_A, arraySize * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, h_B, arraySize * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    countRangesGlobal<<<gridSize, blockSize>>>(arraySize, d_A, d_B);\n\n    \n    cudaMemcpy(h_B, d_B, arraySize * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%d \", h_B[i]);\n    }\n\n    \n    free(h_A);\n    free(h_B);\n    cudaFree(d_A);\n    cudaFree(d_B);\n\n    return 0;\n}\n"
    },
    {
        "id": "28",
        "c_code": "#include <stdio.h>\n\nvoid dsubtract_matrix(double *a, double *b, double *c, int N) {\n    for (int idx = 0; idx < N; idx++) {\n        c[idx] = a[idx] - b[idx];\n    }\n}\n\nint main() {\n    \n    int arraySize = 6;\n    double arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};\n    double arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5, 5.5};\n    double resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 A\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayA[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 B\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayB[i]);\n    }\n\n    \n    dsubtract_matrix(arrayA, arrayB, resultArray, arraySize);\n\n    printf(\"\\n\u6570\u7ec4 C\uff08\u5dee\uff09\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void dsubtract_matrix(double* a, double* b, double* c, int N) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < N) {\n        c[idx] = a[idx] - b[idx];\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    double* h_a = (double*)malloc(arraySize * sizeof(double));\n    double* h_b = (double*)malloc(arraySize * sizeof(double));\n    double* h_c = (double*)malloc(arraySize * sizeof(double));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_a[i] = static_cast<double>(i);\n        h_b[i] = static_cast<double>(2 * i);\n    }\n\n    \n    double* d_a;\n    double* d_b;\n    double* d_c;\n    cudaMalloc((void**)&d_a, arraySize * sizeof(double));\n    cudaMalloc((void**)&d_b, arraySize * sizeof(double));\n    cudaMalloc((void**)&d_c, arraySize * sizeof(double));\n\n    \n    cudaMemcpy(d_a, h_a, arraySize * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, arraySize * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    dsubtract_matrix<<<gridSize, blockSize>>>(d_a, d_b, d_c, arraySize);\n\n    \n    cudaMemcpy(h_c, d_c, arraySize * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_c[i]);\n    }\n\n    \n    free(h_a);\n    free(h_b);\n    free(h_c);\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "29",
        "c_code": "#include <stdio.h>\n\nvoid add_arrays(int n, float *x, float *y, float *z) {\n    for (int i = 0; i < n; i++) {\n        z[i] = x[i] + y[i];\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float arrayY[] = {0.5, 1.5, 2.5, 3.5, 4.5};\n    float resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 X\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayX[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 Y\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayY[i]);\n    }\n\n    \n    add_arrays(arraySize, arrayX, arrayY, resultArray);\n\n    printf(\"\\n\u6570\u7ec4 Z\uff08\u548c\uff09\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void add_arrays(int n, float* x, float* y, float* z) {\n    int i = blockDim.x * blockIdx.x + threadIdx.x;\n    if (i < n) {\n        z[i] = x[i] + y[i];\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float* h_x = (float*)malloc(arraySize * sizeof(float));\n    float* h_y = (float*)malloc(arraySize * sizeof(float));\n    float* h_z = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_x[i] = static_cast<float>(i);\n        h_y[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_x;\n    float* d_y;\n    float* d_z;\n    cudaMalloc((void**)&d_x, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_y, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_z, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_y, h_y, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    add_arrays<<<gridSize, blockSize>>>(arraySize, d_x, d_y, d_z);\n\n    \n    cudaMemcpy(h_z, d_z, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_z[i]);\n    }\n\n    \n    free(h_x);\n    free(h_y);\n    free(h_z);\n    cudaFree(d_x);\n    cudaFree(d_y);\n    cudaFree(d_z);\n\n    return 0;\n}\n"
    },
    {
        "id": "3",
        "c_code": "#include <stdio.h>\n\nvoid square(int *array, int arrayCount) {\n    for (int idx = 0; idx < arrayCount; idx++) {\n        array[idx] *= array[idx];\n    }\n}\n\nint main() {\n    \n    int array[] = {2, 4, 6, 8, 10};\n    int numElements = sizeof(array) / sizeof(array[0]);\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%d \", array[i]);\n    }\n\n    \n    square(array, numElements);\n\n    printf(\"\\n\u5e73\u65b9\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%d \", array[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void square(int* array, int arrayCount) {\n    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n    if (idx < arrayCount) {\n        array[idx] *= array[idx];\n    }\n}\n\nint main() {\n    \n    int arrayCount = 1000;\n\n    \n    int* h_array = (int*)malloc(arrayCount * sizeof(int));\n\n    \n    for (int i = 0; i < arrayCount; ++i) {\n        h_array[i] = i;\n    }\n\n    \n    int* d_array;\n    cudaMalloc((void**)&d_array, arrayCount * sizeof(int));\n\n    \n    cudaMemcpy(d_array, h_array, arrayCount * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arrayCount + blockSize - 1) / blockSize;\n\n    \n    square<<<gridSize, blockSize>>>(d_array, arrayCount);\n\n    \n    cudaMemcpy(h_array, d_array, arrayCount * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%d \", h_array[i]);\n    }\n\n    \n    free(h_array);\n    cudaFree(d_array);\n\n    return 0;\n}\n"
    },
    {
        "id": "30",
        "c_code": "#include <stdio.h>\n\nvoid sum_arrays_cpu(int *a, int *b, int *c, int size) {\n    for (int i = 0; i < size; i++) {\n        c[i] = a[i] + b[i];\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    int arrayA[] = {1, 2, 3, 4, 5};\n    int arrayB[] = {10, 20, 30, 40, 50};\n    int resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 A\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", arrayA[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 B\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", arrayB[i]);\n    }\n\n    \n    sum_arrays_cpu(arrayA, arrayB, resultArray, arraySize);\n\n    printf(\"\\n\u6570\u7ec4 C\uff08\u548c\uff09\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void sum_arrays_gpu(int* a, int* b, int* c, int size) {\n    int index = blockDim.x * blockIdx.x + threadIdx.x;\n    if (index < size) {\n        c[index] = a[index] + b[index];\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    int* h_a = (int*)malloc(arraySize * sizeof(int));\n    int* h_b = (int*)malloc(arraySize * sizeof(int));\n    int* h_c = (int*)malloc(arraySize * sizeof(int));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_a[i] = i;\n        h_b[i] = 2 * i;\n    }\n\n    \n    int* d_a;\n    int* d_b;\n    int* d_c;\n    cudaMalloc((void**)&d_a, arraySize * sizeof(int));\n    cudaMalloc((void**)&d_b, arraySize * sizeof(int));\n    cudaMalloc((void**)&d_c, arraySize * sizeof(int));\n\n    \n    cudaMemcpy(d_a, h_a, arraySize * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, arraySize * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    sum_arrays_gpu<<<gridSize, blockSize>>>(d_a, d_b, d_c, arraySize);\n\n    \n    cudaMemcpy(h_c, d_c, arraySize * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%d \", h_c[i]);\n    }\n\n    \n    free(h_a);\n    free(h_b);\n    free(h_c);\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "31",
        "c_code": "#include <stdio.h>\n\nvoid iKernel_cpu(float *A, float *B, float *C, const int N) {\n    for (int i = 0; i < N; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n\nint main() {\n    \n    int arraySize = 6;\n    float arrayA[] = {1.1, 2.2, 3.3, 4.4, 5.5, 6.6};\n    float arrayB[] = {0.5, 1.5, 2.5, 3.5, 4.5, 5.5};\n    float resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 A\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayA[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 B\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayB[i]);\n    }\n\n    \n    iKernel_cpu(arrayA, arrayB, resultArray, arraySize);\n\n    printf(\"\\n\u6570\u7ec4 C\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void iKernel(float* A, float* B, float* C, const int N) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N) {\n        C[i] = A[i] + B[i];\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    float* h_A = (float*)malloc(arraySize * sizeof(float));\n    float* h_B = (float*)malloc(arraySize * sizeof(float));\n    float* h_C = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_A[i] = static_cast<float>(i);\n        h_B[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_A;\n    float* d_B;\n    float* d_C;\n    cudaMalloc((void**)&d_A, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_B, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_C, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_A, h_A, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, h_B, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    iKernel<<<gridSize, blockSize>>>(d_A, d_B, d_C, arraySize);\n\n    \n    cudaMemcpy(h_C, d_C, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_C[i]);\n    }\n\n    \n    free(h_A);\n    free(h_B);\n    free(h_C);\n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n\n    return 0;\n}\n"
    },
    {
        "id": "32",
        "c_code": "#include <stdio.h>\n\nvoid multiplyIntValues(int *destination, int *vector, int value, unsigned int end) {\n    for (unsigned int i = 0; i < end; i++) {\n        destination[i] = vector[i] * value;\n    }\n}\n\nint main() {\n    \n    unsigned int arraySize = 5;\n    int vector[] = {1, 2, 3, 4, 5};\n    int resultArray[arraySize];\n    int multiplier = 3;\n\n    printf(\"\u539f\u59cb\u5411\u91cf\uff1a\");\n    for (unsigned int i = 0; i < arraySize; i++) {\n        printf(\"%d \", vector[i]);\n    }\n\n    \n    multiplyIntValues(resultArray, vector, multiplier, arraySize);\n\n    printf(\"\\n\u4e58\u6cd5\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (unsigned int i = 0; i < arraySize; i++) {\n        printf(\"%d \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void intMultiply(int* result, const int* val1, const int val2, const unsigned int size) {\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    if (i < size) {\n        result[i] = val1[i] * val2;\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    int* h_result = (int*)malloc(arraySize * sizeof(int));\n    int* h_val1 = (int*)malloc(arraySize * sizeof(int));\n    const int h_val2 = 2;  \n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_val1[i] = i;\n    }\n\n    \n    int* d_result;\n    int* d_val1;\n    cudaMalloc((void**)&d_result, arraySize * sizeof(int));\n    cudaMalloc((void**)&d_val1, arraySize * sizeof(int));\n\n    \n    cudaMemcpy(d_val1, h_val1, arraySize * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    intMultiply<<<gridSize, blockSize>>>(d_result, d_val1, h_val2, arraySize);\n\n    \n    cudaMemcpy(h_result, d_result, arraySize * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%d \", h_result[i]);\n    }\n\n    \n    free(h_result);\n    free(h_val1);\n    cudaFree(d_result);\n    cudaFree(d_val1);\n\n    return 0;\n}\n"
    },
    {
        "id": "33",
        "c_code": "#include <stdio.h>\n\nvoid doubleArrayScalarDivide_cpu(double *d_in, int *d_out, int length, double scalar) {\n    for (int idx = 0; idx < length; idx++) {\n        d_out[idx] = d_in[idx] / scalar;\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    double doubleArray[] = {10.0, 20.0, 30.0, 40.0, 50.0};\n    int resultArray[arraySize];\n    double scalar = 2.0;\n\n    printf(\"\u539f\u59cb\u53cc\u7cbe\u5ea6\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", doubleArray[i]);\n    }\n\n    \n    doubleArrayScalarDivide_cpu(doubleArray, resultArray, arraySize, scalar);\n\n    printf(\"\\n\u9664\u6cd5\u540e\u7684\u6574\u6570\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void doubleArrayScalarDivideKernel(double* d_in, int* d_out, int length, double scalar) {\n    int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n    if (tid < length) {\n        d_out[tid] = static_cast<int>(d_in[tid] / scalar);\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    double* h_d_in = (double*)malloc(arraySize * sizeof(double));\n    int* h_d_out = (int*)malloc(arraySize * sizeof(int));\n    const double scalar = 2.0;  \n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_d_in[i] = static_cast<double>(i);\n    }\n\n    \n    double* d_d_in;\n    int* d_d_out;\n    cudaMalloc((void**)&d_d_in, arraySize * sizeof(double));\n    cudaMalloc((void**)&d_d_out, arraySize * sizeof(int));\n\n    \n    cudaMemcpy(d_d_in, h_d_in, arraySize * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    doubleArrayScalarDivideKernel<<<gridSize, blockSize>>>(d_d_in, d_d_out, arraySize, scalar);\n\n    \n    cudaMemcpy(h_d_out, d_d_out, arraySize * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%d \", h_d_out[i]);\n    }\n\n    \n    free(h_d_in);\n    free(h_d_out);\n    cudaFree(d_d_in);\n    cudaFree(d_d_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "34",
        "c_code": "#include <stdio.h>\n\nvoid add(const int x, const int y, const int WIDTH, int *c, const int *a, const int *b) {\n    int i = y * WIDTH + x;\n    c[i] = a[i] + b[i];\n}\n\nint main() {\n    \n    const int WIDTH = 3;\n    const int HEIGHT = 2;\n    const int arraySize = WIDTH * HEIGHT;\n\n    int arrayA[arraySize] = {1, 2, 3, 4, 5, 6};\n    int arrayB[arraySize] = {7, 8, 9, 10, 11, 12};\n    int resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 A\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", arrayA[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 B\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", arrayB[i]);\n    }\n\n    \n    add(1, 1, WIDTH, resultArray, arrayA, arrayB);\n\n    printf(\"\\n\u6570\u7ec4 C\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n#define N 16\n\n__global__ void addKernel(int* c, const int* a, const int* b) {\n    int x = threadIdx.x;\n    int y = threadIdx.y;\n    int i = y * blockDim.x + x;\n    c[i] = a[i] + b[i];\n}\n\nint main() {\n    \n    int a[N][N], b[N][N], c[N][N];\n\n    \n    int* d_a;\n    int* d_b;\n    int* d_c;\n    cudaMalloc((void**)&d_a, N * N * sizeof(int));\n    cudaMalloc((void**)&d_b, N * N * sizeof(int));\n    cudaMalloc((void**)&d_c, N * N * sizeof(int));\n\n    \n    for (int i = 0; i < N * N; ++i) {\n        a[i / N][i % N] = i;\n        b[i / N][i % N] = 2 * i;\n    }\n\n    \n    cudaMemcpy(d_a, a, N * N * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, b, N * N * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(N, N);\n    dim3 gridSize(1, 1);\n\n    \n    addKernel<<<gridSize, blockSize>>>(d_c, d_a, d_b);\n\n    \n    cudaMemcpy(c, d_c, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            printf(\"%d \", c[i][j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "35",
        "c_code": "#include <stdio.h>\n\nvoid activate_array_leaky_cpu(float *x, int n) {\n    for (int index = 0; index < n; index++) {\n        float val = x[index];\n        x[index] = (val > 0) ? val : val / 10;\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float inputArray[] = {2.0, -3.0, 4.0, -5.0, 6.0};\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", inputArray[i]);\n    }\n\n    \n    activate_array_leaky_cpu(inputArray, arraySize);\n\n    printf(\"\\n\u6fc0\u6d3b\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", inputArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void activate_array_leaky_kernel(float* x, int n) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n    if (index < n) {\n        float val = x[index];\n        x[index] = (val > 0) ? val : val / 10;\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    float* h_x = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_x[i] = static_cast<float>(i - 500);  \n    }\n\n    \n    float* d_x;\n    cudaMalloc((void**)&d_x, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    activate_array_leaky_kernel<<<gridSize, blockSize>>>(d_x, arraySize);\n\n    \n    cudaMemcpy(h_x, d_x, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_x[i]);\n    }\n\n    \n    free(h_x);\n    cudaFree(d_x);\n\n    return 0;\n}\n"
    },
    {
        "id": "36",
        "c_code": "#include <stdio.h>\n\nvoid logistic_cpu(unsigned int n, float a, float *x, float *z) {\n    for (unsigned int myId = 0; myId < n; myId++) {\n        z[myId] = a * x[myId] * (1 - x[myId]);\n    }\n}\n\nint main() {\n    \n    unsigned int arraySize = 5;\n    float inputArray[] = {0.2, 0.5, 0.7, 0.3, 0.8};\n    float resultArray[arraySize];\n    float a = 2.0;\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (unsigned int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", inputArray[i]);\n    }\n\n    \n    logistic_cpu(arraySize, a, inputArray, resultArray);\n\n    printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (unsigned int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void logistic(unsigned int n, float a, float* x, float* z) {\n    unsigned int myId = blockDim.x * blockIdx.x + threadIdx.x;\n    if (myId < n) {\n        z[myId] = a * x[myId] * (1 - x[myId]);\n    }\n}\n\nint main() {\n    \n    const unsigned int arraySize = 1000;\n\n    \n    float* h_x = (float*)malloc(arraySize * sizeof(float));\n    float* h_z = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (unsigned int i = 0; i < arraySize; ++i) {\n        h_x[i] = static_cast<float>(i) / arraySize;  \n    }\n\n    \n    float* d_x;\n    float* d_z;\n    cudaMalloc((void**)&d_x, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_z, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    logistic<<<gridSize, blockSize>>>(arraySize, 2.0f, d_x, d_z);\n\n    \n    cudaMemcpy(h_z, d_z, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (unsigned int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_z[i]);\n    }\n\n    \n    free(h_x);\n    free(h_z);\n    cudaFree(d_x);\n    cudaFree(d_z);\n\n    return 0;\n}\n"
    },
    {
        "id": "37",
        "c_code": "#include <stdio.h>\n\nvoid add_kernel(float *inputleft, float *inputright, float *output, int count) {\n    for (int idx = 0; idx < count; idx++) {\n        output[idx] = inputleft[idx] + inputright[idx];\n    }\n}\n\nint main() {\n    \n    int arraySize = 4;\n    float inputLeft[] = {1.1, 2.2, 3.3, 4.4};\n    float inputRight[] = {0.5, 1.5, 2.5, 3.5};\n    float resultArray[arraySize];\n\n    printf(\"\u5de6\u8f93\u5165\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", inputLeft[i]);\n    }\n\n    printf(\"\\n\u53f3\u8f93\u5165\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", inputRight[i]);\n    }\n\n    \n    add_kernel(inputLeft, inputRight, resultArray, arraySize);\n\n    printf(\"\\n\u8f93\u51fa\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void add_kernel(float* inputleft, float* inputright, float* output, int count) {\n    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n    if (idx < count) {\n        output[idx] = inputleft[idx] + inputright[idx];\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    float* h_inputleft = (float*)malloc(arraySize * sizeof(float));\n    float* h_inputright = (float*)malloc(arraySize * sizeof(float));\n    float* h_output = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_inputleft[i] = static_cast<float>(i);\n        h_inputright[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_inputleft;\n    float* d_inputright;\n    float* d_output;\n    cudaMalloc((void**)&d_inputleft, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_inputright, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_output, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_inputleft, h_inputleft, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_inputright, h_inputright, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    add_kernel<<<gridSize, blockSize>>>(d_inputleft, d_inputright, d_output, arraySize);\n\n    \n    cudaMemcpy(h_output, d_output, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_output[i]);\n    }\n\n    \n    free(h_inputleft);\n    free(h_inputright);\n    free(h_output);\n    cudaFree(d_inputleft);\n    cudaFree(d_inputright);\n    cudaFree(d_output);\n\n    return 0;\n}\n"
    },
    {
        "id": "38",
        "c_code": "#include <stdio.h>\n\nvoid mul_cpu(int N, float *X, int INCX, float *Y, int INCY) {\n    for (int i = 0; i < N; ++i) {\n        Y[i * INCY] *= X[i * INCX];\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float arrayY[] = {0.5, 1.5, 2.5, 3.5, 4.5};\n\n    printf(\"\u6570\u7ec4 X\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayX[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 Y\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayY[i]);\n    }\n\n    \n    mul_cpu(arraySize, arrayX, 1, arrayY, 1);\n\n    printf(\"\\n\u6570\u7ec4 Y\uff08\u4e58\u6cd5\u540e\uff09\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayY[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void mul_kernel(int N, float* X, int INCX, float* Y, int INCY) {\n    int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n    if (i < N) {\n        Y[i * INCY] *= X[i * INCX];\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    float* h_X = (float*)malloc(arraySize * sizeof(float));\n    float* h_Y = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_X[i] = static_cast<float>(i);\n        h_Y[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_X;\n    float* d_Y;\n    cudaMalloc((void**)&d_X, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_Y, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_X, h_X, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_Y, h_Y, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    mul_kernel<<<gridSize, blockSize>>>(arraySize, d_X, 1, d_Y, 1);\n\n    \n    cudaMemcpy(h_Y, d_Y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_Y[i]);\n    }\n\n    \n    free(h_X);\n    free(h_Y);\n    cudaFree(d_X);\n    cudaFree(d_Y);\n\n    return 0;\n}\n"
    },
    {
        "id": "39",
        "c_code": "#include <stdio.h>\n\nvoid pathPlan(int *devSpeed, int *devSteer, int size) {\n    for (int tid = 0; tid < size; tid++) {\n        devSpeed[tid] += 1;\n        devSteer[tid] += 1;\n    }\n}\n\nint main() {\n    \n    int arraySize = 4;\n    int speedArray[] = {10, 20, 30, 40};\n    int steerArray[] = {1, 2, 3, 4};\n\n    printf(\"\u901f\u5ea6\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", speedArray[i]);\n    }\n\n    printf(\"\\n\u65b9\u5411\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", steerArray[i]);\n    }\n\n    \n    pathPlan(speedArray, steerArray, arraySize);\n\n    printf(\"\\n\u8ba1\u5212\u540e\u7684\u901f\u5ea6\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", speedArray[i]);\n    }\n\n    printf(\"\\n\u8ba1\u5212\u540e\u7684\u65b9\u5411\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", steerArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void pathPlan(int* devSpeed, int* devSteer, int size) {\n    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    while (tid < size) {\n        devSpeed[tid] += 1;\n        devSteer[tid] += 1;\n        tid += blockDim.x * gridDim.x;\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    int* h_devSpeed = (int*)malloc(arraySize * sizeof(int));\n    int* h_devSteer = (int*)malloc(arraySize * sizeof(int));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_devSpeed[i] = i;\n        h_devSteer[i] = 2 * i;\n    }\n\n    \n    int* d_devSpeed;\n    int* d_devSteer;\n    cudaMalloc((void**)&d_devSpeed, arraySize * sizeof(int));\n    cudaMalloc((void**)&d_devSteer, arraySize * sizeof(int));\n\n    \n    cudaMemcpy(d_devSpeed, h_devSpeed, arraySize * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_devSteer, h_devSteer, arraySize * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    pathPlan<<<gridSize, blockSize>>>(d_devSpeed, d_devSteer, arraySize);\n\n    \n    cudaMemcpy(h_devSpeed, d_devSpeed, arraySize * sizeof(int), cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_devSteer, d_devSteer, arraySize * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"Speed: %d, Steer: %d\\n\", h_devSpeed[i], h_devSteer[i]);\n    }\n\n    \n    free(h_devSpeed);\n    free(h_devSteer);\n    cudaFree(d_devSpeed);\n    cudaFree(d_devSteer);\n\n    return 0;\n}\n"
    },
    {
        "id": "4",
        "c_code": "#include <stdio.h>\n\nvoid add(int n, float *x, float *y) {\n    for (int i = 0; i < n; i++) {\n        y[i] = x[i] + y[i];\n    }\n}\n\nint main() {\n    \n    int numElements = 5;\n    float x[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float y[] = {2.0, 4.0, 6.0, 8.0, 10.0};\n\n    printf(\"\u539f\u59cb\u6570\u7ec4 x\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%.2f \", x[i]);\n    }\n\n    printf(\"\\n\u539f\u59cb\u6570\u7ec4 y\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%.2f \", y[i]);\n    }\n\n    \n    add(numElements, x, y);\n\n    printf(\"\\n\u76f8\u52a0\u540e\u7684\u6570\u7ec4 y\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%.2f \", y[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void add(int n, float* x, float* y) {\n    int i = threadIdx.x;\n    if (i < n) {\n        y[i] = x[i] + y[i];\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float* h_x = (float*)malloc(arraySize * sizeof(float));\n    float* h_y = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_x[i] = static_cast<float>(i);\n        h_y[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_x;\n    float* d_y;\n    cudaMalloc((void**)&d_x, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_y, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_x, h_x, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_y, h_y, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    add<<<gridSize, blockSize>>>(arraySize, d_x, d_y);\n\n    \n    cudaMemcpy(h_y, d_y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_y[i]);\n    }\n\n    \n    free(h_x);\n    free(h_y);\n    cudaFree(d_x);\n    cudaFree(d_y);\n\n    return 0;\n}\n"
    },
    {
        "id": "40",
        "c_code": "#include <stdio.h>\n\nvoid mult_add_into_cpu(int N, float *X, float *Y, float *Z) {\n    for (int i = 0; i < N; ++i) {\n        Z[i] += X[i] * Y[i];\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float arrayX[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float arrayY[] = {0.5, 1.5, 2.5, 3.5, 4.5};\n    float resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 X\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayX[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 Y\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayY[i]);\n    }\n\n    \n    mult_add_into_cpu(arraySize, arrayX, arrayY, resultArray);\n\n    printf(\"\\n\u6570\u7ec4 Z\uff08\u4e58\u6cd5\u5e76\u52a0\u6cd5\u540e\uff09\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void mult_add_into_kernel(int n, float* a, float* b, float* c) {\n    int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n    if (i < n) {\n        c[i] += a[i] * b[i];\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    float* h_a = (float*)malloc(arraySize * sizeof(float));\n    float* h_b = (float*)malloc(arraySize * sizeof(float));\n    float* h_c = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_a[i] = static_cast<float>(i);\n        h_b[i] = static_cast<float>(2 * i);\n        h_c[i] = static_cast<float>(3 * i);\n    }\n\n    \n    float* d_a;\n    float* d_b;\n    float* d_c;\n    cudaMalloc((void**)&d_a, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_b, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_c, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_c, h_c, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    mult_add_into_kernel<<<gridSize, blockSize>>>(arraySize, d_a, d_b, d_c);\n\n    \n    cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_c[i]);\n    }\n\n    \n    free(h_a);\n    free(h_b);\n    free(h_c);\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "41",
        "c_code": "#include <stdio.h>\n\nvoid InitReduction(int *flags, int voxelCount, int *reduction, int reductionSize) {\n    for (int tid = 0; tid < reductionSize; tid++) {\n        reduction[tid] = (tid < voxelCount) ? flags[tid] : 0;\n    }\n}\n\nint main() {\n    \n    int voxelCount = 4;\n    int reductionSize = 6;\n    int flagsArray[] = {1, 0, 1, 0};\n    int reductionArray[reductionSize];\n\n    printf(\"\u6807\u5fd7\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < voxelCount; i++) {\n        printf(\"%d \", flagsArray[i]);\n    }\n\n    \n    InitReduction(flagsArray, voxelCount, reductionArray, reductionSize);\n\n    printf(\"\\n\u521d\u59cb\u5316\u7684\u7f29\u51cf\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < reductionSize; i++) {\n        printf(\"%d \", reductionArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void InitReduction(bool* flags, int voxelCount, int* reduction, int reductionSize) {\n    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    if (tid < reductionSize) {\n        reduction[tid] = (tid < voxelCount) ? flags[tid] : 0;\n    }\n}\n\nint main() {\n    \n    const int voxelCount = 1000;\n    const int reductionSize = 1024; \n\n    \n    bool* h_flags = (bool*)malloc(voxelCount * sizeof(bool));\n    int* h_reduction = (int*)malloc(reductionSize * sizeof(int));\n\n    \n    for (int i = 0; i < voxelCount; ++i) {\n        h_flags[i] = i % 2 == 0; \n    }\n\n    \n    bool* d_flags;\n    int* d_reduction;\n    cudaMalloc((void**)&d_flags, voxelCount * sizeof(bool));\n    cudaMalloc((void**)&d_reduction, reductionSize * sizeof(int));\n\n    \n    cudaMemcpy(d_flags, h_flags, voxelCount * sizeof(bool), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((reductionSize + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    InitReduction<<<gridSize, blockSize>>>(d_flags, voxelCount, d_reduction, reductionSize);\n\n    \n    cudaMemcpy(h_reduction, d_reduction, reductionSize * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%d \", h_reduction[i]);\n    }\n\n    \n    free(h_flags);\n    free(h_reduction);\n    cudaFree(d_flags);\n    cudaFree(d_reduction);\n\n    return 0;\n}\n"
    },
    {
        "id": "42",
        "c_code": "#include <stdio.h>\n\nvoid Function_update_sgd_cpu(float lr, float *parameter, float *gradient, int size) {\n    for (int i = 0; i < size; i++) {\n        parameter[i] -= lr * gradient[i];\n    }\n}\n\nint main() {\n    \n    int arraySize = 3;\n    float learningRate = 0.1;\n    float parameterArray[] = {1.0, 2.0, 3.0};\n    float gradientArray[] = {0.5, 1.0, 1.5};\n\n    printf(\"\u53c2\u6570\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", parameterArray[i]);\n    }\n\n    printf(\"\\n\u68af\u5ea6\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", gradientArray[i]);\n    }\n\n    \n    Function_update_sgd_cpu(learningRate, parameterArray, gradientArray, arraySize);\n\n    printf(\"\\n\u66f4\u65b0\u540e\u7684\u53c2\u6570\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", parameterArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void Kernel_Function_update_sgd(float lr, float* dev_parameter, float* dev_gradient, int size) {\n    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    int N = size;\n    while (tid < N) {\n        dev_parameter[tid] -= lr * dev_gradient[tid];\n        tid += gridDim.x * blockDim.x;\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    float* h_dev_parameter = (float*)malloc(arraySize * sizeof(float));\n    float* h_dev_gradient = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_dev_parameter[i] = static_cast<float>(i);\n        h_dev_gradient[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_dev_parameter;\n    float* d_dev_gradient;\n    cudaMalloc((void**)&d_dev_parameter, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_dev_gradient, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_dev_parameter, h_dev_parameter, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_dev_gradient, h_dev_gradient, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    Kernel_Function_update_sgd<<<gridSize, blockSize>>>(0.01f, d_dev_parameter, d_dev_gradient, arraySize);\n\n    \n    cudaMemcpy(h_dev_parameter, d_dev_parameter, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_dev_parameter[i]);\n    }\n\n    \n    free(h_dev_parameter);\n    free(h_dev_gradient);\n    cudaFree(d_dev_parameter);\n    cudaFree(d_dev_gradient);\n\n    return 0;\n}\n"
    },
    {
        "id": "43",
        "c_code": "#include <stdio.h>\n\nvoid operacionCPU(float *u, float *lu, float u_m, float u_d, int n) {\n    int idx = 0;\n    while (idx < n) {\n        lu[idx] = (u[idx] - u_m) / u_d;\n        idx += 1;\n    }\n}\n\nint main() {\n    \n    int arraySize = 4;\n    float uArray[] = {2.0, 3.0, 4.0, 5.0};\n    float luArray[arraySize];\n    float u_m = 3.0;\n    float u_d = 2.0;\n\n    printf(\"\u6570\u7ec4 u\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", uArray[i]);\n    }\n\n    \n    operacionCPU(uArray, luArray, u_m, u_d, arraySize);\n\n    printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4 lu\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", luArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void operacionKernelGPU(float* u, float* lu, float u_m, float u_d, int n) {\n    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n    if (idx < n) {\n        lu[idx] = (u[idx] - u_m) / u_d;\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    float* h_u = (float*)malloc(arraySize * sizeof(float));\n    float* h_lu = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_u[i] = static_cast<float>(i);\n    }\n\n    \n    float* d_u;\n    float* d_lu;\n    cudaMalloc((void**)&d_u, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_lu, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_u, h_u, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    operacionKernelGPU<<<gridSize, blockSize>>>(d_u, d_lu, 5.0f, 2.0f, arraySize);\n\n    \n    cudaMemcpy(h_lu, d_lu, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_lu[i]);\n    }\n\n    \n    free(h_u);\n    free(h_lu);\n    cudaFree(d_u);\n    cudaFree(d_lu);\n\n    return 0;\n}\n"
    },
    {
        "id": "44",
        "c_code": "#include <stdio.h>\n\nvoid host_add(float *c, float *a, float *b, int n) {\n    for (int k = 0; k < n; k++) {\n        c[k] = a[k] + b[k];\n    }\n}\n\nint main() {\n    \n    int arraySize = 4;\n    float arrayA[] = {1.0, 2.0, 3.0, 4.0};\n    float arrayB[] = {5.0, 6.0, 7.0, 8.0};\n    float resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 A\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayA[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 B\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayB[i]);\n    }\n\n    \n    host_add(resultArray, arrayA, arrayB, arraySize);\n\n    printf(\"\\n\u6570\u7ec4 C\uff08\u76f8\u52a0\u540e\uff09\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void gpu_add(float* c, float* a, float* b, int n) {\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\n    int m = gridDim.x * blockDim.x;\n    for (int k = j; k < n; k += m) {\n        c[k] = a[k] + b[k];\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    float* h_a = (float*)malloc(arraySize * sizeof(float));\n    float* h_b = (float*)malloc(arraySize * sizeof(float));\n    float* h_c = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_a[i] = static_cast<float>(i);\n        h_b[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_a;\n    float* d_b;\n    float* d_c;\n    cudaMalloc((void**)&d_a, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_b, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_c, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_a, h_a, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    gpu_add<<<gridSize, blockSize>>>(d_c, d_a, d_b, arraySize);\n\n    \n    cudaMemcpy(h_c, d_c, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_c[i]);\n    }\n\n    \n    free(h_a);\n    free(h_b);\n    free(h_c);\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "45",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid squareSerial(float *d_in, float *d_out, int N) {\n    for (unsigned int i = 0; i < N; ++i) {\n        d_out[i] = pow(d_in[i] / (d_in[i] - 2.3), 3);\n    }\n}\n\nint main() {\n    \n    int arraySize = 3;\n    float inputArray[] = {1.0, 3.0, 5.0};\n    float outputArray[arraySize];\n\n    printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", inputArray[i]);\n    }\n\n    \n    squareSerial(inputArray, outputArray, arraySize);\n\n    printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", outputArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <cmath>\n\n__global__ void squareKernel(float* d_in, float* d_out, int N) {\n    const unsigned int lid = threadIdx.x;\n    const unsigned int gid = blockIdx.x * blockDim.x + lid;\n    if (gid < N) {\n        d_out[gid] = pow(d_in[gid] / (d_in[gid] - 2.3), 3);\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    float* h_d_in = (float*)malloc(arraySize * sizeof(float));\n    float* h_d_out = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_d_in[i] = static_cast<float>(i);\n    }\n\n    \n    float* d_d_in;\n    float* d_d_out;\n    cudaMalloc((void**)&d_d_in, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_d_out, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_d_in, h_d_in, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    squareKernel<<<gridSize, blockSize>>>(d_d_in, d_d_out, arraySize);\n\n    \n    cudaMemcpy(h_d_out, d_d_out, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_d_out[i]);\n    }\n\n    \n    free(h_d_in);\n    free(h_d_out);\n    cudaFree(d_d_in);\n    cudaFree(d_d_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "46",
        "c_code": "#include <stdio.h>\n\nvoid doubleArrayVectorAdd_cpu(double *d_in_a, double *d_in_b, double *d_out, int length) {\n    for (int idx = 0; idx < length; idx++) {\n        d_out[idx] = d_in_a[idx] + d_in_b[idx];\n    }\n}\n\nint main() {\n    \n    int arraySize = 3;\n    double arrayA[] = {1.5, 2.5, 3.5};\n    double arrayB[] = {0.5, 1.0, 1.5};\n    double resultArray[arraySize];\n\n    printf(\"\u6570\u7ec4 A\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayA[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec4 B\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", arrayB[i]);\n    }\n\n    \n    doubleArrayVectorAdd_cpu(arrayA, arrayB, resultArray, arraySize);\n\n    printf(\"\\n\u6570\u7ec4 C\uff08\u76f8\u52a0\u540e\uff09\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", resultArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void doubleArrayVectorAddKernel(double* d_in_a, double* d_in_b, double* d_out, int length) {\n    int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n    if (tid < length) {\n        d_out[tid] = d_in_a[tid] + d_in_b[tid];\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    double* h_d_in_a = (double*)malloc(arraySize * sizeof(double));\n    double* h_d_in_b = (double*)malloc(arraySize * sizeof(double));\n    double* h_d_out = (double*)malloc(arraySize * sizeof(double));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_d_in_a[i] = static_cast<double>(i);\n        h_d_in_b[i] = static_cast<double>(2 * i);\n    }\n\n    \n    double* d_d_in_a;\n    double* d_d_in_b;\n    double* d_d_out;\n    cudaMalloc((void**)&d_d_in_a, arraySize * sizeof(double));\n    cudaMalloc((void**)&d_d_in_b, arraySize * sizeof(double));\n    cudaMalloc((void**)&d_d_out, arraySize * sizeof(double));\n\n    \n    cudaMemcpy(d_d_in_a, h_d_in_a, arraySize * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_d_in_b, h_d_in_b, arraySize * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    doubleArrayVectorAddKernel<<<gridSize, blockSize>>>(d_d_in_a, d_d_in_b, d_d_out, arraySize);\n\n    \n    cudaMemcpy(h_d_out, d_d_out, arraySize * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_d_out[i]);\n    }\n\n    \n    free(h_d_in_a);\n    free(h_d_in_b);\n    free(h_d_out);\n    cudaFree(d_d_in_a);\n    cudaFree(d_d_in_b);\n    cudaFree(d_d_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "47",
        "c_code": "#include <stdio.h>\n\nvoid fill_matrix(double *const A, const int rows, const int cols) {\n    for (int row = 0; row < rows; row++) {\n        for (int col = 0; col < cols; col++) {\n            A[row * cols + col] = row;\n        }\n    }\n}\n\nint main() {\n    \n    int numRows = 3;\n    int numCols = 4;\n    double matrix[numRows * numCols];\n\n    \n    fill_matrix(matrix, numRows, numCols);\n\n    \n    printf(\"\u586b\u5145\u540e\u7684\u77e9\u9635\uff1a\\n\");\n    for (int row = 0; row < numRows; row++) {\n        for (int col = 0; col < numCols; col++) {\n            printf(\"%.2f \", matrix[row * numCols + col]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void fill_matrix(double* const A, const int rows, const int cols) {\n    const int row = blockIdx.y * blockDim.y + threadIdx.y;\n    const int col = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row < rows && col < cols) {\n        A[row * cols + col] = static_cast<double>(row);\n    }\n}\n\nint main() {\n    \n    const int rows = 10;\n    const int cols = 5;\n\n    \n    double* h_A = (double*)malloc(rows * cols * sizeof(double));\n\n    \n    double* d_A;\n    cudaMalloc((void**)&d_A, rows * cols * sizeof(double));\n\n    \n    dim3 blockSize(16, 16);\n    dim3 gridSize((cols + blockSize.x - 1) / blockSize.x, (rows + blockSize.y - 1) / blockSize.y);\n\n    \n    fill_matrix<<<gridSize, blockSize>>>(d_A, rows, cols);\n\n    \n    cudaMemcpy(h_A, d_A, rows * cols * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < std::min(10, rows); ++i) {\n        for (int j = 0; j < std::min(5, cols); ++j) {\n            printf(\"%f \", h_A[i * cols + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    free(h_A);\n    cudaFree(d_A);\n\n    return 0;\n}\n"
    },
    {
        "id": "48",
        "c_code": "#include <stdio.h>\n\nvoid evenoddincrement_cpu(float *g_data, int even_inc, int odd_inc, int size) {\n    for (int tx = 0; tx < size; tx++) {\n        if ((tx % 2) == 0) {\n            g_data[tx] += even_inc;\n        } else {\n            g_data[tx] += odd_inc;\n        }\n    }\n}\n\nint main() {\n    \n    int arraySize = 6;\n    float dataArray[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    int evenIncrement = 2;\n    int oddIncrement = 1;\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", dataArray[i]);\n    }\n\n    \n    evenoddincrement_cpu(dataArray, evenIncrement, oddIncrement, arraySize);\n\n    printf(\"\\n\u589e\u91cf\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", dataArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void evenoddincrement(float* g_data, int even_inc, int odd_inc) {\n    int tx = threadIdx.x + blockIdx.x * blockDim.x;\n    if ((tx % 2) == 0) {\n        g_data[tx] += even_inc;\n    } else {\n        g_data[tx] += odd_inc;\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    float* h_data = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_data[i] = static_cast<float>(i);\n    }\n\n    \n    float* d_data;\n    cudaMalloc((void**)&d_data, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_data, h_data, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    evenoddincrement<<<gridSize, blockSize>>>(d_data, 2, 3);\n\n    \n    cudaMemcpy(h_data, d_data, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_data[i]);\n    }\n\n    \n    free(h_data);\n    cudaFree(d_data);\n\n    return 0;\n}\n"
    },
    {
        "id": "49",
        "c_code": "#include <stdio.h>\n\nvoid copy_cpu(int N, float *X, int INCX, float *Y, int INCY) {\n    for (int i = 0; i < N; ++i) {\n        Y[i * INCY] = X[i * INCX];\n    }\n}\n\nint main() {\n    \n    int arraySize = 4;\n    float sourceArray[] = {1.1, 2.2, 3.3, 4.4};\n    float destinationArray[arraySize];\n    int INCX = 1;\n    int INCY = 2;\n\n    printf(\"\u6e90\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", sourceArray[i]);\n    }\n\n    \n    copy_cpu(arraySize, sourceArray, INCX, destinationArray, INCY);\n\n    printf(\"\\n\u590d\u5236\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", destinationArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void copy_kernel(int N, float* X, int OFFX, int INCX, float* Y, int OFFY, int INCY) {\n    int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n    if (i < N) {\n        Y[i * INCY + OFFY] = X[i * INCX + OFFX];\n    }\n}\n\nint main() {\n    \n    const int arraySize = 1000;\n\n    \n    float* h_X = (float*)malloc(arraySize * sizeof(float));\n    float* h_Y = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_X[i] = static_cast<float>(i);\n    }\n\n    \n    float* d_X;\n    float* d_Y;\n    cudaMalloc((void**)&d_X, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_Y, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_X, h_X, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((arraySize + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    copy_kernel<<<gridSize, blockSize>>>(arraySize, d_X, 0, 1, d_Y, 0, 1);\n\n    \n    cudaMemcpy(h_Y, d_Y, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_Y[i]);\n    }\n\n    \n    free(h_X);\n    free(h_Y);\n    cudaFree(d_X);\n    cudaFree(d_Y);\n\n    return 0;\n}\n"
    },
    {
        "id": "5",
        "c_code": "#include <stdio.h>\n\nvoid scale_host(float *array, float scale, int N) {\n    for (int idx = 0; idx < N; idx++) {\n        array[idx] *= scale;\n    }\n}\n\nint main() {\n    \n    int numElements = 5;\n    float array[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float scale_factor = 2.0;\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%.2f \", array[i]);\n    }\n\n    \n    scale_host(array, scale_factor, numElements);\n\n    printf(\"\\n\u7f29\u653e\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%.2f \", array[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void scale_dev(float* array, float scale, int N) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < N) {\n        array[idx] *= scale;\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float scale = 1.5f;\n\n    \n    float* h_array = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_array[i] = static_cast<float>(i);\n    }\n\n    \n    float* d_array;\n    cudaMalloc((void**)&d_array, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_array, h_array, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    scale_dev<<<gridSize, blockSize>>>(d_array, scale, arraySize);\n\n    \n    cudaMemcpy(h_array, d_array, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_array[i]);\n    }\n\n    \n    free(h_array);\n    cudaFree(d_array);\n\n    return 0;\n}\n"
    },
    {
        "id": "50",
        "c_code": "#include <stdio.h>\n\nvoid clearLabel(float *prA, float *prB, unsigned int num_nodes, float base) {\n    for (unsigned int id = 0; id < num_nodes; id++) {\n        prA[id] = base + prA[id] * 0.85;\n        prB[id] = 0;\n    }\n}\n\nint main() {\n    \n    unsigned int numNodes = 5;\n    float prAArray[] = {0.1, 0.2, 0.3, 0.4, 0.5};\n    float prBArray[numNodes];\n    float baseValue = 0.05;\n\n    printf(\"prA \u6570\u7ec4\uff1a\");\n    for (unsigned int i = 0; i < numNodes; i++) {\n        printf(\"%.2f \", prAArray[i]);\n    }\n\n    \n    clearLabel(prAArray, prBArray, numNodes, baseValue);\n\n    printf(\"\\n\u6e05\u96f6\u540e\u7684 prA \u6570\u7ec4\uff1a\");\n    for (unsigned int i = 0; i < numNodes; i++) {\n        printf(\"%.2f \", prAArray[i]);\n    }\n\n    printf(\"\\n\u6e05\u96f6\u540e\u7684 prB \u6570\u7ec4\uff1a\");\n    for (unsigned int i = 0; i < numNodes; i++) {\n        printf(\"%.2f \", prBArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void clearLabel(float* prA, float* prB, unsigned int num_nodes, float base) {\n    unsigned int id = blockDim.x * blockIdx.x + threadIdx.x;\n    if (id < num_nodes) {\n        prA[id] = base + prA[id] * 0.85;\n        prB[id] = 0;\n    }\n}\n\nint main() {\n    \n    const unsigned int num_nodes = 1000;\n\n    \n    float* h_prA = (float*)malloc(num_nodes * sizeof(float));\n    float* h_prB = (float*)malloc(num_nodes * sizeof(float));\n\n    \n    for (unsigned int i = 0; i < num_nodes; ++i) {\n        h_prA[i] = static_cast<float>(i);\n        h_prB[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_prA;\n    float* d_prB;\n    cudaMalloc((void**)&d_prA, num_nodes * sizeof(float));\n    cudaMalloc((void**)&d_prB, num_nodes * sizeof(float));\n\n    \n    cudaMemcpy(d_prA, h_prA, num_nodes * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_prB, h_prB, num_nodes * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((num_nodes + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    clearLabel<<<gridSize, blockSize>>>(d_prA, d_prB, num_nodes, 1.0);\n\n    \n    cudaMemcpy(h_prA, d_prA, num_nodes * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_prB, d_prB, num_nodes * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (unsigned int i = 0; i < 10; ++i) {\n        printf(\"prA[%u]: %f, prB[%u]: %f\\n\", i, h_prA[i], i, h_prB[i]);\n    }\n\n    \n    free(h_prA);\n    free(h_prB);\n    cudaFree(d_prA);\n    cudaFree(d_prB);\n\n    return 0;\n}\n"
    },
    {
        "id": "51",
        "c_code": "#include <stdio.h>\n\nvoid delay_kernel_cpu(int *N_mobil, int *Tau, int dia) {\n    int N = N_mobil[0];\n    for (int id = 0; id < N; id++) {\n        if (Tau[id] > 0) {\n            Tau[id] = Tau[id] - 1;\n        }\n    }\n}\n\nint main() {\n    \n    int numElements = 5;\n    int N_mobilArray[] = {numElements};\n    int TauArray[] = {2, 0, 4, 1, 0};\n    int diaValue = 0;\n\n    printf(\"Tau \u6570\u7ec4\uff08\u521d\u59cb\uff09\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%d \", TauArray[i]);\n    }\n\n    \n    delay_kernel_cpu(N_mobilArray, TauArray, diaValue);\n\n    printf(\"\\n\u5ef6\u8fdf\u540e\u7684 Tau \u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%d \", TauArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void delay_kernel(int* N_mobil, int* Tau, int dia) {\n    int N = N_mobil[0];\n    int id = blockIdx.x * blockDim.x + threadIdx.x;\n    if (id < N) {\n        if (Tau[id] > 0) {\n            Tau[id] = Tau[id] - 1;\n        }\n    }\n}\n\nint main() {\n    \n    const int N = 1000;\n\n    \n    int* h_N_mobil = (int*)malloc(sizeof(int));\n    int* h_Tau = (int*)malloc(N * sizeof(int));\n\n    \n    h_N_mobil[0] = N;\n    for (int i = 0; i < N; ++i) {\n        h_Tau[i] = static_cast<int>(i);\n    }\n\n    \n    int* d_N_mobil;\n    int* d_Tau;\n    cudaMalloc((void**)&d_N_mobil, sizeof(int));\n    cudaMalloc((void**)&d_Tau, N * sizeof(int));\n\n    \n    cudaMemcpy(d_N_mobil, h_N_mobil, sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_Tau, h_Tau, N * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    delay_kernel<<<gridSize, blockSize>>>(d_N_mobil, d_Tau, 1);\n\n    \n    cudaMemcpy(h_Tau, d_Tau, N * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"Tau[%d]: %d\\n\", i, h_Tau[i]);\n    }\n\n    \n    free(h_N_mobil);\n    free(h_Tau);\n    cudaFree(d_N_mobil);\n    cudaFree(d_Tau);\n\n    return 0;\n}\n"
    },
    {
        "id": "52",
        "c_code": "#include <stdio.h>\n\nvoid resetHeap_cpu(int *heap, int *heapPtr, int numBlock) {\n    for (int index = 0; index < numBlock; index++) {\n        if (index == 0)\n            heapPtr[0] = numBlock - 1;\n        heap[index] = numBlock - index - 1;\n    }\n}\n\nint main() {\n    \n    int numBlocks = 4;\n    int heapArray[numBlocks];\n    int heapPtrArray[] = {0};\n\n    printf(\"\u521d\u59cb\u7684 heap \u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numBlocks; i++) {\n        printf(\"%d \", heapArray[i]);\n    }\n\n    printf(\"\\n\u521d\u59cb\u7684 heapPtr \u6570\u7ec4\uff1a%d\", heapPtrArray[0]);\n\n    \n    resetHeap_cpu(heapArray, heapPtrArray, numBlocks);\n\n    printf(\"\\n\u91cd\u7f6e\u540e\u7684 heap \u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numBlocks; i++) {\n        printf(\"%d \", heapArray[i]);\n    }\n\n    printf(\"\\n\u91cd\u7f6e\u540e\u7684 heapPtr \u6570\u7ec4\uff1a%d\", heapPtrArray[0]);\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void delay_kernel(int* N_mobil, int* Tau, int dia) {\n    int N = N_mobil[0];\n    int id = blockIdx.x * blockDim.x + threadIdx.x;\n    if (id < N) {\n        if (Tau[id] > 0) {\n            Tau[id] = Tau[id] - 1;\n        }\n    }\n}\n\nint main() {\n    \n    const int N = 1000;\n\n    \n    int* h_N_mobil = (int*)malloc(sizeof(int));\n    int* h_Tau = (int*)malloc(N * sizeof(int));\n\n    \n    h_N_mobil[0] = N;\n    for (int i = 0; i < N; ++i) {\n        h_Tau[i] = static_cast<int>(i);\n    }\n\n    \n    int* d_N_mobil;\n    int* d_Tau;\n    cudaMalloc((void**)&d_N_mobil, sizeof(int));\n    cudaMalloc((void**)&d_Tau, N * sizeof(int));\n\n    \n    cudaMemcpy(d_N_mobil, h_N_mobil, sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_Tau, h_Tau, N * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    delay_kernel<<<gridSize, blockSize>>>(d_N_mobil, d_Tau, 1);\n\n    \n    cudaMemcpy(h_Tau, d_Tau, N * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"Tau[%d]: %d\\n\", i, h_Tau[i]);\n    }\n\n    \n    free(h_N_mobil);\n    free(h_Tau);\n    cudaFree(d_N_mobil);\n    cudaFree(d_Tau);\n\n    return 0;\n}\n"
    },
    {
        "id": "53",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid pow_cpu(int N, float ALPHA, float *X, int INCX, float *Y, int INCY) {\n    for (int i = 0; i < N; ++i) {\n        Y[i * INCY] = pow(X[i * INCX], ALPHA);\n    }\n}\n\nint main() {\n    \n    int arraySize = 4;\n    float inputArray[] = {2.0, 3.0, 4.0, 5.0};\n    float outputArray[arraySize];\n    float alphaValue = 3.0;\n\n    printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", inputArray[i]);\n    }\n\n    \n    pow_cpu(arraySize, alphaValue, inputArray, 1, outputArray, 1);\n\n    printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", outputArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <cmath>\n\n__global__ void pow_kernel(int N, float ALPHA, float* X, int INCX, float* Y, int INCY) {\n    int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n    if (i < N) {\n        Y[i * INCY] = pow(X[i * INCX], ALPHA);\n    }\n}\n\nint main() {\n    \n    const int N = 1000;\n\n    \n    float* h_X = (float*)malloc(N * sizeof(float));\n    float* h_Y = (float*)malloc(N * sizeof(float));\n\n    \n    for (int i = 0; i < N; ++i) {\n        h_X[i] = static_cast<float>(i);\n    }\n\n    \n    float* d_X;\n    float* d_Y;\n    cudaMalloc((void**)&d_X, N * sizeof(float));\n    cudaMalloc((void**)&d_Y, N * sizeof(float));\n\n    \n    cudaMemcpy(d_X, h_X, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    pow_kernel<<<gridSize, blockSize>>>(N, 2.0, d_X, 1, d_Y, 1);\n\n    \n    cudaMemcpy(h_Y, d_Y, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"Y[%d]: %f\\n\", i, h_Y[i]);\n    }\n\n    \n    free(h_X);\n    free(h_Y);\n    cudaFree(d_X);\n    cudaFree(d_Y);\n\n    return 0;\n}\n"
    },
    {
        "id": "54",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid kComputeActs(const float *d_nets, float *d_acts, int size) {\n    for (int un_idx = 0; un_idx < size; un_idx++) {\n        float tact = 1.0f / (1.0f + expf(-d_nets[un_idx]));\n        d_acts[un_idx] = tact;\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    float netsArray[] = {0.5, -1.0, 1.5, -2.0, 2.5};\n    float actsArray[arraySize];\n\n    printf(\"\u8f93\u5165\u6570\u7ec4\uff08nets\uff09\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", netsArray[i]);\n    }\n\n    \n    kComputeActs(netsArray, actsArray, arraySize);\n\n    printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff08acts\uff09\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.4f \", actsArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <cmath>\n\n__global__ void kComputeActs(const float* d_nets, float* d_acts) {\n    int un_idx = blockIdx.x * blockDim.x + threadIdx.x;\n    float tact = 1.0f / (1.0f + expf(-d_acts[un_idx]));\n    __syncthreads();\n    d_acts[un_idx] = tact;\n}\n\nint main() {\n    \n    const int N = 1000;\n\n    \n    float* h_nets = (float*)malloc(N * sizeof(float));\n    float* h_acts = (float*)malloc(N * sizeof(float));\n\n    \n    for (int i = 0; i < N; ++i) {\n        h_nets[i] = static_cast<float>(i);\n        h_acts[i] = static_cast<float>(i);\n    }\n\n    \n    float* d_nets;\n    float* d_acts;\n    cudaMalloc((void**)&d_nets, N * sizeof(float));\n    cudaMalloc((void**)&d_acts, N * sizeof(float));\n\n    \n    cudaMemcpy(d_nets, h_nets, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_acts, h_acts, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    kComputeActs<<<gridSize, blockSize>>>(d_nets, d_acts);\n\n    \n    cudaMemcpy(h_acts, d_acts, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"acts[%d]: %f\\n\", i, h_acts[i]);\n    }\n\n    \n    free(h_nets);\n    free(h_acts);\n    cudaFree(d_nets);\n    cudaFree(d_acts);\n\n    return 0;\n}\n"
    },
    {
        "id": "55",
        "c_code": "#include <stdio.h>\n\nvoid transpositionCPU(int *vector, int *transposed, int size) {\n    for (int i = 0; i < size; i++) {\n        for (int j = 0; j < size; j++) {\n            transposed[i + j * size] = vector[j + i * size];\n        }\n    }\n}\n\nint main() {\n    \n    int matrixSize = 3;\n    int inputMatrix[] = {1, 2, 3, 4, 5, 6, 7, 8, 9};\n    int transposedMatrix[matrixSize * matrixSize];\n\n    printf(\"\u8f93\u5165\u77e9\u9635\uff1a\\n\");\n    for (int i = 0; i < matrixSize; i++) {\n        for (int j = 0; j < matrixSize; j++) {\n            printf(\"%d \", inputMatrix[i * matrixSize + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    transpositionCPU(inputMatrix, transposedMatrix, matrixSize);\n\n    printf(\"\\n\u8f6c\u7f6e\u540e\u7684\u77e9\u9635\uff1a\\n\");\n    for (int i = 0; i < matrixSize; i++) {\n        for (int j = 0; j < matrixSize; j++) {\n            printf(\"%d \", transposedMatrix[i * matrixSize + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void transposeNaive(int* vector, int* transposed, int size) {\n    int column = threadIdx.x + blockDim.x * blockIdx.x;\n    int row = threadIdx.y + blockDim.y * blockIdx.y;\n\n    if (row < size && column < size) {\n        transposed[row + column * size] = vector[column + row * size];\n    }\n}\n\nint main() {\n    \n    const int size = 4;\n\n    \n    int* h_vector = (int*)malloc(size * size * sizeof(int));\n    int* h_transposed = (int*)malloc(size * size * sizeof(int));\n\n    \n    for (int i = 0; i < size * size; ++i) {\n        h_vector[i] = i;\n    }\n\n    \n    int* d_vector;\n    int* d_transposed;\n    cudaMalloc((void**)&d_vector, size * size * sizeof(int));\n    cudaMalloc((void**)&d_transposed, size * size * sizeof(int));\n\n    \n    cudaMemcpy(d_vector, h_vector, size * size * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(2, 2);  \n    dim3 gridSize((size + blockSize.x - 1) / blockSize.x, (size + blockSize.y - 1) / blockSize.y);\n\n    \n    transposeNaive<<<gridSize, blockSize>>>(d_vector, d_transposed, size);\n\n    \n    cudaMemcpy(h_transposed, d_transposed, size * size * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    printf(\"Original Matrix:\\n\");\n    for (int i = 0; i < size; ++i) {\n        for (int j = 0; j < size; ++j) {\n            printf(\"%d\\t\", h_vector[j + i * size]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    printf(\"\\nTransposed Matrix:\\n\");\n    for (int i = 0; i < size; ++i) {\n        for (int j = 0; j < size; ++j) {\n            printf(\"%d\\t\", h_transposed[j + i * size]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    free(h_vector);\n    free(h_transposed);\n    cudaFree(d_vector);\n    cudaFree(d_transposed);\n\n    return 0;\n}\n"
    },
    {
        "id": "56",
        "c_code": "#include <stdio.h>\n\nvoid compute_array_square(float *array, float *outArray, int size) {\n    for (int i = 0; i < size; i++) {\n        outArray[i] = array[i] * array[i];\n    }\n}\n\nint main() {\n    \n    int arraySize = 4;\n    float inputArray[] = {2.0, 3.0, 4.0, 5.0};\n    float outputArray[arraySize];\n\n    printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", inputArray[i]);\n    }\n\n    \n    compute_array_square(inputArray, outputArray, arraySize);\n\n    printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%.2f \", outputArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void compute_array_square(float* array, float* outArray, int size) {\n    int thread_index = threadIdx.x + blockIdx.x * blockDim.x;\n    int num_threads = blockDim.x * gridDim.x;\n\n    for (int i = 0; i < size; i += num_threads) {\n        int index = i + thread_index;\n\n        if (index < size) {\n            outArray[index] = array[index] * array[index];\n        }\n    }\n}\n\nint main() {\n    \n    const int size = 1000;\n\n    \n    float* h_array = (float*)malloc(size * sizeof(float));\n    float* h_outArray = (float*)malloc(size * sizeof(float));\n\n    \n    for (int i = 0; i < size; ++i) {\n        h_array[i] = static_cast<float>(i);\n    }\n\n    \n    float* d_array;\n    float* d_outArray;\n    cudaMalloc((void**)&d_array, size * sizeof(float));\n    cudaMalloc((void**)&d_outArray, size * sizeof(float));\n\n    \n    cudaMemcpy(d_array, h_array, size * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((size + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    compute_array_square<<<gridSize, blockSize>>>(d_array, d_outArray, size);\n\n    \n    cudaMemcpy(h_outArray, d_outArray, size * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"outArray[%d]: %f\\n\", i, h_outArray[i]);\n    }\n\n    \n    free(h_array);\n    free(h_outArray);\n    cudaFree(d_array);\n    cudaFree(d_outArray);\n\n    return 0;\n}\n"
    },
    {
        "id": "57",
        "c_code": "#include <stdio.h>\n\nvoid testInt1_cpu(const int *input, int dims) {\n    for (int tid = 0; tid < dims; tid++) {\n        int sum = 0;\n        for (int i = 0; i < 3000 * 4; i++) {\n            if (input[i] == 0) {\n                sum++;\n            }\n        }\n    }\n}\n\nint main() {\n    \n    int arraySize = 3000 * 4;\n    int inputArray[arraySize];\n\n    \n    for (int i = 0; i < arraySize; i++) {\n        inputArray[i] = 0;\n    }\n\n    \n    testInt1_cpu(inputArray, arraySize);\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void testInt1(const int* input, int dims) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid >= dims) {\n        return;\n    }\n\n    int sum = 0;\n\n    for (int i = 0; i < 3000 * 4; i++) {\n        if (input[i] == 0) {\n            sum++;\n        }\n    }\n}\n\nint main() {\n    \n    const int dims = 3000 * 4;\n\n    \n    int* h_input = (int*)malloc(dims * sizeof(int));\n\n    \n    for (int i = 0; i < dims; ++i) {\n        h_input[i] = i % 2; \n    }\n\n    \n    int* d_input;\n    cudaMalloc((void**)&d_input, dims * sizeof(int));\n\n    \n    cudaMemcpy(d_input, h_input, dims * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((dims + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    testInt1<<<gridSize, blockSize>>>(d_input, dims);\n\n    \n    cudaDeviceSynchronize();\n\n    \n    free(h_input);\n    cudaFree(d_input);\n\n    return 0;\n}\n"
    },
    {
        "id": "58",
        "c_code": "#include <stdio.h>\n\nvoid incKernel(int *g_out, int *g_in, int N, int inner_reps) {\n    for (int idx = 0; idx < N; idx++) {\n        for (int i = 0; i < inner_reps; ++i) {\n            g_out[idx] = g_in[idx] + 1;\n        }\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    int inputArray[] = {1, 2, 3, 4, 5};\n    int outputArray[arraySize];\n\n    printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", inputArray[i]);\n    }\n\n    \n    incKernel(outputArray, inputArray, arraySize, 3);\n\n    printf(\"\\n\u8ba1\u7b97\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", outputArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void incKernel(int* g_out, const int* g_in, int N, int inner_reps) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (idx < N) {\n        for (int i = 0; i < inner_reps; ++i) {\n            g_out[idx] = g_in[idx] + 1;\n        }\n    }\n}\n\nint main() {\n    \n    const int N = 1000;\n    const int inner_reps = 1000;\n\n    \n    int* h_in = (int*)malloc(N * sizeof(int));\n    int* h_out = (int*)malloc(N * sizeof(int));\n\n    \n    for (int i = 0; i < N; ++i) {\n        h_in[i] = i;\n    }\n\n    \n    int* d_in;\n    int* d_out;\n    cudaMalloc((void**)&d_in, N * sizeof(int));\n    cudaMalloc((void**)&d_out, N * sizeof(int));\n\n    \n    cudaMemcpy(d_in, h_in, N * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    incKernel<<<gridSize, blockSize>>>(d_out, d_in, N, inner_reps);\n\n    \n    cudaMemcpy(h_out, d_out, N * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"h_out[%d]: %d\\n\", i, h_out[i]);\n    }\n\n    \n    free(h_in);\n    free(h_out);\n    cudaFree(d_in);\n    cudaFree(d_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "59",
        "c_code": "#include <stdio.h>\n\nvoid forward_dropout_layer(int batch, int inputs, float *input, float probability, float *rand, float scale) {\n    for (int i = 0; i < batch * inputs; ++i) {\n        if (rand[i] < probability) {\n            input[i] = 0;\n        } else {\n            input[i] *= scale;\n        }\n    }\n}\n\nint main() {\n    \n    int batchSize = 2;\n    int inputSize = 3;\n    float inputArray[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0};\n    float randArray[] = {0.2, 0.8, 0.4, 0.1, 0.9, 0.5};\n    float probability = 0.5;\n    float scale = 2.0;\n\n    printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < batchSize * inputSize; i++) {\n        printf(\"%.2f \", inputArray[i]);\n    }\n\n    \n    forward_dropout_layer(batchSize, inputSize, inputArray, probability, randArray, scale);\n\n    printf(\"\\n\u5904\u7406\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < batchSize * inputSize; i++) {\n        printf(\"%.2f \", inputArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <curand_kernel.h>\n#include <stdio.h>\n\n__global__ void forward_dropout_layer(float* input, int size, float* rand, float prob, float scale) {\n    int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (id < size) {\n        input[id] = (rand[id] < prob) ? 0 : input[id] * scale;\n    }\n}\n\nint main() {\n    \n    const int size = 1000;\n\n    \n    float* h_input = (float*)malloc(size * sizeof(float));\n    float* h_rand = (float*)malloc(size * sizeof(float));\n\n    \n    for (int i = 0; i < size; ++i) {\n        h_input[i] = static_cast<float>(i);\n        h_rand[i] = static_cast<float>(i) / size; \n    }\n\n    \n    float* d_input;\n    float* d_rand;\n    cudaMalloc((void**)&d_input, size * sizeof(float));\n    cudaMalloc((void**)&d_rand, size * sizeof(float));\n\n    \n    cudaMemcpy(d_input, h_input, size * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_rand, h_rand, size * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((size + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    forward_dropout_layer<<<gridSize, blockSize>>>(d_input, size, d_rand, 0.5f, 2.0f);\n\n    \n    cudaMemcpy(h_input, d_input, size * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"h_input[%d]: %f\\n\", i, h_input[i]);\n    }\n\n    \n    free(h_input);\n    free(h_rand);\n    cudaFree(d_input);\n    cudaFree(d_rand);\n\n    return 0;\n}\n"
    },
    {
        "id": "6",
        "c_code": "#include <stdio.h>\n\nvoid allAddInplace_cpu(double *arr, double alpha, int n) {\n    for (int i = 0; i < n; i++) {\n        arr[i] += alpha;\n    }\n}\n\nint main() {\n    \n    int numElements = 5;\n    double array[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    double alpha = 10.0;\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%.2f \", array[i]);\n    }\n\n    \n    allAddInplace_cpu(array, alpha, numElements);\n\n    printf(\"\\n\u6240\u6709\u5143\u7d20\u52a0\u4e0a\u5e38\u6570\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%.2f \", array[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void allAddInplaceKernel(double* arr, double alpha, int n) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < n) {\n        arr[i] += alpha;\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    double alpha = 5.0;\n\n    \n    double* h_arr = (double*)malloc(arraySize * sizeof(double));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_arr[i] = static_cast<double>(i);\n    }\n\n    \n    double* d_arr;\n    cudaMalloc((void**)&d_arr, arraySize * sizeof(double));\n\n    \n    cudaMemcpy(d_arr, h_arr, arraySize * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    allAddInplaceKernel<<<gridSize, blockSize>>>(d_arr, alpha, arraySize);\n\n    \n    cudaMemcpy(h_arr, d_arr, arraySize * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_arr[i]);\n    }\n\n    \n    free(h_arr);\n    cudaFree(d_arr);\n\n    return 0;\n}\n"
    },
    {
        "id": "60",
        "c_code": "#include <stdio.h>\n\nvoid boundaryCorrectIndexes_cpu(int *d_in, int *d_out, int length, int N) {\n    for (int idx = 0; idx < length; idx++) {\n        if (d_in[idx] > N) {\n            d_out[idx] = N;\n        } else {\n            d_out[idx] = d_in[idx];\n        }\n    }\n}\n\nint main() {\n    \n    int arraySize = 5;\n    int inputArray[] = {2, 8, 5, 12, 6};\n    int outputArray[arraySize];\n    int boundaryValue = 10;\n\n    printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", inputArray[i]);\n    }\n\n    \n    boundaryCorrectIndexes_cpu(inputArray, outputArray, arraySize, boundaryValue);\n\n    printf(\"\\n\u5904\u7406\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", outputArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void boundaryCorrectIndexesKernel(int* d_in, int* d_out, int length, int N) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid < length) {\n        if (d_in[tid] > N) {\n            d_out[tid] = N;\n        } else {\n            d_out[tid] = d_in[tid];\n        }\n    }\n}\n\nint main() {\n    \n    const int length = 1000;\n    const int N = 500;\n\n    \n    int* h_in = (int*)malloc(length * sizeof(int));\n    int* h_out = (int*)malloc(length * sizeof(int));\n\n    \n    for (int i = 0; i < length; ++i) {\n        h_in[i] = i * 2; \n    }\n\n    \n    int* d_in;\n    int* d_out;\n    cudaMalloc((void**)&d_in, length * sizeof(int));\n    cudaMalloc((void**)&d_out, length * sizeof(int));\n\n    \n    cudaMemcpy(d_in, h_in, length * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((length + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    boundaryCorrectIndexesKernel<<<gridSize, blockSize>>>(d_in, d_out, length, N);\n\n    \n    cudaMemcpy(h_out, d_out, length * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"h_out[%d]: %d\\n\", i, h_out[i]);\n    }\n\n    \n    free(h_in);\n    free(h_out);\n    cudaFree(d_in);\n    cudaFree(d_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "61",
        "c_code": "#include <stdio.h>\n\nvoid upsweep_scan(int twod, int N, int *output) {\n    int twod1 = twod * 2;\n    int idx;\n    for (idx = 0; idx + twod1 - 1 < N; idx += twod1) {\n        output[idx + twod1 - 1] += output[idx + twod - 1];\n    }\n}\n\nint main() {\n    \n    int arraySize = 8;\n    int outputArray[] = {1, 2, 3, 4, 5, 6, 7, 8};\n    int twodValue = 1;\n\n    printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", outputArray[i]);\n    }\n\n    \n    upsweep_scan(twodValue, arraySize, outputArray);\n\n    printf(\"\\n\u5904\u7406\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < arraySize; i++) {\n        printf(\"%d \", outputArray[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void upsweep_scan(int twod, int N, int* output) {\n    int twod1 = twod * 2;\n    int idx = (blockIdx.x * blockDim.x + threadIdx.x) * twod1;\n\n    if (idx + twod1 - 1 < N) {\n        output[idx + twod1 - 1] += output[idx + twod - 1];\n    }\n}\n\nint main() {\n    \n    const int N = 1000;\n    const int twod = 32;  \n\n    \n    int* h_output = (int*)malloc(N * sizeof(int));\n\n    \n    for (int i = 0; i < N; ++i) {\n        h_output[i] = i * 2;  \n    }\n\n    \n    int* d_output;\n    cudaMalloc((void**)&d_output, N * sizeof(int));\n\n    \n    cudaMemcpy(d_output, h_output, N * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    upsweep_scan<<<gridSize, blockSize>>>(twod, N, d_output);\n\n    \n    cudaMemcpy(h_output, d_output, N * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"h_output[%d]: %d\\n\", i, h_output[i]);\n    }\n\n    \n    free(h_output);\n    cudaFree(d_output);\n\n    return 0;\n}\n"
    },
    {
        "id": "62",
        "c_code": "#include <stdio.h>\n\nvoid Blend_CPU(unsigned char *aImg1, unsigned char *aImg2, unsigned char *aRS, int width, int height) {\n    for (int i = 0; i < width * height; ++i) {\n        aRS[i] = (unsigned char)(0.5 * aImg1[i] + 0.5 * aImg2[i]);\n    }\n}\n\nint main() {\n    \n    int width = 2;\n    int height = 2;\n    unsigned char img1[] = {100, 150, 200, 255};\n    unsigned char img2[] = {50, 75, 100, 255};\n    unsigned char result[width * height];\n\n    printf(\"\u8f93\u5165\u56fe\u50cf1\uff1a\");\n    for (int i = 0; i < width * height; i++) {\n        printf(\"%d \", img1[i]);\n    }\n\n    printf(\"\\n\u8f93\u5165\u56fe\u50cf2\uff1a\");\n    for (int i = 0; i < width * height; i++) {\n        printf(\"%d \", img2[i]);\n    }\n\n    \n    Blend_CPU(img1, img2, result, width, height);\n\n    printf(\"\\n\u6df7\u5408\u540e\u7684\u56fe\u50cf\uff1a\");\n    for (int i = 0; i < width * height; i++) {\n        printf(\"%d \", result[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void Blending_Kernel(unsigned char* aR1, unsigned char* aR2, unsigned char* aRS, int size) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (index < size) {\n        aRS[index] = 0.5 * aR1[index] + 0.5 * aR2[index];\n    }\n}\n\nint main() {\n    \n    const int size = 1000;\n\n    \n    unsigned char* h_aR1 = (unsigned char*)malloc(size * sizeof(unsigned char));\n    unsigned char* h_aR2 = (unsigned char*)malloc(size * sizeof(unsigned char));\n    unsigned char* h_aRS = (unsigned char*)malloc(size * sizeof(unsigned char));\n\n    \n    for (int i = 0; i < size; ++i) {\n        h_aR1[i] = static_cast<unsigned char>(i * 2); \n        h_aR2[i] = static_cast<unsigned char>(i * 3); \n    }\n\n    \n    unsigned char* d_aR1;\n    unsigned char* d_aR2;\n    unsigned char* d_aRS;\n    cudaMalloc((void**)&d_aR1, size * sizeof(unsigned char));\n    cudaMalloc((void**)&d_aR2, size * sizeof(unsigned char));\n    cudaMalloc((void**)&d_aRS, size * sizeof(unsigned char));\n\n    \n    cudaMemcpy(d_aR1, h_aR1, size * sizeof(unsigned char), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_aR2, h_aR2, size * sizeof(unsigned char), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((size + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    Blending_Kernel<<<gridSize, blockSize>>>(d_aR1, d_aR2, d_aRS, size);\n\n    \n    cudaMemcpy(h_aRS, d_aRS, size * sizeof(unsigned char), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"h_aRS[%d]: %u\\n\", i, h_aRS[i]);\n    }\n\n    \n    free(h_aR1);\n    free(h_aR2);\n    free(h_aRS);\n    cudaFree(d_aR1);\n    cudaFree(d_aR2);\n    cudaFree(d_aRS);\n\n    return 0;\n}\n"
    },
    {
        "id": "63",
        "c_code": "#include <stdio.h>\n\nvoid matVecRowSubInplace_cpu(double *mat, const double *vec, int m, int n) {\n    for (int index = 0; index < m * n; index++) {\n        int i = index / n;\n        int j = index % n;\n        mat[i * n + j] -= vec[j];\n    }\n}\n\nint main() {\n    \n    int rows = 3;\n    int cols = 4;\n    double matrix[] = {1.0, 2.0, 3.0, 4.0,\n                       5.0, 6.0, 7.0, 8.0,\n                       9.0, 10.0, 11.0, 12.0};\n\n    double vector[] = {0.5, 1.0, 1.5, 2.0};\n\n    printf(\"\u8f93\u5165\u77e9\u9635\uff1a\\n\");\n    for (int i = 0; i < rows; i++) {\n        for (int j = 0; j < cols; j++) {\n            printf(\"%.2f \", matrix[i * cols + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    matVecRowSubInplace_cpu(matrix, vector, rows, cols);\n\n    printf(\"\\n\u51cf\u53bb\u5411\u91cf\u540e\u7684\u77e9\u9635\uff1a\\n\");\n    for (int i = 0; i < rows; i++) {\n        for (int j = 0; j < cols; j++) {\n            printf(\"%.2f \", matrix[i * cols + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void matVecRowSubInplaceKernel(double* mat, const double* vec, int m, int n) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (index < m * n) {\n        int i = index / n;\n        int j = index % n;\n        mat[i * n + j] -= vec[j];\n    }\n}\n\nint main() {\n    \n    const int m = 5;\n    const int n = 3;\n\n    \n    double* h_mat = (double*)malloc(m * n * sizeof(double));\n    double* h_vec = (double*)malloc(n * sizeof(double));\n\n    \n    for (int i = 0; i < m * n; ++i) {\n        h_mat[i] = static_cast<double>(i); \n    }\n\n    for (int i = 0; i < n; ++i) {\n        h_vec[i] = static_cast<double>(i * 2); \n    }\n\n    \n    double* d_mat;\n    double* d_vec;\n    cudaMalloc((void**)&d_mat, m * n * sizeof(double));\n    cudaMalloc((void**)&d_vec, n * sizeof(double));\n\n    \n    cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_vec, h_vec, n * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((m * n + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    matVecRowSubInplaceKernel<<<gridSize, blockSize>>>(d_mat, d_vec, m, n);\n\n    \n    cudaMemcpy(h_mat, d_mat, m * n * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < m; ++i) {\n        for (int j = 0; j < n; ++j) {\n            printf(\"h_mat[%d][%d]: %f\\n\", i, j, h_mat[i * n + j]);\n        }\n    }\n\n    \n    free(h_mat);\n    free(h_vec);\n    cudaFree(d_mat);\n    cudaFree(d_vec);\n\n    return 0;\n}\n"
    },
    {
        "id": "64",
        "c_code": "#include <stdio.h>\n\nvoid matVecColAddInplace_cpu(double *mat, const double *vec, int m, int n) {\n    for (int index = 0; index < m * n; index++) {\n        int i = index / n;\n        int j = index % n;\n        mat[i * n + j] += vec[i];\n    }\n}\n\nint main() {\n    \n    int rows = 3;\n    int cols = 4;\n    double matrix[] = {1.0, 2.0, 3.0, 4.0,\n                       5.0, 6.0, 7.0, 8.0,\n                       9.0, 10.0, 11.0, 12.0};\n\n    double vector[] = {0.5, 1.0, 1.5};\n\n    printf(\"\u8f93\u5165\u77e9\u9635\uff1a\\n\");\n    for (int i = 0; i < rows; i++) {\n        for (int j = 0; j < cols; j++) {\n            printf(\"%.2f \", matrix[i * cols + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    matVecColAddInplace_cpu(matrix, vector, rows, cols);\n\n    printf(\"\\n\u6bcf\u5217\u52a0\u4e0a\u5411\u91cf\u540e\u7684\u77e9\u9635\uff1a\\n\");\n    for (int i = 0; i < rows; i++) {\n        for (int j = 0; j < cols; j++) {\n            printf(\"%.2f \", matrix[i * cols + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void matVecColAddInplaceKernel(double* mat, const double* vec, int m, int n) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (index < m * n) {\n        int i = index / n;\n        int j = index % n;\n        mat[i * n + j] += vec[i];\n    }\n}\n\nint main() {\n    \n    const int m = 5;\n    const int n = 3;\n\n    \n    double* h_mat = (double*)malloc(m * n * sizeof(double));\n    double* h_vec = (double*)malloc(m * sizeof(double));\n\n    \n    for (int i = 0; i < m * n; ++i) {\n        h_mat[i] = static_cast<double>(i); \n    }\n\n    for (int i = 0; i < m; ++i) {\n        h_vec[i] = static_cast<double>(i * 2); \n    }\n\n    \n    double* d_mat;\n    double* d_vec;\n    cudaMalloc((void**)&d_mat, m * n * sizeof(double));\n    cudaMalloc((void**)&d_vec, m * sizeof(double));\n\n    \n    cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_vec, h_vec, m * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((m * n + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    matVecColAddInplaceKernel<<<gridSize, blockSize>>>(d_mat, d_vec, m, n);\n\n    \n    cudaMemcpy(h_mat, d_mat, m * n * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < m; ++i) {\n        for (int j = 0; j < n; ++j) {\n            printf(\"h_mat[%d][%d]: %f\\n\", i, j, h_mat[i * n + j]);\n        }\n    }\n\n    \n    free(h_mat);\n    free(h_vec);\n    cudaFree(d_mat);\n    cudaFree(d_vec);\n\n    return 0;\n}\n"
    },
    {
        "id": "65",
        "c_code": "#include <stdio.h>\n\nvoid MMDOuterProdComputeWithSum(float *x_average, int size_x, float *x_outer_prod) {\n    for (int i = 0; i < size_x; i++) {\n        x_outer_prod[i] = x_average[i] * x_average[i];\n    }\n}\n\nint main() {\n    \n    int size = 4;\n    float averageValues[] = {1.5, 2.0, 3.5, 4.0};\n    float outerProdResult[size];\n\n    printf(\"\u5e73\u5747\u503c\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", averageValues[i]);\n    }\n\n    \n    MMDOuterProdComputeWithSum(averageValues, size, outerProdResult);\n\n    printf(\"\\n\u5916\u79ef\u7ed3\u679c\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", outerProdResult[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void MMDOuterProdComputeWithSum(float* x_average, int size_x, float* x_outer_prod) {\n    int block_id = blockIdx.x;\n    int thread_id = threadIdx.x;\n\n    for (int i = block_id * blockDim.x + thread_id; i < size_x; i += gridDim.x * blockDim.x) {\n        x_outer_prod[i] = x_average[i] * x_average[i];\n    }\n}\n\nint main() {\n    \n    const int size_x = 100;\n\n    \n    float* h_x_average = (float*)malloc(size_x * sizeof(float));\n    float* h_x_outer_prod = (float*)malloc(size_x * sizeof(float));\n\n    \n    for (int i = 0; i < size_x; ++i) {\n        h_x_average[i] = static_cast<float>(i); \n    }\n\n    \n    float* d_x_average;\n    float* d_x_outer_prod;\n    cudaMalloc((void**)&d_x_average, size_x * sizeof(float));\n    cudaMalloc((void**)&d_x_outer_prod, size_x * sizeof(float));\n\n    \n    cudaMemcpy(d_x_average, h_x_average, size_x * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((size_x + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    MMDOuterProdComputeWithSum<<<gridSize, blockSize>>>(d_x_average, size_x, d_x_outer_prod);\n\n    \n    cudaMemcpy(h_x_outer_prod, d_x_outer_prod, size_x * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < size_x; ++i) {\n        printf(\"h_x_outer_prod[%d]: %f\\n\", i, h_x_outer_prod[i]);\n    }\n\n    \n    free(h_x_average);\n    free(h_x_outer_prod);\n    cudaFree(d_x_average);\n    cudaFree(d_x_outer_prod);\n\n    return 0;\n}\n"
    },
    {
        "id": "66",
        "c_code": "#include <stdio.h>\n\nvoid saxpy_cpu(float *vecY, float *vecX, float alpha, int n) {\n    for (int i = 0; i < n; i++) {\n        vecY[i] = alpha * vecX[i] + vecY[i];\n    }\n}\n\nint main() {\n    \n    int size = 5;\n    float vecY[] = {1.0, 2.0, 3.0, 4.0, 5.0};\n    float vecX[] = {0.5, 1.0, 1.5, 2.0, 2.5};\n    float alpha = 2.0;\n\n    printf(\"\u8f93\u5165\u5411\u91cf vecY\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", vecY[i]);\n    }\n\n    printf(\"\\n\u8f93\u5165\u5411\u91cf vecX\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", vecX[i]);\n    }\n\n    \n    saxpy_cpu(vecY, vecX, alpha, size);\n\n    printf(\"\\n\u6267\u884c saxpy \u540e\u7684\u5411\u91cf vecY\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", vecY[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void saxpy_gpu(float* vecY, float* vecX, float alpha, int n) {\n    int x, y, i;\n    x = blockIdx.x * blockDim.x + threadIdx.x;\n    y = blockIdx.y * blockDim.y + threadIdx.y;\n    i = y * 1024 + x;\n\n    if (i < n) {\n        vecY[i] = alpha * vecX[i] + vecY[i];\n    }\n}\n\nint main() {\n    \n    const int n = 1024 * 1024;\n\n    \n    float* h_vecY = (float*)malloc(n * sizeof(float));\n    float* h_vecX = (float*)malloc(n * sizeof(float));\n\n    \n    for (int i = 0; i < n; ++i) {\n        h_vecY[i] = static_cast<float>(i); \n        h_vecX[i] = static_cast<float>(i * 2); \n    }\n\n    \n    float* d_vecY;\n    float* d_vecX;\n    cudaMalloc((void**)&d_vecY, n * sizeof(float));\n    cudaMalloc((void**)&d_vecX, n * sizeof(float));\n\n    \n    cudaMemcpy(d_vecY, h_vecY, n * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_vecX, h_vecX, n * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(32, 32); \n    dim3 gridSize((n + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);\n\n    \n    saxpy_gpu<<<gridSize, blockSize>>>(d_vecY, d_vecX, 2.0f, n);\n\n    \n    cudaMemcpy(h_vecY, d_vecY, n * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"h_vecY[%d]: %f\\n\", i, h_vecY[i]);\n    }\n\n    \n    free(h_vecY);\n    free(h_vecX);\n    cudaFree(d_vecY);\n    cudaFree(d_vecX);\n\n    return 0;\n}\n"
    },
    {
        "id": "67",
        "c_code": "#include <stdio.h>\n\nvoid set_valid_mask_cpu(const float *score, float score_thr, int *valid_mask, int dims) {\n    for (int tid = 0; tid < dims; tid++) {\n        if (score[tid] > score_thr) {\n            valid_mask[tid] = 1;\n        } else {\n            valid_mask[tid] = 0;\n        }\n    }\n}\n\nint main() {\n    \n    int size = 6;\n    float scores[] = {0.8, 0.5, 0.9, 0.3, 0.7, 0.6};\n    float threshold = 0.6;\n    int validMask[size];\n\n    printf(\"\u8f93\u5165\u5206\u6570\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", scores[i]);\n    }\n\n    \n    set_valid_mask_cpu(scores, threshold, validMask, size);\n\n    printf(\"\\n\u6709\u6548\u63a9\u7801\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%d \", validMask[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void set_valid_mask(const float* score, float score_thr, int* valid_mask, int dims) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid < dims) {\n        valid_mask[tid] = (score[tid] > score_thr) ? 1 : 0;\n    }\n}\n\nint main() {\n    \n    const int dims = 1024;\n\n    \n    float* h_score = (float*)malloc(dims * sizeof(float));\n    int* h_valid_mask = (int*)malloc(dims * sizeof(int));\n\n    \n    for (int i = 0; i < dims; ++i) {\n        h_score[i] = static_cast<float>(i); \n    }\n\n    \n    float* d_score;\n    int* d_valid_mask;\n    cudaMalloc((void**)&d_score, dims * sizeof(float));\n    cudaMalloc((void**)&d_valid_mask, dims * sizeof(int));\n\n    \n    cudaMemcpy(d_score, h_score, dims * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((dims + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    set_valid_mask<<<gridSize, blockSize>>>(d_score, 500.0f, d_valid_mask, dims);\n\n    \n    cudaMemcpy(h_valid_mask, d_valid_mask, dims * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"h_valid_mask[%d]: %d\\n\", i, h_valid_mask[i]);\n    }\n\n    \n    free(h_score);\n    free(h_valid_mask);\n    cudaFree(d_score);\n    cudaFree(d_valid_mask);\n\n    return 0;\n}\n"
    },
    {
        "id": "68",
        "c_code": "#include <stdio.h>\n\nvoid copy_swap(float *f_in, float *f_target, const int L_x) {\n    for (int k_x = 0; k_x < L_x; k_x++) {\n        float tempval = 0.0f;\n        tempval = f_in[k_x];\n        f_in[k_x] = f_target[k_x];\n        f_target[k_x] = tempval;\n    }\n}\n\nint main() {\n    \n    int size = 5;\n    float array1[] = {1.0, 2.0, 3.0, 4.0, 5.0};\n    float array2[] = {10.0, 20.0, 30.0, 40.0, 50.0};\n\n    printf(\"\u6570\u7ec41\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", array1[i]);\n    }\n\n    printf(\"\\n\u6570\u7ec42\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", array2[i]);\n    }\n\n    \n    copy_swap(array1, array2, size);\n\n    printf(\"\\n\u4ea4\u6362\u540e\u7684\u6570\u7ec41\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", array1[i]);\n    }\n\n    printf(\"\\n\u4ea4\u6362\u540e\u7684\u6570\u7ec42\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", array2[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void copy_swap(float* f_in, float* f_target, const int L_x) {\n    const int k_x = threadIdx.x + blockIdx.x * blockDim.x;\n\n    if (k_x < L_x) {\n        float tempval = f_in[k_x];\n        f_in[k_x] = f_target[k_x];\n        f_target[k_x] = tempval;\n    }\n}\n\nint main() {\n    \n    const int L_x = 1024;\n\n    \n    float* h_f_in = (float*)malloc(L_x * sizeof(float));\n    float* h_f_target = (float*)malloc(L_x * sizeof(float));\n\n    \n    for (int i = 0; i < L_x; ++i) {\n        h_f_in[i] = static_cast<float>(i); \n        h_f_target[i] = static_cast<float>(i * 2); \n    }\n\n    \n    float* d_f_in;\n    float* d_f_target;\n    cudaMalloc((void**)&d_f_in, L_x * sizeof(float));\n    cudaMalloc((void**)&d_f_target, L_x * sizeof(float));\n\n    \n    cudaMemcpy(d_f_in, h_f_in, L_x * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_f_target, h_f_target, L_x * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((L_x + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    copy_swap<<<gridSize, blockSize>>>(d_f_in, d_f_target, L_x);\n\n    \n    cudaMemcpy(h_f_in, d_f_in, L_x * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_f_target, d_f_target, L_x * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"h_f_in[%d]: %f, h_f_target[%d]: %f\\n\", i, h_f_in[i], i, h_f_target[i]);\n    }\n\n    \n    free(h_f_in);\n    free(h_f_target);\n    cudaFree(d_f_in);\n    cudaFree(d_f_target);\n\n    return 0;\n}\n"
    },
    {
        "id": "69",
        "c_code": "#include <stdio.h>\n\nvoid sum_backward(float *db, float *dout, int r, int c) {\n    for (int j = 0; j < c; j++) {\n        for (int i = 0; i < r; i++) {\n            db[j] += dout[i * c + j];\n        }\n    }\n}\n\nint main() {\n    \n    int rows = 3;\n    int cols = 4;\n    float dout[] = {1.0, 2.0, 3.0, 4.0,\n                    5.0, 6.0, 7.0, 8.0,\n                    9.0, 10.0, 11.0, 12.0};\n    float db[cols];\n\n    printf(\"\u8f93\u5165 dout \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < rows; i++) {\n        for (int j = 0; j < cols; j++) {\n            printf(\"%.2f \", dout[i * cols + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    for (int i = 0; i < cols; i++) {\n        db[i] = 0.0;\n    }\n\n    \n    sum_backward(db, dout, rows, cols);\n\n    printf(\"\\n\u8ba1\u7b97\u540e\u7684 db \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < cols; i++) {\n        printf(\"%.2f \", db[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void Kernel_Sum_backward_opt2(float* db, float* sum, int r_sum, int c) {\n    unsigned int j = blockDim.x * blockIdx.x + threadIdx.x;\n\n    if (j >= c)\n        return;\n\n    float temp = 0;\n\n    for (int i = 0; i < r_sum; i++) {\n        temp += sum[i * c + j];\n    }\n\n    db[j] = temp;\n}\n\nint main() {\n    \n    const int r_sum = 100;  \n    const int c = 50;       \n\n    \n    float* h_db = (float*)malloc(c * sizeof(float));\n    float* h_sum = (float*)malloc(r_sum * c * sizeof(float));\n\n    \n    for (int i = 0; i < r_sum * c; ++i) {\n        h_sum[i] = static_cast<float>(i);  \n    }\n\n    \n    float* d_db;\n    float* d_sum;\n    cudaMalloc((void**)&d_db, c * sizeof(float));\n    cudaMalloc((void**)&d_sum, r_sum * c * sizeof(float));\n\n    \n    cudaMemcpy(d_sum, h_sum, r_sum * c * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((c + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    Kernel_Sum_backward_opt2<<<gridSize, blockSize>>>(d_db, d_sum, r_sum, c);\n\n    \n    cudaMemcpy(h_db, d_db, c * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"h_db[%d]: %f\\n\", i, h_db[i]);\n    }\n\n    \n    free(h_db);\n    free(h_sum);\n    cudaFree(d_db);\n    cudaFree(d_sum);\n\n    return 0;\n}\n"
    },
    {
        "id": "7",
        "c_code": "#include <stdio.h>\n\nvoid memsetCpuInt(int *data, int val, int N) {\n    for (int index = 0; index < N; index++) {\n        data[index] = val;\n    }\n}\n\nint main() {\n    \n    int numElements = 5;\n    int array[] = {1, 2, 3, 4, 5};\n    int value = 42;\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%d \", array[i]);\n    }\n\n    \n    memsetCpuInt(array, value, numElements);\n\n    printf(\"\\n\u8bbe\u7f6e\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numElements; i++) {\n        printf(\"%d \", array[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void memsetCudaInt(int* data, int val, int N) {\n    unsigned int index = blockDim.x * blockIdx.x + threadIdx.x;\n    if (index < N) {\n        data[index] = val;\n    }\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    int initialValue = 42;\n\n    \n    int* h_data = (int*)malloc(arraySize * sizeof(int));\n\n    \n    int* d_data;\n    cudaMalloc((void**)&d_data, arraySize * sizeof(int));\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    memsetCudaInt<<<gridSize, blockSize>>>(d_data, initialValue, arraySize);\n\n    \n    cudaMemcpy(h_data, d_data, arraySize * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%d \", h_data[i]);\n    }\n\n    \n    free(h_data);\n    cudaFree(d_data);\n\n    return 0;\n}\n"
    },
    {
        "id": "70",
        "c_code": "#include <stdio.h>\n\nvoid is_repeat(int N, int *device_input, int *device_output) {\n    for (int idx = 0; idx < N; idx++) {\n        device_output[idx] = 0;\n        if (idx + 1 < N && device_input[idx] == device_input[idx + 1]) {\n            device_output[idx] = 1;\n        }\n    }\n}\n\nint main() {\n    \n    int size = 8;\n    int input[] = {1, 2, 2, 3, 4, 4, 4, 5};\n    int output[size];\n\n    printf(\"\u8f93\u5165\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%d \", input[i]);\n    }\n\n    \n    is_repeat(size, input, output);\n\n    printf(\"\\n\u91cd\u590d\u4f4d\u7f6e\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%d \", output[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void is_repeat(int N, int* device_input, int* device_output) {\n    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n\n    if (idx < N) {\n        device_output[idx] = 0;\n\n        if (idx + 1 < N && device_input[idx] == device_input[idx + 1])\n            device_output[idx] = 1;\n    }\n}\n\nint main() {\n    \n    const int N = 100;  \n\n    \n    int* h_device_input = (int*)malloc(N * sizeof(int));\n    int* h_device_output = (int*)malloc(N * sizeof(int));\n\n    \n    for (int i = 0; i < N; ++i) {\n        h_device_input[i] = i % 10;  \n    }\n\n    \n    int* d_device_input;\n    int* d_device_output;\n    cudaMalloc((void**)&d_device_input, N * sizeof(int));\n    cudaMalloc((void**)&d_device_output, N * sizeof(int));\n\n    \n    cudaMemcpy(d_device_input, h_device_input, N * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 blockSize(256);\n    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, 1);\n\n    \n    is_repeat<<<gridSize, blockSize>>>(N, d_device_input, d_device_output);\n\n    \n    cudaMemcpy(h_device_output, d_device_output, N * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < N; ++i) {\n        printf(\"h_device_output[%d]: %d\\n\", i, h_device_output[i]);\n    }\n\n    \n    free(h_device_input);\n    free(h_device_output);\n    cudaFree(d_device_input);\n    cudaFree(d_device_output);\n\n    return 0;\n}\n"
    },
    {
        "id": "71",
        "c_code": "#include <stdio.h>\n\nvoid kmeans_average(int *means, int *counts, int BID, int DIM) {\n    for (int bid = 0; bid < BID; bid++) {\n        for (int tid = 0; tid < DIM; tid++) {\n            if (counts[bid] == 0) {\n                means[bid * DIM + tid] = 0;\n            } else {\n                means[bid * DIM + tid] /= counts[bid];\n            }\n        }\n    }\n}\n\nint main() {\n    \n    int BID = 3;\n    int DIM = 4;\n    int means[BID * DIM];\n    int counts[BID];\n\n    \n    for (int i = 0; i < BID; i++) {\n        counts[i] = i + 1;  \n        for (int j = 0; j < DIM; j++) {\n            means[i * DIM + j] = i * DIM + j + 1;  \n        }\n    }\n\n    printf(\"\u8f93\u5165 means \u6570\u7ec4\u548c counts \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < BID; i++) {\n        for (int j = 0; j < DIM; j++) {\n            printf(\"%d \", means[i * DIM + j]);\n        }\n        printf(\" | Count: %d\\n\", counts[i]);\n    }\n\n    \n    kmeans_average(means, counts, BID, DIM);\n\n    printf(\"\\n\u5e73\u5747\u5316\u540e\u7684 means \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < BID; i++) {\n        for (int j = 0; j < DIM; j++) {\n            printf(\"%d \", means[i * DIM + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void kmeans_average(int* means, int* counts) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (counts[index] == 0)\n        means[index] = 0;\n    else\n        means[index] /= counts[index];\n}\n\nint main() {\n    const int K = 10;  \n    const int threadsPerBlock = 256;\n    const int blocksPerGrid = (K + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    int* h_means = (int*)malloc(K * sizeof(int));\n    int* h_counts = (int*)malloc(K * sizeof(int));\n\n    \n    for (int i = 0; i < K; ++i) {\n        h_means[i] = i * 10;\n        h_counts[i] = i + 1;\n    }\n\n    \n    int* d_means;\n    int* d_counts;\n    cudaMalloc((void**)&d_means, K * sizeof(int));\n    cudaMalloc((void**)&d_counts, K * sizeof(int));\n\n    \n    cudaMemcpy(d_means, h_means, K * sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_counts, h_counts, K * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    kmeans_average<<<blocksPerGrid, threadsPerBlock>>>(d_means, d_counts);\n\n    \n    cudaMemcpy(h_means, d_means, K * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    printf(\"Means after averaging:\\n\");\n    for (int i = 0; i < K; ++i) {\n        printf(\"%d \", h_means[i]);\n    }\n\n    \n    free(h_means);\n    free(h_counts);\n    cudaFree(d_means);\n    cudaFree(d_counts);\n\n    return 0;\n}\n"
    },
    {
        "id": "72",
        "c_code": "#include <stdio.h>\n\nvoid matPerRowDivInplace_cpu(double *mat, const double *alphas, int m, int n) {\n    for (int index = 0; index < m * n; index++) {\n        int i = index / n;\n        int j = index % n;\n        mat[i * n + j] /= (alphas[i] + 10 * 3);\n    }\n}\n\nint main() {\n    \n    int m = 3;\n    int n = 4;\n    double mat[] = {1.0, 2.0, 3.0, 4.0,\n                    5.0, 6.0, 7.0, 8.0,\n                    9.0, 10.0, 11.0, 12.0};\n    double alphas[] = {2.0, 3.0, 4.0};\n\n    printf(\"\u8f93\u5165\u77e9\u9635 mat\uff1a\\n\");\n    for (int i = 0; i < m; i++) {\n        for (int j = 0; j < n; j++) {\n            printf(\"%.2f \", mat[i * n + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n\u8f93\u5165 alphas \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < m; i++) {\n        printf(\"%.2f \", alphas[i]);\n    }\n\n    \n    matPerRowDivInplace_cpu(mat, alphas, m, n);\n\n    printf(\"\\n\u6bcf\u884c\u9664\u4ee5 alphas \u540e\u7684\u77e9\u9635 mat\uff1a\\n\");\n    for (int i = 0; i < m; i++) {\n        for (int j = 0; j < n; j++) {\n            printf(\"%.2f \", mat[i * n + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void matPerRowDivInplaceKernel(double* mat, const double* alphas, int m, int n) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (index < m * n) {\n        int i = index / n;\n        int j = index % n;\n        mat[i * n + j] /= (alphas[i] + 10 * 3);\n    }\n}\n\nint main() {\n    const int m = 5;  \n    const int n = 4;  \n    const int threadsPerBlock = 256;\n    const int blocksPerGrid = (m * n + threadsPerBlock - 1) / threadsPerBlock;\n\n    \n    double* h_mat = (double*)malloc(m * n * sizeof(double));\n    double* h_alphas = (double*)malloc(m * sizeof(double));\n\n    \n    for (int i = 0; i < m * n; ++i) {\n        h_mat[i] = i + 1;\n    }\n\n    for (int i = 0; i < m; ++i) {\n        h_alphas[i] = i + 1;\n    }\n\n    \n    double* d_mat;\n    double* d_alphas;\n    cudaMalloc((void**)&d_mat, m * n * sizeof(double));\n    cudaMalloc((void**)&d_alphas, m * sizeof(double));\n\n    \n    cudaMemcpy(d_mat, h_mat, m * n * sizeof(double), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_alphas, h_alphas, m * sizeof(double), cudaMemcpyHostToDevice);\n\n    \n    matPerRowDivInplaceKernel<<<blocksPerGrid, threadsPerBlock>>>(d_mat, d_alphas, m, n);\n\n    \n    cudaMemcpy(h_mat, d_mat, m * n * sizeof(double), cudaMemcpyDeviceToHost);\n\n    \n    printf(\"Matrix after per row division:\\n\");\n    for (int i = 0; i < m; ++i) {\n        for (int j = 0; j < n; ++j) {\n            printf(\"%f \", h_mat[i * n + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    free(h_mat);\n    free(h_alphas);\n    cudaFree(d_mat);\n    cudaFree(d_alphas);\n\n    return 0;\n}\n"
    },
    {
        "id": "73",
        "c_code": "#include <stdio.h>\n\n\nint max(int a, int b) {\n    return (a > b) ? a : b;\n}\n\nvoid compute_new_means(float *mx, float *my, const float *sx, const float *sy, const int *c, int size) {\n    int cluster = 0;\n    const int count = max(1, c[cluster]);\n\n    for (cluster = 0; cluster < size; cluster++) {\n        mx[cluster] = sx[cluster] / count;\n        my[cluster] = sy[cluster] / count;\n    }\n}\n\nint main() {\n    \n    int size = 3;\n    float mx[] = {1.0, 2.0, 3.0};\n    float my[] = {4.0, 5.0, 6.0};\n    float sx[] = {7.0, 8.0, 9.0};\n    float sy[] = {10.0, 11.0, 12.0};\n    int c[] = {2, 0, 1};\n\n    printf(\"\u8f93\u5165 mx \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", mx[i]);\n    }\n\n    printf(\"\\n\u8f93\u5165 my \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", my[i]);\n    }\n\n    printf(\"\\n\u8f93\u5165 sx \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", sx[i]);\n    }\n\n    printf(\"\\n\u8f93\u5165 sy \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", sy[i]);\n    }\n\n    printf(\"\\n\u8f93\u5165 c \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%d \", c[i]);\n    }\n\n    \n    compute_new_means(mx, my, sx, sy, c, size);\n\n    printf(\"\\n\u8ba1\u7b97\u65b0\u5747\u503c\u540e\u7684 mx \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", mx[i]);\n    }\n\n    printf(\"\\n\u8ba1\u7b97\u65b0\u5747\u503c\u540e\u7684 my \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%.2f \", my[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void compute_new_means(float* mx, float* my, const float* sx, const float* sy, const int* c) {\n    const int cluster = threadIdx.x;\n\n    if (cluster < blockDim.x) {\n        const int count = max(1, c[cluster]);\n        mx[cluster] = sx[cluster] / count;\n        my[cluster] = sy[cluster] / count;\n    }\n}\n\nint main() {\n    const int clusters = 5;  \n    const int threadsPerBlock = clusters;\n    const int blocksPerGrid = 1;  \n\n    \n    float* h_mx = (float*)malloc(clusters * sizeof(float));\n    float* h_my = (float*)malloc(clusters * sizeof(float));\n    float* h_sx = (float*)malloc(clusters * sizeof(float));\n    float* h_sy = (float*)malloc(clusters * sizeof(float));\n    int* h_c = (int*)malloc(clusters * sizeof(int));\n\n    \n    for (int i = 0; i < clusters; ++i) {\n        h_sx[i] = i + 1;\n        h_sy[i] = i + 1;\n        h_c[i] = i + 1;\n    }\n\n    \n    float* d_mx;\n    float* d_my;\n    float* d_sx;\n    float* d_sy;\n    int* d_c;\n    cudaMalloc((void**)&d_mx, clusters * sizeof(float));\n    cudaMalloc((void**)&d_my, clusters * sizeof(float));\n    cudaMalloc((void**)&d_sx, clusters * sizeof(float));\n    cudaMalloc((void**)&d_sy, clusters * sizeof(float));\n    cudaMalloc((void**)&d_c, clusters * sizeof(int));\n\n    \n    cudaMemcpy(d_mx, h_mx, clusters * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_my, h_my, clusters * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_sx, h_sx, clusters * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_sy, h_sy, clusters * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_c, h_c, clusters * sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    compute_new_means<<<blocksPerGrid, threadsPerBlock>>>(d_mx, d_my, d_sx, d_sy, d_c);\n\n    \n    cudaMemcpy(h_mx, d_mx, clusters * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_my, d_my, clusters * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    printf(\"New means:\\n\");\n    for (int i = 0; i < clusters; ++i) {\n        printf(\"(%f, %f)\\n\", h_mx[i], h_my[i]);\n    }\n\n    \n    free(h_mx);\n    free(h_my);\n    free(h_sx);\n    free(h_sy);\n    free(h_c);\n    cudaFree(d_mx);\n    cudaFree(d_my);\n    cudaFree(d_sx);\n    cudaFree(d_sy);\n    cudaFree(d_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "74",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid copy_array_d2d(double **src, double **dst, int m, int n) {\n    int i, j;\n    for (i = 1; i < m + 1; i++)\n        for (j = 1; j < n + 1; j++)\n            dst[i][j] = src[i][j];\n}\n\nint main() {\n    \n    int m = 3;\n    int n = 4;\n\n    \n    double **src = (double **)malloc((m + 2) * sizeof(double *));\n    for (int i = 0; i < m + 2; i++) {\n        src[i] = (double *)malloc((n + 2) * sizeof(double));\n        for (int j = 0; j < n + 2; j++) {\n            src[i][j] = i * (n + 2) + j; \n        }\n    }\n\n    \n    double **dst = (double **)malloc((m + 2) * sizeof(double *));\n    for (int i = 0; i < m + 2; i++) {\n        dst[i] = (double *)malloc((n + 2) * sizeof(double));\n    }\n\n    \n    copy_array_d2d(src, dst, m, n);\n\n    \n    printf(\"\u6e90\u6570\u7ec4 src\uff1a\\n\");\n    for (int i = 0; i < m + 2; i++) {\n        for (int j = 0; j < n + 2; j++) {\n            printf(\"%.2f \", src[i][j]);\n        }\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n\u76ee\u6807\u6570\u7ec4 dst\uff08\u590d\u5236\u540e\uff09\uff1a\\n\");\n    for (int i = 0; i < m + 2; i++) {\n        for (int j = 0; j < n + 2; j++) {\n            printf(\"%.2f \", dst[i][j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    for (int i = 0; i < m + 2; i++) {\n        free(src[i]);\n        free(dst[i]);\n    }\n    free(src);\n    free(dst);\n\n    return 0;\n}\n",
        "cuda_code": "#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <stdio.h>\n\n__global__ void copy_array_d2d(double** src, double** dst, int m, int n) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (i < m && j < n) {\n        dst[i][j] = src[i][j];\n    }\n}\n\nint main() {\n    const int m = 10; \n    const int n = 5;  \n\n    \n    double** h_src = new double*[m];\n    double** h_dst = new double*[m];\n    for (int i = 0; i < m; ++i) {\n        h_src[i] = new double[n];\n        h_dst[i] = new double[n];\n        for (int j = 0; j < n; ++j) {\n            h_src[i][j] = i * n + j; \n        }\n    }\n\n    \n    double** d_src;\n    double** d_dst;\n    cudaMalloc((void**)&d_src, m * sizeof(double*));\n    cudaMalloc((void**)&d_dst, m * sizeof(double*));\n\n    for (int i = 0; i < m; ++i) {\n        cudaMalloc((void**)&d_src[i], n * sizeof(double));\n        cudaMalloc((void**)&d_dst[i], n * sizeof(double));\n        cudaMemcpy(d_src[i], h_src[i], n * sizeof(double), cudaMemcpyHostToDevice);\n    }\n\n    \n    dim3 blockSize(16, 16);\n    dim3 gridSize((m + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);\n    copy_array_d2d<<<gridSize, blockSize>>>(d_src, d_dst, m, n);\n\n    \n    for (int i = 0; i < m; ++i) {\n        cudaMemcpy(h_dst[i], d_dst[i], n * sizeof(double), cudaMemcpyDeviceToHost);\n    }\n\n    \n    printf(\"Original array:\\n\");\n    for (int i = 0; i < m; ++i) {\n        for (int j = 0; j < n; ++j) {\n            printf(\"%f \", h_src[i][j]);\n        }\n        printf(\"\\n\");\n    }\n\n    printf(\"\\nCopied array:\\n\");\n    for (int i = 0; i < m; ++i) {\n        for (int j = 0; j < n; ++j) {\n            printf(\"%f \", h_dst[i][j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    for (int i = 0; i < m; ++i) {\n        cudaFree(d_src[i]);\n        cudaFree(d_dst[i]);\n        delete[] h_src[i];\n        delete[] h_dst[i];\n    }\n\n    cudaFree(d_src);\n    cudaFree(d_dst);\n    delete[] h_src;\n    delete[] h_dst;\n\n    return 0;\n}\n"
    },
    {
        "id": "75",
        "c_code": "#include <stdio.h>\n\nvoid InitCCL(int labelList[], int reference[], int width, int height) {\n    int x, y;\n    for (x = 0; x < width; x++) {\n        for (y = 0; y < height; y++) {\n            int id = x + y * width;\n            labelList[id] = reference[id] = id;\n        }\n    }\n}\n\nint main() {\n    \n    int width = 3;\n    int height = 3;\n\n    \n    int *labelList = new int[width * height];\n    int *reference = new int[width * height];\n\n    \n    InitCCL(labelList, reference, width, height);\n\n    \n    printf(\"\u521d\u59cb\u5316\u540e\u7684 labelList \u6570\u7ec4\uff1a\\n\");\n    for (int y = 0; y < height; y++) {\n        for (int x = 0; x < width; x++) {\n            int id = x + y * width;\n            printf(\"%d \", labelList[id]);\n        }\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n\u521d\u59cb\u5316\u540e\u7684 reference \u6570\u7ec4\uff1a\\n\");\n    for (int y = 0; y < height; y++) {\n        for (int x = 0; x < width; x++) {\n            int id = x + y * width;\n            printf(\"%d \", reference[id]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    delete[] labelList;\n    delete[] reference;\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void InitCCL(int labelList[], int reference[], int width, int height) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (x >= width || y >= height) return;\n\n    int id = x + y * width;\n    labelList[id] = reference[id] = id;\n}\n\nint main() {\n    \n    int width = 512;\n    int height = 512;\n\n    \n    dim3 gridSize((width + 15) / 16, (height + 15) / 16);\n    dim3 blockSize(16, 16);\n\n    \n    int* h_labelList = (int*)malloc(width * height * sizeof(int));\n    int* h_reference = (int*)malloc(width * height * sizeof(int));\n\n    \n    int* d_labelList, * d_reference;\n    cudaMalloc((void**)&d_labelList, width * height * sizeof(int));\n    cudaMalloc((void**)&d_reference, width * height * sizeof(int));\n\n    \n    InitCCL<<<gridSize, blockSize>>>(d_labelList, d_reference, width, height);\n\n    \n    cudaMemcpy(h_labelList, d_labelList, width * height * sizeof(int), cudaMemcpyDeviceToHost);\n    cudaMemcpy(h_reference, d_reference, width * height * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_labelList);\n    cudaFree(d_reference);\n\n    \n    free(h_labelList);\n    free(h_reference);\n\n    return 0;\n}\n"
    },
    {
        "id": "76",
        "c_code": "#include <stdio.h>\n\nvoid cpu_set_sg(int *sxz, int sxbeg, int szbeg, int jsx, int jsz, int ns, int npml, int nnz) {\n    for (int id = 0; id < ns; id++) {\n        sxz[id] = nnz * (sxbeg + id * jsx + npml) + (szbeg + id * jsz + npml);\n    }\n}\n\nint main() {\n    \n    int ns = 3;   \n    int *sxz = new int[ns];\n\n    \n    cpu_set_sg(sxz, 1, 2, 3, 4, ns, 5, 6);\n\n    \n    printf(\"\u521d\u59cb\u5316\u540e\u7684 sxz \u6570\u7ec4\uff1a\\n\");\n    for (int id = 0; id < ns; id++) {\n        printf(\"%d \", sxz[id]);\n    }\n\n    \n    delete[] sxz;\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void cuda_set_sg(int* sxz, int sxbeg, int szbeg, int jsx, int jsz, int ns, int npml, int nnz) {\n    int id = threadIdx.x + blockDim.x * blockIdx.x;\n\n    if (id < ns) {\n        sxz[id] = nnz * (sxbeg + id * jsx + npml) + (szbeg + id * jsz + npml);\n    }\n}\n\nint main() {\n    \n    int ns = 512;  \n    int npml = 10;  \n    int nnz = 100;  \n    int sxbeg = 0;\n    int szbeg = 0;\n    int jsx = 1;\n    int jsz = 1;\n\n    \n    int* h_sxz = (int*)malloc(ns * sizeof(int));\n\n    \n    int* d_sxz;\n    cudaMalloc((void**)&d_sxz, ns * sizeof(int));\n\n    \n    dim3 gridSize((ns + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    cuda_set_sg<<<gridSize, blockSize>>>(d_sxz, sxbeg, szbeg, jsx, jsz, ns, npml, nnz);\n\n    \n    cudaMemcpy(h_sxz, d_sxz, ns * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_sxz);\n\n    \n    free(h_sxz);\n\n    return 0;\n}\n"
    },
    {
        "id": "77",
        "c_code": "#include <stdio.h>\n\nvoid addMatrix(float *a, float *b, float *c, int N) {\n    int i, j, idx;\n    for (i = 0; i < N; i++) {\n        for (j = 0; j < N; j++) {\n            idx = i * N + j;\n            a[idx] = b[idx] + c[idx];\n        }\n    }\n}\n\nint main() {\n    \n    int N = 3;   \n    float *a = new float[N * N];\n    float *b = new float[N * N];\n    float *c = new float[N * N];\n\n    \n\n    \n    addMatrix(a, b, c, N);\n\n    \n    printf(\"\u77e9\u9635\u76f8\u52a0\u540e\u7684\u7ed3\u679c\uff08a\u77e9\u9635\uff09\uff1a\\n\");\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            int idx = i * N + j;\n            printf(\"%.2f \", a[idx]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    delete[] a;\n    delete[] b;\n    delete[] c;\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void addMatrixGPU(float* a, float* b, float* c, int N) {\n    int j = threadIdx.x + blockIdx.x * blockDim.x;\n    int i = threadIdx.y + blockIdx.y * blockDim.y;\n\n    if ((i < N) && (j < N)) {\n        int idx = i * N + j;\n        a[idx] = b[idx] + c[idx];\n    }\n}\n\nint main() {\n    \n    int N = 512;\n\n    \n    float* h_a = (float*)malloc(N * N * sizeof(float));\n    float* h_b = (float*)malloc(N * N * sizeof(float));\n    float* h_c = (float*)malloc(N * N * sizeof(float));\n\n    \n\n    \n    float* d_a, * d_b, * d_c;\n    cudaMalloc((void**)&d_a, N * N * sizeof(float));\n    cudaMalloc((void**)&d_b, N * N * sizeof(float));\n    cudaMalloc((void**)&d_c, N * N * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((N + 15) / 16, (N + 15) / 16);\n    dim3 blockSize(16, 16);\n\n    \n    addMatrixGPU<<<gridSize, blockSize>>>(d_a, d_b, d_c, N);\n\n    \n\n    \n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    \n    free(h_a);\n    free(h_b);\n    free(h_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "78",
        "c_code": "#include <stdio.h>\n\nvoid resizedClsScore_cpu(const float *score, const float *score_factors, float *output, int dims) {\n    for (int tid = 0; tid < dims; tid++) {\n        if (score[tid] == (-1)) {\n            output[tid] = -1;\n        } else {\n            output[tid] = score[tid] * score_factors[tid];\n        }\n    }\n}\n\nint main() {\n    \n    int dims = 5;   \n    float *score = new float[dims];\n    float *score_factors = new float[dims];\n    float *output = new float[dims];\n\n    \n\n    \n    resizedClsScore_cpu(score, score_factors, output, dims);\n\n    \n    printf(\"\u5904\u7406\u540e\u7684 output \u6570\u7ec4\uff1a\\n\");\n    for (int tid = 0; tid < dims; tid++) {\n        printf(\"%.2f \", output[tid]);\n    }\n\n    \n    delete[] score;\n    delete[] score_factors;\n    delete[] output;\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void resizedClsScore(const float* score, const float* score_factors, float* output, int dims) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid >= dims) {\n        return;\n    }\n\n    if (score[tid] == (-1)) {\n        output[tid] = -1;\n    } else {\n        output[tid] = score[tid] * score_factors[tid];\n    }\n}\n\nint main() {\n    \n    int dims = 512;\n\n    \n    float* h_score = (float*)malloc(dims * sizeof(float));\n    float* h_score_factors = (float*)malloc(dims * sizeof(float));\n    float* h_output = (float*)malloc(dims * sizeof(float));\n\n    \n\n    \n    float* d_score, * d_score_factors, * d_output;\n    cudaMalloc((void**)&d_score, dims * sizeof(float));\n    cudaMalloc((void**)&d_score_factors, dims * sizeof(float));\n    cudaMalloc((void**)&d_output, dims * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((dims + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    resizedClsScore<<<gridSize, blockSize>>>(d_score, d_score_factors, d_output, dims);\n\n    \n\n    \n    cudaFree(d_score);\n    cudaFree(d_score_factors);\n    cudaFree(d_output);\n\n    \n    free(h_score);\n    free(h_score_factors);\n    free(h_output);\n\n    return 0;\n}\n"
    },
    {
        "id": "79",
        "c_code": " \n#include <stdio.h>\n#include <math.h>\n\nvoid l1_cpu(int n, float *pred, float *truth, float *delta, float *error) {\n    for (int i = 0; i < n; ++i) {\n        float diff = truth[i] - pred[i];\n        error[i] = fabs(diff);\n        delta[i] = diff > 0 ? 1 : -1;\n    }\n}\n\nint main() {\n    \n    int n = 5;   \n    float *pred = new float[n];\n    float *truth = new float[n];\n    float *delta = new float[n];\n    float *error = new float[n];\n\n    \n\n    \n    l1_cpu(n, pred, truth, delta, error);\n\n    \n    printf(\"\u5904\u7406\u540e\u7684 delta \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < n; i++) {\n        printf(\"%.2f \", delta[i]);\n    }\n\n    printf(\"\\n\u5904\u7406\u540e\u7684 error \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < n; i++) {\n        printf(\"%.2f \", error[i]);\n    }\n\n    \n    delete[] pred;\n    delete[] truth;\n    delete[] delta;\n    delete[] error;\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <cmath>\n\n\n__global__ void l1_kernel(int n, float* pred, float* truth, float* delta, float* error) {\n    int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;\n\n    if (i < n) {\n        float diff = truth[i] - pred[i];\n        error[i] = fabs(diff);\n        delta[i] = (diff > 0) ? 1 : -1;\n    }\n}\n\nint main() {\n    \n    int n = 512;\n\n    \n    float* h_pred = (float*)malloc(n * sizeof(float));\n    float* h_truth = (float*)malloc(n * sizeof(float));\n    float* h_delta = (float*)malloc(n * sizeof(float));\n    float* h_error = (float*)malloc(n * sizeof(float));\n\n    \n\n    \n    float* d_pred, * d_truth, * d_delta, * d_error;\n    cudaMalloc((void**)&d_pred, n * sizeof(float));\n    cudaMalloc((void**)&d_truth, n * sizeof(float));\n    cudaMalloc((void**)&d_delta, n * sizeof(float));\n    cudaMalloc((void**)&d_error, n * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((n + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    l1_kernel<<<gridSize, blockSize>>>(n, d_pred, d_truth, d_delta, d_error);\n\n    \n\n    \n    cudaFree(d_pred);\n    cudaFree(d_truth);\n    cudaFree(d_delta);\n    cudaFree(d_error);\n\n    \n    free(h_pred);\n    free(h_truth);\n    free(h_delta);\n    free(h_error);\n\n    return 0;\n}\n"
    },
    {
        "id": "8",
        "c_code": "#include <stdio.h>\n\nvoid initialArray0_cpu(int tasks, int *f3) {\n    for (int i = 0; i < tasks; i++) {\n        f3[i] = 0;\n    }\n}\n\nint main() {\n    \n    int numTasks = 8;\n    int array[numTasks];\n\n    printf(\"\u539f\u59cb\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numTasks; i++) {\n        printf(\"%d \", array[i]);\n    }\n\n    \n    initialArray0_cpu(numTasks, array);\n\n    printf(\"\\n\u521d\u59cb\u5316\u540e\u7684\u6570\u7ec4\uff1a\");\n    for (int i = 0; i < numTasks; i++) {\n        printf(\"%d \", array[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void initialArray0(int tasks, int* f3) {\n    for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < tasks; i += blockDim.x * gridDim.x) {\n        f3[i] = 0;\n    }\n}\n\nint main() {\n    \n    int numTasks = 1000;\n\n    \n    int* h_f3 = (int*)malloc(numTasks * sizeof(int));\n\n    \n    int* d_f3;\n    cudaMalloc((void**)&d_f3, numTasks * sizeof(int));\n\n    \n    int blockSize = 256;\n    int gridSize = (numTasks + blockSize - 1) / blockSize;\n\n    \n    initialArray0<<<gridSize, blockSize>>>(numTasks, d_f3);\n\n    \n    cudaMemcpy(h_f3, d_f3, numTasks * sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%d \", h_f3[i]);\n    }\n\n    \n    free(h_f3);\n    cudaFree(d_f3);\n\n    return 0;\n}\n"
    },
    {
        "id": "80",
        "c_code": "#include <stdio.h>\n\nvoid AddMatrixOnCPU(int *A, int *B, int *C, int nx, int ny) {\n    int i, j;\n    int cnt = 0;\n    for (j = 0; j < ny; j++) {\n        for (i = 0; i < nx; i++) {\n            C[cnt] = A[cnt] + B[cnt];\n            cnt++;\n        }\n    }\n}\n\nint main() {\n    \n    int nx = 3;   \n    int ny = 3;   \n    int size = nx * ny;\n    int *A = new int[size];\n    int *B = new int[size];\n    int *C = new int[size];\n\n    \n\n    \n    AddMatrixOnCPU(A, B, C, nx, ny);\n\n    \n    printf(\"\u5904\u7406\u540e\u7684 C \u77e9\u9635\uff1a\\n\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%d \", C[i]);\n    }\n\n    \n    delete[] A;\n    delete[] B;\n    delete[] C;\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void AddMatrixOnGPU(float* A, float* B, float* C, int nx, int ny) {\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int j = threadIdx.y + blockIdx.y * blockDim.y;\n    int idx = i * nx + j;\n\n    if (i < nx && j < ny) {\n        C[idx] = A[idx] + B[idx];\n    }\n}\n\nint main() {\n    \n    int nx = 512;\n    int ny = 512;\n\n    \n    float* h_A = (float*)malloc(nx * ny * sizeof(float));\n    float* h_B = (float*)malloc(nx * ny * sizeof(float));\n    float* h_C = (float*)malloc(nx * ny * sizeof(float));\n\n    \n\n    \n    float* d_A, * d_B, * d_C;\n    cudaMalloc((void**)&d_A, nx * ny * sizeof(float));\n    cudaMalloc((void**)&d_B, nx * ny * sizeof(float));\n    cudaMalloc((void**)&d_C, nx * ny * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((nx + 15) / 16, (ny + 15) / 16);\n    dim3 blockSize(16, 16);\n\n    \n    AddMatrixOnGPU<<<gridSize, blockSize>>>(d_A, d_B, d_C, nx, ny);\n\n    \n\n    \n    cudaFree(d_A);\n    cudaFree(d_B);\n    cudaFree(d_C);\n\n    \n    free(h_A);\n    free(h_B);\n    free(h_C);\n\n    return 0;\n}\n"
    },
    {
        "id": "81",
        "c_code": "#include <stdio.h>\n\nvoid LreluForward(float *srcData, float *dstData, int data_size, float alpha) {\n    for (int i = 0; i < data_size; i++) {\n        dstData[i] = srcData[i] > 0 ? srcData[i] : srcData[i] * alpha;\n    }\n}\n\nint main() {\n    \n    int data_size = 5;   \n    float alpha = 0.01;   \n    float *srcData = new float[data_size];\n    float *dstData = new float[data_size];\n\n    \n\n    \n    LreluForward(srcData, dstData, data_size, alpha);\n\n    \n    printf(\"\u5904\u7406\u540e\u7684 dstData \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < data_size; i++) {\n        printf(\"%.2f \", dstData[i]);\n    }\n\n    \n    delete[] srcData;\n    delete[] dstData;\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void LreluForward(float* srcData, float* dstData, int data_size, float alpha) {\n    int thread_index = threadIdx.x + blockIdx.x * blockDim.x;\n    int num_threads = blockDim.x * gridDim.x;\n\n    for (int i = 0; i < data_size; i += num_threads) {\n        int index = i + thread_index;\n\n        if (index < data_size) {\n            dstData[index] = (srcData[index] > 0) ? srcData[index] : srcData[index] * alpha;\n        }\n    }\n}\n\nint main() {\n    \n    int data_size = 512;\n    float alpha = 0.01; \n\n    \n    float* h_srcData = (float*)malloc(data_size * sizeof(float));\n    float* h_dstData = (float*)malloc(data_size * sizeof(float));\n\n    \n\n    \n    float* d_srcData, * d_dstData;\n    cudaMalloc((void**)&d_srcData, data_size * sizeof(float));\n    cudaMalloc((void**)&d_dstData, data_size * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((data_size + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    LreluForward<<<gridSize, blockSize>>>(d_srcData, d_dstData, data_size, alpha);\n\n    \n\n    \n    cudaFree(d_srcData);\n    cudaFree(d_dstData);\n\n    \n    free(h_srcData);\n    free(h_dstData);\n\n    return 0;\n}\n"
    },
    {
        "id": "82",
        "c_code": "#include <stdio.h>\n\nvoid filterFFT_cpu(float *FFT, float *filter, int nxprj2, int nviews, float scale) {\n    for (int i = 0; i < nviews; i++) {\n        for (int j = 0; j < nxprj2; j++) {\n            FFT[i * nxprj2 + j] *= filter[i * nxprj2 + j] * scale;\n        }\n    }\n}\n\nint main() {\n    \n    int nxprj2 = 3;    \n    int nviews = 2;    \n    float scale = 0.5; \n    float *FFT = new float[nxprj2 * nviews];\n    float *filter = new float[nxprj2 * nviews];\n\n    \n\n    \n    filterFFT_cpu(FFT, filter, nxprj2, nviews, scale);\n\n    \n    printf(\"\u5904\u7406\u540e\u7684 FFT \u6570\u7ec4\uff1a\\n\");\n    for (int i = 0; i < nviews; i++) {\n        for (int j = 0; j < nxprj2; j++) {\n            printf(\"%.2f \", FFT[i * nxprj2 + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    delete[] FFT;\n    delete[] filter;\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void filterFFT(float* FFT, float* filter, int nxprj2, int nviews, float scale) {\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\n    int i = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (i < nviews && j < nxprj2) {\n        FFT[i * nxprj2 + j] *= filter[i * nxprj2 + j] * scale;\n    }\n}\n\nint main() {\n    \n    int nxprj2 = 512;\n    int nviews = 512;\n    float scale = 0.5; \n\n    \n    float* h_FFT = (float*)malloc(nxprj2 * nviews * sizeof(float));\n    float* h_filter = (float*)malloc(nxprj2 * nviews * sizeof(float));\n\n    \n\n    \n    float* d_FFT, * d_filter;\n    cudaMalloc((void**)&d_FFT, nxprj2 * nviews * sizeof(float));\n    cudaMalloc((void**)&d_filter, nxprj2 * nviews * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((nxprj2 + 15) / 16, (nviews + 15) / 16);\n    dim3 blockSize(16, 16);\n\n    \n    filterFFT<<<gridSize, blockSize>>>(d_FFT, d_filter, nxprj2, nviews, scale);\n\n    \n\n    \n    cudaFree(d_FFT);\n    cudaFree(d_filter);\n\n    \n    free(h_FFT);\n    free(h_filter);\n\n    return 0;\n}\n"
    },
    {
        "id": "83",
        "c_code": "#include <stdio.h>\n\nvoid convertFloatToRGBA_cpu(char *out_image, const float *in_image, int width, int height) {\n    for (int x = 0; x < width; x++) {\n        for (int y = 0; y < height; y++) {\n            int IND = (y * width + x) * 4;  \n            float val = in_image[y * width + x];\n\n            \n            char temp = static_cast<char>(val * 255.0f);\n\n            \n            out_image[IND] = temp;     \n            out_image[IND + 1] = temp; \n            out_image[IND + 2] = temp; \n            out_image[IND + 3] = 255;  \n        }\n    }\n}\n\nint main() {\n    \n    int width = 3;   \n    int height = 2;  \n    float *in_image = new float[width * height];  \n    char *out_image = new char[width * height * 4]; \n\n    \n\n    \n    convertFloatToRGBA_cpu(out_image, in_image, width, height);\n\n    \n    for (int i = 0; i < width * height * 4; i++) {\n        printf(\"%d \", out_image[i]);\n    }\n\n    \n    delete[] in_image;\n    delete[] out_image;\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void convertFloatToRGBA_kernel(char* out_image, const float* in_image, int width, int height) {\n    const int x = blockIdx.x * blockDim.x + threadIdx.x;\n    const int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (x < width && y < height) {\n        int IND = y * width + x;\n        float val = in_image[IND];\n        char temp = 255;\n        out_image[IND] = temp;\n    }\n}\n\nint main() {\n    \n    int width = 512;\n    int height = 512;\n\n    \n    char* h_out_image = (char*)malloc(width * height * sizeof(char));\n    float* h_in_image = (float*)malloc(width * height * sizeof(float));\n\n    \n\n    \n    char* d_out_image;\n    float* d_in_image;\n    cudaMalloc((void**)&d_out_image, width * height * sizeof(char));\n    cudaMalloc((void**)&d_in_image, width * height * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((width + 15) / 16, (height + 15) / 16);\n    dim3 blockSize(16, 16);\n\n    \n    convertFloatToRGBA_kernel<<<gridSize, blockSize>>>(d_out_image, d_in_image, width, height);\n\n    \n\n    \n    cudaFree(d_out_image);\n    cudaFree(d_in_image);\n\n    \n    free(h_out_image);\n    free(h_in_image);\n\n    return 0;\n}\n"
    },
    {
        "id": "84",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid convertEdgeMaskToFloatCpu(float *d_output, unsigned char *d_input, unsigned int width, unsigned int height) {\n    for (int x = 0; x < width; x++) {\n        for (int y = 0; y < height; y++) {\n            d_output[y * width + x] = fminf(d_input[y * width + x], d_input[width * height + y * width + x]);\n        }\n    }\n}\n\nint main() {\n    \n    unsigned int width = 5;\n    unsigned int height = 5;\n\n    \n    unsigned char *d_input = (unsigned char *)malloc(width * height * 2 * sizeof(unsigned char));  \n    float *d_output = (float *)malloc(width * height * sizeof(float));\n\n    \n    for (int i = 0; i < width * height * 2; i++) {\n        d_input[i] = i % 256;  \n    }\n\n    \n    convertEdgeMaskToFloatCpu(d_output, d_input, width, height);\n\n    \n    for (int i = 0; i < width * height; i++) {\n        printf(\"%f \", d_output[i]);\n    }\n\n    \n    free(d_input);\n    free(d_output);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void convertEdgeMaskToFloatDevice(float* d_output, unsigned char* d_input, unsigned int width, unsigned int height) {\n    const int x = blockIdx.x * blockDim.x + threadIdx.x;\n    const int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (x >= width || y >= height) return;\n\n    d_output[y * width + x] = min(d_input[y * width + x], d_input[width * height + y * width + x]);\n}\n\nint main() {\n    \n    unsigned int width = 512;\n    unsigned int height = 512;\n\n    \n    float* h_output = (float*)malloc(width * height * sizeof(float));\n    unsigned char* h_input = (unsigned char*)malloc(2 * width * height * sizeof(unsigned char));\n\n    \n\n    \n    float* d_output;\n    unsigned char* d_input;\n    cudaMalloc((void**)&d_output, width * height * sizeof(float));\n    cudaMalloc((void**)&d_input, 2 * width * height * sizeof(unsigned char));\n\n    \n\n    \n    dim3 gridSize((width + 15) / 16, (height + 15) / 16);\n    dim3 blockSize(16, 16);\n\n    \n    convertEdgeMaskToFloatDevice<<<gridSize, blockSize>>>(d_output, d_input, width, height);\n\n    \n\n    \n    cudaFree(d_output);\n    cudaFree(d_input);\n\n    \n    free(h_output);\n    free(h_input);\n\n    return 0;\n}\n"
    },
    {
        "id": "85",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid gpu_matrix_transpose(int *mat_in, int *mat_out, unsigned int rows, unsigned int cols) {\n    unsigned int idx;\n    unsigned int idy;\n\n    for (idx = 0; idx < cols; idx++) {\n        for (idy = 0; idy < rows; idy++) {\n            unsigned int pos = idy * cols + idx;\n            unsigned int trans_pos = idx * rows + idy;\n            mat_out[trans_pos] = mat_in[pos];\n        }\n    }\n}\n\nint main() {\n    \n    unsigned int rows = 3;\n    unsigned int cols = 4;\n\n    \n    int *mat_in = (int *)malloc(rows * cols * sizeof(int));\n    int *mat_out = (int *)malloc(rows * cols * sizeof(int));\n\n    \n    for (unsigned int i = 0; i < rows * cols; i++) {\n        mat_in[i] = i;\n    }\n\n    \n    gpu_matrix_transpose(mat_in, mat_out, rows, cols);\n\n    \n    for (unsigned int i = 0; i < rows * cols; i++) {\n        printf(\"%d \", mat_out[i]);\n    }\n\n    \n    free(mat_in);\n    free(mat_out);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void gpu_matrix_transpose(int* mat_in, int* mat_out, unsigned int rows, unsigned int cols) {\n    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    unsigned int idy = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (idx < cols && idy < rows) {\n        unsigned int pos = idy * cols + idx;\n        unsigned int trans_pos = idx * rows + idy;\n        mat_out[trans_pos] = mat_in[pos];\n    }\n}\n\nint main() {\n    \n    unsigned int rows = 512;\n    unsigned int cols = 512;\n\n    \n    int* h_mat_in = (int*)malloc(rows * cols * sizeof(int));\n    int* h_mat_out = (int*)malloc(rows * cols * sizeof(int));\n\n    \n\n    \n    int* d_mat_in, * d_mat_out;\n    cudaMalloc((void**)&d_mat_in, rows * cols * sizeof(int));\n    cudaMalloc((void**)&d_mat_out, rows * cols * sizeof(int));\n\n    \n\n    \n    dim3 gridSize((cols + 15) / 16, (rows + 15) / 16);\n    dim3 blockSize(16, 16);\n\n    \n    gpu_matrix_transpose<<<gridSize, blockSize>>>(d_mat_in, d_mat_out, rows, cols);\n\n    \n\n    \n    cudaFree(d_mat_in);\n    cudaFree(d_mat_out);\n\n    \n    free(h_mat_in);\n    free(h_mat_out);\n\n    return 0;\n}\n"
    },
    {
        "id": "86",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid LreluBackward(float *srcDiff, float *dstDiff, float *srcData, int data_size, float alpha) {\n    for (int i = 0; i < data_size; i++) {\n        dstDiff[i] = (srcData[i] > 0) ? srcDiff[i] * 1.0 : srcDiff[i] * alpha;\n    }\n}\n\nint main() {\n    \n    int data_size = 5;\n\n    \n    float *srcDiff = (float *)malloc(data_size * sizeof(float));\n    float *dstDiff = (float *)malloc(data_size * sizeof(float));\n    float *srcData = (float *)malloc(data_size * sizeof(float));\n\n    \n    for (int i = 0; i < data_size; i++) {\n        srcDiff[i] = i;\n        srcData[i] = i - 2.0;\n    }\n\n    \n    float alpha = 0.1;\n\n    \n    LreluBackward(srcDiff, dstDiff, srcData, data_size, alpha);\n\n    \n    printf(\"srcDiff: \");\n    for (int i = 0; i < data_size; i++) {\n        printf(\"%f \", srcDiff[i]);\n    }\n\n    printf(\"\\nsrcData: \");\n    for (int i = 0; i < data_size; i++) {\n        printf(\"%f \", srcData[i]);\n    }\n\n    printf(\"\\ndstDiff: \");\n    for (int i = 0; i < data_size; i++) {\n        printf(\"%f \", dstDiff[i]);\n    }\n\n    \n    free(srcDiff);\n    free(dstDiff);\n    free(srcData);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void LreluBackward(float* srcDiff, float* dstDiff, float* srcData, int data_size, float alpha) {\n    int thread_index = threadIdx.x + blockIdx.x * blockDim.x;\n    int num_threads = blockDim.x * gridDim.x;\n\n    for (int i = 0; i < data_size; i += num_threads) {\n        int index = i + thread_index;\n\n        if (index < data_size) {\n            dstDiff[index] = srcDiff[index] * ((srcData[index] > 0) + (srcData[index] <= 0) * alpha);\n        }\n    }\n}\n\nint main() {\n    \n    int data_size = 512;\n    float alpha = 0.01; \n\n    \n    float* h_srcDiff = (float*)malloc(data_size * sizeof(float));\n    float* h_dstDiff = (float*)malloc(data_size * sizeof(float));\n    float* h_srcData = (float*)malloc(data_size * sizeof(float));\n\n    \n\n    \n    float* d_srcDiff, * d_dstDiff, * d_srcData;\n    cudaMalloc((void**)&d_srcDiff, data_size * sizeof(float));\n    cudaMalloc((void**)&d_dstDiff, data_size * sizeof(float));\n    cudaMalloc((void**)&d_srcData, data_size * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((data_size + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    LreluBackward<<<gridSize, blockSize>>>(d_srcDiff, d_dstDiff, d_srcData, data_size, alpha);\n\n    \n\n    \n    cudaFree(d_srcDiff);\n    cudaFree(d_dstDiff);\n    cudaFree(d_srcData);\n\n    \n    free(h_srcDiff);\n    free(h_dstDiff);\n    free(h_srcData);\n\n    return 0;\n}\n"
    },
    {
        "id": "87",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nint cpuReduce(int *N, const int size) {\n    if (size == 1)\n        return N[0];\n\n    int stride = size / 2;\n\n    for (int i = 0; i < stride; i++)\n        N[i] += N[i + stride];\n\n    return cpuReduce(N, stride);\n}\n\nint main() {\n    \n    const int size = 8;\n\n    \n    int *N = (int *)malloc(size * sizeof(int));\n\n    \n    for (int i = 0; i < size; i++) {\n        N[i] = i + 1;\n    }\n\n    \n    int result = cpuReduce(N, size);\n\n    \n    printf(\"Reduced value: %d\\n\", result);\n\n    \n    free(N);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void gpuReduceRecursive(int* I, int* O, unsigned int n) {\n    unsigned int tid = threadIdx.x;\n    unsigned int idx = threadIdx.x + blockIdx.x * blockDim.x;\n\n    if (idx >= n) return;\n\n    int* N = I + blockIdx.x * blockDim.x;\n\n    for (int stride = 1; stride < blockDim.x; stride *= 2) {\n        if ((tid % (2 * stride)) == 0)\n            N[tid] += N[tid + stride];\n\n        __syncthreads();\n    }\n\n    if (tid == 0)\n        O[blockIdx.x] = N[0];\n}\n\nint main() {\n    \n    unsigned int n = 512;\n\n    \n    int* h_I = (int*)malloc(n * sizeof(int));\n    int* h_O = (int*)malloc((n + 255) / 256 * sizeof(int));\n\n    \n\n    \n    int* d_I, * d_O;\n    cudaMalloc((void**)&d_I, n * sizeof(int));\n    cudaMalloc((void**)&d_O, (n + 255) / 256 * sizeof(int));\n\n    \n\n    \n    dim3 gridSize((n + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    gpuReduceRecursive<<<gridSize, blockSize>>>(d_I, d_O, n);\n\n    \n\n    \n    cudaFree(d_I);\n    cudaFree(d_O);\n\n    \n    free(h_I);\n    free(h_O);\n\n    return 0;\n}\n"
    },
    {
        "id": "88",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid devidecountInnerCPU(long Xsize, long Ysize, long Zsize, double *p, double *pn, int *pcountinner) {\n    for (int tid = 0; tid < Xsize * Ysize * Zsize; tid++) {\n        if (pcountinner[tid] > 1) {\n            p[tid] = pn[tid] / pcountinner[tid];\n            pn[tid] = 0;\n        }\n    }\n}\n\nint main() {\n    \n    long Xsize = 3;\n    long Ysize = 3;\n    long Zsize = 3;\n\n    \n    double *p = (double *)malloc(Xsize * Ysize * Zsize * sizeof(double));\n    double *pn = (double *)malloc(Xsize * Ysize * Zsize * sizeof(double));\n    int *pcountinner = (int *)malloc(Xsize * Ysize * Zsize * sizeof(int));\n\n    \n    for (int i = 0; i < Xsize * Ysize * Zsize; i++) {\n        p[i] = i + 1;\n        pn[i] = 2 * i;\n        pcountinner[i] = i % 3;  \n    }\n\n    \n    devidecountInnerCPU(Xsize, Ysize, Zsize, p, pn, pcountinner);\n\n    \n    printf(\"p: \");\n    for (int i = 0; i < Xsize * Ysize * Zsize; i++) {\n        printf(\"%f \", p[i]);\n    }\n\n    printf(\"\\npn: \");\n    for (int i = 0; i < Xsize * Ysize * Zsize; i++) {\n        printf(\"%f \", pn[i]);\n    }\n\n    \n    free(p);\n    free(pn);\n    free(pcountinner);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void devidecountInner(long Xsize, long Ysize, long Zsize, double* p, double* pn, int* pcountinner) {\n    long tid = threadIdx.x + blockDim.x * blockIdx.x;\n\n    while (tid < Xsize * Ysize * Zsize) {\n        if (pcountinner[tid] > 1) {\n            p[tid] = pn[tid] / pcountinner[tid];\n            pn[tid] = 0;\n        }\n\n        tid += blockDim.x * gridDim.x;\n    }\n}\n\nint main() {\n    \n    long Xsize = 512;\n    long Ysize = 512;\n    long Zsize = 512;\n\n    \n    double* h_p = (double*)malloc(Xsize * Ysize * Zsize * sizeof(double));\n    double* h_pn = (double*)malloc(Xsize * Ysize * Zsize * sizeof(double));\n    int* h_pcountinner = (int*)malloc(Xsize * Ysize * Zsize * sizeof(int));\n\n    \n\n    \n    double* d_p, * d_pn;\n    int* d_pcountinner;\n    cudaMalloc((void**)&d_p, Xsize * Ysize * Zsize * sizeof(double));\n    cudaMalloc((void**)&d_pn, Xsize * Ysize * Zsize * sizeof(double));\n    cudaMalloc((void**)&d_pcountinner, Xsize * Ysize * Zsize * sizeof(int));\n\n    \n\n    \n    dim3 gridSize((Xsize * Ysize * Zsize + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    devidecountInner<<<gridSize, blockSize>>>(Xsize, Ysize, Zsize, d_p, d_pn, d_pcountinner);\n\n    \n\n    \n    cudaFree(d_p);\n    cudaFree(d_pn);\n    cudaFree(d_pcountinner);\n\n    \n    free(h_p);\n    free(h_pn);\n    free(h_pcountinner);\n\n    return 0;\n}\n"
    },
    {
        "id": "89",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid cpuConvertToBits(int *bit_decisions, unsigned short *bit_stream, int dec_size) {\n    for (int dec_index = 0; dec_index < dec_size; dec_index++) {\n        int bit_index = dec_index * 2;\n        int curr_decision = bit_decisions[dec_index];\n        bit_stream[bit_index] = ((curr_decision & 2) >> 1);\n        bit_stream[bit_index + 1] = (curr_decision & 1);\n    }\n}\n\nint main() {\n    \n    int dec_size = 5;\n\n    \n    int *bit_decisions = (int *)malloc(dec_size * sizeof(int));\n    unsigned short *bit_stream = (unsigned short *)malloc(dec_size * 2 * sizeof(unsigned short));\n\n    \n    for (int i = 0; i < dec_size; i++) {\n        bit_decisions[i] = i % 4;  \n    }\n\n    \n    cpuConvertToBits(bit_decisions, bit_stream, dec_size);\n\n    \n    printf(\"bit_decisions: \");\n    for (int i = 0; i < dec_size; i++) {\n        printf(\"%d \", bit_decisions[i]);\n    }\n\n    printf(\"\\nbit_stream: \");\n    for (int i = 0; i < dec_size * 2; i++) {\n        printf(\"%hu \", bit_stream[i]);\n    }\n\n    \n    free(bit_decisions);\n    free(bit_stream);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void cudaConvertToBits(int* bit_decisions, unsigned short* bit_stream, int dec_size) {\n    int dec_index = (blockIdx.x * blockDim.x) + threadIdx.x;\n    int bit_index = dec_index * 2;\n\n    if (dec_index >= dec_size)\n        return;\n\n    int curr_decision = bit_decisions[dec_index];\n    bit_stream[bit_index] = ((curr_decision & 2) >> 1);\n    bit_stream[bit_index + 1] = (curr_decision & 1);\n}\n\nint main() {\n    \n    int dec_size = 512;\n\n    \n    int* h_bit_decisions = (int*)malloc(dec_size * sizeof(int));\n    unsigned short* h_bit_stream = (unsigned short*)malloc(dec_size * 2 * sizeof(unsigned short));\n\n    \n\n    \n    int* d_bit_decisions;\n    unsigned short* d_bit_stream;\n    cudaMalloc((void**)&d_bit_decisions, dec_size * sizeof(int));\n    cudaMalloc((void**)&d_bit_stream, dec_size * 2 * sizeof(unsigned short));\n\n    \n\n    \n    dim3 gridSize((dec_size + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    cudaConvertToBits<<<gridSize, blockSize>>>(d_bit_decisions, d_bit_stream, dec_size);\n\n    \n\n    \n    cudaFree(d_bit_decisions);\n    cudaFree(d_bit_stream);\n\n    \n    free(h_bit_decisions);\n    free(h_bit_stream);\n\n    return 0;\n}\n"
    },
    {
        "id": "9",
        "c_code": "#include <stdio.h>\n\nvoid add_vector_cpu(float *a, float *b, float *c, int size) {\n    for (int i = 0; i < size; ++i) {\n        c[i] = a[i] + b[i];\n    }\n}\n\nint main() {\n    \n    int vectorSize = 5;\n    float vectorA[] = {1.1, 2.2, 3.3, 4.4, 5.5};\n    float vectorB[] = {0.5, 1.5, 2.5, 3.5, 4.5};\n    float resultVector[vectorSize];\n\n    printf(\"\u5411\u91cf A\uff1a\");\n    for (int i = 0; i < vectorSize; i++) {\n        printf(\"%.2f \", vectorA[i]);\n    }\n\n    printf(\"\\n\u5411\u91cf B\uff1a\");\n    for (int i = 0; i < vectorSize; i++) {\n        printf(\"%.2f \", vectorB[i]);\n    }\n\n    \n    add_vector_cpu(vectorA, vectorB, resultVector, vectorSize);\n\n    printf(\"\\n\u76f8\u52a0\u540e\u7684\u5411\u91cf C\uff1a\");\n    for (int i = 0; i < vectorSize; i++) {\n        printf(\"%.2f \", resultVector[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <stdio.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n\n__global__ void VectorAdd(float* arrayA, float* arrayB, float* output) {\n    int idx = threadIdx.x;\n    output[idx] = arrayA[idx] + arrayB[idx];\n}\n\nint main() {\n    \n    int arraySize = 1000;\n\n    \n    float* h_arrayA = (float*)malloc(arraySize * sizeof(float));\n    float* h_arrayB = (float*)malloc(arraySize * sizeof(float));\n    float* h_output = (float*)malloc(arraySize * sizeof(float));\n\n    \n    for (int i = 0; i < arraySize; ++i) {\n        h_arrayA[i] = static_cast<float>(i);\n        h_arrayB[i] = static_cast<float>(2 * i);\n    }\n\n    \n    float* d_arrayA;\n    float* d_arrayB;\n    float* d_output;\n    cudaMalloc((void**)&d_arrayA, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_arrayB, arraySize * sizeof(float));\n    cudaMalloc((void**)&d_output, arraySize * sizeof(float));\n\n    \n    cudaMemcpy(d_arrayA, h_arrayA, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_arrayB, h_arrayB, arraySize * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n    int blockSize = 256;\n    int gridSize = (arraySize + blockSize - 1) / blockSize;\n\n    \n    VectorAdd<<<gridSize, blockSize>>>(d_arrayA, d_arrayB, d_output);\n\n    \n    cudaMemcpy(h_output, d_output, arraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n    \n    for (int i = 0; i < 10; ++i) {\n        printf(\"%f \", h_output[i]);\n    }\n\n    \n    free(h_arrayA);\n    free(h_arrayB);\n    free(h_output);\n    cudaFree(d_arrayA);\n    cudaFree(d_arrayB);\n    cudaFree(d_output);\n\n    return 0;\n}\n"
    },
    {
        "id": "90",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid copyAliasRow(int *devMat, int memWidth, int memHeight, int size) {\n    for (int devMatX = 0; devMatX < size; devMatX++) {\n        devMat[memWidth * 0 + devMatX] = devMat[memWidth * (memHeight - 2) + devMatX];\n        devMat[memWidth * (memHeight - 1) + devMatX] = devMat[memWidth * 1 + devMatX];\n    }\n}\n\nint main() {\n    \n    int memWidth = 4;\n    int memHeight = 4;\n    int size = memWidth;\n\n    \n    int *devMat = (int *)malloc(memWidth * memHeight * sizeof(int));\n\n    \n    for (int i = 0; i < memWidth * memHeight; i++) {\n        devMat[i] = i + 1;\n    }\n\n    \n    copyAliasRow(devMat, memWidth, memHeight, size);\n\n    \n    printf(\"devMat after copyAliasRow:\\n\");\n    for (int i = 0; i < memHeight; i++) {\n        for (int j = 0; j < memWidth; j++) {\n            printf(\"%d \", devMat[i * memWidth + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    free(devMat);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void copyAliasRow(int* devMat, int memWidth, int memHeight) {\n    int devMatX = blockIdx.x * blockDim.x + threadIdx.x + 1;\n\n    devMat[memWidth * 0 + devMatX] = devMat[memWidth * (memHeight - 2) + devMatX];\n    devMat[memWidth * (memHeight - 1) + devMatX] = devMat[memWidth * 1 + devMatX];\n}\n\nint main() {\n    \n    int memWidth = 512;\n    int memHeight = 512;\n\n    \n    int* h_devMat = (int*)malloc(memWidth * memHeight * sizeof(int));\n\n    \n\n    \n    int* d_devMat;\n    cudaMalloc((void**)&d_devMat, memWidth * memHeight * sizeof(int));\n\n    \n\n    \n    dim3 gridSize((memWidth - 1 + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    copyAliasRow<<<gridSize, blockSize>>>(d_devMat, memWidth, memHeight);\n\n    \n\n    \n    cudaFree(d_devMat);\n\n    \n    free(h_devMat);\n\n    return 0;\n}\n"
    },
    {
        "id": "91",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\ndouble *ObjFeatures_circularity(const int compCount, const int *areaRes, const double *perimeter) {\n    if (compCount > 0) {\n        double *circ = (double *)malloc(compCount * sizeof(double));\n        for (int i = 0; i < compCount; i++) {\n            circ[i] = (4.0 * 3.14159265359 * (double)areaRes[i]) / (perimeter[i] * perimeter[i]);\n        }\n        return circ;\n    }\n    return (double *)0;\n}\n\nint main() {\n    \n    const int compCount = 3;\n    int areaRes[] = {10, 15, 20};\n    double perimeter[] = {12.56, 18.85, 25.13};\n\n    \n    double *circ = ObjFeatures_circularity(compCount, areaRes, perimeter);\n\n    \n    printf(\"Circularity features:\\n\");\n    for (int i = 0; i < compCount; i++) {\n        printf(\"%f \", circ[i]);\n    }\n\n    \n    free(circ);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void circularity(const int compCount, const int* areaRes, const float* perimeterRes, float* circ) {\n    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n    if (tid < compCount) {\n        circ[tid] = (4.0 * 3.14159265359 * (float)areaRes[tid]) / (perimeterRes[tid] * perimeterRes[tid]);\n    }\n}\n\nint main() {\n    \n    int compCount = 512;\n\n    \n    int* h_areaRes = (int*)malloc(compCount * sizeof(int));\n    float* h_perimeterRes = (float*)malloc(compCount * sizeof(float));\n    float* h_circ = (float*)malloc(compCount * sizeof(float));\n\n    \n\n    \n    int* d_areaRes;\n    float* d_perimeterRes;\n    float* d_circ;\n    cudaMalloc((void**)&d_areaRes, compCount * sizeof(int));\n    cudaMalloc((void**)&d_perimeterRes, compCount * sizeof(float));\n    cudaMalloc((void**)&d_circ, compCount * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((compCount + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    circularity<<<gridSize, blockSize>>>(compCount, d_areaRes, d_perimeterRes, d_circ);\n\n    \n\n    \n    cudaFree(d_areaRes);\n    cudaFree(d_perimeterRes);\n    cudaFree(d_circ);\n\n    \n    free(h_areaRes);\n    free(h_perimeterRes);\n    free(h_circ);\n\n    return 0;\n}\n"
    },
    {
        "id": "92",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid devidecountCPU(long Xsize, long Ysize, long Zsize, double *pint, int *pcount) {\n    int n = Xsize * Ysize * 2 + (Ysize - 2) * Zsize * 2 + (Xsize - 2) * (Zsize - 2) * 2;\n    \n    for (int tid = 0; tid < n * n; tid++) {\n        if (pcount[tid] > 1) {\n            pint[tid] /= pcount[tid];\n        }\n    }\n}\n\nint main() {\n    \n    long Xsize = 3;\n    long Ysize = 3;\n    long Zsize = 3;\n\n    \n    double *pint = (double *)malloc(Xsize * Ysize * Zsize * 2 * sizeof(double));\n    int *pcount = (int *)malloc(Xsize * Ysize * Zsize * 2 * sizeof(int));\n\n    \n    for (int i = 0; i < Xsize * Ysize * Zsize * 2; i++) {\n        pint[i] = i + 1;\n        pcount[i] = i % 3;  \n    }\n\n    \n    devidecountCPU(Xsize, Ysize, Zsize, pint, pcount);\n\n    \n    printf(\"pint after devidecountCPU:\\n\");\n    for (int i = 0; i < Xsize * Ysize * Zsize * 2; i++) {\n        printf(\"%f \", pint[i]);\n    }\n\n    \n    free(pint);\n    free(pcount);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void devidecount(long Xsize, long Ysize, long Zsize, double* pint, int* pcount) {\n    int n = Xsize * Ysize * 2 + (Ysize - 2) * Zsize * 2 + (Xsize - 2) * (Zsize - 2) * 2;\n    long tid = threadIdx.x + blockDim.x * blockIdx.x;\n\n    while (tid < n * n) {\n        if (pcount[tid] > 1) {\n            pint[tid] /= pcount[tid];\n        }\n\n        tid += blockDim.x * gridDim.x;\n    }\n}\n\nint main() {\n    \n    long Xsize = 512;\n    long Ysize = 512;\n    long Zsize = 512;\n\n    \n    double* h_pint = (double*)malloc(Xsize * Ysize * Zsize * sizeof(double));\n    int* h_pcount = (int*)malloc(Xsize * Ysize * Zsize * sizeof(int));\n\n    \n\n    \n    double* d_pint;\n    int* d_pcount;\n    cudaMalloc((void**)&d_pint, Xsize * Ysize * Zsize * sizeof(double));\n    cudaMalloc((void**)&d_pcount, Xsize * Ysize * Zsize * sizeof(int));\n\n    \n\n    \n    dim3 gridSize((n + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    devidecount<<<gridSize, blockSize>>>(Xsize, Ysize, Zsize, d_pint, d_pcount);\n\n    \n\n    \n    cudaFree(d_pint);\n    cudaFree(d_pcount);\n\n    \n    free(h_pint);\n    free(h_pcount);\n\n    return 0;\n}\n"
    },
    {
        "id": "93",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid bubbleSort(int *p, const int size) {\n    for (int i = 0; i < size - 1; i++) {\n        for (int j = 0; j < size - i - 1; j++) {\n            if (p[j] > p[j + 1]) {\n                int temp = p[j];\n                p[j] = p[j + 1];\n                p[j + 1] = temp;\n            }\n        }\n    }\n}\n\nint main() {\n    \n    const int size = 5;\n\n    \n    int *p = (int *)malloc(size * sizeof(int));\n\n    \n    p[0] = 5;\n    p[1] = 3;\n    p[2] = 1;\n    p[3] = 4;\n    p[4] = 2;\n\n    \n    bubbleSort(p, size);\n\n    \n    printf(\"Sorted array: \");\n    for (int i = 0; i < size; i++) {\n        printf(\"%d \", p[i]);\n    }\n\n    \n    free(p);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void oddevenSort(int* d_in, int size, int oe_flag, int& d_ch_flag) {\n    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n    int p = 2 * idx + oe_flag;\n\n    if (p + 1 < size) {\n        if (d_in[p] > d_in[p + 1]) {\n            int temp = d_in[p];\n            d_in[p] = d_in[p + 1];\n            d_in[p + 1] = temp;\n            d_ch_flag = 1;\n        }\n    }\n}\n\nint main() {\n    \n    int size = 512;\n\n    \n    int* h_d_in = (int*)malloc(size * sizeof(int));\n\n    \n\n    \n    int* d_d_in;\n    cudaMalloc((void**)&d_d_in, size * sizeof(int));\n\n    \n\n    \n    int h_d_ch_flag = 0;\n\n    \n    int* d_d_ch_flag;\n    cudaMalloc((void**)&d_d_ch_flag, sizeof(int));\n\n    \n    cudaMemcpy(d_d_ch_flag, &h_d_ch_flag, sizeof(int), cudaMemcpyHostToDevice);\n\n    \n    dim3 gridSize((size + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    oddevenSort<<<gridSize, blockSize>>>(d_d_in, size, 0, *d_d_ch_flag);\n\n    \n    cudaMemcpy(&h_d_ch_flag, d_d_ch_flag, sizeof(int), cudaMemcpyDeviceToHost);\n\n    \n    cudaFree(d_d_in);\n    cudaFree(d_d_ch_flag);\n\n    \n    free(h_d_in);\n\n    return 0;\n}\n"
    },
    {
        "id": "94",
        "c_code": "#include <stdio.h>\n\nvoid matmul(int a[100][100], int b[100][100], int c[100][100]) {\n    for (int i = 0; i < 100; i++) {\n        for (int j = 0; j < 100; j++) {\n            c[i][j] = 0;\n            for (int k = 0; k < 100; k++) {\n                c[i][j] += a[i][k] * b[k][j];\n            }\n        }\n    }\n}\n\nint main() {\n    \n    int a[100][100];\n    int b[100][100];\n    int c[100][100];\n\n    \n    for (int i = 0; i < 100; i++) {\n        for (int j = 0; j < 100; j++) {\n            a[i][j] = i + j;\n            b[i][j] = i - j;\n        }\n    }\n\n    \n    matmul(a, b, c);\n\n    \n    printf(\"Resultant matrix c:\\n\");\n    for (int i = 0; i < 100; i++) {\n        for (int j = 0; j < 100; j++) {\n            printf(\"%d \", c[i][j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void matmul(float* a, float* b, float* c, int width) {\n    float result = 0;\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    for (int k = 0; k < width; k++) {\n        result += a[row * width + k] * b[k * width + col];\n    }\n\n    c[row * width + col] = result;\n}\n\nint main() {\n    \n    int width = 512;\n\n    \n    float* h_a = (float*)malloc(width * width * sizeof(float));\n    float* h_b = (float*)malloc(width * width * sizeof(float));\n    float* h_c = (float*)malloc(width * width * sizeof(float));\n\n    \n\n    \n    float* d_a, * d_b, * d_c;\n    cudaMalloc((void**)&d_a, width * width * sizeof(float));\n    cudaMalloc((void**)&d_b, width * width * sizeof(float));\n    cudaMalloc((void**)&d_c, width * width * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((width + 15) / 16, (width + 15) / 16, 1);\n    dim3 blockSize(16, 16, 1);\n\n    \n    matmul<<<gridSize, blockSize>>>(d_a, d_b, d_c, width);\n\n    \n\n    \n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    \n    free(h_a);\n    free(h_b);\n    free(h_c);\n\n    return 0;\n}\n"
    },
    {
        "id": "95",
        "c_code": "#include <stdio.h>\n\nvoid cudaKernel_estimateSnr_cpu(const float *corrSum, const int *corrValidCount, const float *maxval, float *snrValue, const int size) {\n    for (int idx = 0; idx < size; idx++) {\n        float mean = (corrSum[idx] - maxval[idx] * maxval[idx]) / (corrValidCount[idx] - 1);\n        snrValue[idx] = maxval[idx] * maxval[idx] / mean;\n    }\n}\n\nint main() {\n    \n    const int size = 5;\n    float corrSum[] = {10.0, 20.0, 30.0, 40.0, 50.0};\n    int corrValidCount[] = {2, 3, 4, 5, 6};\n    float maxval[] = {2.0, 4.0, 6.0, 8.0, 10.0};\n    float snrValue[size];\n\n    \n    cudaKernel_estimateSnr_cpu(corrSum, corrValidCount, maxval, snrValue, size);\n\n    \n    printf(\"SNR Values:\\n\");\n    for (int i = 0; i < size; i++) {\n        printf(\"%f \", snrValue[i]);\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void cudaKernel_estimateSnr(const float* corrSum, const int* corrValidCount, const float* maxval, float* snrValue, const int size) {\n    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n\n    if (idx >= size)\n        return;\n\n    float mean = (corrSum[idx] - maxval[idx] * maxval[idx]) / (corrValidCount[idx] - 1);\n    snrValue[idx] = maxval[idx] * maxval[idx] / mean;\n}\n\nint main() {\n    \n    int size = 512;\n\n    \n    float* h_corrSum = (float*)malloc(size * sizeof(float));\n    int* h_corrValidCount = (int*)malloc(size * sizeof(int));\n    float* h_maxval = (float*)malloc(size * sizeof(float));\n    float* h_snrValue = (float*)malloc(size * sizeof(float));\n\n    \n\n    \n    float* d_corrSum, * d_maxval, * d_snrValue;\n    int* d_corrValidCount;\n    cudaMalloc((void**)&d_corrSum, size * sizeof(float));\n    cudaMalloc((void**)&d_corrValidCount, size * sizeof(int));\n    cudaMalloc((void**)&d_maxval, size * sizeof(float));\n    cudaMalloc((void**)&d_snrValue, size * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((size + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    cudaKernel_estimateSnr<<<gridSize, blockSize>>>(d_corrSum, d_corrValidCount, d_maxval, d_snrValue, size);\n\n    \n\n    \n    cudaFree(d_corrSum);\n    cudaFree(d_corrValidCount);\n    cudaFree(d_maxval);\n    cudaFree(d_snrValue);\n\n    \n    free(h_corrSum);\n    free(h_corrValidCount);\n    free(h_maxval);\n    free(h_snrValue);\n\n    return 0;\n}\n"
    },
    {
        "id": "96",
        "c_code": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid cpu_sgemm(float *C, float *A, float *B, long size) {\n    for (long i = 0; i < size; i++) {\n        for (long k = 0; k < size; k++) {\n            for (long j = 0; j < size; j++) {\n                C[i * size + j] += A[i * size + k] * B[k * size + j];\n            }\n        }\n    }\n}\n\nint main() {\n    \n    const long size = 3;\n\n    \n    float *A = (float *)malloc(size * size * sizeof(float));\n    float *B = (float *)malloc(size * size * sizeof(float));\n    float *C = (float *)malloc(size * size * sizeof(float));\n\n    \n    for (long i = 0; i < size * size; i++) {\n        A[i] = i + 1;\n        B[i] = i - 1;\n        C[i] = 0.0;\n    }\n\n    \n    cpu_sgemm(C, A, B, size);\n\n    \n    printf(\"Resultant matrix C:\\n\");\n    for (long i = 0; i < size; i++) {\n        for (long j = 0; j < size; j++) {\n            printf(\"%f \", C[i * size + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    \n    free(A);\n    free(B);\n    free(C);\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void naive_sgemm_kernel(float* C, float* A, float* B, long size) {\n    const long i = blockIdx.x * blockDim.x + threadIdx.x;\n    const long j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    float val = 0.0;\n\n    if (i >= size || j >= size)\n        return;\n\n    for (long k = 0; k < size; k++) {\n        val += A[i * size + k] * B[k * size + j];\n    }\n\n    C[i * size + j] += val;\n}\n\nint main() {\n    \n    long size = 512;\n\n    \n    float* h_C = (float*)malloc(size * size * sizeof(float));\n    float* h_A = (float*)malloc(size * size * sizeof(float));\n    float* h_B = (float*)malloc(size * size * sizeof(float));\n\n    \n\n    \n    float* d_C, * d_A, * d_B;\n    cudaMalloc((void**)&d_C, size * size * sizeof(float));\n    cudaMalloc((void**)&d_A, size * size * sizeof(float));\n    cudaMalloc((void**)&d_B, size * size * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((size + 15) / 16, (size + 15) / 16, 1);\n    dim3 blockSize(16, 16, 1);\n\n    \n    naive_sgemm_kernel<<<gridSize, blockSize>>>(d_C, d_A, d_B, size);\n\n    \n\n    \n    cudaFree(d_C);\n    cudaFree(d_A);\n    cudaFree(d_B);\n\n    \n    free(h_C);\n    free(h_A);\n    free(h_B);\n\n    return 0;\n}\n"
    },
    {
        "id": "97",
        "c_code": "#include <stdio.h>\n\nvoid kernelXor(unsigned int key, char *input_str_cuda, unsigned char *possible_plaintext_str_cuda, int input_length) {\n    int id;\n    char *keyCharPtr;\n\n    for (id = 0; id < input_length; id++) {\n        int keyIndex = id % 4;\n        keyCharPtr = ((char *)&key);\n        char keyChar = keyCharPtr[keyIndex];\n        possible_plaintext_str_cuda[id] = keyChar ^ input_str_cuda[id];\n    }\n}\n\nint main() {\n    \n    const int input_length = 10;\n    const unsigned int key = 12345;\n\n    \n    char input_str[input_length];\n    unsigned char possible_plaintext_str[input_length];\n\n    \n    for (int i = 0; i < input_length; i++) {\n        input_str[i] = 'A' + i;\n    }\n\n    \n    kernelXor(key, input_str, possible_plaintext_str, input_length);\n\n    \n    printf(\"Input String: %s\\n\", input_str);\n    printf(\"Possible Plaintext String after XOR: \");\n    for (int i = 0; i < input_length; i++) {\n        printf(\"%c \", possible_plaintext_str[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void kernelXor(unsigned int key, char* input_str_cuda, unsigned char* possible_plaintext_str_cuda, int input_length) {\n    int id = threadIdx.x + blockDim.x * blockIdx.x;\n\n    if (id >= input_length)\n        return;\n\n    int keyIndex = id % 4;\n    char* keyCharPtr = ((char*)&key);\n    char keyChar = keyCharPtr[keyIndex];\n\n    possible_plaintext_str_cuda[id] = keyChar ^ input_str_cuda[id];\n}\n\nint main() {\n    \n    int input_length = 512;\n    unsigned int key = 0x12345678; \n\n    \n    char* h_input_str = (char*)malloc(input_length * sizeof(char));\n    unsigned char* h_possible_plaintext_str = (unsigned char*)malloc(input_length * sizeof(unsigned char));\n\n    \n\n    \n    char* d_input_str;\n    unsigned char* d_possible_plaintext_str;\n    cudaMalloc((void**)&d_input_str, input_length * sizeof(char));\n    cudaMalloc((void**)&d_possible_plaintext_str, input_length * sizeof(unsigned char));\n\n    \n\n    \n    dim3 gridSize((input_length + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    kernelXor<<<gridSize, blockSize>>>(key, d_input_str, d_possible_plaintext_str, input_length);\n\n    \n\n    \n    cudaFree(d_input_str);\n    cudaFree(d_possible_plaintext_str);\n\n    \n    free(h_input_str);\n    free(h_possible_plaintext_str);\n\n    return 0;\n}\n"
    },
    {
        "id": "98",
        "c_code": "#include <stdio.h>\n\nvoid envejecer_kernel_cpu(int *estado, int *edad, int *pupacion, int *N_mobil, int dia) {\n    int N = N_mobil[0];\n    \n    for (int id = 0; id < N; id++) {\n        if (dia < 80 || dia > 320) {\n            if (edad[id] > pupacion[id]) {\n                edad[id]++;\n            }\n        } else {\n            edad[id]++;\n        }\n    }\n}\n\nint main() {\n    \n    const int N = 5;\n    int estado[N] = {1, 1, 1, 0, 1};\n    int edad[N] = {75, 90, 100, 50, 60};\n    int pupacion[N] = {70, 80, 95, 45, 55};\n    int N_mobil[1] = {N};\n    int dia = 100;\n\n    \n    envejecer_kernel_cpu(estado, edad, pupacion, N_mobil, dia);\n\n    \n    printf(\"Edad after envejecer_kernel_cpu:\\n\");\n    for (int i = 0; i < N; i++) {\n        printf(\"%d \", edad[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n\n\n__global__ void envejecer_kernel(int* estado, int* edad, int* pupacion, int* N_mobil, int dia) {\n    int N = N_mobil[0];\n    int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (id < N) {\n        if (dia < 80 || dia > 320) {\n            if (edad[id] > pupacion[id])\n                edad[id]++;\n        } else {\n            edad[id]++;\n        }\n    }\n}\n\nint main() {\n    \n    int N = 512; \n    int dia = 150; \n\n    \n    int* h_estado = (int*)malloc(N * sizeof(int));\n    int* h_edad = (int*)malloc(N * sizeof(int));\n    int* h_pupacion = (int*)malloc(N * sizeof(int));\n    int* h_N_mobil = (int*)malloc(sizeof(int));\n\n    \n\n    \n    int* d_estado, * d_edad, * d_pupacion, * d_N_mobil;\n    cudaMalloc((void**)&d_estado, N * sizeof(int));\n    cudaMalloc((void**)&d_edad, N * sizeof(int));\n    cudaMalloc((void**)&d_pupacion, N * sizeof(int));\n    cudaMalloc((void**)&d_N_mobil, sizeof(int));\n\n    \n\n    \n    dim3 gridSize((N + 255) / 256, 1, 1);\n    dim3 blockSize(256, 1, 1);\n\n    \n    envejecer_kernel<<<gridSize, blockSize>>>(d_estado, d_edad, d_pupacion, d_N_mobil, dia);\n\n    \n\n    \n    cudaFree(d_estado);\n    cudaFree(d_edad);\n    cudaFree(d_pupacion);\n    cudaFree(d_N_mobil);\n\n    \n    free(h_estado);\n    free(h_edad);\n    free(h_pupacion);\n    free(h_N_mobil);\n\n    return 0;\n}\n"
    },
    {
        "id": "99",
        "c_code": "#include <stdio.h>\n#include <math.h>\n\nvoid globalCalculateKernel(float *c, float *a, float *b, int size) {\n    for (int i = 0; i < size; i++) {\n        for (int j = 0; j < size; j++) {\n            c[i * size + j] = sin(a[i * size + j]) * sin(a[i * size + j]) +\n                               cos(b[i * size + j]) * cos(b[i * size + j]) * cos(b[i * size + j]);\n        }\n    }\n}\n\nint main() {\n    \n    const int size = 3;\n    float a[size * size];\n    float b[size * size];\n    float c[size * size];\n\n    \n    for (int i = 0; i < size * size; i++) {\n        a[i] = i + 1;\n        b[i] = i - 1;\n    }\n\n    \n    globalCalculateKernel(c, a, b, size);\n\n    \n    printf(\"Resultant matrix c:\\n\");\n    for (int i = 0; i < size; i++) {\n        for (int j = 0; j < size; j++) {\n            printf(\"%f \", c[i * size + j]);\n        }\n        printf(\"\\n\");\n    }\n\n    return 0;\n}\n",
        "cuda_code": "#include <device_launch_parameters.h>\n#include <stdio.h>\n#include <math.h>\n\n\n__global__ void globalCalculateKernel(float* c, float* a, float* b) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    c[i * j] = sin(a[i * j]) * sin(a[i * j]) + cos(b[i * j]) * cos(b[i * j]) * cos(b[i * j]);\n}\n\nint main() {\n    \n    int width = 512; \n\n    \n    float* h_c = (float*)malloc(width * width * sizeof(float));\n    float* h_a = (float*)malloc(width * width * sizeof(float));\n    float* h_b = (float*)malloc(width * width * sizeof(float));\n\n    \n\n    \n    float* d_c, * d_a, * d_b;\n    cudaMalloc((void**)&d_c, width * width * sizeof(float));\n    cudaMalloc((void**)&d_a, width * width * sizeof(float));\n    cudaMalloc((void**)&d_b, width * width * sizeof(float));\n\n    \n\n    \n    dim3 gridSize((width + 15) / 16, (width + 15) / 16, 1);\n    dim3 blockSize(16, 16, 1);\n\n    \n    globalCalculateKernel<<<gridSize, blockSize>>>(d_c, d_a, d_b);\n\n    \n\n    \n    cudaFree(d_c);\n    cudaFree(d_a);\n    cudaFree(d_b);\n\n    \n    free(h_c);\n    free(h_a);\n    free(h_b);\n\n    return 0;\n}\n"
    }
]