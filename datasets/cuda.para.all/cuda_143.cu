#include <device_launch_parameters.h>
#include <stdio.h>

// CUDA kernel
__global__ void sgemm_kernelGPU(const float* host_inputArray1, const float* host_inputArray2, float* host_inputArray3, int M, int N, int K, float alpha, float beta) {
    int column = blockIdx.x * blockDim.x + threadIdx.x;
    int row = blockIdx.y * blockDim.y + threadIdx.y;

    if (row < M && column < N) {
        float element_c = 0.f;

        for (int eachElement = 0; eachElement < K; eachElement++) {
            element_c += host_inputArray1[row * K + eachElement] * host_inputArray2[eachElement * N + column];
        }

        host_inputArray3[row * N + column] = alpha * element_c + beta * host_inputArray3[row * N + column];
    }
}

int main() {
    // Your main program logic here

    // Example: Allocate and initialize host and device memory
    int M = 512;  // Replace with your actual M dimension
    int N = 512;  // Replace with your actual N dimension
    int K = 256;  // Replace with your actual K dimension

    float* h_inputArray1 = /* Your initialization */;
    float* h_inputArray2 = /* Your initialization */;
    float* h_inputArray3 = /* Your initialization */;

    float* d_inputArray1, *d_inputArray2, *d_inputArray3;
    cudaMalloc((void**)&d_inputArray1, M * K * sizeof(float));
    cudaMalloc((void**)&d_inputArray2, K * N * sizeof(float));
    cudaMalloc((void**)&d_inputArray3, M * N * sizeof(float));

    // Copy host memory to device
    cudaMemcpy(d_inputArray1, h_inputArray1, M * K * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_inputArray2, h_inputArray2, K * N * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_inputArray3, h_inputArray3, M * N * sizeof(float), cudaMemcpyHostToDevice);

    // Configure and launch the CUDA kernel
    dim3 blockSize(16, 16);  // Adjust block dimensions based on your requirements
    dim3 gridSize((N + blockSize.x - 1) / blockSize.x, (M + blockSize.y - 1) / blockSize.y);

    sgemm_kernelGPU<<<gridSize, blockSize>>>(d_inputArray1, d_inputArray2, d_inputArray3, M, N, K, 1.0f, 0.0f);

    // Copy device memory back to host
    cudaMemcpy(h_inputArray3, d_inputArray3, M * N * sizeof(float), cudaMemcpyDeviceToHost);

    // Your post-kernel logic here

    // Free allocated memory
    cudaFree(d_inputArray1);
    cudaFree(d_inputArray2);
    cudaFree(d_inputArray3);

    return 0;
}
